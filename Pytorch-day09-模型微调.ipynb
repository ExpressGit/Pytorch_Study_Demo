{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72f40c34",
   "metadata": {},
   "source": [
    "# 模型微调（fine-tune)-迁移学习\n",
    "- torchvision微调\n",
    "- timm微调\n",
    "- 半精度训练\n",
    "\n",
    "起源：\n",
    "\n",
    "- 1、随着深度学习的发展，模型的参数越来越大，许多开源模型都是在较大数据集上进行训练的，比如Imagenet-1k，Imagenet-11k等\n",
    "- 2、如果数据集可能只有几千张，训练几千万参数的大模型，过拟合无法避免\n",
    "- 3、如果我们想从零开始训练一个大模型，那么我们的解决办法是收集更多的数据。然而，收集和标注数据会花费大量的时间和资⾦，成本无法承受\n",
    "\n",
    "解决方案：\n",
    "\n",
    "- 应用迁移学习(transfer learning)，将从源数据集学到的知识迁移到目标数据集上\n",
    "- 比如：ImageNet数据集的图像大多跟椅子无关，但在该数据集上训练的模型可以抽取较通用的图像特征，从而能够帮助识别边缘、纹理、形状和物体组成\n",
    "- 模型微调（finetune）:就是先找到一个同类的别人训练好的模型，基于已经训练好的模型换成自己的数据，通过训练调整一下参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df103bee",
   "metadata": {},
   "source": [
    "#### 不同数据集下使用微调：\n",
    "\n",
    "- 数据集1 - 数据量少，但数据相似度非常高 - 在这种情况下，我们所做的只是修改最后几层或最终的softmax图层的输出类别。\n",
    "\n",
    "- 数据集2 - 数据量少，数据相似度低 - 在这种情况下，我们可以冻结预训练模型的初始层（比如k层），并再次训练剩余的（n-k）层。由于新数据集的相似度较低，因此根据新数据集对较高层进行重新训练具有重要意义。\n",
    "\n",
    "- 数据集3 - 数据量大，数据相似度低 - 在这种情况下，由于我们有一个大的数据集，我们的神经网络训练将会很有效。但是，由于我们的数据与用于训练我们的预训练模型的数据相比有很大不同。使用预训练模型进行的预测不会有效。因此，最好根据你的数据从头开始训练神经网络（Training from scatch）\n",
    "\n",
    "- 数据集4 - 数据量大，数据相似度高 - 这是理想情况。在这种情况下，预训练模型应该是最有效的。使用模型的最好方法是保留模型的体系结构和模型的初始权重。然后，我们可以使用在预先训练的模型中的权重来重新训练该模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002f55e1",
   "metadata": {},
   "source": [
    "#### 微调的是什么？\n",
    "- 换数据源\n",
    "- 针对K层进行重新训练\n",
    "- K层的权重&shape调整"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909ef8d0",
   "metadata": {},
   "source": [
    "## 1、模型微调(fine-tune)一般流程：\n",
    "- 1、在源数据集(如ImageNet数据集)上预训练一个神经网络模型，即源模型\n",
    "- 2、创建一个新的神经网络模型，即目标模型，它复制了源模型上除了输出层外的所有模型设计及其参数\n",
    "- 3、为目标模型添加一个输出⼤小为⽬标数据集类别个数的输出层，并随机初始化该层的模型参数\n",
    "- 4、在目标数据集上训练目标模型。我们将从头训练输出层，而其余层的参数都是基于源模型的参数微调得到的"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "85f661e1",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fc241b",
   "metadata": {},
   "source": [
    "## 2、torchvision微调\n",
    "### 2.1 实例化Model\n",
    "\n",
    "```python\n",
    "import torchvision.models as models\n",
    "resnet34 = models.resnet34(pretrained=True)\n",
    "```\n",
    "\n",
    "pretrained参数说明：\n",
    "- 1、通过True或者False来决定是否使用预训练好的权重，在默认状态下pretrained = False，意味着我们不使用预训练得到的权重\n",
    "- 2、当pretrained = True，意味着我们将使用在一些数据集上预训练得到的权重\n",
    "\n",
    "注意：如果中途强行停止下载的话，一定要去对应路径下将权重文件删除干净，否则会报错。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66dd69c",
   "metadata": {},
   "source": [
    "### 2.2 训练特定层\n",
    "如果我们正在提取特征并且只想为新初始化的层计算梯度，其他参数不进行改变。那我们就需要通过设置requires_grad = False来冻结部分层\n",
    "\n",
    "```python\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "```\n",
    "\n",
    "### 2.3 实例\n",
    "- 使用resnet34为例的将1000类改为10类，但是仅改变最后一层的模型参数\n",
    "- 我们先冻结模型参数的梯度，再对模型输出部分的全连接层进行修改\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d87a7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b933692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#超参数定义\n",
    "# 批次的大小\n",
    "batch_size = 16 #可选32、64、128\n",
    "# 优化器的学习率\n",
    "lr = 1e-4\n",
    "#运行epoch\n",
    "max_epochs = 2\n",
    "# 方案二：使用“device”，后续对要使用GPU的变量用.to(device)即可\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f9ede6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据读取\n",
    "#cifar10数据集为例给出构建Dataset类的方式\n",
    "from torchvision import datasets\n",
    "\n",
    "#“data_transform”可以对图像进行一定的变换，如翻转、裁剪、归一化等操作，可自己定义\n",
    "data_transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "                   ])\n",
    "\n",
    "\n",
    "train_cifar_dataset = datasets.CIFAR10('cifar10',train=True, download=False,transform=data_transform)\n",
    "test_cifar_dataset = datasets.CIFAR10('cifar10',train=False, download=False,transform=data_transform)\n",
    "\n",
    "#构建好Dataset后，就可以使用DataLoader来按批次读入数据了\n",
    "train_loader = torch.utils.data.DataLoader(train_cifar_dataset, \n",
    "                                           batch_size=batch_size, num_workers=4, \n",
    "                                           shuffle=True, drop_last=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_cifar_dataset, \n",
    "                                         batch_size=batch_size, num_workers=4, \n",
    "                                         shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eac1d876",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\xulele\\Anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\Users\\xulele\\Anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to C:\\Users\\xulele/.cache\\torch\\hub\\checkpoints\\resnet34-b627a593.pth\n",
      "100%|██████████| 83.3M/83.3M [00:10<00:00, 8.57MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 下载预训练模型 restnet34\n",
    "resnet34 = models.resnet34(pretrained=True)\n",
    "print(resnet34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc37d875",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [1, 1000]                 --\n",
       "├─Conv2d: 1-1                            [1, 64, 112, 112]         9,408\n",
       "├─BatchNorm2d: 1-2                       [1, 64, 112, 112]         128\n",
       "├─ReLU: 1-3                              [1, 64, 112, 112]         --\n",
       "├─MaxPool2d: 1-4                         [1, 64, 56, 56]           --\n",
       "├─Sequential: 1-5                        [1, 64, 56, 56]           --\n",
       "│    └─BasicBlock: 2-1                   [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-1                  [1, 64, 56, 56]           36,864\n",
       "│    │    └─BatchNorm2d: 3-2             [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-3                    [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-4                  [1, 64, 56, 56]           36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-6                    [1, 64, 56, 56]           --\n",
       "│    └─BasicBlock: 2-2                   [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-7                  [1, 64, 56, 56]           36,864\n",
       "│    │    └─BatchNorm2d: 3-8             [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-9                    [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-10                 [1, 64, 56, 56]           36,864\n",
       "│    │    └─BatchNorm2d: 3-11            [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-12                   [1, 64, 56, 56]           --\n",
       "│    └─BasicBlock: 2-3                   [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-13                 [1, 64, 56, 56]           36,864\n",
       "│    │    └─BatchNorm2d: 3-14            [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-15                   [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-16                 [1, 64, 56, 56]           36,864\n",
       "│    │    └─BatchNorm2d: 3-17            [1, 64, 56, 56]           128\n",
       "│    │    └─ReLU: 3-18                   [1, 64, 56, 56]           --\n",
       "├─Sequential: 1-6                        [1, 128, 28, 28]          --\n",
       "│    └─BasicBlock: 2-4                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-19                 [1, 128, 28, 28]          73,728\n",
       "│    │    └─BatchNorm2d: 3-20            [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-21                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-22                 [1, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-23            [1, 128, 28, 28]          256\n",
       "│    │    └─Sequential: 3-24             [1, 128, 28, 28]          8,448\n",
       "│    │    └─ReLU: 3-25                   [1, 128, 28, 28]          --\n",
       "│    └─BasicBlock: 2-5                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-26                 [1, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-27            [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-28                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-29                 [1, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-30            [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-31                   [1, 128, 28, 28]          --\n",
       "│    └─BasicBlock: 2-6                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-32                 [1, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-33            [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-34                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-35                 [1, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-36            [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-37                   [1, 128, 28, 28]          --\n",
       "│    └─BasicBlock: 2-7                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-38                 [1, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-39            [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-40                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-41                 [1, 128, 28, 28]          147,456\n",
       "│    │    └─BatchNorm2d: 3-42            [1, 128, 28, 28]          256\n",
       "│    │    └─ReLU: 3-43                   [1, 128, 28, 28]          --\n",
       "├─Sequential: 1-7                        [1, 256, 14, 14]          --\n",
       "│    └─BasicBlock: 2-8                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-44                 [1, 256, 14, 14]          294,912\n",
       "│    │    └─BatchNorm2d: 3-45            [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-46                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-47                 [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-48            [1, 256, 14, 14]          512\n",
       "│    │    └─Sequential: 3-49             [1, 256, 14, 14]          33,280\n",
       "│    │    └─ReLU: 3-50                   [1, 256, 14, 14]          --\n",
       "│    └─BasicBlock: 2-9                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-51                 [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-52            [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-53                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-54                 [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-55            [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-56                   [1, 256, 14, 14]          --\n",
       "│    └─BasicBlock: 2-10                  [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-57                 [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-58            [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-59                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-60                 [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-61            [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-62                   [1, 256, 14, 14]          --\n",
       "│    └─BasicBlock: 2-11                  [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-63                 [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-64            [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-65                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-66                 [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-67            [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-68                   [1, 256, 14, 14]          --\n",
       "│    └─BasicBlock: 2-12                  [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-69                 [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-70            [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-71                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-72                 [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-73            [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-74                   [1, 256, 14, 14]          --\n",
       "│    └─BasicBlock: 2-13                  [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-75                 [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-76            [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-77                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-78                 [1, 256, 14, 14]          589,824\n",
       "│    │    └─BatchNorm2d: 3-79            [1, 256, 14, 14]          512\n",
       "│    │    └─ReLU: 3-80                   [1, 256, 14, 14]          --\n",
       "├─Sequential: 1-8                        [1, 512, 7, 7]            --\n",
       "│    └─BasicBlock: 2-14                  [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-81                 [1, 512, 7, 7]            1,179,648\n",
       "│    │    └─BatchNorm2d: 3-82            [1, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-83                   [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-84                 [1, 512, 7, 7]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-85            [1, 512, 7, 7]            1,024\n",
       "│    │    └─Sequential: 3-86             [1, 512, 7, 7]            132,096\n",
       "│    │    └─ReLU: 3-87                   [1, 512, 7, 7]            --\n",
       "│    └─BasicBlock: 2-15                  [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-88                 [1, 512, 7, 7]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-89            [1, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-90                   [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-91                 [1, 512, 7, 7]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-92            [1, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-93                   [1, 512, 7, 7]            --\n",
       "│    └─BasicBlock: 2-16                  [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-94                 [1, 512, 7, 7]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-95            [1, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-96                   [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-97                 [1, 512, 7, 7]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-98            [1, 512, 7, 7]            1,024\n",
       "│    │    └─ReLU: 3-99                   [1, 512, 7, 7]            --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [1, 512, 1, 1]            --\n",
       "├─Linear: 1-10                           [1, 1000]                 513,000\n",
       "==========================================================================================\n",
       "Total params: 21,797,672\n",
       "Trainable params: 21,797,672\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 3.66\n",
       "==========================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 59.82\n",
       "Params size (MB): 87.19\n",
       "Estimated Total Size (MB): 147.61\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看模型结构\n",
    "summary(resnet34, (1, 3, 224, 224)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14b819d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#检测 模型准确率\n",
    "def cal_predict_correct(model):\n",
    "    test_total_correct = 0\n",
    "    for iter,(images,labels) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "    \n",
    "        outputs = model(images)\n",
    "        test_total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "#     print(\"test_total_correct: \"+ str(test_total_correct))\n",
    "    return test_total_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2bbf316b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_total_correct: 0.1\n"
     ]
    }
   ],
   "source": [
    "total_correct = cal_predict_correct(resnet34)\n",
    "print(\"test_total_correct: \"+ str(test_total_correct / 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bb62f57",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#微调模型 resnet34\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "\n",
    "# 冻结参数的梯度\n",
    "feature_extract = True\n",
    "new_model = resnet34\n",
    "set_parameter_requires_grad(new_model, feature_extract)\n",
    "\n",
    "# 修改模型\n",
    "#训练过程中，model仍会进行梯度回传，但是参数更新则只会发生在fc层\n",
    "num_ftrs = new_model.fc.in_features\n",
    "new_model.fc = nn.Linear(in_features=num_ftrs, out_features=10, bias=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c14a4f4f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [1, 10]                   --\n",
       "├─Conv2d: 1-1                            [1, 64, 112, 112]         (9,408)\n",
       "├─BatchNorm2d: 1-2                       [1, 64, 112, 112]         (128)\n",
       "├─ReLU: 1-3                              [1, 64, 112, 112]         --\n",
       "├─MaxPool2d: 1-4                         [1, 64, 56, 56]           --\n",
       "├─Sequential: 1-5                        [1, 64, 56, 56]           --\n",
       "│    └─BasicBlock: 2-1                   [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-1                  [1, 64, 56, 56]           (36,864)\n",
       "│    │    └─BatchNorm2d: 3-2             [1, 64, 56, 56]           (128)\n",
       "│    │    └─ReLU: 3-3                    [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-4                  [1, 64, 56, 56]           (36,864)\n",
       "│    │    └─BatchNorm2d: 3-5             [1, 64, 56, 56]           (128)\n",
       "│    │    └─ReLU: 3-6                    [1, 64, 56, 56]           --\n",
       "│    └─BasicBlock: 2-2                   [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-7                  [1, 64, 56, 56]           (36,864)\n",
       "│    │    └─BatchNorm2d: 3-8             [1, 64, 56, 56]           (128)\n",
       "│    │    └─ReLU: 3-9                    [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-10                 [1, 64, 56, 56]           (36,864)\n",
       "│    │    └─BatchNorm2d: 3-11            [1, 64, 56, 56]           (128)\n",
       "│    │    └─ReLU: 3-12                   [1, 64, 56, 56]           --\n",
       "│    └─BasicBlock: 2-3                   [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-13                 [1, 64, 56, 56]           (36,864)\n",
       "│    │    └─BatchNorm2d: 3-14            [1, 64, 56, 56]           (128)\n",
       "│    │    └─ReLU: 3-15                   [1, 64, 56, 56]           --\n",
       "│    │    └─Conv2d: 3-16                 [1, 64, 56, 56]           (36,864)\n",
       "│    │    └─BatchNorm2d: 3-17            [1, 64, 56, 56]           (128)\n",
       "│    │    └─ReLU: 3-18                   [1, 64, 56, 56]           --\n",
       "├─Sequential: 1-6                        [1, 128, 28, 28]          --\n",
       "│    └─BasicBlock: 2-4                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-19                 [1, 128, 28, 28]          (73,728)\n",
       "│    │    └─BatchNorm2d: 3-20            [1, 128, 28, 28]          (256)\n",
       "│    │    └─ReLU: 3-21                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-22                 [1, 128, 28, 28]          (147,456)\n",
       "│    │    └─BatchNorm2d: 3-23            [1, 128, 28, 28]          (256)\n",
       "│    │    └─Sequential: 3-24             [1, 128, 28, 28]          (8,448)\n",
       "│    │    └─ReLU: 3-25                   [1, 128, 28, 28]          --\n",
       "│    └─BasicBlock: 2-5                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-26                 [1, 128, 28, 28]          (147,456)\n",
       "│    │    └─BatchNorm2d: 3-27            [1, 128, 28, 28]          (256)\n",
       "│    │    └─ReLU: 3-28                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-29                 [1, 128, 28, 28]          (147,456)\n",
       "│    │    └─BatchNorm2d: 3-30            [1, 128, 28, 28]          (256)\n",
       "│    │    └─ReLU: 3-31                   [1, 128, 28, 28]          --\n",
       "│    └─BasicBlock: 2-6                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-32                 [1, 128, 28, 28]          (147,456)\n",
       "│    │    └─BatchNorm2d: 3-33            [1, 128, 28, 28]          (256)\n",
       "│    │    └─ReLU: 3-34                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-35                 [1, 128, 28, 28]          (147,456)\n",
       "│    │    └─BatchNorm2d: 3-36            [1, 128, 28, 28]          (256)\n",
       "│    │    └─ReLU: 3-37                   [1, 128, 28, 28]          --\n",
       "│    └─BasicBlock: 2-7                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-38                 [1, 128, 28, 28]          (147,456)\n",
       "│    │    └─BatchNorm2d: 3-39            [1, 128, 28, 28]          (256)\n",
       "│    │    └─ReLU: 3-40                   [1, 128, 28, 28]          --\n",
       "│    │    └─Conv2d: 3-41                 [1, 128, 28, 28]          (147,456)\n",
       "│    │    └─BatchNorm2d: 3-42            [1, 128, 28, 28]          (256)\n",
       "│    │    └─ReLU: 3-43                   [1, 128, 28, 28]          --\n",
       "├─Sequential: 1-7                        [1, 256, 14, 14]          --\n",
       "│    └─BasicBlock: 2-8                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-44                 [1, 256, 14, 14]          (294,912)\n",
       "│    │    └─BatchNorm2d: 3-45            [1, 256, 14, 14]          (512)\n",
       "│    │    └─ReLU: 3-46                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-47                 [1, 256, 14, 14]          (589,824)\n",
       "│    │    └─BatchNorm2d: 3-48            [1, 256, 14, 14]          (512)\n",
       "│    │    └─Sequential: 3-49             [1, 256, 14, 14]          (33,280)\n",
       "│    │    └─ReLU: 3-50                   [1, 256, 14, 14]          --\n",
       "│    └─BasicBlock: 2-9                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-51                 [1, 256, 14, 14]          (589,824)\n",
       "│    │    └─BatchNorm2d: 3-52            [1, 256, 14, 14]          (512)\n",
       "│    │    └─ReLU: 3-53                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-54                 [1, 256, 14, 14]          (589,824)\n",
       "│    │    └─BatchNorm2d: 3-55            [1, 256, 14, 14]          (512)\n",
       "│    │    └─ReLU: 3-56                   [1, 256, 14, 14]          --\n",
       "│    └─BasicBlock: 2-10                  [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-57                 [1, 256, 14, 14]          (589,824)\n",
       "│    │    └─BatchNorm2d: 3-58            [1, 256, 14, 14]          (512)\n",
       "│    │    └─ReLU: 3-59                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-60                 [1, 256, 14, 14]          (589,824)\n",
       "│    │    └─BatchNorm2d: 3-61            [1, 256, 14, 14]          (512)\n",
       "│    │    └─ReLU: 3-62                   [1, 256, 14, 14]          --\n",
       "│    └─BasicBlock: 2-11                  [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-63                 [1, 256, 14, 14]          (589,824)\n",
       "│    │    └─BatchNorm2d: 3-64            [1, 256, 14, 14]          (512)\n",
       "│    │    └─ReLU: 3-65                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-66                 [1, 256, 14, 14]          (589,824)\n",
       "│    │    └─BatchNorm2d: 3-67            [1, 256, 14, 14]          (512)\n",
       "│    │    └─ReLU: 3-68                   [1, 256, 14, 14]          --\n",
       "│    └─BasicBlock: 2-12                  [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-69                 [1, 256, 14, 14]          (589,824)\n",
       "│    │    └─BatchNorm2d: 3-70            [1, 256, 14, 14]          (512)\n",
       "│    │    └─ReLU: 3-71                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-72                 [1, 256, 14, 14]          (589,824)\n",
       "│    │    └─BatchNorm2d: 3-73            [1, 256, 14, 14]          (512)\n",
       "│    │    └─ReLU: 3-74                   [1, 256, 14, 14]          --\n",
       "│    └─BasicBlock: 2-13                  [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-75                 [1, 256, 14, 14]          (589,824)\n",
       "│    │    └─BatchNorm2d: 3-76            [1, 256, 14, 14]          (512)\n",
       "│    │    └─ReLU: 3-77                   [1, 256, 14, 14]          --\n",
       "│    │    └─Conv2d: 3-78                 [1, 256, 14, 14]          (589,824)\n",
       "│    │    └─BatchNorm2d: 3-79            [1, 256, 14, 14]          (512)\n",
       "│    │    └─ReLU: 3-80                   [1, 256, 14, 14]          --\n",
       "├─Sequential: 1-8                        [1, 512, 7, 7]            --\n",
       "│    └─BasicBlock: 2-14                  [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-81                 [1, 512, 7, 7]            (1,179,648)\n",
       "│    │    └─BatchNorm2d: 3-82            [1, 512, 7, 7]            (1,024)\n",
       "│    │    └─ReLU: 3-83                   [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-84                 [1, 512, 7, 7]            (2,359,296)\n",
       "│    │    └─BatchNorm2d: 3-85            [1, 512, 7, 7]            (1,024)\n",
       "│    │    └─Sequential: 3-86             [1, 512, 7, 7]            (132,096)\n",
       "│    │    └─ReLU: 3-87                   [1, 512, 7, 7]            --\n",
       "│    └─BasicBlock: 2-15                  [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-88                 [1, 512, 7, 7]            (2,359,296)\n",
       "│    │    └─BatchNorm2d: 3-89            [1, 512, 7, 7]            (1,024)\n",
       "│    │    └─ReLU: 3-90                   [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-91                 [1, 512, 7, 7]            (2,359,296)\n",
       "│    │    └─BatchNorm2d: 3-92            [1, 512, 7, 7]            (1,024)\n",
       "│    │    └─ReLU: 3-93                   [1, 512, 7, 7]            --\n",
       "│    └─BasicBlock: 2-16                  [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-94                 [1, 512, 7, 7]            (2,359,296)\n",
       "│    │    └─BatchNorm2d: 3-95            [1, 512, 7, 7]            (1,024)\n",
       "│    │    └─ReLU: 3-96                   [1, 512, 7, 7]            --\n",
       "│    │    └─Conv2d: 3-97                 [1, 512, 7, 7]            (2,359,296)\n",
       "│    │    └─BatchNorm2d: 3-98            [1, 512, 7, 7]            (1,024)\n",
       "│    │    └─ReLU: 3-99                   [1, 512, 7, 7]            --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [1, 512, 1, 1]            --\n",
       "├─Linear: 1-10                           [1, 10]                   5,130\n",
       "==========================================================================================\n",
       "Total params: 21,289,802\n",
       "Trainable params: 5,130\n",
       "Non-trainable params: 21,284,672\n",
       "Total mult-adds (G): 3.66\n",
       "==========================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 59.81\n",
       "Params size (MB): 85.16\n",
       "Estimated Total Size (MB): 145.57\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(new_model, (1, 3, 224, 224)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4530d187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [1/3125], train_loss:0.150127\n",
      "Epoch [1/2], Iter [2/3125], train_loss:0.174470\n",
      "Epoch [1/2], Iter [3/3125], train_loss:0.165727\n",
      "Epoch [1/2], Iter [4/3125], train_loss:0.174811\n",
      "Epoch [1/2], Iter [5/3125], train_loss:0.158658\n",
      "Epoch [1/2], Iter [6/3125], train_loss:0.153260\n",
      "Epoch [1/2], Iter [7/3125], train_loss:0.164495\n",
      "Epoch [1/2], Iter [8/3125], train_loss:0.164485\n",
      "Epoch [1/2], Iter [9/3125], train_loss:0.157202\n",
      "Epoch [1/2], Iter [10/3125], train_loss:0.149555\n",
      "Epoch [1/2], Iter [11/3125], train_loss:0.172609\n",
      "Epoch [1/2], Iter [12/3125], train_loss:0.180861\n",
      "Epoch [1/2], Iter [13/3125], train_loss:0.156719\n",
      "Epoch [1/2], Iter [14/3125], train_loss:0.172375\n",
      "Epoch [1/2], Iter [15/3125], train_loss:0.169886\n",
      "Epoch [1/2], Iter [16/3125], train_loss:0.148726\n",
      "Epoch [1/2], Iter [17/3125], train_loss:0.160391\n",
      "Epoch [1/2], Iter [18/3125], train_loss:0.160285\n",
      "Epoch [1/2], Iter [19/3125], train_loss:0.167672\n",
      "Epoch [1/2], Iter [20/3125], train_loss:0.151213\n",
      "Epoch [1/2], Iter [21/3125], train_loss:0.154690\n",
      "Epoch [1/2], Iter [22/3125], train_loss:0.155165\n",
      "Epoch [1/2], Iter [23/3125], train_loss:0.162777\n",
      "Epoch [1/2], Iter [24/3125], train_loss:0.169136\n",
      "Epoch [1/2], Iter [25/3125], train_loss:0.151533\n",
      "Epoch [1/2], Iter [26/3125], train_loss:0.168992\n",
      "Epoch [1/2], Iter [27/3125], train_loss:0.176258\n",
      "Epoch [1/2], Iter [28/3125], train_loss:0.162240\n",
      "Epoch [1/2], Iter [29/3125], train_loss:0.161768\n",
      "Epoch [1/2], Iter [30/3125], train_loss:0.165359\n",
      "Epoch [1/2], Iter [31/3125], train_loss:0.166174\n",
      "Epoch [1/2], Iter [32/3125], train_loss:0.173654\n",
      "Epoch [1/2], Iter [33/3125], train_loss:0.162488\n",
      "Epoch [1/2], Iter [34/3125], train_loss:0.164815\n",
      "Epoch [1/2], Iter [35/3125], train_loss:0.154411\n",
      "Epoch [1/2], Iter [36/3125], train_loss:0.159386\n",
      "Epoch [1/2], Iter [37/3125], train_loss:0.176261\n",
      "Epoch [1/2], Iter [38/3125], train_loss:0.163848\n",
      "Epoch [1/2], Iter [39/3125], train_loss:0.174402\n",
      "Epoch [1/2], Iter [40/3125], train_loss:0.178917\n",
      "Epoch [1/2], Iter [41/3125], train_loss:0.149938\n",
      "Epoch [1/2], Iter [42/3125], train_loss:0.156186\n",
      "Epoch [1/2], Iter [43/3125], train_loss:0.162950\n",
      "Epoch [1/2], Iter [44/3125], train_loss:0.169058\n",
      "Epoch [1/2], Iter [45/3125], train_loss:0.168587\n",
      "Epoch [1/2], Iter [46/3125], train_loss:0.173754\n",
      "Epoch [1/2], Iter [47/3125], train_loss:0.158612\n",
      "Epoch [1/2], Iter [48/3125], train_loss:0.163891\n",
      "Epoch [1/2], Iter [49/3125], train_loss:0.149220\n",
      "Epoch [1/2], Iter [50/3125], train_loss:0.175387\n",
      "Epoch [1/2], Iter [51/3125], train_loss:0.163082\n",
      "Epoch [1/2], Iter [52/3125], train_loss:0.156597\n",
      "Epoch [1/2], Iter [53/3125], train_loss:0.179248\n",
      "Epoch [1/2], Iter [54/3125], train_loss:0.170053\n",
      "Epoch [1/2], Iter [55/3125], train_loss:0.140899\n",
      "Epoch [1/2], Iter [56/3125], train_loss:0.168686\n",
      "Epoch [1/2], Iter [57/3125], train_loss:0.189548\n",
      "Epoch [1/2], Iter [58/3125], train_loss:0.169847\n",
      "Epoch [1/2], Iter [59/3125], train_loss:0.171854\n",
      "Epoch [1/2], Iter [60/3125], train_loss:0.175660\n",
      "Epoch [1/2], Iter [61/3125], train_loss:0.163686\n",
      "Epoch [1/2], Iter [62/3125], train_loss:0.174950\n",
      "Epoch [1/2], Iter [63/3125], train_loss:0.173237\n",
      "Epoch [1/2], Iter [64/3125], train_loss:0.146743\n",
      "Epoch [1/2], Iter [65/3125], train_loss:0.159798\n",
      "Epoch [1/2], Iter [66/3125], train_loss:0.169616\n",
      "Epoch [1/2], Iter [67/3125], train_loss:0.167541\n",
      "Epoch [1/2], Iter [68/3125], train_loss:0.136470\n",
      "Epoch [1/2], Iter [69/3125], train_loss:0.185080\n",
      "Epoch [1/2], Iter [70/3125], train_loss:0.166373\n",
      "Epoch [1/2], Iter [71/3125], train_loss:0.160634\n",
      "Epoch [1/2], Iter [72/3125], train_loss:0.163522\n",
      "Epoch [1/2], Iter [73/3125], train_loss:0.157858\n",
      "Epoch [1/2], Iter [74/3125], train_loss:0.157069\n",
      "Epoch [1/2], Iter [75/3125], train_loss:0.183969\n",
      "Epoch [1/2], Iter [76/3125], train_loss:0.166041\n",
      "Epoch [1/2], Iter [77/3125], train_loss:0.151215\n",
      "Epoch [1/2], Iter [78/3125], train_loss:0.164155\n",
      "Epoch [1/2], Iter [79/3125], train_loss:0.158990\n",
      "Epoch [1/2], Iter [80/3125], train_loss:0.178859\n",
      "Epoch [1/2], Iter [81/3125], train_loss:0.139378\n",
      "Epoch [1/2], Iter [82/3125], train_loss:0.150422\n",
      "Epoch [1/2], Iter [83/3125], train_loss:0.155447\n",
      "Epoch [1/2], Iter [84/3125], train_loss:0.146703\n",
      "Epoch [1/2], Iter [85/3125], train_loss:0.165099\n",
      "Epoch [1/2], Iter [86/3125], train_loss:0.175539\n",
      "Epoch [1/2], Iter [87/3125], train_loss:0.178613\n",
      "Epoch [1/2], Iter [88/3125], train_loss:0.169430\n",
      "Epoch [1/2], Iter [89/3125], train_loss:0.160620\n",
      "Epoch [1/2], Iter [90/3125], train_loss:0.172726\n",
      "Epoch [1/2], Iter [91/3125], train_loss:0.139834\n",
      "Epoch [1/2], Iter [92/3125], train_loss:0.162758\n",
      "Epoch [1/2], Iter [93/3125], train_loss:0.160110\n",
      "Epoch [1/2], Iter [94/3125], train_loss:0.176203\n",
      "Epoch [1/2], Iter [95/3125], train_loss:0.170835\n",
      "Epoch [1/2], Iter [96/3125], train_loss:0.166727\n",
      "Epoch [1/2], Iter [97/3125], train_loss:0.175421\n",
      "Epoch [1/2], Iter [98/3125], train_loss:0.173413\n",
      "Epoch [1/2], Iter [99/3125], train_loss:0.154259\n",
      "Epoch [1/2], Iter [100/3125], train_loss:0.146670\n",
      "Epoch [1/2], Iter [101/3125], train_loss:0.161012\n",
      "Epoch [1/2], Iter [102/3125], train_loss:0.151979\n",
      "Epoch [1/2], Iter [103/3125], train_loss:0.163212\n",
      "Epoch [1/2], Iter [104/3125], train_loss:0.174235\n",
      "Epoch [1/2], Iter [105/3125], train_loss:0.152968\n",
      "Epoch [1/2], Iter [106/3125], train_loss:0.156215\n",
      "Epoch [1/2], Iter [107/3125], train_loss:0.164557\n",
      "Epoch [1/2], Iter [108/3125], train_loss:0.144438\n",
      "Epoch [1/2], Iter [109/3125], train_loss:0.168143\n",
      "Epoch [1/2], Iter [110/3125], train_loss:0.144444\n",
      "Epoch [1/2], Iter [111/3125], train_loss:0.153808\n",
      "Epoch [1/2], Iter [112/3125], train_loss:0.172484\n",
      "Epoch [1/2], Iter [113/3125], train_loss:0.168573\n",
      "Epoch [1/2], Iter [114/3125], train_loss:0.157955\n",
      "Epoch [1/2], Iter [115/3125], train_loss:0.170679\n",
      "Epoch [1/2], Iter [116/3125], train_loss:0.150308\n",
      "Epoch [1/2], Iter [117/3125], train_loss:0.152166\n",
      "Epoch [1/2], Iter [118/3125], train_loss:0.175642\n",
      "Epoch [1/2], Iter [119/3125], train_loss:0.167162\n",
      "Epoch [1/2], Iter [120/3125], train_loss:0.159675\n",
      "Epoch [1/2], Iter [121/3125], train_loss:0.176089\n",
      "Epoch [1/2], Iter [122/3125], train_loss:0.154275\n",
      "Epoch [1/2], Iter [123/3125], train_loss:0.139308\n",
      "Epoch [1/2], Iter [124/3125], train_loss:0.156106\n",
      "Epoch [1/2], Iter [125/3125], train_loss:0.140437\n",
      "Epoch [1/2], Iter [126/3125], train_loss:0.154971\n",
      "Epoch [1/2], Iter [127/3125], train_loss:0.148948\n",
      "Epoch [1/2], Iter [128/3125], train_loss:0.173654\n",
      "Epoch [1/2], Iter [129/3125], train_loss:0.175725\n",
      "Epoch [1/2], Iter [130/3125], train_loss:0.160516\n",
      "Epoch [1/2], Iter [131/3125], train_loss:0.170737\n",
      "Epoch [1/2], Iter [132/3125], train_loss:0.161662\n",
      "Epoch [1/2], Iter [133/3125], train_loss:0.179921\n",
      "Epoch [1/2], Iter [134/3125], train_loss:0.160738\n",
      "Epoch [1/2], Iter [135/3125], train_loss:0.134471\n",
      "Epoch [1/2], Iter [136/3125], train_loss:0.170317\n",
      "Epoch [1/2], Iter [137/3125], train_loss:0.153042\n",
      "Epoch [1/2], Iter [138/3125], train_loss:0.163370\n",
      "Epoch [1/2], Iter [139/3125], train_loss:0.169346\n",
      "Epoch [1/2], Iter [140/3125], train_loss:0.156637\n",
      "Epoch [1/2], Iter [141/3125], train_loss:0.164446\n",
      "Epoch [1/2], Iter [142/3125], train_loss:0.166337\n",
      "Epoch [1/2], Iter [143/3125], train_loss:0.150206\n",
      "Epoch [1/2], Iter [144/3125], train_loss:0.156191\n",
      "Epoch [1/2], Iter [145/3125], train_loss:0.169191\n",
      "Epoch [1/2], Iter [146/3125], train_loss:0.165300\n",
      "Epoch [1/2], Iter [147/3125], train_loss:0.177487\n",
      "Epoch [1/2], Iter [148/3125], train_loss:0.179514\n",
      "Epoch [1/2], Iter [149/3125], train_loss:0.153518\n",
      "Epoch [1/2], Iter [150/3125], train_loss:0.155025\n",
      "Epoch [1/2], Iter [151/3125], train_loss:0.169826\n",
      "Epoch [1/2], Iter [152/3125], train_loss:0.150576\n",
      "Epoch [1/2], Iter [153/3125], train_loss:0.149755\n",
      "Epoch [1/2], Iter [154/3125], train_loss:0.156437\n",
      "Epoch [1/2], Iter [155/3125], train_loss:0.163630\n",
      "Epoch [1/2], Iter [156/3125], train_loss:0.163358\n",
      "Epoch [1/2], Iter [157/3125], train_loss:0.168501\n",
      "Epoch [1/2], Iter [158/3125], train_loss:0.152938\n",
      "Epoch [1/2], Iter [159/3125], train_loss:0.162743\n",
      "Epoch [1/2], Iter [160/3125], train_loss:0.164684\n",
      "Epoch [1/2], Iter [161/3125], train_loss:0.134906\n",
      "Epoch [1/2], Iter [162/3125], train_loss:0.171217\n",
      "Epoch [1/2], Iter [163/3125], train_loss:0.166338\n",
      "Epoch [1/2], Iter [164/3125], train_loss:0.173403\n",
      "Epoch [1/2], Iter [165/3125], train_loss:0.166951\n",
      "Epoch [1/2], Iter [166/3125], train_loss:0.161986\n",
      "Epoch [1/2], Iter [167/3125], train_loss:0.167642\n",
      "Epoch [1/2], Iter [168/3125], train_loss:0.163133\n",
      "Epoch [1/2], Iter [169/3125], train_loss:0.176087\n",
      "Epoch [1/2], Iter [170/3125], train_loss:0.181500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [171/3125], train_loss:0.182332\n",
      "Epoch [1/2], Iter [172/3125], train_loss:0.159162\n",
      "Epoch [1/2], Iter [173/3125], train_loss:0.173818\n",
      "Epoch [1/2], Iter [174/3125], train_loss:0.151095\n",
      "Epoch [1/2], Iter [175/3125], train_loss:0.169016\n",
      "Epoch [1/2], Iter [176/3125], train_loss:0.168345\n",
      "Epoch [1/2], Iter [177/3125], train_loss:0.171198\n",
      "Epoch [1/2], Iter [178/3125], train_loss:0.158377\n",
      "Epoch [1/2], Iter [179/3125], train_loss:0.150349\n",
      "Epoch [1/2], Iter [180/3125], train_loss:0.154732\n",
      "Epoch [1/2], Iter [181/3125], train_loss:0.159255\n",
      "Epoch [1/2], Iter [182/3125], train_loss:0.180752\n",
      "Epoch [1/2], Iter [183/3125], train_loss:0.130398\n",
      "Epoch [1/2], Iter [184/3125], train_loss:0.149835\n",
      "Epoch [1/2], Iter [185/3125], train_loss:0.163545\n",
      "Epoch [1/2], Iter [186/3125], train_loss:0.165769\n",
      "Epoch [1/2], Iter [187/3125], train_loss:0.165499\n",
      "Epoch [1/2], Iter [188/3125], train_loss:0.191183\n",
      "Epoch [1/2], Iter [189/3125], train_loss:0.165406\n",
      "Epoch [1/2], Iter [190/3125], train_loss:0.158130\n",
      "Epoch [1/2], Iter [191/3125], train_loss:0.167049\n",
      "Epoch [1/2], Iter [192/3125], train_loss:0.158406\n",
      "Epoch [1/2], Iter [193/3125], train_loss:0.155791\n",
      "Epoch [1/2], Iter [194/3125], train_loss:0.154068\n",
      "Epoch [1/2], Iter [195/3125], train_loss:0.173929\n",
      "Epoch [1/2], Iter [196/3125], train_loss:0.166356\n",
      "Epoch [1/2], Iter [197/3125], train_loss:0.153073\n",
      "Epoch [1/2], Iter [198/3125], train_loss:0.159932\n",
      "Epoch [1/2], Iter [199/3125], train_loss:0.158823\n",
      "Epoch [1/2], Iter [200/3125], train_loss:0.187810\n",
      "Epoch [1/2], Iter [201/3125], train_loss:0.178415\n",
      "Epoch [1/2], Iter [202/3125], train_loss:0.156469\n",
      "Epoch [1/2], Iter [203/3125], train_loss:0.160102\n",
      "Epoch [1/2], Iter [204/3125], train_loss:0.147824\n",
      "Epoch [1/2], Iter [205/3125], train_loss:0.159959\n",
      "Epoch [1/2], Iter [206/3125], train_loss:0.168457\n",
      "Epoch [1/2], Iter [207/3125], train_loss:0.152751\n",
      "Epoch [1/2], Iter [208/3125], train_loss:0.153071\n",
      "Epoch [1/2], Iter [209/3125], train_loss:0.162002\n",
      "Epoch [1/2], Iter [210/3125], train_loss:0.177490\n",
      "Epoch [1/2], Iter [211/3125], train_loss:0.153973\n",
      "Epoch [1/2], Iter [212/3125], train_loss:0.178655\n",
      "Epoch [1/2], Iter [213/3125], train_loss:0.172759\n",
      "Epoch [1/2], Iter [214/3125], train_loss:0.161288\n",
      "Epoch [1/2], Iter [215/3125], train_loss:0.145693\n",
      "Epoch [1/2], Iter [216/3125], train_loss:0.149355\n",
      "Epoch [1/2], Iter [217/3125], train_loss:0.177612\n",
      "Epoch [1/2], Iter [218/3125], train_loss:0.156104\n",
      "Epoch [1/2], Iter [219/3125], train_loss:0.146696\n",
      "Epoch [1/2], Iter [220/3125], train_loss:0.168620\n",
      "Epoch [1/2], Iter [221/3125], train_loss:0.134316\n",
      "Epoch [1/2], Iter [222/3125], train_loss:0.164465\n",
      "Epoch [1/2], Iter [223/3125], train_loss:0.161020\n",
      "Epoch [1/2], Iter [224/3125], train_loss:0.144464\n",
      "Epoch [1/2], Iter [225/3125], train_loss:0.145501\n",
      "Epoch [1/2], Iter [226/3125], train_loss:0.156721\n",
      "Epoch [1/2], Iter [227/3125], train_loss:0.160348\n",
      "Epoch [1/2], Iter [228/3125], train_loss:0.157792\n",
      "Epoch [1/2], Iter [229/3125], train_loss:0.143886\n",
      "Epoch [1/2], Iter [230/3125], train_loss:0.146231\n",
      "Epoch [1/2], Iter [231/3125], train_loss:0.161353\n",
      "Epoch [1/2], Iter [232/3125], train_loss:0.172967\n",
      "Epoch [1/2], Iter [233/3125], train_loss:0.173051\n",
      "Epoch [1/2], Iter [234/3125], train_loss:0.173887\n",
      "Epoch [1/2], Iter [235/3125], train_loss:0.155447\n",
      "Epoch [1/2], Iter [236/3125], train_loss:0.162683\n",
      "Epoch [1/2], Iter [237/3125], train_loss:0.147682\n",
      "Epoch [1/2], Iter [238/3125], train_loss:0.170582\n",
      "Epoch [1/2], Iter [239/3125], train_loss:0.159764\n",
      "Epoch [1/2], Iter [240/3125], train_loss:0.157225\n",
      "Epoch [1/2], Iter [241/3125], train_loss:0.153664\n",
      "Epoch [1/2], Iter [242/3125], train_loss:0.166018\n",
      "Epoch [1/2], Iter [243/3125], train_loss:0.175373\n",
      "Epoch [1/2], Iter [244/3125], train_loss:0.146529\n",
      "Epoch [1/2], Iter [245/3125], train_loss:0.166091\n",
      "Epoch [1/2], Iter [246/3125], train_loss:0.161189\n",
      "Epoch [1/2], Iter [247/3125], train_loss:0.144563\n",
      "Epoch [1/2], Iter [248/3125], train_loss:0.150318\n",
      "Epoch [1/2], Iter [249/3125], train_loss:0.140906\n",
      "Epoch [1/2], Iter [250/3125], train_loss:0.169033\n",
      "Epoch [1/2], Iter [251/3125], train_loss:0.155781\n",
      "Epoch [1/2], Iter [252/3125], train_loss:0.163493\n",
      "Epoch [1/2], Iter [253/3125], train_loss:0.153378\n",
      "Epoch [1/2], Iter [254/3125], train_loss:0.183447\n",
      "Epoch [1/2], Iter [255/3125], train_loss:0.178129\n",
      "Epoch [1/2], Iter [256/3125], train_loss:0.177007\n",
      "Epoch [1/2], Iter [257/3125], train_loss:0.179591\n",
      "Epoch [1/2], Iter [258/3125], train_loss:0.169509\n",
      "Epoch [1/2], Iter [259/3125], train_loss:0.146213\n",
      "Epoch [1/2], Iter [260/3125], train_loss:0.171849\n",
      "Epoch [1/2], Iter [261/3125], train_loss:0.163851\n",
      "Epoch [1/2], Iter [262/3125], train_loss:0.178366\n",
      "Epoch [1/2], Iter [263/3125], train_loss:0.194072\n",
      "Epoch [1/2], Iter [264/3125], train_loss:0.172418\n",
      "Epoch [1/2], Iter [265/3125], train_loss:0.143541\n",
      "Epoch [1/2], Iter [266/3125], train_loss:0.158418\n",
      "Epoch [1/2], Iter [267/3125], train_loss:0.163535\n",
      "Epoch [1/2], Iter [268/3125], train_loss:0.171397\n",
      "Epoch [1/2], Iter [269/3125], train_loss:0.183410\n",
      "Epoch [1/2], Iter [270/3125], train_loss:0.191745\n",
      "Epoch [1/2], Iter [271/3125], train_loss:0.195354\n",
      "Epoch [1/2], Iter [272/3125], train_loss:0.166208\n",
      "Epoch [1/2], Iter [273/3125], train_loss:0.148297\n",
      "Epoch [1/2], Iter [274/3125], train_loss:0.164007\n",
      "Epoch [1/2], Iter [275/3125], train_loss:0.168109\n",
      "Epoch [1/2], Iter [276/3125], train_loss:0.187189\n",
      "Epoch [1/2], Iter [277/3125], train_loss:0.171387\n",
      "Epoch [1/2], Iter [278/3125], train_loss:0.143764\n",
      "Epoch [1/2], Iter [279/3125], train_loss:0.175919\n",
      "Epoch [1/2], Iter [280/3125], train_loss:0.172834\n",
      "Epoch [1/2], Iter [281/3125], train_loss:0.173480\n",
      "Epoch [1/2], Iter [282/3125], train_loss:0.141544\n",
      "Epoch [1/2], Iter [283/3125], train_loss:0.187073\n",
      "Epoch [1/2], Iter [284/3125], train_loss:0.147416\n",
      "Epoch [1/2], Iter [285/3125], train_loss:0.163346\n",
      "Epoch [1/2], Iter [286/3125], train_loss:0.155601\n",
      "Epoch [1/2], Iter [287/3125], train_loss:0.160135\n",
      "Epoch [1/2], Iter [288/3125], train_loss:0.153201\n",
      "Epoch [1/2], Iter [289/3125], train_loss:0.157078\n",
      "Epoch [1/2], Iter [290/3125], train_loss:0.143863\n",
      "Epoch [1/2], Iter [291/3125], train_loss:0.170847\n",
      "Epoch [1/2], Iter [292/3125], train_loss:0.160009\n",
      "Epoch [1/2], Iter [293/3125], train_loss:0.160868\n",
      "Epoch [1/2], Iter [294/3125], train_loss:0.159037\n",
      "Epoch [1/2], Iter [295/3125], train_loss:0.148768\n",
      "Epoch [1/2], Iter [296/3125], train_loss:0.172005\n",
      "Epoch [1/2], Iter [297/3125], train_loss:0.170369\n",
      "Epoch [1/2], Iter [298/3125], train_loss:0.150250\n",
      "Epoch [1/2], Iter [299/3125], train_loss:0.203501\n",
      "Epoch [1/2], Iter [300/3125], train_loss:0.172398\n",
      "Epoch [1/2], Iter [301/3125], train_loss:0.184601\n",
      "Epoch [1/2], Iter [302/3125], train_loss:0.156175\n",
      "Epoch [1/2], Iter [303/3125], train_loss:0.161752\n",
      "Epoch [1/2], Iter [304/3125], train_loss:0.154050\n",
      "Epoch [1/2], Iter [305/3125], train_loss:0.151905\n",
      "Epoch [1/2], Iter [306/3125], train_loss:0.154861\n",
      "Epoch [1/2], Iter [307/3125], train_loss:0.157530\n",
      "Epoch [1/2], Iter [308/3125], train_loss:0.162054\n",
      "Epoch [1/2], Iter [309/3125], train_loss:0.172370\n",
      "Epoch [1/2], Iter [310/3125], train_loss:0.149971\n",
      "Epoch [1/2], Iter [311/3125], train_loss:0.155449\n",
      "Epoch [1/2], Iter [312/3125], train_loss:0.168246\n",
      "Epoch [1/2], Iter [313/3125], train_loss:0.161156\n",
      "Epoch [1/2], Iter [314/3125], train_loss:0.182064\n",
      "Epoch [1/2], Iter [315/3125], train_loss:0.168014\n",
      "Epoch [1/2], Iter [316/3125], train_loss:0.155707\n",
      "Epoch [1/2], Iter [317/3125], train_loss:0.155345\n",
      "Epoch [1/2], Iter [318/3125], train_loss:0.157537\n",
      "Epoch [1/2], Iter [319/3125], train_loss:0.158657\n",
      "Epoch [1/2], Iter [320/3125], train_loss:0.162647\n",
      "Epoch [1/2], Iter [321/3125], train_loss:0.165201\n",
      "Epoch [1/2], Iter [322/3125], train_loss:0.187565\n",
      "Epoch [1/2], Iter [323/3125], train_loss:0.153937\n",
      "Epoch [1/2], Iter [324/3125], train_loss:0.147520\n",
      "Epoch [1/2], Iter [325/3125], train_loss:0.139758\n",
      "Epoch [1/2], Iter [326/3125], train_loss:0.177869\n",
      "Epoch [1/2], Iter [327/3125], train_loss:0.178201\n",
      "Epoch [1/2], Iter [328/3125], train_loss:0.154316\n",
      "Epoch [1/2], Iter [329/3125], train_loss:0.178173\n",
      "Epoch [1/2], Iter [330/3125], train_loss:0.159244\n",
      "Epoch [1/2], Iter [331/3125], train_loss:0.177582\n",
      "Epoch [1/2], Iter [332/3125], train_loss:0.153592\n",
      "Epoch [1/2], Iter [333/3125], train_loss:0.154490\n",
      "Epoch [1/2], Iter [334/3125], train_loss:0.150733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [335/3125], train_loss:0.169697\n",
      "Epoch [1/2], Iter [336/3125], train_loss:0.155575\n",
      "Epoch [1/2], Iter [337/3125], train_loss:0.158214\n",
      "Epoch [1/2], Iter [338/3125], train_loss:0.174536\n",
      "Epoch [1/2], Iter [339/3125], train_loss:0.139395\n",
      "Epoch [1/2], Iter [340/3125], train_loss:0.163447\n",
      "Epoch [1/2], Iter [341/3125], train_loss:0.146871\n",
      "Epoch [1/2], Iter [342/3125], train_loss:0.160089\n",
      "Epoch [1/2], Iter [343/3125], train_loss:0.161521\n",
      "Epoch [1/2], Iter [344/3125], train_loss:0.148263\n",
      "Epoch [1/2], Iter [345/3125], train_loss:0.156887\n",
      "Epoch [1/2], Iter [346/3125], train_loss:0.163093\n",
      "Epoch [1/2], Iter [347/3125], train_loss:0.130156\n",
      "Epoch [1/2], Iter [348/3125], train_loss:0.153562\n",
      "Epoch [1/2], Iter [349/3125], train_loss:0.183320\n",
      "Epoch [1/2], Iter [350/3125], train_loss:0.151159\n",
      "Epoch [1/2], Iter [351/3125], train_loss:0.144421\n",
      "Epoch [1/2], Iter [352/3125], train_loss:0.145968\n",
      "Epoch [1/2], Iter [353/3125], train_loss:0.150598\n",
      "Epoch [1/2], Iter [354/3125], train_loss:0.163271\n",
      "Epoch [1/2], Iter [355/3125], train_loss:0.191171\n",
      "Epoch [1/2], Iter [356/3125], train_loss:0.166442\n",
      "Epoch [1/2], Iter [357/3125], train_loss:0.153268\n",
      "Epoch [1/2], Iter [358/3125], train_loss:0.160086\n",
      "Epoch [1/2], Iter [359/3125], train_loss:0.172394\n",
      "Epoch [1/2], Iter [360/3125], train_loss:0.160697\n",
      "Epoch [1/2], Iter [361/3125], train_loss:0.158556\n",
      "Epoch [1/2], Iter [362/3125], train_loss:0.148141\n",
      "Epoch [1/2], Iter [363/3125], train_loss:0.161616\n",
      "Epoch [1/2], Iter [364/3125], train_loss:0.164506\n",
      "Epoch [1/2], Iter [365/3125], train_loss:0.153889\n",
      "Epoch [1/2], Iter [366/3125], train_loss:0.149990\n",
      "Epoch [1/2], Iter [367/3125], train_loss:0.172651\n",
      "Epoch [1/2], Iter [368/3125], train_loss:0.167421\n",
      "Epoch [1/2], Iter [369/3125], train_loss:0.157874\n",
      "Epoch [1/2], Iter [370/3125], train_loss:0.175726\n",
      "Epoch [1/2], Iter [371/3125], train_loss:0.168166\n",
      "Epoch [1/2], Iter [372/3125], train_loss:0.160632\n",
      "Epoch [1/2], Iter [373/3125], train_loss:0.169915\n",
      "Epoch [1/2], Iter [374/3125], train_loss:0.141351\n",
      "Epoch [1/2], Iter [375/3125], train_loss:0.157579\n",
      "Epoch [1/2], Iter [376/3125], train_loss:0.159373\n",
      "Epoch [1/2], Iter [377/3125], train_loss:0.173719\n",
      "Epoch [1/2], Iter [378/3125], train_loss:0.156862\n",
      "Epoch [1/2], Iter [379/3125], train_loss:0.164567\n",
      "Epoch [1/2], Iter [380/3125], train_loss:0.151420\n",
      "Epoch [1/2], Iter [381/3125], train_loss:0.155565\n",
      "Epoch [1/2], Iter [382/3125], train_loss:0.156861\n",
      "Epoch [1/2], Iter [383/3125], train_loss:0.162360\n",
      "Epoch [1/2], Iter [384/3125], train_loss:0.155612\n",
      "Epoch [1/2], Iter [385/3125], train_loss:0.187500\n",
      "Epoch [1/2], Iter [386/3125], train_loss:0.167519\n",
      "Epoch [1/2], Iter [387/3125], train_loss:0.150314\n",
      "Epoch [1/2], Iter [388/3125], train_loss:0.171371\n",
      "Epoch [1/2], Iter [389/3125], train_loss:0.170002\n",
      "Epoch [1/2], Iter [390/3125], train_loss:0.171281\n",
      "Epoch [1/2], Iter [391/3125], train_loss:0.154229\n",
      "Epoch [1/2], Iter [392/3125], train_loss:0.152277\n",
      "Epoch [1/2], Iter [393/3125], train_loss:0.160335\n",
      "Epoch [1/2], Iter [394/3125], train_loss:0.160123\n",
      "Epoch [1/2], Iter [395/3125], train_loss:0.157730\n",
      "Epoch [1/2], Iter [396/3125], train_loss:0.148626\n",
      "Epoch [1/2], Iter [397/3125], train_loss:0.164090\n",
      "Epoch [1/2], Iter [398/3125], train_loss:0.181123\n",
      "Epoch [1/2], Iter [399/3125], train_loss:0.144987\n",
      "Epoch [1/2], Iter [400/3125], train_loss:0.147743\n",
      "Epoch [1/2], Iter [401/3125], train_loss:0.156141\n",
      "Epoch [1/2], Iter [402/3125], train_loss:0.182602\n",
      "Epoch [1/2], Iter [403/3125], train_loss:0.186334\n",
      "Epoch [1/2], Iter [404/3125], train_loss:0.158865\n",
      "Epoch [1/2], Iter [405/3125], train_loss:0.157437\n",
      "Epoch [1/2], Iter [406/3125], train_loss:0.151499\n",
      "Epoch [1/2], Iter [407/3125], train_loss:0.155167\n",
      "Epoch [1/2], Iter [408/3125], train_loss:0.158371\n",
      "Epoch [1/2], Iter [409/3125], train_loss:0.170319\n",
      "Epoch [1/2], Iter [410/3125], train_loss:0.172921\n",
      "Epoch [1/2], Iter [411/3125], train_loss:0.175661\n",
      "Epoch [1/2], Iter [412/3125], train_loss:0.170778\n",
      "Epoch [1/2], Iter [413/3125], train_loss:0.173227\n",
      "Epoch [1/2], Iter [414/3125], train_loss:0.162998\n",
      "Epoch [1/2], Iter [415/3125], train_loss:0.144094\n",
      "Epoch [1/2], Iter [416/3125], train_loss:0.154685\n",
      "Epoch [1/2], Iter [417/3125], train_loss:0.177953\n",
      "Epoch [1/2], Iter [418/3125], train_loss:0.151602\n",
      "Epoch [1/2], Iter [419/3125], train_loss:0.165047\n",
      "Epoch [1/2], Iter [420/3125], train_loss:0.146441\n",
      "Epoch [1/2], Iter [421/3125], train_loss:0.155056\n",
      "Epoch [1/2], Iter [422/3125], train_loss:0.144277\n",
      "Epoch [1/2], Iter [423/3125], train_loss:0.156635\n",
      "Epoch [1/2], Iter [424/3125], train_loss:0.154019\n",
      "Epoch [1/2], Iter [425/3125], train_loss:0.161336\n",
      "Epoch [1/2], Iter [426/3125], train_loss:0.203085\n",
      "Epoch [1/2], Iter [427/3125], train_loss:0.146707\n",
      "Epoch [1/2], Iter [428/3125], train_loss:0.158310\n",
      "Epoch [1/2], Iter [429/3125], train_loss:0.171015\n",
      "Epoch [1/2], Iter [430/3125], train_loss:0.142477\n",
      "Epoch [1/2], Iter [431/3125], train_loss:0.189910\n",
      "Epoch [1/2], Iter [432/3125], train_loss:0.165581\n",
      "Epoch [1/2], Iter [433/3125], train_loss:0.163553\n",
      "Epoch [1/2], Iter [434/3125], train_loss:0.162628\n",
      "Epoch [1/2], Iter [435/3125], train_loss:0.166308\n",
      "Epoch [1/2], Iter [436/3125], train_loss:0.174060\n",
      "Epoch [1/2], Iter [437/3125], train_loss:0.170486\n",
      "Epoch [1/2], Iter [438/3125], train_loss:0.170334\n",
      "Epoch [1/2], Iter [439/3125], train_loss:0.170027\n",
      "Epoch [1/2], Iter [440/3125], train_loss:0.176327\n",
      "Epoch [1/2], Iter [441/3125], train_loss:0.185929\n",
      "Epoch [1/2], Iter [442/3125], train_loss:0.164644\n",
      "Epoch [1/2], Iter [443/3125], train_loss:0.155429\n",
      "Epoch [1/2], Iter [444/3125], train_loss:0.156190\n",
      "Epoch [1/2], Iter [445/3125], train_loss:0.183739\n",
      "Epoch [1/2], Iter [446/3125], train_loss:0.168132\n",
      "Epoch [1/2], Iter [447/3125], train_loss:0.156675\n",
      "Epoch [1/2], Iter [448/3125], train_loss:0.174648\n",
      "Epoch [1/2], Iter [449/3125], train_loss:0.176605\n",
      "Epoch [1/2], Iter [450/3125], train_loss:0.165744\n",
      "Epoch [1/2], Iter [451/3125], train_loss:0.159427\n",
      "Epoch [1/2], Iter [452/3125], train_loss:0.137918\n",
      "Epoch [1/2], Iter [453/3125], train_loss:0.154664\n",
      "Epoch [1/2], Iter [454/3125], train_loss:0.188046\n",
      "Epoch [1/2], Iter [455/3125], train_loss:0.157990\n",
      "Epoch [1/2], Iter [456/3125], train_loss:0.161434\n",
      "Epoch [1/2], Iter [457/3125], train_loss:0.164751\n",
      "Epoch [1/2], Iter [458/3125], train_loss:0.147707\n",
      "Epoch [1/2], Iter [459/3125], train_loss:0.156135\n",
      "Epoch [1/2], Iter [460/3125], train_loss:0.170298\n",
      "Epoch [1/2], Iter [461/3125], train_loss:0.157925\n",
      "Epoch [1/2], Iter [462/3125], train_loss:0.161613\n",
      "Epoch [1/2], Iter [463/3125], train_loss:0.156034\n",
      "Epoch [1/2], Iter [464/3125], train_loss:0.154685\n",
      "Epoch [1/2], Iter [465/3125], train_loss:0.159974\n",
      "Epoch [1/2], Iter [466/3125], train_loss:0.137804\n",
      "Epoch [1/2], Iter [467/3125], train_loss:0.173479\n",
      "Epoch [1/2], Iter [468/3125], train_loss:0.160113\n",
      "Epoch [1/2], Iter [469/3125], train_loss:0.181849\n",
      "Epoch [1/2], Iter [470/3125], train_loss:0.154617\n",
      "Epoch [1/2], Iter [471/3125], train_loss:0.145756\n",
      "Epoch [1/2], Iter [472/3125], train_loss:0.173865\n",
      "Epoch [1/2], Iter [473/3125], train_loss:0.179762\n",
      "Epoch [1/2], Iter [474/3125], train_loss:0.148816\n",
      "Epoch [1/2], Iter [475/3125], train_loss:0.143284\n",
      "Epoch [1/2], Iter [476/3125], train_loss:0.171798\n",
      "Epoch [1/2], Iter [477/3125], train_loss:0.180198\n",
      "Epoch [1/2], Iter [478/3125], train_loss:0.160204\n",
      "Epoch [1/2], Iter [479/3125], train_loss:0.166848\n",
      "Epoch [1/2], Iter [480/3125], train_loss:0.168912\n",
      "Epoch [1/2], Iter [481/3125], train_loss:0.151769\n",
      "Epoch [1/2], Iter [482/3125], train_loss:0.164199\n",
      "Epoch [1/2], Iter [483/3125], train_loss:0.159082\n",
      "Epoch [1/2], Iter [484/3125], train_loss:0.157923\n",
      "Epoch [1/2], Iter [485/3125], train_loss:0.175519\n",
      "Epoch [1/2], Iter [486/3125], train_loss:0.161383\n",
      "Epoch [1/2], Iter [487/3125], train_loss:0.162508\n",
      "Epoch [1/2], Iter [488/3125], train_loss:0.165235\n",
      "Epoch [1/2], Iter [489/3125], train_loss:0.179577\n",
      "Epoch [1/2], Iter [490/3125], train_loss:0.151752\n",
      "Epoch [1/2], Iter [491/3125], train_loss:0.171913\n",
      "Epoch [1/2], Iter [492/3125], train_loss:0.163084\n",
      "Epoch [1/2], Iter [493/3125], train_loss:0.156714\n",
      "Epoch [1/2], Iter [494/3125], train_loss:0.156022\n",
      "Epoch [1/2], Iter [495/3125], train_loss:0.157305\n",
      "Epoch [1/2], Iter [496/3125], train_loss:0.156836\n",
      "Epoch [1/2], Iter [497/3125], train_loss:0.154605\n",
      "Epoch [1/2], Iter [498/3125], train_loss:0.174036\n",
      "Epoch [1/2], Iter [499/3125], train_loss:0.164733\n",
      "Epoch [1/2], Iter [500/3125], train_loss:0.162918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [501/3125], train_loss:0.149830\n",
      "Epoch [1/2], Iter [502/3125], train_loss:0.186489\n",
      "Epoch [1/2], Iter [503/3125], train_loss:0.145313\n",
      "Epoch [1/2], Iter [504/3125], train_loss:0.152114\n",
      "Epoch [1/2], Iter [505/3125], train_loss:0.150460\n",
      "Epoch [1/2], Iter [506/3125], train_loss:0.172033\n",
      "Epoch [1/2], Iter [507/3125], train_loss:0.156441\n",
      "Epoch [1/2], Iter [508/3125], train_loss:0.151387\n",
      "Epoch [1/2], Iter [509/3125], train_loss:0.174799\n",
      "Epoch [1/2], Iter [510/3125], train_loss:0.156212\n",
      "Epoch [1/2], Iter [511/3125], train_loss:0.157743\n",
      "Epoch [1/2], Iter [512/3125], train_loss:0.171979\n",
      "Epoch [1/2], Iter [513/3125], train_loss:0.183507\n",
      "Epoch [1/2], Iter [514/3125], train_loss:0.174797\n",
      "Epoch [1/2], Iter [515/3125], train_loss:0.151998\n",
      "Epoch [1/2], Iter [516/3125], train_loss:0.164528\n",
      "Epoch [1/2], Iter [517/3125], train_loss:0.164061\n",
      "Epoch [1/2], Iter [518/3125], train_loss:0.184687\n",
      "Epoch [1/2], Iter [519/3125], train_loss:0.153723\n",
      "Epoch [1/2], Iter [520/3125], train_loss:0.140085\n",
      "Epoch [1/2], Iter [521/3125], train_loss:0.161860\n",
      "Epoch [1/2], Iter [522/3125], train_loss:0.142582\n",
      "Epoch [1/2], Iter [523/3125], train_loss:0.158409\n",
      "Epoch [1/2], Iter [524/3125], train_loss:0.197436\n",
      "Epoch [1/2], Iter [525/3125], train_loss:0.170067\n",
      "Epoch [1/2], Iter [526/3125], train_loss:0.150738\n",
      "Epoch [1/2], Iter [527/3125], train_loss:0.164096\n",
      "Epoch [1/2], Iter [528/3125], train_loss:0.159754\n",
      "Epoch [1/2], Iter [529/3125], train_loss:0.152052\n",
      "Epoch [1/2], Iter [530/3125], train_loss:0.161230\n",
      "Epoch [1/2], Iter [531/3125], train_loss:0.181889\n",
      "Epoch [1/2], Iter [532/3125], train_loss:0.149528\n",
      "Epoch [1/2], Iter [533/3125], train_loss:0.156530\n",
      "Epoch [1/2], Iter [534/3125], train_loss:0.143401\n",
      "Epoch [1/2], Iter [535/3125], train_loss:0.164431\n",
      "Epoch [1/2], Iter [536/3125], train_loss:0.155525\n",
      "Epoch [1/2], Iter [537/3125], train_loss:0.170614\n",
      "Epoch [1/2], Iter [538/3125], train_loss:0.172353\n",
      "Epoch [1/2], Iter [539/3125], train_loss:0.167426\n",
      "Epoch [1/2], Iter [540/3125], train_loss:0.141499\n",
      "Epoch [1/2], Iter [541/3125], train_loss:0.165216\n",
      "Epoch [1/2], Iter [542/3125], train_loss:0.164144\n",
      "Epoch [1/2], Iter [543/3125], train_loss:0.149974\n",
      "Epoch [1/2], Iter [544/3125], train_loss:0.157108\n",
      "Epoch [1/2], Iter [545/3125], train_loss:0.169725\n",
      "Epoch [1/2], Iter [546/3125], train_loss:0.181695\n",
      "Epoch [1/2], Iter [547/3125], train_loss:0.161326\n",
      "Epoch [1/2], Iter [548/3125], train_loss:0.187204\n",
      "Epoch [1/2], Iter [549/3125], train_loss:0.152687\n",
      "Epoch [1/2], Iter [550/3125], train_loss:0.144457\n",
      "Epoch [1/2], Iter [551/3125], train_loss:0.160662\n",
      "Epoch [1/2], Iter [552/3125], train_loss:0.154854\n",
      "Epoch [1/2], Iter [553/3125], train_loss:0.159735\n",
      "Epoch [1/2], Iter [554/3125], train_loss:0.147193\n",
      "Epoch [1/2], Iter [555/3125], train_loss:0.157361\n",
      "Epoch [1/2], Iter [556/3125], train_loss:0.186600\n",
      "Epoch [1/2], Iter [557/3125], train_loss:0.152398\n",
      "Epoch [1/2], Iter [558/3125], train_loss:0.175364\n",
      "Epoch [1/2], Iter [559/3125], train_loss:0.167578\n",
      "Epoch [1/2], Iter [560/3125], train_loss:0.158512\n",
      "Epoch [1/2], Iter [561/3125], train_loss:0.173613\n",
      "Epoch [1/2], Iter [562/3125], train_loss:0.160966\n",
      "Epoch [1/2], Iter [563/3125], train_loss:0.172676\n",
      "Epoch [1/2], Iter [564/3125], train_loss:0.158586\n",
      "Epoch [1/2], Iter [565/3125], train_loss:0.180590\n",
      "Epoch [1/2], Iter [566/3125], train_loss:0.192027\n",
      "Epoch [1/2], Iter [567/3125], train_loss:0.157700\n",
      "Epoch [1/2], Iter [568/3125], train_loss:0.162584\n",
      "Epoch [1/2], Iter [569/3125], train_loss:0.183801\n",
      "Epoch [1/2], Iter [570/3125], train_loss:0.167326\n",
      "Epoch [1/2], Iter [571/3125], train_loss:0.164745\n",
      "Epoch [1/2], Iter [572/3125], train_loss:0.173292\n",
      "Epoch [1/2], Iter [573/3125], train_loss:0.153456\n",
      "Epoch [1/2], Iter [574/3125], train_loss:0.160368\n",
      "Epoch [1/2], Iter [575/3125], train_loss:0.151965\n",
      "Epoch [1/2], Iter [576/3125], train_loss:0.154746\n",
      "Epoch [1/2], Iter [577/3125], train_loss:0.170880\n",
      "Epoch [1/2], Iter [578/3125], train_loss:0.161438\n",
      "Epoch [1/2], Iter [579/3125], train_loss:0.180224\n",
      "Epoch [1/2], Iter [580/3125], train_loss:0.178791\n",
      "Epoch [1/2], Iter [581/3125], train_loss:0.145772\n",
      "Epoch [1/2], Iter [582/3125], train_loss:0.160606\n",
      "Epoch [1/2], Iter [583/3125], train_loss:0.176088\n",
      "Epoch [1/2], Iter [584/3125], train_loss:0.164863\n",
      "Epoch [1/2], Iter [585/3125], train_loss:0.181251\n",
      "Epoch [1/2], Iter [586/3125], train_loss:0.151516\n",
      "Epoch [1/2], Iter [587/3125], train_loss:0.176537\n",
      "Epoch [1/2], Iter [588/3125], train_loss:0.159592\n",
      "Epoch [1/2], Iter [589/3125], train_loss:0.156307\n",
      "Epoch [1/2], Iter [590/3125], train_loss:0.149772\n",
      "Epoch [1/2], Iter [591/3125], train_loss:0.168533\n",
      "Epoch [1/2], Iter [592/3125], train_loss:0.156289\n",
      "Epoch [1/2], Iter [593/3125], train_loss:0.171735\n",
      "Epoch [1/2], Iter [594/3125], train_loss:0.159490\n",
      "Epoch [1/2], Iter [595/3125], train_loss:0.156549\n",
      "Epoch [1/2], Iter [596/3125], train_loss:0.172349\n",
      "Epoch [1/2], Iter [597/3125], train_loss:0.163044\n",
      "Epoch [1/2], Iter [598/3125], train_loss:0.153242\n",
      "Epoch [1/2], Iter [599/3125], train_loss:0.178958\n",
      "Epoch [1/2], Iter [600/3125], train_loss:0.154345\n",
      "Epoch [1/2], Iter [601/3125], train_loss:0.169848\n",
      "Epoch [1/2], Iter [602/3125], train_loss:0.148637\n",
      "Epoch [1/2], Iter [603/3125], train_loss:0.168987\n",
      "Epoch [1/2], Iter [604/3125], train_loss:0.181611\n",
      "Epoch [1/2], Iter [605/3125], train_loss:0.155290\n",
      "Epoch [1/2], Iter [606/3125], train_loss:0.159152\n",
      "Epoch [1/2], Iter [607/3125], train_loss:0.158287\n",
      "Epoch [1/2], Iter [608/3125], train_loss:0.165115\n",
      "Epoch [1/2], Iter [609/3125], train_loss:0.170284\n",
      "Epoch [1/2], Iter [610/3125], train_loss:0.180462\n",
      "Epoch [1/2], Iter [611/3125], train_loss:0.170581\n",
      "Epoch [1/2], Iter [612/3125], train_loss:0.156333\n",
      "Epoch [1/2], Iter [613/3125], train_loss:0.158744\n",
      "Epoch [1/2], Iter [614/3125], train_loss:0.151848\n",
      "Epoch [1/2], Iter [615/3125], train_loss:0.146951\n",
      "Epoch [1/2], Iter [616/3125], train_loss:0.164550\n",
      "Epoch [1/2], Iter [617/3125], train_loss:0.163717\n",
      "Epoch [1/2], Iter [618/3125], train_loss:0.143995\n",
      "Epoch [1/2], Iter [619/3125], train_loss:0.174511\n",
      "Epoch [1/2], Iter [620/3125], train_loss:0.161177\n",
      "Epoch [1/2], Iter [621/3125], train_loss:0.178878\n",
      "Epoch [1/2], Iter [622/3125], train_loss:0.170491\n",
      "Epoch [1/2], Iter [623/3125], train_loss:0.172630\n",
      "Epoch [1/2], Iter [624/3125], train_loss:0.185353\n",
      "Epoch [1/2], Iter [625/3125], train_loss:0.162375\n",
      "Epoch [1/2], Iter [626/3125], train_loss:0.166046\n",
      "Epoch [1/2], Iter [627/3125], train_loss:0.187614\n",
      "Epoch [1/2], Iter [628/3125], train_loss:0.171770\n",
      "Epoch [1/2], Iter [629/3125], train_loss:0.137850\n",
      "Epoch [1/2], Iter [630/3125], train_loss:0.160116\n",
      "Epoch [1/2], Iter [631/3125], train_loss:0.147122\n",
      "Epoch [1/2], Iter [632/3125], train_loss:0.182244\n",
      "Epoch [1/2], Iter [633/3125], train_loss:0.143999\n",
      "Epoch [1/2], Iter [634/3125], train_loss:0.182345\n",
      "Epoch [1/2], Iter [635/3125], train_loss:0.156759\n",
      "Epoch [1/2], Iter [636/3125], train_loss:0.148806\n",
      "Epoch [1/2], Iter [637/3125], train_loss:0.154144\n",
      "Epoch [1/2], Iter [638/3125], train_loss:0.149763\n",
      "Epoch [1/2], Iter [639/3125], train_loss:0.154106\n",
      "Epoch [1/2], Iter [640/3125], train_loss:0.168608\n",
      "Epoch [1/2], Iter [641/3125], train_loss:0.152673\n",
      "Epoch [1/2], Iter [642/3125], train_loss:0.173711\n",
      "Epoch [1/2], Iter [643/3125], train_loss:0.168833\n",
      "Epoch [1/2], Iter [644/3125], train_loss:0.169643\n",
      "Epoch [1/2], Iter [645/3125], train_loss:0.155612\n",
      "Epoch [1/2], Iter [646/3125], train_loss:0.161894\n",
      "Epoch [1/2], Iter [647/3125], train_loss:0.173931\n",
      "Epoch [1/2], Iter [648/3125], train_loss:0.195914\n",
      "Epoch [1/2], Iter [649/3125], train_loss:0.156067\n",
      "Epoch [1/2], Iter [650/3125], train_loss:0.182341\n",
      "Epoch [1/2], Iter [651/3125], train_loss:0.162687\n",
      "Epoch [1/2], Iter [652/3125], train_loss:0.146367\n",
      "Epoch [1/2], Iter [653/3125], train_loss:0.188726\n",
      "Epoch [1/2], Iter [654/3125], train_loss:0.141544\n",
      "Epoch [1/2], Iter [655/3125], train_loss:0.136832\n",
      "Epoch [1/2], Iter [656/3125], train_loss:0.165494\n",
      "Epoch [1/2], Iter [657/3125], train_loss:0.173287\n",
      "Epoch [1/2], Iter [658/3125], train_loss:0.178410\n",
      "Epoch [1/2], Iter [659/3125], train_loss:0.153449\n",
      "Epoch [1/2], Iter [660/3125], train_loss:0.141325\n",
      "Epoch [1/2], Iter [661/3125], train_loss:0.160569\n",
      "Epoch [1/2], Iter [662/3125], train_loss:0.168849\n",
      "Epoch [1/2], Iter [663/3125], train_loss:0.170920\n",
      "Epoch [1/2], Iter [664/3125], train_loss:0.168509\n",
      "Epoch [1/2], Iter [665/3125], train_loss:0.174167\n",
      "Epoch [1/2], Iter [666/3125], train_loss:0.165306\n",
      "Epoch [1/2], Iter [667/3125], train_loss:0.173296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [668/3125], train_loss:0.161691\n",
      "Epoch [1/2], Iter [669/3125], train_loss:0.164216\n",
      "Epoch [1/2], Iter [670/3125], train_loss:0.153614\n",
      "Epoch [1/2], Iter [671/3125], train_loss:0.176628\n",
      "Epoch [1/2], Iter [672/3125], train_loss:0.170113\n",
      "Epoch [1/2], Iter [673/3125], train_loss:0.164020\n",
      "Epoch [1/2], Iter [674/3125], train_loss:0.170262\n",
      "Epoch [1/2], Iter [675/3125], train_loss:0.160252\n",
      "Epoch [1/2], Iter [676/3125], train_loss:0.159595\n",
      "Epoch [1/2], Iter [677/3125], train_loss:0.174482\n",
      "Epoch [1/2], Iter [678/3125], train_loss:0.174136\n",
      "Epoch [1/2], Iter [679/3125], train_loss:0.169684\n",
      "Epoch [1/2], Iter [680/3125], train_loss:0.156718\n",
      "Epoch [1/2], Iter [681/3125], train_loss:0.172149\n",
      "Epoch [1/2], Iter [682/3125], train_loss:0.153396\n",
      "Epoch [1/2], Iter [683/3125], train_loss:0.152438\n",
      "Epoch [1/2], Iter [684/3125], train_loss:0.175598\n",
      "Epoch [1/2], Iter [685/3125], train_loss:0.144732\n",
      "Epoch [1/2], Iter [686/3125], train_loss:0.146447\n",
      "Epoch [1/2], Iter [687/3125], train_loss:0.149588\n",
      "Epoch [1/2], Iter [688/3125], train_loss:0.158347\n",
      "Epoch [1/2], Iter [689/3125], train_loss:0.173472\n",
      "Epoch [1/2], Iter [690/3125], train_loss:0.164299\n",
      "Epoch [1/2], Iter [691/3125], train_loss:0.147107\n",
      "Epoch [1/2], Iter [692/3125], train_loss:0.138865\n",
      "Epoch [1/2], Iter [693/3125], train_loss:0.147721\n",
      "Epoch [1/2], Iter [694/3125], train_loss:0.186929\n",
      "Epoch [1/2], Iter [695/3125], train_loss:0.149825\n",
      "Epoch [1/2], Iter [696/3125], train_loss:0.159169\n",
      "Epoch [1/2], Iter [697/3125], train_loss:0.168211\n",
      "Epoch [1/2], Iter [698/3125], train_loss:0.155869\n",
      "Epoch [1/2], Iter [699/3125], train_loss:0.175861\n",
      "Epoch [1/2], Iter [700/3125], train_loss:0.147055\n",
      "Epoch [1/2], Iter [701/3125], train_loss:0.152602\n",
      "Epoch [1/2], Iter [702/3125], train_loss:0.165213\n",
      "Epoch [1/2], Iter [703/3125], train_loss:0.155550\n",
      "Epoch [1/2], Iter [704/3125], train_loss:0.165959\n",
      "Epoch [1/2], Iter [705/3125], train_loss:0.184858\n",
      "Epoch [1/2], Iter [706/3125], train_loss:0.156636\n",
      "Epoch [1/2], Iter [707/3125], train_loss:0.141014\n",
      "Epoch [1/2], Iter [708/3125], train_loss:0.172110\n",
      "Epoch [1/2], Iter [709/3125], train_loss:0.166598\n",
      "Epoch [1/2], Iter [710/3125], train_loss:0.181486\n",
      "Epoch [1/2], Iter [711/3125], train_loss:0.149520\n",
      "Epoch [1/2], Iter [712/3125], train_loss:0.141277\n",
      "Epoch [1/2], Iter [713/3125], train_loss:0.150582\n",
      "Epoch [1/2], Iter [714/3125], train_loss:0.170460\n",
      "Epoch [1/2], Iter [715/3125], train_loss:0.166523\n",
      "Epoch [1/2], Iter [716/3125], train_loss:0.140562\n",
      "Epoch [1/2], Iter [717/3125], train_loss:0.157862\n",
      "Epoch [1/2], Iter [718/3125], train_loss:0.158880\n",
      "Epoch [1/2], Iter [719/3125], train_loss:0.151162\n",
      "Epoch [1/2], Iter [720/3125], train_loss:0.150862\n",
      "Epoch [1/2], Iter [721/3125], train_loss:0.172271\n",
      "Epoch [1/2], Iter [722/3125], train_loss:0.167076\n",
      "Epoch [1/2], Iter [723/3125], train_loss:0.160416\n",
      "Epoch [1/2], Iter [724/3125], train_loss:0.164712\n",
      "Epoch [1/2], Iter [725/3125], train_loss:0.155195\n",
      "Epoch [1/2], Iter [726/3125], train_loss:0.173203\n",
      "Epoch [1/2], Iter [727/3125], train_loss:0.203542\n",
      "Epoch [1/2], Iter [728/3125], train_loss:0.132789\n",
      "Epoch [1/2], Iter [729/3125], train_loss:0.170022\n",
      "Epoch [1/2], Iter [730/3125], train_loss:0.150648\n",
      "Epoch [1/2], Iter [731/3125], train_loss:0.152137\n",
      "Epoch [1/2], Iter [732/3125], train_loss:0.165179\n",
      "Epoch [1/2], Iter [733/3125], train_loss:0.181513\n",
      "Epoch [1/2], Iter [734/3125], train_loss:0.144627\n",
      "Epoch [1/2], Iter [735/3125], train_loss:0.156241\n",
      "Epoch [1/2], Iter [736/3125], train_loss:0.156647\n",
      "Epoch [1/2], Iter [737/3125], train_loss:0.156439\n",
      "Epoch [1/2], Iter [738/3125], train_loss:0.184127\n",
      "Epoch [1/2], Iter [739/3125], train_loss:0.149900\n",
      "Epoch [1/2], Iter [740/3125], train_loss:0.178831\n",
      "Epoch [1/2], Iter [741/3125], train_loss:0.154100\n",
      "Epoch [1/2], Iter [742/3125], train_loss:0.173619\n",
      "Epoch [1/2], Iter [743/3125], train_loss:0.174960\n",
      "Epoch [1/2], Iter [744/3125], train_loss:0.158306\n",
      "Epoch [1/2], Iter [745/3125], train_loss:0.157812\n",
      "Epoch [1/2], Iter [746/3125], train_loss:0.170903\n",
      "Epoch [1/2], Iter [747/3125], train_loss:0.158708\n",
      "Epoch [1/2], Iter [748/3125], train_loss:0.177305\n",
      "Epoch [1/2], Iter [749/3125], train_loss:0.157574\n",
      "Epoch [1/2], Iter [750/3125], train_loss:0.163793\n",
      "Epoch [1/2], Iter [751/3125], train_loss:0.175222\n",
      "Epoch [1/2], Iter [752/3125], train_loss:0.167615\n",
      "Epoch [1/2], Iter [753/3125], train_loss:0.175142\n",
      "Epoch [1/2], Iter [754/3125], train_loss:0.164994\n",
      "Epoch [1/2], Iter [755/3125], train_loss:0.173740\n",
      "Epoch [1/2], Iter [756/3125], train_loss:0.184293\n",
      "Epoch [1/2], Iter [757/3125], train_loss:0.174505\n",
      "Epoch [1/2], Iter [758/3125], train_loss:0.151717\n",
      "Epoch [1/2], Iter [759/3125], train_loss:0.149027\n",
      "Epoch [1/2], Iter [760/3125], train_loss:0.181634\n",
      "Epoch [1/2], Iter [761/3125], train_loss:0.157314\n",
      "Epoch [1/2], Iter [762/3125], train_loss:0.137242\n",
      "Epoch [1/2], Iter [763/3125], train_loss:0.168438\n",
      "Epoch [1/2], Iter [764/3125], train_loss:0.141019\n",
      "Epoch [1/2], Iter [765/3125], train_loss:0.154936\n",
      "Epoch [1/2], Iter [766/3125], train_loss:0.155263\n",
      "Epoch [1/2], Iter [767/3125], train_loss:0.156193\n",
      "Epoch [1/2], Iter [768/3125], train_loss:0.154753\n",
      "Epoch [1/2], Iter [769/3125], train_loss:0.152388\n",
      "Epoch [1/2], Iter [770/3125], train_loss:0.154891\n",
      "Epoch [1/2], Iter [771/3125], train_loss:0.150887\n",
      "Epoch [1/2], Iter [772/3125], train_loss:0.170387\n",
      "Epoch [1/2], Iter [773/3125], train_loss:0.142415\n",
      "Epoch [1/2], Iter [774/3125], train_loss:0.157543\n",
      "Epoch [1/2], Iter [775/3125], train_loss:0.161519\n",
      "Epoch [1/2], Iter [776/3125], train_loss:0.153466\n",
      "Epoch [1/2], Iter [777/3125], train_loss:0.164538\n",
      "Epoch [1/2], Iter [778/3125], train_loss:0.167005\n",
      "Epoch [1/2], Iter [779/3125], train_loss:0.164542\n",
      "Epoch [1/2], Iter [780/3125], train_loss:0.136895\n",
      "Epoch [1/2], Iter [781/3125], train_loss:0.143366\n",
      "Epoch [1/2], Iter [782/3125], train_loss:0.159515\n",
      "Epoch [1/2], Iter [783/3125], train_loss:0.159623\n",
      "Epoch [1/2], Iter [784/3125], train_loss:0.175021\n",
      "Epoch [1/2], Iter [785/3125], train_loss:0.188726\n",
      "Epoch [1/2], Iter [786/3125], train_loss:0.167352\n",
      "Epoch [1/2], Iter [787/3125], train_loss:0.159414\n",
      "Epoch [1/2], Iter [788/3125], train_loss:0.143568\n",
      "Epoch [1/2], Iter [789/3125], train_loss:0.157005\n",
      "Epoch [1/2], Iter [790/3125], train_loss:0.150693\n",
      "Epoch [1/2], Iter [791/3125], train_loss:0.142032\n",
      "Epoch [1/2], Iter [792/3125], train_loss:0.158453\n",
      "Epoch [1/2], Iter [793/3125], train_loss:0.171967\n",
      "Epoch [1/2], Iter [794/3125], train_loss:0.154673\n",
      "Epoch [1/2], Iter [795/3125], train_loss:0.161099\n",
      "Epoch [1/2], Iter [796/3125], train_loss:0.149141\n",
      "Epoch [1/2], Iter [797/3125], train_loss:0.172768\n",
      "Epoch [1/2], Iter [798/3125], train_loss:0.136935\n",
      "Epoch [1/2], Iter [799/3125], train_loss:0.150901\n",
      "Epoch [1/2], Iter [800/3125], train_loss:0.177802\n",
      "Epoch [1/2], Iter [801/3125], train_loss:0.151622\n",
      "Epoch [1/2], Iter [802/3125], train_loss:0.175425\n",
      "Epoch [1/2], Iter [803/3125], train_loss:0.158219\n",
      "Epoch [1/2], Iter [804/3125], train_loss:0.160822\n",
      "Epoch [1/2], Iter [805/3125], train_loss:0.171360\n",
      "Epoch [1/2], Iter [806/3125], train_loss:0.173840\n",
      "Epoch [1/2], Iter [807/3125], train_loss:0.170521\n",
      "Epoch [1/2], Iter [808/3125], train_loss:0.155042\n",
      "Epoch [1/2], Iter [809/3125], train_loss:0.201056\n",
      "Epoch [1/2], Iter [810/3125], train_loss:0.167513\n",
      "Epoch [1/2], Iter [811/3125], train_loss:0.159135\n",
      "Epoch [1/2], Iter [812/3125], train_loss:0.161629\n",
      "Epoch [1/2], Iter [813/3125], train_loss:0.172826\n",
      "Epoch [1/2], Iter [814/3125], train_loss:0.148274\n",
      "Epoch [1/2], Iter [815/3125], train_loss:0.183451\n",
      "Epoch [1/2], Iter [816/3125], train_loss:0.164296\n",
      "Epoch [1/2], Iter [817/3125], train_loss:0.177334\n",
      "Epoch [1/2], Iter [818/3125], train_loss:0.154336\n",
      "Epoch [1/2], Iter [819/3125], train_loss:0.170955\n",
      "Epoch [1/2], Iter [820/3125], train_loss:0.168194\n",
      "Epoch [1/2], Iter [821/3125], train_loss:0.165284\n",
      "Epoch [1/2], Iter [822/3125], train_loss:0.153692\n",
      "Epoch [1/2], Iter [823/3125], train_loss:0.164452\n",
      "Epoch [1/2], Iter [824/3125], train_loss:0.160168\n",
      "Epoch [1/2], Iter [825/3125], train_loss:0.143389\n",
      "Epoch [1/2], Iter [826/3125], train_loss:0.125640\n",
      "Epoch [1/2], Iter [827/3125], train_loss:0.154325\n",
      "Epoch [1/2], Iter [828/3125], train_loss:0.170027\n",
      "Epoch [1/2], Iter [829/3125], train_loss:0.163227\n",
      "Epoch [1/2], Iter [830/3125], train_loss:0.180084\n",
      "Epoch [1/2], Iter [831/3125], train_loss:0.153447\n",
      "Epoch [1/2], Iter [832/3125], train_loss:0.174136\n",
      "Epoch [1/2], Iter [833/3125], train_loss:0.166332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [834/3125], train_loss:0.157354\n",
      "Epoch [1/2], Iter [835/3125], train_loss:0.120264\n",
      "Epoch [1/2], Iter [836/3125], train_loss:0.148319\n",
      "Epoch [1/2], Iter [837/3125], train_loss:0.156353\n",
      "Epoch [1/2], Iter [838/3125], train_loss:0.153210\n",
      "Epoch [1/2], Iter [839/3125], train_loss:0.169396\n",
      "Epoch [1/2], Iter [840/3125], train_loss:0.163863\n",
      "Epoch [1/2], Iter [841/3125], train_loss:0.156365\n",
      "Epoch [1/2], Iter [842/3125], train_loss:0.166741\n",
      "Epoch [1/2], Iter [843/3125], train_loss:0.153688\n",
      "Epoch [1/2], Iter [844/3125], train_loss:0.173625\n",
      "Epoch [1/2], Iter [845/3125], train_loss:0.167021\n",
      "Epoch [1/2], Iter [846/3125], train_loss:0.149013\n",
      "Epoch [1/2], Iter [847/3125], train_loss:0.165667\n",
      "Epoch [1/2], Iter [848/3125], train_loss:0.153663\n",
      "Epoch [1/2], Iter [849/3125], train_loss:0.179361\n",
      "Epoch [1/2], Iter [850/3125], train_loss:0.175290\n",
      "Epoch [1/2], Iter [851/3125], train_loss:0.168034\n",
      "Epoch [1/2], Iter [852/3125], train_loss:0.161994\n",
      "Epoch [1/2], Iter [853/3125], train_loss:0.171823\n",
      "Epoch [1/2], Iter [854/3125], train_loss:0.147653\n",
      "Epoch [1/2], Iter [855/3125], train_loss:0.159570\n",
      "Epoch [1/2], Iter [856/3125], train_loss:0.157177\n",
      "Epoch [1/2], Iter [857/3125], train_loss:0.155356\n",
      "Epoch [1/2], Iter [858/3125], train_loss:0.159401\n",
      "Epoch [1/2], Iter [859/3125], train_loss:0.179499\n",
      "Epoch [1/2], Iter [860/3125], train_loss:0.153504\n",
      "Epoch [1/2], Iter [861/3125], train_loss:0.174314\n",
      "Epoch [1/2], Iter [862/3125], train_loss:0.145309\n",
      "Epoch [1/2], Iter [863/3125], train_loss:0.170880\n",
      "Epoch [1/2], Iter [864/3125], train_loss:0.171654\n",
      "Epoch [1/2], Iter [865/3125], train_loss:0.125795\n",
      "Epoch [1/2], Iter [866/3125], train_loss:0.161326\n",
      "Epoch [1/2], Iter [867/3125], train_loss:0.170622\n",
      "Epoch [1/2], Iter [868/3125], train_loss:0.164444\n",
      "Epoch [1/2], Iter [869/3125], train_loss:0.138547\n",
      "Epoch [1/2], Iter [870/3125], train_loss:0.158241\n",
      "Epoch [1/2], Iter [871/3125], train_loss:0.158963\n",
      "Epoch [1/2], Iter [872/3125], train_loss:0.198872\n",
      "Epoch [1/2], Iter [873/3125], train_loss:0.171953\n",
      "Epoch [1/2], Iter [874/3125], train_loss:0.135011\n",
      "Epoch [1/2], Iter [875/3125], train_loss:0.187574\n",
      "Epoch [1/2], Iter [876/3125], train_loss:0.183588\n",
      "Epoch [1/2], Iter [877/3125], train_loss:0.172207\n",
      "Epoch [1/2], Iter [878/3125], train_loss:0.163572\n",
      "Epoch [1/2], Iter [879/3125], train_loss:0.177148\n",
      "Epoch [1/2], Iter [880/3125], train_loss:0.156533\n",
      "Epoch [1/2], Iter [881/3125], train_loss:0.164676\n",
      "Epoch [1/2], Iter [882/3125], train_loss:0.155344\n",
      "Epoch [1/2], Iter [883/3125], train_loss:0.179421\n",
      "Epoch [1/2], Iter [884/3125], train_loss:0.152775\n",
      "Epoch [1/2], Iter [885/3125], train_loss:0.183656\n",
      "Epoch [1/2], Iter [886/3125], train_loss:0.178685\n",
      "Epoch [1/2], Iter [887/3125], train_loss:0.174813\n",
      "Epoch [1/2], Iter [888/3125], train_loss:0.164418\n",
      "Epoch [1/2], Iter [889/3125], train_loss:0.151287\n",
      "Epoch [1/2], Iter [890/3125], train_loss:0.159186\n",
      "Epoch [1/2], Iter [891/3125], train_loss:0.176169\n",
      "Epoch [1/2], Iter [892/3125], train_loss:0.153548\n",
      "Epoch [1/2], Iter [893/3125], train_loss:0.163016\n",
      "Epoch [1/2], Iter [894/3125], train_loss:0.152066\n",
      "Epoch [1/2], Iter [895/3125], train_loss:0.161777\n",
      "Epoch [1/2], Iter [896/3125], train_loss:0.147675\n",
      "Epoch [1/2], Iter [897/3125], train_loss:0.176385\n",
      "Epoch [1/2], Iter [898/3125], train_loss:0.163108\n",
      "Epoch [1/2], Iter [899/3125], train_loss:0.157772\n",
      "Epoch [1/2], Iter [900/3125], train_loss:0.176365\n",
      "Epoch [1/2], Iter [901/3125], train_loss:0.163414\n",
      "Epoch [1/2], Iter [902/3125], train_loss:0.152687\n",
      "Epoch [1/2], Iter [903/3125], train_loss:0.149312\n",
      "Epoch [1/2], Iter [904/3125], train_loss:0.145944\n",
      "Epoch [1/2], Iter [905/3125], train_loss:0.183935\n",
      "Epoch [1/2], Iter [906/3125], train_loss:0.141416\n",
      "Epoch [1/2], Iter [907/3125], train_loss:0.148432\n",
      "Epoch [1/2], Iter [908/3125], train_loss:0.161458\n",
      "Epoch [1/2], Iter [909/3125], train_loss:0.159551\n",
      "Epoch [1/2], Iter [910/3125], train_loss:0.147279\n",
      "Epoch [1/2], Iter [911/3125], train_loss:0.149100\n",
      "Epoch [1/2], Iter [912/3125], train_loss:0.147561\n",
      "Epoch [1/2], Iter [913/3125], train_loss:0.153887\n",
      "Epoch [1/2], Iter [914/3125], train_loss:0.155617\n",
      "Epoch [1/2], Iter [915/3125], train_loss:0.138967\n",
      "Epoch [1/2], Iter [916/3125], train_loss:0.187655\n",
      "Epoch [1/2], Iter [917/3125], train_loss:0.189089\n",
      "Epoch [1/2], Iter [918/3125], train_loss:0.185985\n",
      "Epoch [1/2], Iter [919/3125], train_loss:0.159035\n",
      "Epoch [1/2], Iter [920/3125], train_loss:0.158106\n",
      "Epoch [1/2], Iter [921/3125], train_loss:0.160929\n",
      "Epoch [1/2], Iter [922/3125], train_loss:0.165616\n",
      "Epoch [1/2], Iter [923/3125], train_loss:0.159126\n",
      "Epoch [1/2], Iter [924/3125], train_loss:0.166481\n",
      "Epoch [1/2], Iter [925/3125], train_loss:0.166022\n",
      "Epoch [1/2], Iter [926/3125], train_loss:0.143194\n",
      "Epoch [1/2], Iter [927/3125], train_loss:0.166617\n",
      "Epoch [1/2], Iter [928/3125], train_loss:0.165519\n",
      "Epoch [1/2], Iter [929/3125], train_loss:0.149431\n",
      "Epoch [1/2], Iter [930/3125], train_loss:0.158727\n",
      "Epoch [1/2], Iter [931/3125], train_loss:0.143095\n",
      "Epoch [1/2], Iter [932/3125], train_loss:0.153236\n",
      "Epoch [1/2], Iter [933/3125], train_loss:0.148599\n",
      "Epoch [1/2], Iter [934/3125], train_loss:0.159922\n",
      "Epoch [1/2], Iter [935/3125], train_loss:0.168778\n",
      "Epoch [1/2], Iter [936/3125], train_loss:0.149560\n",
      "Epoch [1/2], Iter [937/3125], train_loss:0.160552\n",
      "Epoch [1/2], Iter [938/3125], train_loss:0.151009\n",
      "Epoch [1/2], Iter [939/3125], train_loss:0.171371\n",
      "Epoch [1/2], Iter [940/3125], train_loss:0.156552\n",
      "Epoch [1/2], Iter [941/3125], train_loss:0.153480\n",
      "Epoch [1/2], Iter [942/3125], train_loss:0.144583\n",
      "Epoch [1/2], Iter [943/3125], train_loss:0.156411\n",
      "Epoch [1/2], Iter [944/3125], train_loss:0.153091\n",
      "Epoch [1/2], Iter [945/3125], train_loss:0.158801\n",
      "Epoch [1/2], Iter [946/3125], train_loss:0.139097\n",
      "Epoch [1/2], Iter [947/3125], train_loss:0.171316\n",
      "Epoch [1/2], Iter [948/3125], train_loss:0.179716\n",
      "Epoch [1/2], Iter [949/3125], train_loss:0.150855\n",
      "Epoch [1/2], Iter [950/3125], train_loss:0.159264\n",
      "Epoch [1/2], Iter [951/3125], train_loss:0.178506\n",
      "Epoch [1/2], Iter [952/3125], train_loss:0.165264\n",
      "Epoch [1/2], Iter [953/3125], train_loss:0.163345\n",
      "Epoch [1/2], Iter [954/3125], train_loss:0.163006\n",
      "Epoch [1/2], Iter [955/3125], train_loss:0.180055\n",
      "Epoch [1/2], Iter [956/3125], train_loss:0.152678\n",
      "Epoch [1/2], Iter [957/3125], train_loss:0.149015\n",
      "Epoch [1/2], Iter [958/3125], train_loss:0.167205\n",
      "Epoch [1/2], Iter [959/3125], train_loss:0.159652\n",
      "Epoch [1/2], Iter [960/3125], train_loss:0.172454\n",
      "Epoch [1/2], Iter [961/3125], train_loss:0.152453\n",
      "Epoch [1/2], Iter [962/3125], train_loss:0.159779\n",
      "Epoch [1/2], Iter [963/3125], train_loss:0.157254\n",
      "Epoch [1/2], Iter [964/3125], train_loss:0.171195\n",
      "Epoch [1/2], Iter [965/3125], train_loss:0.129605\n",
      "Epoch [1/2], Iter [966/3125], train_loss:0.171718\n",
      "Epoch [1/2], Iter [967/3125], train_loss:0.135528\n",
      "Epoch [1/2], Iter [968/3125], train_loss:0.171078\n",
      "Epoch [1/2], Iter [969/3125], train_loss:0.177459\n",
      "Epoch [1/2], Iter [970/3125], train_loss:0.155430\n",
      "Epoch [1/2], Iter [971/3125], train_loss:0.162782\n",
      "Epoch [1/2], Iter [972/3125], train_loss:0.179943\n",
      "Epoch [1/2], Iter [973/3125], train_loss:0.159568\n",
      "Epoch [1/2], Iter [974/3125], train_loss:0.145395\n",
      "Epoch [1/2], Iter [975/3125], train_loss:0.162883\n",
      "Epoch [1/2], Iter [976/3125], train_loss:0.152242\n",
      "Epoch [1/2], Iter [977/3125], train_loss:0.178401\n",
      "Epoch [1/2], Iter [978/3125], train_loss:0.149824\n",
      "Epoch [1/2], Iter [979/3125], train_loss:0.164016\n",
      "Epoch [1/2], Iter [980/3125], train_loss:0.173642\n",
      "Epoch [1/2], Iter [981/3125], train_loss:0.184837\n",
      "Epoch [1/2], Iter [982/3125], train_loss:0.157643\n",
      "Epoch [1/2], Iter [983/3125], train_loss:0.170323\n",
      "Epoch [1/2], Iter [984/3125], train_loss:0.145053\n",
      "Epoch [1/2], Iter [985/3125], train_loss:0.177159\n",
      "Epoch [1/2], Iter [986/3125], train_loss:0.170435\n",
      "Epoch [1/2], Iter [987/3125], train_loss:0.140393\n",
      "Epoch [1/2], Iter [988/3125], train_loss:0.170333\n",
      "Epoch [1/2], Iter [989/3125], train_loss:0.154973\n",
      "Epoch [1/2], Iter [990/3125], train_loss:0.168512\n",
      "Epoch [1/2], Iter [991/3125], train_loss:0.171748\n",
      "Epoch [1/2], Iter [992/3125], train_loss:0.191529\n",
      "Epoch [1/2], Iter [993/3125], train_loss:0.164100\n",
      "Epoch [1/2], Iter [994/3125], train_loss:0.169794\n",
      "Epoch [1/2], Iter [995/3125], train_loss:0.161297\n",
      "Epoch [1/2], Iter [996/3125], train_loss:0.154997\n",
      "Epoch [1/2], Iter [997/3125], train_loss:0.174858\n",
      "Epoch [1/2], Iter [998/3125], train_loss:0.131562\n",
      "Epoch [1/2], Iter [999/3125], train_loss:0.170373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [1000/3125], train_loss:0.174953\n",
      "Epoch [1/2], Iter [1001/3125], train_loss:0.171201\n",
      "Epoch [1/2], Iter [1002/3125], train_loss:0.157745\n",
      "Epoch [1/2], Iter [1003/3125], train_loss:0.165321\n",
      "Epoch [1/2], Iter [1004/3125], train_loss:0.166191\n",
      "Epoch [1/2], Iter [1005/3125], train_loss:0.161590\n",
      "Epoch [1/2], Iter [1006/3125], train_loss:0.155218\n",
      "Epoch [1/2], Iter [1007/3125], train_loss:0.161306\n",
      "Epoch [1/2], Iter [1008/3125], train_loss:0.160885\n",
      "Epoch [1/2], Iter [1009/3125], train_loss:0.150420\n",
      "Epoch [1/2], Iter [1010/3125], train_loss:0.180716\n",
      "Epoch [1/2], Iter [1011/3125], train_loss:0.170864\n",
      "Epoch [1/2], Iter [1012/3125], train_loss:0.155604\n",
      "Epoch [1/2], Iter [1013/3125], train_loss:0.138882\n",
      "Epoch [1/2], Iter [1014/3125], train_loss:0.163906\n",
      "Epoch [1/2], Iter [1015/3125], train_loss:0.157286\n",
      "Epoch [1/2], Iter [1016/3125], train_loss:0.176689\n",
      "Epoch [1/2], Iter [1017/3125], train_loss:0.164429\n",
      "Epoch [1/2], Iter [1018/3125], train_loss:0.151421\n",
      "Epoch [1/2], Iter [1019/3125], train_loss:0.173269\n",
      "Epoch [1/2], Iter [1020/3125], train_loss:0.159520\n",
      "Epoch [1/2], Iter [1021/3125], train_loss:0.136108\n",
      "Epoch [1/2], Iter [1022/3125], train_loss:0.168635\n",
      "Epoch [1/2], Iter [1023/3125], train_loss:0.172606\n",
      "Epoch [1/2], Iter [1024/3125], train_loss:0.169962\n",
      "Epoch [1/2], Iter [1025/3125], train_loss:0.171667\n",
      "Epoch [1/2], Iter [1026/3125], train_loss:0.186360\n",
      "Epoch [1/2], Iter [1027/3125], train_loss:0.154808\n",
      "Epoch [1/2], Iter [1028/3125], train_loss:0.162741\n",
      "Epoch [1/2], Iter [1029/3125], train_loss:0.168956\n",
      "Epoch [1/2], Iter [1030/3125], train_loss:0.167106\n",
      "Epoch [1/2], Iter [1031/3125], train_loss:0.150996\n",
      "Epoch [1/2], Iter [1032/3125], train_loss:0.148269\n",
      "Epoch [1/2], Iter [1033/3125], train_loss:0.159704\n",
      "Epoch [1/2], Iter [1034/3125], train_loss:0.169828\n",
      "Epoch [1/2], Iter [1035/3125], train_loss:0.170876\n",
      "Epoch [1/2], Iter [1036/3125], train_loss:0.152638\n",
      "Epoch [1/2], Iter [1037/3125], train_loss:0.156386\n",
      "Epoch [1/2], Iter [1038/3125], train_loss:0.158583\n",
      "Epoch [1/2], Iter [1039/3125], train_loss:0.131727\n",
      "Epoch [1/2], Iter [1040/3125], train_loss:0.159804\n",
      "Epoch [1/2], Iter [1041/3125], train_loss:0.150478\n",
      "Epoch [1/2], Iter [1042/3125], train_loss:0.172487\n",
      "Epoch [1/2], Iter [1043/3125], train_loss:0.172604\n",
      "Epoch [1/2], Iter [1044/3125], train_loss:0.176825\n",
      "Epoch [1/2], Iter [1045/3125], train_loss:0.155156\n",
      "Epoch [1/2], Iter [1046/3125], train_loss:0.159919\n",
      "Epoch [1/2], Iter [1047/3125], train_loss:0.158133\n",
      "Epoch [1/2], Iter [1048/3125], train_loss:0.171692\n",
      "Epoch [1/2], Iter [1049/3125], train_loss:0.148961\n",
      "Epoch [1/2], Iter [1050/3125], train_loss:0.145803\n",
      "Epoch [1/2], Iter [1051/3125], train_loss:0.166840\n",
      "Epoch [1/2], Iter [1052/3125], train_loss:0.144305\n",
      "Epoch [1/2], Iter [1053/3125], train_loss:0.148482\n",
      "Epoch [1/2], Iter [1054/3125], train_loss:0.159671\n",
      "Epoch [1/2], Iter [1055/3125], train_loss:0.160208\n",
      "Epoch [1/2], Iter [1056/3125], train_loss:0.167555\n",
      "Epoch [1/2], Iter [1057/3125], train_loss:0.161161\n",
      "Epoch [1/2], Iter [1058/3125], train_loss:0.149388\n",
      "Epoch [1/2], Iter [1059/3125], train_loss:0.181070\n",
      "Epoch [1/2], Iter [1060/3125], train_loss:0.171973\n",
      "Epoch [1/2], Iter [1061/3125], train_loss:0.180709\n",
      "Epoch [1/2], Iter [1062/3125], train_loss:0.153507\n",
      "Epoch [1/2], Iter [1063/3125], train_loss:0.145896\n",
      "Epoch [1/2], Iter [1064/3125], train_loss:0.166199\n",
      "Epoch [1/2], Iter [1065/3125], train_loss:0.166107\n",
      "Epoch [1/2], Iter [1066/3125], train_loss:0.155540\n",
      "Epoch [1/2], Iter [1067/3125], train_loss:0.154284\n",
      "Epoch [1/2], Iter [1068/3125], train_loss:0.187118\n",
      "Epoch [1/2], Iter [1069/3125], train_loss:0.159748\n",
      "Epoch [1/2], Iter [1070/3125], train_loss:0.164387\n",
      "Epoch [1/2], Iter [1071/3125], train_loss:0.142183\n",
      "Epoch [1/2], Iter [1072/3125], train_loss:0.138724\n",
      "Epoch [1/2], Iter [1073/3125], train_loss:0.146154\n",
      "Epoch [1/2], Iter [1074/3125], train_loss:0.162630\n",
      "Epoch [1/2], Iter [1075/3125], train_loss:0.185121\n",
      "Epoch [1/2], Iter [1076/3125], train_loss:0.160997\n",
      "Epoch [1/2], Iter [1077/3125], train_loss:0.179530\n",
      "Epoch [1/2], Iter [1078/3125], train_loss:0.153985\n",
      "Epoch [1/2], Iter [1079/3125], train_loss:0.147778\n",
      "Epoch [1/2], Iter [1080/3125], train_loss:0.149064\n",
      "Epoch [1/2], Iter [1081/3125], train_loss:0.151860\n",
      "Epoch [1/2], Iter [1082/3125], train_loss:0.161012\n",
      "Epoch [1/2], Iter [1083/3125], train_loss:0.197195\n",
      "Epoch [1/2], Iter [1084/3125], train_loss:0.157916\n",
      "Epoch [1/2], Iter [1085/3125], train_loss:0.162013\n",
      "Epoch [1/2], Iter [1086/3125], train_loss:0.160678\n",
      "Epoch [1/2], Iter [1087/3125], train_loss:0.168688\n",
      "Epoch [1/2], Iter [1088/3125], train_loss:0.139971\n",
      "Epoch [1/2], Iter [1089/3125], train_loss:0.184158\n",
      "Epoch [1/2], Iter [1090/3125], train_loss:0.184676\n",
      "Epoch [1/2], Iter [1091/3125], train_loss:0.150608\n",
      "Epoch [1/2], Iter [1092/3125], train_loss:0.151490\n",
      "Epoch [1/2], Iter [1093/3125], train_loss:0.176660\n",
      "Epoch [1/2], Iter [1094/3125], train_loss:0.153394\n",
      "Epoch [1/2], Iter [1095/3125], train_loss:0.163054\n",
      "Epoch [1/2], Iter [1096/3125], train_loss:0.144125\n",
      "Epoch [1/2], Iter [1097/3125], train_loss:0.167320\n",
      "Epoch [1/2], Iter [1098/3125], train_loss:0.158095\n",
      "Epoch [1/2], Iter [1099/3125], train_loss:0.150448\n",
      "Epoch [1/2], Iter [1100/3125], train_loss:0.167379\n",
      "Epoch [1/2], Iter [1101/3125], train_loss:0.151696\n",
      "Epoch [1/2], Iter [1102/3125], train_loss:0.174957\n",
      "Epoch [1/2], Iter [1103/3125], train_loss:0.159035\n",
      "Epoch [1/2], Iter [1104/3125], train_loss:0.163059\n",
      "Epoch [1/2], Iter [1105/3125], train_loss:0.170439\n",
      "Epoch [1/2], Iter [1106/3125], train_loss:0.163471\n",
      "Epoch [1/2], Iter [1107/3125], train_loss:0.180205\n",
      "Epoch [1/2], Iter [1108/3125], train_loss:0.148346\n",
      "Epoch [1/2], Iter [1109/3125], train_loss:0.170757\n",
      "Epoch [1/2], Iter [1110/3125], train_loss:0.155306\n",
      "Epoch [1/2], Iter [1111/3125], train_loss:0.173857\n",
      "Epoch [1/2], Iter [1112/3125], train_loss:0.149888\n",
      "Epoch [1/2], Iter [1113/3125], train_loss:0.164874\n",
      "Epoch [1/2], Iter [1114/3125], train_loss:0.165291\n",
      "Epoch [1/2], Iter [1115/3125], train_loss:0.143524\n",
      "Epoch [1/2], Iter [1116/3125], train_loss:0.151315\n",
      "Epoch [1/2], Iter [1117/3125], train_loss:0.169421\n",
      "Epoch [1/2], Iter [1118/3125], train_loss:0.166722\n",
      "Epoch [1/2], Iter [1119/3125], train_loss:0.167637\n",
      "Epoch [1/2], Iter [1120/3125], train_loss:0.155744\n",
      "Epoch [1/2], Iter [1121/3125], train_loss:0.162011\n",
      "Epoch [1/2], Iter [1122/3125], train_loss:0.160295\n",
      "Epoch [1/2], Iter [1123/3125], train_loss:0.154625\n",
      "Epoch [1/2], Iter [1124/3125], train_loss:0.151765\n",
      "Epoch [1/2], Iter [1125/3125], train_loss:0.170621\n",
      "Epoch [1/2], Iter [1126/3125], train_loss:0.155552\n",
      "Epoch [1/2], Iter [1127/3125], train_loss:0.173134\n",
      "Epoch [1/2], Iter [1128/3125], train_loss:0.153150\n",
      "Epoch [1/2], Iter [1129/3125], train_loss:0.145719\n",
      "Epoch [1/2], Iter [1130/3125], train_loss:0.187136\n",
      "Epoch [1/2], Iter [1131/3125], train_loss:0.169417\n",
      "Epoch [1/2], Iter [1132/3125], train_loss:0.178974\n",
      "Epoch [1/2], Iter [1133/3125], train_loss:0.149931\n",
      "Epoch [1/2], Iter [1134/3125], train_loss:0.155474\n",
      "Epoch [1/2], Iter [1135/3125], train_loss:0.161715\n",
      "Epoch [1/2], Iter [1136/3125], train_loss:0.165408\n",
      "Epoch [1/2], Iter [1137/3125], train_loss:0.170022\n",
      "Epoch [1/2], Iter [1138/3125], train_loss:0.147393\n",
      "Epoch [1/2], Iter [1139/3125], train_loss:0.175394\n",
      "Epoch [1/2], Iter [1140/3125], train_loss:0.157841\n",
      "Epoch [1/2], Iter [1141/3125], train_loss:0.164718\n",
      "Epoch [1/2], Iter [1142/3125], train_loss:0.154701\n",
      "Epoch [1/2], Iter [1143/3125], train_loss:0.168679\n",
      "Epoch [1/2], Iter [1144/3125], train_loss:0.181446\n",
      "Epoch [1/2], Iter [1145/3125], train_loss:0.148103\n",
      "Epoch [1/2], Iter [1146/3125], train_loss:0.151220\n",
      "Epoch [1/2], Iter [1147/3125], train_loss:0.186586\n",
      "Epoch [1/2], Iter [1148/3125], train_loss:0.174347\n",
      "Epoch [1/2], Iter [1149/3125], train_loss:0.170932\n",
      "Epoch [1/2], Iter [1150/3125], train_loss:0.165207\n",
      "Epoch [1/2], Iter [1151/3125], train_loss:0.158725\n",
      "Epoch [1/2], Iter [1152/3125], train_loss:0.155164\n",
      "Epoch [1/2], Iter [1153/3125], train_loss:0.171893\n",
      "Epoch [1/2], Iter [1154/3125], train_loss:0.162601\n",
      "Epoch [1/2], Iter [1155/3125], train_loss:0.160125\n",
      "Epoch [1/2], Iter [1156/3125], train_loss:0.181936\n",
      "Epoch [1/2], Iter [1157/3125], train_loss:0.172337\n",
      "Epoch [1/2], Iter [1158/3125], train_loss:0.147319\n",
      "Epoch [1/2], Iter [1159/3125], train_loss:0.183120\n",
      "Epoch [1/2], Iter [1160/3125], train_loss:0.168000\n",
      "Epoch [1/2], Iter [1161/3125], train_loss:0.163454\n",
      "Epoch [1/2], Iter [1162/3125], train_loss:0.158614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [1163/3125], train_loss:0.170988\n",
      "Epoch [1/2], Iter [1164/3125], train_loss:0.162558\n",
      "Epoch [1/2], Iter [1165/3125], train_loss:0.164345\n",
      "Epoch [1/2], Iter [1166/3125], train_loss:0.151922\n",
      "Epoch [1/2], Iter [1167/3125], train_loss:0.182245\n",
      "Epoch [1/2], Iter [1168/3125], train_loss:0.162371\n",
      "Epoch [1/2], Iter [1169/3125], train_loss:0.155639\n",
      "Epoch [1/2], Iter [1170/3125], train_loss:0.157078\n",
      "Epoch [1/2], Iter [1171/3125], train_loss:0.168648\n",
      "Epoch [1/2], Iter [1172/3125], train_loss:0.160894\n",
      "Epoch [1/2], Iter [1173/3125], train_loss:0.172699\n",
      "Epoch [1/2], Iter [1174/3125], train_loss:0.186120\n",
      "Epoch [1/2], Iter [1175/3125], train_loss:0.163291\n",
      "Epoch [1/2], Iter [1176/3125], train_loss:0.160210\n",
      "Epoch [1/2], Iter [1177/3125], train_loss:0.157460\n",
      "Epoch [1/2], Iter [1178/3125], train_loss:0.169464\n",
      "Epoch [1/2], Iter [1179/3125], train_loss:0.155117\n",
      "Epoch [1/2], Iter [1180/3125], train_loss:0.175044\n",
      "Epoch [1/2], Iter [1181/3125], train_loss:0.171335\n",
      "Epoch [1/2], Iter [1182/3125], train_loss:0.156485\n",
      "Epoch [1/2], Iter [1183/3125], train_loss:0.166067\n",
      "Epoch [1/2], Iter [1184/3125], train_loss:0.161618\n",
      "Epoch [1/2], Iter [1185/3125], train_loss:0.158961\n",
      "Epoch [1/2], Iter [1186/3125], train_loss:0.158767\n",
      "Epoch [1/2], Iter [1187/3125], train_loss:0.158581\n",
      "Epoch [1/2], Iter [1188/3125], train_loss:0.150107\n",
      "Epoch [1/2], Iter [1189/3125], train_loss:0.151393\n",
      "Epoch [1/2], Iter [1190/3125], train_loss:0.157746\n",
      "Epoch [1/2], Iter [1191/3125], train_loss:0.162504\n",
      "Epoch [1/2], Iter [1192/3125], train_loss:0.162217\n",
      "Epoch [1/2], Iter [1193/3125], train_loss:0.184125\n",
      "Epoch [1/2], Iter [1194/3125], train_loss:0.155755\n",
      "Epoch [1/2], Iter [1195/3125], train_loss:0.163561\n",
      "Epoch [1/2], Iter [1196/3125], train_loss:0.169904\n",
      "Epoch [1/2], Iter [1197/3125], train_loss:0.163287\n",
      "Epoch [1/2], Iter [1198/3125], train_loss:0.162994\n",
      "Epoch [1/2], Iter [1199/3125], train_loss:0.179970\n",
      "Epoch [1/2], Iter [1200/3125], train_loss:0.175508\n",
      "Epoch [1/2], Iter [1201/3125], train_loss:0.171165\n",
      "Epoch [1/2], Iter [1202/3125], train_loss:0.157112\n",
      "Epoch [1/2], Iter [1203/3125], train_loss:0.162217\n",
      "Epoch [1/2], Iter [1204/3125], train_loss:0.168821\n",
      "Epoch [1/2], Iter [1205/3125], train_loss:0.197255\n",
      "Epoch [1/2], Iter [1206/3125], train_loss:0.160194\n",
      "Epoch [1/2], Iter [1207/3125], train_loss:0.151903\n",
      "Epoch [1/2], Iter [1208/3125], train_loss:0.149178\n",
      "Epoch [1/2], Iter [1209/3125], train_loss:0.146489\n",
      "Epoch [1/2], Iter [1210/3125], train_loss:0.154193\n",
      "Epoch [1/2], Iter [1211/3125], train_loss:0.157028\n",
      "Epoch [1/2], Iter [1212/3125], train_loss:0.162961\n",
      "Epoch [1/2], Iter [1213/3125], train_loss:0.176358\n",
      "Epoch [1/2], Iter [1214/3125], train_loss:0.170513\n",
      "Epoch [1/2], Iter [1215/3125], train_loss:0.166415\n",
      "Epoch [1/2], Iter [1216/3125], train_loss:0.150504\n",
      "Epoch [1/2], Iter [1217/3125], train_loss:0.169194\n",
      "Epoch [1/2], Iter [1218/3125], train_loss:0.173286\n",
      "Epoch [1/2], Iter [1219/3125], train_loss:0.170073\n",
      "Epoch [1/2], Iter [1220/3125], train_loss:0.157464\n",
      "Epoch [1/2], Iter [1221/3125], train_loss:0.153022\n",
      "Epoch [1/2], Iter [1222/3125], train_loss:0.164855\n",
      "Epoch [1/2], Iter [1223/3125], train_loss:0.155083\n",
      "Epoch [1/2], Iter [1224/3125], train_loss:0.165551\n",
      "Epoch [1/2], Iter [1225/3125], train_loss:0.185195\n",
      "Epoch [1/2], Iter [1226/3125], train_loss:0.177821\n",
      "Epoch [1/2], Iter [1227/3125], train_loss:0.154561\n",
      "Epoch [1/2], Iter [1228/3125], train_loss:0.159085\n",
      "Epoch [1/2], Iter [1229/3125], train_loss:0.171906\n",
      "Epoch [1/2], Iter [1230/3125], train_loss:0.160470\n",
      "Epoch [1/2], Iter [1231/3125], train_loss:0.151237\n",
      "Epoch [1/2], Iter [1232/3125], train_loss:0.135055\n",
      "Epoch [1/2], Iter [1233/3125], train_loss:0.140605\n",
      "Epoch [1/2], Iter [1234/3125], train_loss:0.183646\n",
      "Epoch [1/2], Iter [1235/3125], train_loss:0.158728\n",
      "Epoch [1/2], Iter [1236/3125], train_loss:0.163355\n",
      "Epoch [1/2], Iter [1237/3125], train_loss:0.148448\n",
      "Epoch [1/2], Iter [1238/3125], train_loss:0.165396\n",
      "Epoch [1/2], Iter [1239/3125], train_loss:0.181543\n",
      "Epoch [1/2], Iter [1240/3125], train_loss:0.166355\n",
      "Epoch [1/2], Iter [1241/3125], train_loss:0.158869\n",
      "Epoch [1/2], Iter [1242/3125], train_loss:0.153979\n",
      "Epoch [1/2], Iter [1243/3125], train_loss:0.155492\n",
      "Epoch [1/2], Iter [1244/3125], train_loss:0.170940\n",
      "Epoch [1/2], Iter [1245/3125], train_loss:0.166005\n",
      "Epoch [1/2], Iter [1246/3125], train_loss:0.158416\n",
      "Epoch [1/2], Iter [1247/3125], train_loss:0.154584\n",
      "Epoch [1/2], Iter [1248/3125], train_loss:0.152003\n",
      "Epoch [1/2], Iter [1249/3125], train_loss:0.168855\n",
      "Epoch [1/2], Iter [1250/3125], train_loss:0.148871\n",
      "Epoch [1/2], Iter [1251/3125], train_loss:0.175113\n",
      "Epoch [1/2], Iter [1252/3125], train_loss:0.149920\n",
      "Epoch [1/2], Iter [1253/3125], train_loss:0.151580\n",
      "Epoch [1/2], Iter [1254/3125], train_loss:0.168768\n",
      "Epoch [1/2], Iter [1255/3125], train_loss:0.166119\n",
      "Epoch [1/2], Iter [1256/3125], train_loss:0.140963\n",
      "Epoch [1/2], Iter [1257/3125], train_loss:0.168684\n",
      "Epoch [1/2], Iter [1258/3125], train_loss:0.158394\n",
      "Epoch [1/2], Iter [1259/3125], train_loss:0.161410\n",
      "Epoch [1/2], Iter [1260/3125], train_loss:0.148364\n",
      "Epoch [1/2], Iter [1261/3125], train_loss:0.165485\n",
      "Epoch [1/2], Iter [1262/3125], train_loss:0.153689\n",
      "Epoch [1/2], Iter [1263/3125], train_loss:0.171761\n",
      "Epoch [1/2], Iter [1264/3125], train_loss:0.163797\n",
      "Epoch [1/2], Iter [1265/3125], train_loss:0.146530\n",
      "Epoch [1/2], Iter [1266/3125], train_loss:0.158110\n",
      "Epoch [1/2], Iter [1267/3125], train_loss:0.160058\n",
      "Epoch [1/2], Iter [1268/3125], train_loss:0.157368\n",
      "Epoch [1/2], Iter [1269/3125], train_loss:0.151690\n",
      "Epoch [1/2], Iter [1270/3125], train_loss:0.142817\n",
      "Epoch [1/2], Iter [1271/3125], train_loss:0.153046\n",
      "Epoch [1/2], Iter [1272/3125], train_loss:0.162205\n",
      "Epoch [1/2], Iter [1273/3125], train_loss:0.179852\n",
      "Epoch [1/2], Iter [1274/3125], train_loss:0.156627\n",
      "Epoch [1/2], Iter [1275/3125], train_loss:0.158944\n",
      "Epoch [1/2], Iter [1276/3125], train_loss:0.148821\n",
      "Epoch [1/2], Iter [1277/3125], train_loss:0.157448\n",
      "Epoch [1/2], Iter [1278/3125], train_loss:0.178943\n",
      "Epoch [1/2], Iter [1279/3125], train_loss:0.170738\n",
      "Epoch [1/2], Iter [1280/3125], train_loss:0.146238\n",
      "Epoch [1/2], Iter [1281/3125], train_loss:0.166454\n",
      "Epoch [1/2], Iter [1282/3125], train_loss:0.147360\n",
      "Epoch [1/2], Iter [1283/3125], train_loss:0.166235\n",
      "Epoch [1/2], Iter [1284/3125], train_loss:0.160503\n",
      "Epoch [1/2], Iter [1285/3125], train_loss:0.155493\n",
      "Epoch [1/2], Iter [1286/3125], train_loss:0.164259\n",
      "Epoch [1/2], Iter [1287/3125], train_loss:0.159880\n",
      "Epoch [1/2], Iter [1288/3125], train_loss:0.174088\n",
      "Epoch [1/2], Iter [1289/3125], train_loss:0.158363\n",
      "Epoch [1/2], Iter [1290/3125], train_loss:0.160815\n",
      "Epoch [1/2], Iter [1291/3125], train_loss:0.168558\n",
      "Epoch [1/2], Iter [1292/3125], train_loss:0.155379\n",
      "Epoch [1/2], Iter [1293/3125], train_loss:0.158657\n",
      "Epoch [1/2], Iter [1294/3125], train_loss:0.152092\n",
      "Epoch [1/2], Iter [1295/3125], train_loss:0.151002\n",
      "Epoch [1/2], Iter [1296/3125], train_loss:0.177545\n",
      "Epoch [1/2], Iter [1297/3125], train_loss:0.155996\n",
      "Epoch [1/2], Iter [1298/3125], train_loss:0.153431\n",
      "Epoch [1/2], Iter [1299/3125], train_loss:0.160402\n",
      "Epoch [1/2], Iter [1300/3125], train_loss:0.164605\n",
      "Epoch [1/2], Iter [1301/3125], train_loss:0.181966\n",
      "Epoch [1/2], Iter [1302/3125], train_loss:0.150270\n",
      "Epoch [1/2], Iter [1303/3125], train_loss:0.153899\n",
      "Epoch [1/2], Iter [1304/3125], train_loss:0.167255\n",
      "Epoch [1/2], Iter [1305/3125], train_loss:0.164807\n",
      "Epoch [1/2], Iter [1306/3125], train_loss:0.176301\n",
      "Epoch [1/2], Iter [1307/3125], train_loss:0.155036\n",
      "Epoch [1/2], Iter [1308/3125], train_loss:0.167926\n",
      "Epoch [1/2], Iter [1309/3125], train_loss:0.176630\n",
      "Epoch [1/2], Iter [1310/3125], train_loss:0.160102\n",
      "Epoch [1/2], Iter [1311/3125], train_loss:0.173452\n",
      "Epoch [1/2], Iter [1312/3125], train_loss:0.172366\n",
      "Epoch [1/2], Iter [1313/3125], train_loss:0.156772\n",
      "Epoch [1/2], Iter [1314/3125], train_loss:0.168792\n",
      "Epoch [1/2], Iter [1315/3125], train_loss:0.178687\n",
      "Epoch [1/2], Iter [1316/3125], train_loss:0.181647\n",
      "Epoch [1/2], Iter [1317/3125], train_loss:0.154158\n",
      "Epoch [1/2], Iter [1318/3125], train_loss:0.151710\n",
      "Epoch [1/2], Iter [1319/3125], train_loss:0.183539\n",
      "Epoch [1/2], Iter [1320/3125], train_loss:0.160138\n",
      "Epoch [1/2], Iter [1321/3125], train_loss:0.177658\n",
      "Epoch [1/2], Iter [1322/3125], train_loss:0.146497\n",
      "Epoch [1/2], Iter [1323/3125], train_loss:0.196226\n",
      "Epoch [1/2], Iter [1324/3125], train_loss:0.165244\n",
      "Epoch [1/2], Iter [1325/3125], train_loss:0.197831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [1326/3125], train_loss:0.175092\n",
      "Epoch [1/2], Iter [1327/3125], train_loss:0.184453\n",
      "Epoch [1/2], Iter [1328/3125], train_loss:0.165453\n",
      "Epoch [1/2], Iter [1329/3125], train_loss:0.145549\n",
      "Epoch [1/2], Iter [1330/3125], train_loss:0.173061\n",
      "Epoch [1/2], Iter [1331/3125], train_loss:0.166073\n",
      "Epoch [1/2], Iter [1332/3125], train_loss:0.156471\n",
      "Epoch [1/2], Iter [1333/3125], train_loss:0.152220\n",
      "Epoch [1/2], Iter [1334/3125], train_loss:0.156158\n",
      "Epoch [1/2], Iter [1335/3125], train_loss:0.165017\n",
      "Epoch [1/2], Iter [1336/3125], train_loss:0.183256\n",
      "Epoch [1/2], Iter [1337/3125], train_loss:0.167704\n",
      "Epoch [1/2], Iter [1338/3125], train_loss:0.154254\n",
      "Epoch [1/2], Iter [1339/3125], train_loss:0.162098\n",
      "Epoch [1/2], Iter [1340/3125], train_loss:0.161697\n",
      "Epoch [1/2], Iter [1341/3125], train_loss:0.164405\n",
      "Epoch [1/2], Iter [1342/3125], train_loss:0.149967\n",
      "Epoch [1/2], Iter [1343/3125], train_loss:0.171982\n",
      "Epoch [1/2], Iter [1344/3125], train_loss:0.155723\n",
      "Epoch [1/2], Iter [1345/3125], train_loss:0.147691\n",
      "Epoch [1/2], Iter [1346/3125], train_loss:0.160214\n",
      "Epoch [1/2], Iter [1347/3125], train_loss:0.154677\n",
      "Epoch [1/2], Iter [1348/3125], train_loss:0.152759\n",
      "Epoch [1/2], Iter [1349/3125], train_loss:0.166476\n",
      "Epoch [1/2], Iter [1350/3125], train_loss:0.163566\n",
      "Epoch [1/2], Iter [1351/3125], train_loss:0.150434\n",
      "Epoch [1/2], Iter [1352/3125], train_loss:0.168793\n",
      "Epoch [1/2], Iter [1353/3125], train_loss:0.162513\n",
      "Epoch [1/2], Iter [1354/3125], train_loss:0.169711\n",
      "Epoch [1/2], Iter [1355/3125], train_loss:0.158046\n",
      "Epoch [1/2], Iter [1356/3125], train_loss:0.151754\n",
      "Epoch [1/2], Iter [1357/3125], train_loss:0.170661\n",
      "Epoch [1/2], Iter [1358/3125], train_loss:0.152679\n",
      "Epoch [1/2], Iter [1359/3125], train_loss:0.167173\n",
      "Epoch [1/2], Iter [1360/3125], train_loss:0.156606\n",
      "Epoch [1/2], Iter [1361/3125], train_loss:0.183170\n",
      "Epoch [1/2], Iter [1362/3125], train_loss:0.142545\n",
      "Epoch [1/2], Iter [1363/3125], train_loss:0.159119\n",
      "Epoch [1/2], Iter [1364/3125], train_loss:0.164405\n",
      "Epoch [1/2], Iter [1365/3125], train_loss:0.159609\n",
      "Epoch [1/2], Iter [1366/3125], train_loss:0.161490\n",
      "Epoch [1/2], Iter [1367/3125], train_loss:0.167248\n",
      "Epoch [1/2], Iter [1368/3125], train_loss:0.165266\n",
      "Epoch [1/2], Iter [1369/3125], train_loss:0.164672\n",
      "Epoch [1/2], Iter [1370/3125], train_loss:0.178968\n",
      "Epoch [1/2], Iter [1371/3125], train_loss:0.139022\n",
      "Epoch [1/2], Iter [1372/3125], train_loss:0.157129\n",
      "Epoch [1/2], Iter [1373/3125], train_loss:0.170236\n",
      "Epoch [1/2], Iter [1374/3125], train_loss:0.172654\n",
      "Epoch [1/2], Iter [1375/3125], train_loss:0.154364\n",
      "Epoch [1/2], Iter [1376/3125], train_loss:0.191031\n",
      "Epoch [1/2], Iter [1377/3125], train_loss:0.154899\n",
      "Epoch [1/2], Iter [1378/3125], train_loss:0.154030\n",
      "Epoch [1/2], Iter [1379/3125], train_loss:0.164986\n",
      "Epoch [1/2], Iter [1380/3125], train_loss:0.149888\n",
      "Epoch [1/2], Iter [1381/3125], train_loss:0.161112\n",
      "Epoch [1/2], Iter [1382/3125], train_loss:0.177446\n",
      "Epoch [1/2], Iter [1383/3125], train_loss:0.181748\n",
      "Epoch [1/2], Iter [1384/3125], train_loss:0.148632\n",
      "Epoch [1/2], Iter [1385/3125], train_loss:0.171001\n",
      "Epoch [1/2], Iter [1386/3125], train_loss:0.146871\n",
      "Epoch [1/2], Iter [1387/3125], train_loss:0.152815\n",
      "Epoch [1/2], Iter [1388/3125], train_loss:0.153880\n",
      "Epoch [1/2], Iter [1389/3125], train_loss:0.167807\n",
      "Epoch [1/2], Iter [1390/3125], train_loss:0.163647\n",
      "Epoch [1/2], Iter [1391/3125], train_loss:0.159752\n",
      "Epoch [1/2], Iter [1392/3125], train_loss:0.148706\n",
      "Epoch [1/2], Iter [1393/3125], train_loss:0.145519\n",
      "Epoch [1/2], Iter [1394/3125], train_loss:0.149635\n",
      "Epoch [1/2], Iter [1395/3125], train_loss:0.156076\n",
      "Epoch [1/2], Iter [1396/3125], train_loss:0.156446\n",
      "Epoch [1/2], Iter [1397/3125], train_loss:0.165825\n",
      "Epoch [1/2], Iter [1398/3125], train_loss:0.145675\n",
      "Epoch [1/2], Iter [1399/3125], train_loss:0.142919\n",
      "Epoch [1/2], Iter [1400/3125], train_loss:0.163214\n",
      "Epoch [1/2], Iter [1401/3125], train_loss:0.155447\n",
      "Epoch [1/2], Iter [1402/3125], train_loss:0.164264\n",
      "Epoch [1/2], Iter [1403/3125], train_loss:0.168581\n",
      "Epoch [1/2], Iter [1404/3125], train_loss:0.149629\n",
      "Epoch [1/2], Iter [1405/3125], train_loss:0.164211\n",
      "Epoch [1/2], Iter [1406/3125], train_loss:0.168869\n",
      "Epoch [1/2], Iter [1407/3125], train_loss:0.153973\n",
      "Epoch [1/2], Iter [1408/3125], train_loss:0.173186\n",
      "Epoch [1/2], Iter [1409/3125], train_loss:0.174420\n",
      "Epoch [1/2], Iter [1410/3125], train_loss:0.154398\n",
      "Epoch [1/2], Iter [1411/3125], train_loss:0.147271\n",
      "Epoch [1/2], Iter [1412/3125], train_loss:0.172150\n",
      "Epoch [1/2], Iter [1413/3125], train_loss:0.144826\n",
      "Epoch [1/2], Iter [1414/3125], train_loss:0.160246\n",
      "Epoch [1/2], Iter [1415/3125], train_loss:0.166100\n",
      "Epoch [1/2], Iter [1416/3125], train_loss:0.151365\n",
      "Epoch [1/2], Iter [1417/3125], train_loss:0.144425\n",
      "Epoch [1/2], Iter [1418/3125], train_loss:0.145632\n",
      "Epoch [1/2], Iter [1419/3125], train_loss:0.167284\n",
      "Epoch [1/2], Iter [1420/3125], train_loss:0.162896\n",
      "Epoch [1/2], Iter [1421/3125], train_loss:0.168027\n",
      "Epoch [1/2], Iter [1422/3125], train_loss:0.160721\n",
      "Epoch [1/2], Iter [1423/3125], train_loss:0.164672\n",
      "Epoch [1/2], Iter [1424/3125], train_loss:0.162177\n",
      "Epoch [1/2], Iter [1425/3125], train_loss:0.166051\n",
      "Epoch [1/2], Iter [1426/3125], train_loss:0.146067\n",
      "Epoch [1/2], Iter [1427/3125], train_loss:0.159922\n",
      "Epoch [1/2], Iter [1428/3125], train_loss:0.152642\n",
      "Epoch [1/2], Iter [1429/3125], train_loss:0.148200\n",
      "Epoch [1/2], Iter [1430/3125], train_loss:0.158262\n",
      "Epoch [1/2], Iter [1431/3125], train_loss:0.149659\n",
      "Epoch [1/2], Iter [1432/3125], train_loss:0.163230\n",
      "Epoch [1/2], Iter [1433/3125], train_loss:0.145847\n",
      "Epoch [1/2], Iter [1434/3125], train_loss:0.173391\n",
      "Epoch [1/2], Iter [1435/3125], train_loss:0.125152\n",
      "Epoch [1/2], Iter [1436/3125], train_loss:0.156048\n",
      "Epoch [1/2], Iter [1437/3125], train_loss:0.157051\n",
      "Epoch [1/2], Iter [1438/3125], train_loss:0.158350\n",
      "Epoch [1/2], Iter [1439/3125], train_loss:0.192877\n",
      "Epoch [1/2], Iter [1440/3125], train_loss:0.167545\n",
      "Epoch [1/2], Iter [1441/3125], train_loss:0.197214\n",
      "Epoch [1/2], Iter [1442/3125], train_loss:0.192135\n",
      "Epoch [1/2], Iter [1443/3125], train_loss:0.172984\n",
      "Epoch [1/2], Iter [1444/3125], train_loss:0.173254\n",
      "Epoch [1/2], Iter [1445/3125], train_loss:0.144135\n",
      "Epoch [1/2], Iter [1446/3125], train_loss:0.169613\n",
      "Epoch [1/2], Iter [1447/3125], train_loss:0.167091\n",
      "Epoch [1/2], Iter [1448/3125], train_loss:0.158223\n",
      "Epoch [1/2], Iter [1449/3125], train_loss:0.172568\n",
      "Epoch [1/2], Iter [1450/3125], train_loss:0.162713\n",
      "Epoch [1/2], Iter [1451/3125], train_loss:0.168839\n",
      "Epoch [1/2], Iter [1452/3125], train_loss:0.168881\n",
      "Epoch [1/2], Iter [1453/3125], train_loss:0.166082\n",
      "Epoch [1/2], Iter [1454/3125], train_loss:0.137113\n",
      "Epoch [1/2], Iter [1455/3125], train_loss:0.156944\n",
      "Epoch [1/2], Iter [1456/3125], train_loss:0.176010\n",
      "Epoch [1/2], Iter [1457/3125], train_loss:0.165683\n",
      "Epoch [1/2], Iter [1458/3125], train_loss:0.166721\n",
      "Epoch [1/2], Iter [1459/3125], train_loss:0.177907\n",
      "Epoch [1/2], Iter [1460/3125], train_loss:0.148519\n",
      "Epoch [1/2], Iter [1461/3125], train_loss:0.178192\n",
      "Epoch [1/2], Iter [1462/3125], train_loss:0.163624\n",
      "Epoch [1/2], Iter [1463/3125], train_loss:0.160104\n",
      "Epoch [1/2], Iter [1464/3125], train_loss:0.175325\n",
      "Epoch [1/2], Iter [1465/3125], train_loss:0.173073\n",
      "Epoch [1/2], Iter [1466/3125], train_loss:0.167916\n",
      "Epoch [1/2], Iter [1467/3125], train_loss:0.161516\n",
      "Epoch [1/2], Iter [1468/3125], train_loss:0.168107\n",
      "Epoch [1/2], Iter [1469/3125], train_loss:0.169824\n",
      "Epoch [1/2], Iter [1470/3125], train_loss:0.160803\n",
      "Epoch [1/2], Iter [1471/3125], train_loss:0.170264\n",
      "Epoch [1/2], Iter [1472/3125], train_loss:0.168911\n",
      "Epoch [1/2], Iter [1473/3125], train_loss:0.143244\n",
      "Epoch [1/2], Iter [1474/3125], train_loss:0.154688\n",
      "Epoch [1/2], Iter [1475/3125], train_loss:0.152704\n",
      "Epoch [1/2], Iter [1476/3125], train_loss:0.153546\n",
      "Epoch [1/2], Iter [1477/3125], train_loss:0.180169\n",
      "Epoch [1/2], Iter [1478/3125], train_loss:0.150831\n",
      "Epoch [1/2], Iter [1479/3125], train_loss:0.171316\n",
      "Epoch [1/2], Iter [1480/3125], train_loss:0.168213\n",
      "Epoch [1/2], Iter [1481/3125], train_loss:0.172205\n",
      "Epoch [1/2], Iter [1482/3125], train_loss:0.142973\n",
      "Epoch [1/2], Iter [1483/3125], train_loss:0.157204\n",
      "Epoch [1/2], Iter [1484/3125], train_loss:0.172524\n",
      "Epoch [1/2], Iter [1485/3125], train_loss:0.157539\n",
      "Epoch [1/2], Iter [1486/3125], train_loss:0.143420\n",
      "Epoch [1/2], Iter [1487/3125], train_loss:0.162053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [1488/3125], train_loss:0.167251\n",
      "Epoch [1/2], Iter [1489/3125], train_loss:0.172743\n",
      "Epoch [1/2], Iter [1490/3125], train_loss:0.166958\n",
      "Epoch [1/2], Iter [1491/3125], train_loss:0.168802\n",
      "Epoch [1/2], Iter [1492/3125], train_loss:0.160231\n",
      "Epoch [1/2], Iter [1493/3125], train_loss:0.171343\n",
      "Epoch [1/2], Iter [1494/3125], train_loss:0.167754\n",
      "Epoch [1/2], Iter [1495/3125], train_loss:0.166312\n",
      "Epoch [1/2], Iter [1496/3125], train_loss:0.162917\n",
      "Epoch [1/2], Iter [1497/3125], train_loss:0.162183\n",
      "Epoch [1/2], Iter [1498/3125], train_loss:0.170274\n",
      "Epoch [1/2], Iter [1499/3125], train_loss:0.177937\n",
      "Epoch [1/2], Iter [1500/3125], train_loss:0.142511\n",
      "Epoch [1/2], Iter [1501/3125], train_loss:0.146676\n",
      "Epoch [1/2], Iter [1502/3125], train_loss:0.165919\n",
      "Epoch [1/2], Iter [1503/3125], train_loss:0.153276\n",
      "Epoch [1/2], Iter [1504/3125], train_loss:0.169737\n",
      "Epoch [1/2], Iter [1505/3125], train_loss:0.155799\n",
      "Epoch [1/2], Iter [1506/3125], train_loss:0.160062\n",
      "Epoch [1/2], Iter [1507/3125], train_loss:0.156737\n",
      "Epoch [1/2], Iter [1508/3125], train_loss:0.171055\n",
      "Epoch [1/2], Iter [1509/3125], train_loss:0.155235\n",
      "Epoch [1/2], Iter [1510/3125], train_loss:0.144856\n",
      "Epoch [1/2], Iter [1511/3125], train_loss:0.154941\n",
      "Epoch [1/2], Iter [1512/3125], train_loss:0.141613\n",
      "Epoch [1/2], Iter [1513/3125], train_loss:0.169685\n",
      "Epoch [1/2], Iter [1514/3125], train_loss:0.153574\n",
      "Epoch [1/2], Iter [1515/3125], train_loss:0.165675\n",
      "Epoch [1/2], Iter [1516/3125], train_loss:0.194039\n",
      "Epoch [1/2], Iter [1517/3125], train_loss:0.136731\n",
      "Epoch [1/2], Iter [1518/3125], train_loss:0.162655\n",
      "Epoch [1/2], Iter [1519/3125], train_loss:0.157449\n",
      "Epoch [1/2], Iter [1520/3125], train_loss:0.172672\n",
      "Epoch [1/2], Iter [1521/3125], train_loss:0.185573\n",
      "Epoch [1/2], Iter [1522/3125], train_loss:0.177209\n",
      "Epoch [1/2], Iter [1523/3125], train_loss:0.144910\n",
      "Epoch [1/2], Iter [1524/3125], train_loss:0.160207\n",
      "Epoch [1/2], Iter [1525/3125], train_loss:0.163809\n",
      "Epoch [1/2], Iter [1526/3125], train_loss:0.161429\n",
      "Epoch [1/2], Iter [1527/3125], train_loss:0.149817\n",
      "Epoch [1/2], Iter [1528/3125], train_loss:0.182072\n",
      "Epoch [1/2], Iter [1529/3125], train_loss:0.175234\n",
      "Epoch [1/2], Iter [1530/3125], train_loss:0.170426\n",
      "Epoch [1/2], Iter [1531/3125], train_loss:0.155083\n",
      "Epoch [1/2], Iter [1532/3125], train_loss:0.180693\n",
      "Epoch [1/2], Iter [1533/3125], train_loss:0.168464\n",
      "Epoch [1/2], Iter [1534/3125], train_loss:0.159503\n",
      "Epoch [1/2], Iter [1535/3125], train_loss:0.161271\n",
      "Epoch [1/2], Iter [1536/3125], train_loss:0.141511\n",
      "Epoch [1/2], Iter [1537/3125], train_loss:0.166983\n",
      "Epoch [1/2], Iter [1538/3125], train_loss:0.146959\n",
      "Epoch [1/2], Iter [1539/3125], train_loss:0.161491\n",
      "Epoch [1/2], Iter [1540/3125], train_loss:0.166418\n",
      "Epoch [1/2], Iter [1541/3125], train_loss:0.158611\n",
      "Epoch [1/2], Iter [1542/3125], train_loss:0.152136\n",
      "Epoch [1/2], Iter [1543/3125], train_loss:0.172768\n",
      "Epoch [1/2], Iter [1544/3125], train_loss:0.152095\n",
      "Epoch [1/2], Iter [1545/3125], train_loss:0.142310\n",
      "Epoch [1/2], Iter [1546/3125], train_loss:0.150826\n",
      "Epoch [1/2], Iter [1547/3125], train_loss:0.147781\n",
      "Epoch [1/2], Iter [1548/3125], train_loss:0.171356\n",
      "Epoch [1/2], Iter [1549/3125], train_loss:0.149514\n",
      "Epoch [1/2], Iter [1550/3125], train_loss:0.156635\n",
      "Epoch [1/2], Iter [1551/3125], train_loss:0.172591\n",
      "Epoch [1/2], Iter [1552/3125], train_loss:0.178937\n",
      "Epoch [1/2], Iter [1553/3125], train_loss:0.165982\n",
      "Epoch [1/2], Iter [1554/3125], train_loss:0.169758\n",
      "Epoch [1/2], Iter [1555/3125], train_loss:0.170617\n",
      "Epoch [1/2], Iter [1556/3125], train_loss:0.168998\n",
      "Epoch [1/2], Iter [1557/3125], train_loss:0.165370\n",
      "Epoch [1/2], Iter [1558/3125], train_loss:0.161071\n",
      "Epoch [1/2], Iter [1559/3125], train_loss:0.158345\n",
      "Epoch [1/2], Iter [1560/3125], train_loss:0.186070\n",
      "Epoch [1/2], Iter [1561/3125], train_loss:0.160171\n",
      "Epoch [1/2], Iter [1562/3125], train_loss:0.179954\n",
      "Epoch [1/2], Iter [1563/3125], train_loss:0.172075\n",
      "Epoch [1/2], Iter [1564/3125], train_loss:0.151861\n",
      "Epoch [1/2], Iter [1565/3125], train_loss:0.173611\n",
      "Epoch [1/2], Iter [1566/3125], train_loss:0.167420\n",
      "Epoch [1/2], Iter [1567/3125], train_loss:0.149860\n",
      "Epoch [1/2], Iter [1568/3125], train_loss:0.154862\n",
      "Epoch [1/2], Iter [1569/3125], train_loss:0.168478\n",
      "Epoch [1/2], Iter [1570/3125], train_loss:0.159789\n",
      "Epoch [1/2], Iter [1571/3125], train_loss:0.145618\n",
      "Epoch [1/2], Iter [1572/3125], train_loss:0.171799\n",
      "Epoch [1/2], Iter [1573/3125], train_loss:0.146416\n",
      "Epoch [1/2], Iter [1574/3125], train_loss:0.151151\n",
      "Epoch [1/2], Iter [1575/3125], train_loss:0.179502\n",
      "Epoch [1/2], Iter [1576/3125], train_loss:0.169216\n",
      "Epoch [1/2], Iter [1577/3125], train_loss:0.162661\n",
      "Epoch [1/2], Iter [1578/3125], train_loss:0.155157\n",
      "Epoch [1/2], Iter [1579/3125], train_loss:0.155743\n",
      "Epoch [1/2], Iter [1580/3125], train_loss:0.189926\n",
      "Epoch [1/2], Iter [1581/3125], train_loss:0.164597\n",
      "Epoch [1/2], Iter [1582/3125], train_loss:0.137085\n",
      "Epoch [1/2], Iter [1583/3125], train_loss:0.160498\n",
      "Epoch [1/2], Iter [1584/3125], train_loss:0.179899\n",
      "Epoch [1/2], Iter [1585/3125], train_loss:0.145678\n",
      "Epoch [1/2], Iter [1586/3125], train_loss:0.157172\n",
      "Epoch [1/2], Iter [1587/3125], train_loss:0.168524\n",
      "Epoch [1/2], Iter [1588/3125], train_loss:0.156430\n",
      "Epoch [1/2], Iter [1589/3125], train_loss:0.133350\n",
      "Epoch [1/2], Iter [1590/3125], train_loss:0.176202\n",
      "Epoch [1/2], Iter [1591/3125], train_loss:0.169190\n",
      "Epoch [1/2], Iter [1592/3125], train_loss:0.175895\n",
      "Epoch [1/2], Iter [1593/3125], train_loss:0.174856\n",
      "Epoch [1/2], Iter [1594/3125], train_loss:0.163053\n",
      "Epoch [1/2], Iter [1595/3125], train_loss:0.181598\n",
      "Epoch [1/2], Iter [1596/3125], train_loss:0.144885\n",
      "Epoch [1/2], Iter [1597/3125], train_loss:0.170181\n",
      "Epoch [1/2], Iter [1598/3125], train_loss:0.171142\n",
      "Epoch [1/2], Iter [1599/3125], train_loss:0.141454\n",
      "Epoch [1/2], Iter [1600/3125], train_loss:0.145220\n",
      "Epoch [1/2], Iter [1601/3125], train_loss:0.141769\n",
      "Epoch [1/2], Iter [1602/3125], train_loss:0.154418\n",
      "Epoch [1/2], Iter [1603/3125], train_loss:0.160915\n",
      "Epoch [1/2], Iter [1604/3125], train_loss:0.168919\n",
      "Epoch [1/2], Iter [1605/3125], train_loss:0.180826\n",
      "Epoch [1/2], Iter [1606/3125], train_loss:0.152858\n",
      "Epoch [1/2], Iter [1607/3125], train_loss:0.164291\n",
      "Epoch [1/2], Iter [1608/3125], train_loss:0.163692\n",
      "Epoch [1/2], Iter [1609/3125], train_loss:0.147713\n",
      "Epoch [1/2], Iter [1610/3125], train_loss:0.157055\n",
      "Epoch [1/2], Iter [1611/3125], train_loss:0.194847\n",
      "Epoch [1/2], Iter [1612/3125], train_loss:0.158709\n",
      "Epoch [1/2], Iter [1613/3125], train_loss:0.166231\n",
      "Epoch [1/2], Iter [1614/3125], train_loss:0.186130\n",
      "Epoch [1/2], Iter [1615/3125], train_loss:0.192118\n",
      "Epoch [1/2], Iter [1616/3125], train_loss:0.167463\n",
      "Epoch [1/2], Iter [1617/3125], train_loss:0.137858\n",
      "Epoch [1/2], Iter [1618/3125], train_loss:0.146418\n",
      "Epoch [1/2], Iter [1619/3125], train_loss:0.173478\n",
      "Epoch [1/2], Iter [1620/3125], train_loss:0.161725\n",
      "Epoch [1/2], Iter [1621/3125], train_loss:0.152998\n",
      "Epoch [1/2], Iter [1622/3125], train_loss:0.185276\n",
      "Epoch [1/2], Iter [1623/3125], train_loss:0.152323\n",
      "Epoch [1/2], Iter [1624/3125], train_loss:0.145322\n",
      "Epoch [1/2], Iter [1625/3125], train_loss:0.161513\n",
      "Epoch [1/2], Iter [1626/3125], train_loss:0.153024\n",
      "Epoch [1/2], Iter [1627/3125], train_loss:0.164977\n",
      "Epoch [1/2], Iter [1628/3125], train_loss:0.165822\n",
      "Epoch [1/2], Iter [1629/3125], train_loss:0.151458\n",
      "Epoch [1/2], Iter [1630/3125], train_loss:0.168540\n",
      "Epoch [1/2], Iter [1631/3125], train_loss:0.181315\n",
      "Epoch [1/2], Iter [1632/3125], train_loss:0.169901\n",
      "Epoch [1/2], Iter [1633/3125], train_loss:0.169646\n",
      "Epoch [1/2], Iter [1634/3125], train_loss:0.161900\n",
      "Epoch [1/2], Iter [1635/3125], train_loss:0.141304\n",
      "Epoch [1/2], Iter [1636/3125], train_loss:0.144623\n",
      "Epoch [1/2], Iter [1637/3125], train_loss:0.156594\n",
      "Epoch [1/2], Iter [1638/3125], train_loss:0.150709\n",
      "Epoch [1/2], Iter [1639/3125], train_loss:0.137099\n",
      "Epoch [1/2], Iter [1640/3125], train_loss:0.153333\n",
      "Epoch [1/2], Iter [1641/3125], train_loss:0.157802\n",
      "Epoch [1/2], Iter [1642/3125], train_loss:0.143059\n",
      "Epoch [1/2], Iter [1643/3125], train_loss:0.189253\n",
      "Epoch [1/2], Iter [1644/3125], train_loss:0.155171\n",
      "Epoch [1/2], Iter [1645/3125], train_loss:0.152370\n",
      "Epoch [1/2], Iter [1646/3125], train_loss:0.166632\n",
      "Epoch [1/2], Iter [1647/3125], train_loss:0.179730\n",
      "Epoch [1/2], Iter [1648/3125], train_loss:0.172416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [1649/3125], train_loss:0.178696\n",
      "Epoch [1/2], Iter [1650/3125], train_loss:0.160341\n",
      "Epoch [1/2], Iter [1651/3125], train_loss:0.144308\n",
      "Epoch [1/2], Iter [1652/3125], train_loss:0.154410\n",
      "Epoch [1/2], Iter [1653/3125], train_loss:0.173912\n",
      "Epoch [1/2], Iter [1654/3125], train_loss:0.168114\n",
      "Epoch [1/2], Iter [1655/3125], train_loss:0.161952\n",
      "Epoch [1/2], Iter [1656/3125], train_loss:0.169061\n",
      "Epoch [1/2], Iter [1657/3125], train_loss:0.159440\n",
      "Epoch [1/2], Iter [1658/3125], train_loss:0.138091\n",
      "Epoch [1/2], Iter [1659/3125], train_loss:0.155012\n",
      "Epoch [1/2], Iter [1660/3125], train_loss:0.172804\n",
      "Epoch [1/2], Iter [1661/3125], train_loss:0.143058\n",
      "Epoch [1/2], Iter [1662/3125], train_loss:0.162421\n",
      "Epoch [1/2], Iter [1663/3125], train_loss:0.143751\n",
      "Epoch [1/2], Iter [1664/3125], train_loss:0.140241\n",
      "Epoch [1/2], Iter [1665/3125], train_loss:0.172097\n",
      "Epoch [1/2], Iter [1666/3125], train_loss:0.163913\n",
      "Epoch [1/2], Iter [1667/3125], train_loss:0.165221\n",
      "Epoch [1/2], Iter [1668/3125], train_loss:0.174985\n",
      "Epoch [1/2], Iter [1669/3125], train_loss:0.157103\n",
      "Epoch [1/2], Iter [1670/3125], train_loss:0.171044\n",
      "Epoch [1/2], Iter [1671/3125], train_loss:0.179402\n",
      "Epoch [1/2], Iter [1672/3125], train_loss:0.166310\n",
      "Epoch [1/2], Iter [1673/3125], train_loss:0.161387\n",
      "Epoch [1/2], Iter [1674/3125], train_loss:0.159246\n",
      "Epoch [1/2], Iter [1675/3125], train_loss:0.159077\n",
      "Epoch [1/2], Iter [1676/3125], train_loss:0.156243\n",
      "Epoch [1/2], Iter [1677/3125], train_loss:0.177382\n",
      "Epoch [1/2], Iter [1678/3125], train_loss:0.161576\n",
      "Epoch [1/2], Iter [1679/3125], train_loss:0.155681\n",
      "Epoch [1/2], Iter [1680/3125], train_loss:0.182101\n",
      "Epoch [1/2], Iter [1681/3125], train_loss:0.168359\n",
      "Epoch [1/2], Iter [1682/3125], train_loss:0.162136\n",
      "Epoch [1/2], Iter [1683/3125], train_loss:0.175528\n",
      "Epoch [1/2], Iter [1684/3125], train_loss:0.139192\n",
      "Epoch [1/2], Iter [1685/3125], train_loss:0.149815\n",
      "Epoch [1/2], Iter [1686/3125], train_loss:0.182981\n",
      "Epoch [1/2], Iter [1687/3125], train_loss:0.160774\n",
      "Epoch [1/2], Iter [1688/3125], train_loss:0.145968\n",
      "Epoch [1/2], Iter [1689/3125], train_loss:0.158807\n",
      "Epoch [1/2], Iter [1690/3125], train_loss:0.158910\n",
      "Epoch [1/2], Iter [1691/3125], train_loss:0.174940\n",
      "Epoch [1/2], Iter [1692/3125], train_loss:0.155379\n",
      "Epoch [1/2], Iter [1693/3125], train_loss:0.170327\n",
      "Epoch [1/2], Iter [1694/3125], train_loss:0.161909\n",
      "Epoch [1/2], Iter [1695/3125], train_loss:0.150474\n",
      "Epoch [1/2], Iter [1696/3125], train_loss:0.170937\n",
      "Epoch [1/2], Iter [1697/3125], train_loss:0.152703\n",
      "Epoch [1/2], Iter [1698/3125], train_loss:0.168881\n",
      "Epoch [1/2], Iter [1699/3125], train_loss:0.172118\n",
      "Epoch [1/2], Iter [1700/3125], train_loss:0.157837\n",
      "Epoch [1/2], Iter [1701/3125], train_loss:0.160279\n",
      "Epoch [1/2], Iter [1702/3125], train_loss:0.181616\n",
      "Epoch [1/2], Iter [1703/3125], train_loss:0.147026\n",
      "Epoch [1/2], Iter [1704/3125], train_loss:0.157656\n",
      "Epoch [1/2], Iter [1705/3125], train_loss:0.179791\n",
      "Epoch [1/2], Iter [1706/3125], train_loss:0.171684\n",
      "Epoch [1/2], Iter [1707/3125], train_loss:0.138092\n",
      "Epoch [1/2], Iter [1708/3125], train_loss:0.177978\n",
      "Epoch [1/2], Iter [1709/3125], train_loss:0.175673\n",
      "Epoch [1/2], Iter [1710/3125], train_loss:0.151395\n",
      "Epoch [1/2], Iter [1711/3125], train_loss:0.159401\n",
      "Epoch [1/2], Iter [1712/3125], train_loss:0.168381\n",
      "Epoch [1/2], Iter [1713/3125], train_loss:0.166301\n",
      "Epoch [1/2], Iter [1714/3125], train_loss:0.156766\n",
      "Epoch [1/2], Iter [1715/3125], train_loss:0.168902\n",
      "Epoch [1/2], Iter [1716/3125], train_loss:0.169495\n",
      "Epoch [1/2], Iter [1717/3125], train_loss:0.159896\n",
      "Epoch [1/2], Iter [1718/3125], train_loss:0.165244\n",
      "Epoch [1/2], Iter [1719/3125], train_loss:0.145941\n",
      "Epoch [1/2], Iter [1720/3125], train_loss:0.166384\n",
      "Epoch [1/2], Iter [1721/3125], train_loss:0.174706\n",
      "Epoch [1/2], Iter [1722/3125], train_loss:0.141559\n",
      "Epoch [1/2], Iter [1723/3125], train_loss:0.174502\n",
      "Epoch [1/2], Iter [1724/3125], train_loss:0.149242\n",
      "Epoch [1/2], Iter [1725/3125], train_loss:0.143743\n",
      "Epoch [1/2], Iter [1726/3125], train_loss:0.159536\n",
      "Epoch [1/2], Iter [1727/3125], train_loss:0.173931\n",
      "Epoch [1/2], Iter [1728/3125], train_loss:0.152694\n",
      "Epoch [1/2], Iter [1729/3125], train_loss:0.167123\n",
      "Epoch [1/2], Iter [1730/3125], train_loss:0.174618\n",
      "Epoch [1/2], Iter [1731/3125], train_loss:0.187746\n",
      "Epoch [1/2], Iter [1732/3125], train_loss:0.188053\n",
      "Epoch [1/2], Iter [1733/3125], train_loss:0.161420\n",
      "Epoch [1/2], Iter [1734/3125], train_loss:0.143247\n",
      "Epoch [1/2], Iter [1735/3125], train_loss:0.164306\n",
      "Epoch [1/2], Iter [1736/3125], train_loss:0.149670\n",
      "Epoch [1/2], Iter [1737/3125], train_loss:0.180123\n",
      "Epoch [1/2], Iter [1738/3125], train_loss:0.158347\n",
      "Epoch [1/2], Iter [1739/3125], train_loss:0.175313\n",
      "Epoch [1/2], Iter [1740/3125], train_loss:0.154087\n",
      "Epoch [1/2], Iter [1741/3125], train_loss:0.180090\n",
      "Epoch [1/2], Iter [1742/3125], train_loss:0.162183\n",
      "Epoch [1/2], Iter [1743/3125], train_loss:0.164401\n",
      "Epoch [1/2], Iter [1744/3125], train_loss:0.164047\n",
      "Epoch [1/2], Iter [1745/3125], train_loss:0.164262\n",
      "Epoch [1/2], Iter [1746/3125], train_loss:0.155122\n",
      "Epoch [1/2], Iter [1747/3125], train_loss:0.164472\n",
      "Epoch [1/2], Iter [1748/3125], train_loss:0.161191\n",
      "Epoch [1/2], Iter [1749/3125], train_loss:0.160144\n",
      "Epoch [1/2], Iter [1750/3125], train_loss:0.161302\n",
      "Epoch [1/2], Iter [1751/3125], train_loss:0.160503\n",
      "Epoch [1/2], Iter [1752/3125], train_loss:0.155728\n",
      "Epoch [1/2], Iter [1753/3125], train_loss:0.140759\n",
      "Epoch [1/2], Iter [1754/3125], train_loss:0.145626\n",
      "Epoch [1/2], Iter [1755/3125], train_loss:0.164837\n",
      "Epoch [1/2], Iter [1756/3125], train_loss:0.157151\n",
      "Epoch [1/2], Iter [1757/3125], train_loss:0.179853\n",
      "Epoch [1/2], Iter [1758/3125], train_loss:0.150290\n",
      "Epoch [1/2], Iter [1759/3125], train_loss:0.144776\n",
      "Epoch [1/2], Iter [1760/3125], train_loss:0.163736\n",
      "Epoch [1/2], Iter [1761/3125], train_loss:0.161901\n",
      "Epoch [1/2], Iter [1762/3125], train_loss:0.137393\n",
      "Epoch [1/2], Iter [1763/3125], train_loss:0.157102\n",
      "Epoch [1/2], Iter [1764/3125], train_loss:0.147714\n",
      "Epoch [1/2], Iter [1765/3125], train_loss:0.168851\n",
      "Epoch [1/2], Iter [1766/3125], train_loss:0.180556\n",
      "Epoch [1/2], Iter [1767/3125], train_loss:0.145371\n",
      "Epoch [1/2], Iter [1768/3125], train_loss:0.182627\n",
      "Epoch [1/2], Iter [1769/3125], train_loss:0.155184\n",
      "Epoch [1/2], Iter [1770/3125], train_loss:0.170251\n",
      "Epoch [1/2], Iter [1771/3125], train_loss:0.156243\n",
      "Epoch [1/2], Iter [1772/3125], train_loss:0.157432\n",
      "Epoch [1/2], Iter [1773/3125], train_loss:0.165467\n",
      "Epoch [1/2], Iter [1774/3125], train_loss:0.166601\n",
      "Epoch [1/2], Iter [1775/3125], train_loss:0.177986\n",
      "Epoch [1/2], Iter [1776/3125], train_loss:0.165314\n",
      "Epoch [1/2], Iter [1777/3125], train_loss:0.171132\n",
      "Epoch [1/2], Iter [1778/3125], train_loss:0.190048\n",
      "Epoch [1/2], Iter [1779/3125], train_loss:0.165800\n",
      "Epoch [1/2], Iter [1780/3125], train_loss:0.160303\n",
      "Epoch [1/2], Iter [1781/3125], train_loss:0.155642\n",
      "Epoch [1/2], Iter [1782/3125], train_loss:0.146157\n",
      "Epoch [1/2], Iter [1783/3125], train_loss:0.160654\n",
      "Epoch [1/2], Iter [1784/3125], train_loss:0.176773\n",
      "Epoch [1/2], Iter [1785/3125], train_loss:0.169321\n",
      "Epoch [1/2], Iter [1786/3125], train_loss:0.150362\n",
      "Epoch [1/2], Iter [1787/3125], train_loss:0.167345\n",
      "Epoch [1/2], Iter [1788/3125], train_loss:0.145898\n",
      "Epoch [1/2], Iter [1789/3125], train_loss:0.150497\n",
      "Epoch [1/2], Iter [1790/3125], train_loss:0.166425\n",
      "Epoch [1/2], Iter [1791/3125], train_loss:0.171549\n",
      "Epoch [1/2], Iter [1792/3125], train_loss:0.154176\n",
      "Epoch [1/2], Iter [1793/3125], train_loss:0.166127\n",
      "Epoch [1/2], Iter [1794/3125], train_loss:0.165764\n",
      "Epoch [1/2], Iter [1795/3125], train_loss:0.162320\n",
      "Epoch [1/2], Iter [1796/3125], train_loss:0.194941\n",
      "Epoch [1/2], Iter [1797/3125], train_loss:0.157635\n",
      "Epoch [1/2], Iter [1798/3125], train_loss:0.163641\n",
      "Epoch [1/2], Iter [1799/3125], train_loss:0.167187\n",
      "Epoch [1/2], Iter [1800/3125], train_loss:0.145284\n",
      "Epoch [1/2], Iter [1801/3125], train_loss:0.161971\n",
      "Epoch [1/2], Iter [1802/3125], train_loss:0.164058\n",
      "Epoch [1/2], Iter [1803/3125], train_loss:0.142048\n",
      "Epoch [1/2], Iter [1804/3125], train_loss:0.160427\n",
      "Epoch [1/2], Iter [1805/3125], train_loss:0.161583\n",
      "Epoch [1/2], Iter [1806/3125], train_loss:0.155377\n",
      "Epoch [1/2], Iter [1807/3125], train_loss:0.191237\n",
      "Epoch [1/2], Iter [1808/3125], train_loss:0.163925\n",
      "Epoch [1/2], Iter [1809/3125], train_loss:0.190522\n",
      "Epoch [1/2], Iter [1810/3125], train_loss:0.160186\n",
      "Epoch [1/2], Iter [1811/3125], train_loss:0.176043\n",
      "Epoch [1/2], Iter [1812/3125], train_loss:0.170882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [1813/3125], train_loss:0.168062\n",
      "Epoch [1/2], Iter [1814/3125], train_loss:0.162766\n",
      "Epoch [1/2], Iter [1815/3125], train_loss:0.168871\n",
      "Epoch [1/2], Iter [1816/3125], train_loss:0.161266\n",
      "Epoch [1/2], Iter [1817/3125], train_loss:0.155407\n",
      "Epoch [1/2], Iter [1818/3125], train_loss:0.145036\n",
      "Epoch [1/2], Iter [1819/3125], train_loss:0.166525\n",
      "Epoch [1/2], Iter [1820/3125], train_loss:0.161894\n",
      "Epoch [1/2], Iter [1821/3125], train_loss:0.179618\n",
      "Epoch [1/2], Iter [1822/3125], train_loss:0.165360\n",
      "Epoch [1/2], Iter [1823/3125], train_loss:0.179443\n",
      "Epoch [1/2], Iter [1824/3125], train_loss:0.182535\n",
      "Epoch [1/2], Iter [1825/3125], train_loss:0.183849\n",
      "Epoch [1/2], Iter [1826/3125], train_loss:0.160797\n",
      "Epoch [1/2], Iter [1827/3125], train_loss:0.155679\n",
      "Epoch [1/2], Iter [1828/3125], train_loss:0.163237\n",
      "Epoch [1/2], Iter [1829/3125], train_loss:0.155929\n",
      "Epoch [1/2], Iter [1830/3125], train_loss:0.169370\n",
      "Epoch [1/2], Iter [1831/3125], train_loss:0.181343\n",
      "Epoch [1/2], Iter [1832/3125], train_loss:0.150245\n",
      "Epoch [1/2], Iter [1833/3125], train_loss:0.173141\n",
      "Epoch [1/2], Iter [1834/3125], train_loss:0.163475\n",
      "Epoch [1/2], Iter [1835/3125], train_loss:0.163326\n",
      "Epoch [1/2], Iter [1836/3125], train_loss:0.157031\n",
      "Epoch [1/2], Iter [1837/3125], train_loss:0.166926\n",
      "Epoch [1/2], Iter [1838/3125], train_loss:0.181456\n",
      "Epoch [1/2], Iter [1839/3125], train_loss:0.166013\n",
      "Epoch [1/2], Iter [1840/3125], train_loss:0.151755\n",
      "Epoch [1/2], Iter [1841/3125], train_loss:0.172941\n",
      "Epoch [1/2], Iter [1842/3125], train_loss:0.175330\n",
      "Epoch [1/2], Iter [1843/3125], train_loss:0.147175\n",
      "Epoch [1/2], Iter [1844/3125], train_loss:0.178653\n",
      "Epoch [1/2], Iter [1845/3125], train_loss:0.152745\n",
      "Epoch [1/2], Iter [1846/3125], train_loss:0.142007\n",
      "Epoch [1/2], Iter [1847/3125], train_loss:0.148765\n",
      "Epoch [1/2], Iter [1848/3125], train_loss:0.166682\n",
      "Epoch [1/2], Iter [1849/3125], train_loss:0.156195\n",
      "Epoch [1/2], Iter [1850/3125], train_loss:0.156262\n",
      "Epoch [1/2], Iter [1851/3125], train_loss:0.160495\n",
      "Epoch [1/2], Iter [1852/3125], train_loss:0.162996\n",
      "Epoch [1/2], Iter [1853/3125], train_loss:0.162435\n",
      "Epoch [1/2], Iter [1854/3125], train_loss:0.161346\n",
      "Epoch [1/2], Iter [1855/3125], train_loss:0.171397\n",
      "Epoch [1/2], Iter [1856/3125], train_loss:0.177385\n",
      "Epoch [1/2], Iter [1857/3125], train_loss:0.130351\n",
      "Epoch [1/2], Iter [1858/3125], train_loss:0.151499\n",
      "Epoch [1/2], Iter [1859/3125], train_loss:0.149441\n",
      "Epoch [1/2], Iter [1860/3125], train_loss:0.164405\n",
      "Epoch [1/2], Iter [1861/3125], train_loss:0.163205\n",
      "Epoch [1/2], Iter [1862/3125], train_loss:0.177325\n",
      "Epoch [1/2], Iter [1863/3125], train_loss:0.155396\n",
      "Epoch [1/2], Iter [1864/3125], train_loss:0.162093\n",
      "Epoch [1/2], Iter [1865/3125], train_loss:0.155531\n",
      "Epoch [1/2], Iter [1866/3125], train_loss:0.147332\n",
      "Epoch [1/2], Iter [1867/3125], train_loss:0.150838\n",
      "Epoch [1/2], Iter [1868/3125], train_loss:0.154241\n",
      "Epoch [1/2], Iter [1869/3125], train_loss:0.142730\n",
      "Epoch [1/2], Iter [1870/3125], train_loss:0.154984\n",
      "Epoch [1/2], Iter [1871/3125], train_loss:0.141732\n",
      "Epoch [1/2], Iter [1872/3125], train_loss:0.169305\n",
      "Epoch [1/2], Iter [1873/3125], train_loss:0.158314\n",
      "Epoch [1/2], Iter [1874/3125], train_loss:0.155676\n",
      "Epoch [1/2], Iter [1875/3125], train_loss:0.162900\n",
      "Epoch [1/2], Iter [1876/3125], train_loss:0.174867\n",
      "Epoch [1/2], Iter [1877/3125], train_loss:0.165536\n",
      "Epoch [1/2], Iter [1878/3125], train_loss:0.153315\n",
      "Epoch [1/2], Iter [1879/3125], train_loss:0.150544\n",
      "Epoch [1/2], Iter [1880/3125], train_loss:0.183719\n",
      "Epoch [1/2], Iter [1881/3125], train_loss:0.160276\n",
      "Epoch [1/2], Iter [1882/3125], train_loss:0.169111\n",
      "Epoch [1/2], Iter [1883/3125], train_loss:0.162062\n",
      "Epoch [1/2], Iter [1884/3125], train_loss:0.136829\n",
      "Epoch [1/2], Iter [1885/3125], train_loss:0.152484\n",
      "Epoch [1/2], Iter [1886/3125], train_loss:0.157395\n",
      "Epoch [1/2], Iter [1887/3125], train_loss:0.153584\n",
      "Epoch [1/2], Iter [1888/3125], train_loss:0.184233\n",
      "Epoch [1/2], Iter [1889/3125], train_loss:0.158605\n",
      "Epoch [1/2], Iter [1890/3125], train_loss:0.160698\n",
      "Epoch [1/2], Iter [1891/3125], train_loss:0.160876\n",
      "Epoch [1/2], Iter [1892/3125], train_loss:0.169683\n",
      "Epoch [1/2], Iter [1893/3125], train_loss:0.157519\n",
      "Epoch [1/2], Iter [1894/3125], train_loss:0.159938\n",
      "Epoch [1/2], Iter [1895/3125], train_loss:0.170259\n",
      "Epoch [1/2], Iter [1896/3125], train_loss:0.184046\n",
      "Epoch [1/2], Iter [1897/3125], train_loss:0.153115\n",
      "Epoch [1/2], Iter [1898/3125], train_loss:0.157097\n",
      "Epoch [1/2], Iter [1899/3125], train_loss:0.162475\n",
      "Epoch [1/2], Iter [1900/3125], train_loss:0.161365\n",
      "Epoch [1/2], Iter [1901/3125], train_loss:0.173105\n",
      "Epoch [1/2], Iter [1902/3125], train_loss:0.148295\n",
      "Epoch [1/2], Iter [1903/3125], train_loss:0.165971\n",
      "Epoch [1/2], Iter [1904/3125], train_loss:0.158941\n",
      "Epoch [1/2], Iter [1905/3125], train_loss:0.167976\n",
      "Epoch [1/2], Iter [1906/3125], train_loss:0.161314\n",
      "Epoch [1/2], Iter [1907/3125], train_loss:0.142002\n",
      "Epoch [1/2], Iter [1908/3125], train_loss:0.155992\n",
      "Epoch [1/2], Iter [1909/3125], train_loss:0.159452\n",
      "Epoch [1/2], Iter [1910/3125], train_loss:0.167375\n",
      "Epoch [1/2], Iter [1911/3125], train_loss:0.160087\n",
      "Epoch [1/2], Iter [1912/3125], train_loss:0.162730\n",
      "Epoch [1/2], Iter [1913/3125], train_loss:0.166080\n",
      "Epoch [1/2], Iter [1914/3125], train_loss:0.186217\n",
      "Epoch [1/2], Iter [1915/3125], train_loss:0.151830\n",
      "Epoch [1/2], Iter [1916/3125], train_loss:0.168950\n",
      "Epoch [1/2], Iter [1917/3125], train_loss:0.153571\n",
      "Epoch [1/2], Iter [1918/3125], train_loss:0.164015\n",
      "Epoch [1/2], Iter [1919/3125], train_loss:0.159809\n",
      "Epoch [1/2], Iter [1920/3125], train_loss:0.146458\n",
      "Epoch [1/2], Iter [1921/3125], train_loss:0.160593\n",
      "Epoch [1/2], Iter [1922/3125], train_loss:0.152458\n",
      "Epoch [1/2], Iter [1923/3125], train_loss:0.170881\n",
      "Epoch [1/2], Iter [1924/3125], train_loss:0.158566\n",
      "Epoch [1/2], Iter [1925/3125], train_loss:0.155870\n",
      "Epoch [1/2], Iter [1926/3125], train_loss:0.188001\n",
      "Epoch [1/2], Iter [1927/3125], train_loss:0.169803\n",
      "Epoch [1/2], Iter [1928/3125], train_loss:0.150111\n",
      "Epoch [1/2], Iter [1929/3125], train_loss:0.163295\n",
      "Epoch [1/2], Iter [1930/3125], train_loss:0.145743\n",
      "Epoch [1/2], Iter [1931/3125], train_loss:0.154151\n",
      "Epoch [1/2], Iter [1932/3125], train_loss:0.160207\n",
      "Epoch [1/2], Iter [1933/3125], train_loss:0.158596\n",
      "Epoch [1/2], Iter [1934/3125], train_loss:0.173918\n",
      "Epoch [1/2], Iter [1935/3125], train_loss:0.184682\n",
      "Epoch [1/2], Iter [1936/3125], train_loss:0.184060\n",
      "Epoch [1/2], Iter [1937/3125], train_loss:0.165681\n",
      "Epoch [1/2], Iter [1938/3125], train_loss:0.172499\n",
      "Epoch [1/2], Iter [1939/3125], train_loss:0.154547\n",
      "Epoch [1/2], Iter [1940/3125], train_loss:0.147814\n",
      "Epoch [1/2], Iter [1941/3125], train_loss:0.161590\n",
      "Epoch [1/2], Iter [1942/3125], train_loss:0.141166\n",
      "Epoch [1/2], Iter [1943/3125], train_loss:0.151419\n",
      "Epoch [1/2], Iter [1944/3125], train_loss:0.152621\n",
      "Epoch [1/2], Iter [1945/3125], train_loss:0.164691\n",
      "Epoch [1/2], Iter [1946/3125], train_loss:0.146373\n",
      "Epoch [1/2], Iter [1947/3125], train_loss:0.148736\n",
      "Epoch [1/2], Iter [1948/3125], train_loss:0.199945\n",
      "Epoch [1/2], Iter [1949/3125], train_loss:0.154226\n",
      "Epoch [1/2], Iter [1950/3125], train_loss:0.173260\n",
      "Epoch [1/2], Iter [1951/3125], train_loss:0.161090\n",
      "Epoch [1/2], Iter [1952/3125], train_loss:0.169187\n",
      "Epoch [1/2], Iter [1953/3125], train_loss:0.164385\n",
      "Epoch [1/2], Iter [1954/3125], train_loss:0.151662\n",
      "Epoch [1/2], Iter [1955/3125], train_loss:0.165125\n",
      "Epoch [1/2], Iter [1956/3125], train_loss:0.154994\n",
      "Epoch [1/2], Iter [1957/3125], train_loss:0.173068\n",
      "Epoch [1/2], Iter [1958/3125], train_loss:0.175447\n",
      "Epoch [1/2], Iter [1959/3125], train_loss:0.170935\n",
      "Epoch [1/2], Iter [1960/3125], train_loss:0.167173\n",
      "Epoch [1/2], Iter [1961/3125], train_loss:0.181798\n",
      "Epoch [1/2], Iter [1962/3125], train_loss:0.149530\n",
      "Epoch [1/2], Iter [1963/3125], train_loss:0.162909\n",
      "Epoch [1/2], Iter [1964/3125], train_loss:0.159980\n",
      "Epoch [1/2], Iter [1965/3125], train_loss:0.152192\n",
      "Epoch [1/2], Iter [1966/3125], train_loss:0.178360\n",
      "Epoch [1/2], Iter [1967/3125], train_loss:0.146795\n",
      "Epoch [1/2], Iter [1968/3125], train_loss:0.143748\n",
      "Epoch [1/2], Iter [1969/3125], train_loss:0.181524\n",
      "Epoch [1/2], Iter [1970/3125], train_loss:0.156961\n",
      "Epoch [1/2], Iter [1971/3125], train_loss:0.157196\n",
      "Epoch [1/2], Iter [1972/3125], train_loss:0.156264\n",
      "Epoch [1/2], Iter [1973/3125], train_loss:0.155585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [1974/3125], train_loss:0.165857\n",
      "Epoch [1/2], Iter [1975/3125], train_loss:0.179051\n",
      "Epoch [1/2], Iter [1976/3125], train_loss:0.154581\n",
      "Epoch [1/2], Iter [1977/3125], train_loss:0.169368\n",
      "Epoch [1/2], Iter [1978/3125], train_loss:0.144383\n",
      "Epoch [1/2], Iter [1979/3125], train_loss:0.152714\n",
      "Epoch [1/2], Iter [1980/3125], train_loss:0.148939\n",
      "Epoch [1/2], Iter [1981/3125], train_loss:0.175638\n",
      "Epoch [1/2], Iter [1982/3125], train_loss:0.168751\n",
      "Epoch [1/2], Iter [1983/3125], train_loss:0.162145\n",
      "Epoch [1/2], Iter [1984/3125], train_loss:0.182724\n",
      "Epoch [1/2], Iter [1985/3125], train_loss:0.155977\n",
      "Epoch [1/2], Iter [1986/3125], train_loss:0.155561\n",
      "Epoch [1/2], Iter [1987/3125], train_loss:0.191799\n",
      "Epoch [1/2], Iter [1988/3125], train_loss:0.167943\n",
      "Epoch [1/2], Iter [1989/3125], train_loss:0.163147\n",
      "Epoch [1/2], Iter [1990/3125], train_loss:0.176683\n",
      "Epoch [1/2], Iter [1991/3125], train_loss:0.158023\n",
      "Epoch [1/2], Iter [1992/3125], train_loss:0.160804\n",
      "Epoch [1/2], Iter [1993/3125], train_loss:0.158202\n",
      "Epoch [1/2], Iter [1994/3125], train_loss:0.170246\n",
      "Epoch [1/2], Iter [1995/3125], train_loss:0.165867\n",
      "Epoch [1/2], Iter [1996/3125], train_loss:0.144000\n",
      "Epoch [1/2], Iter [1997/3125], train_loss:0.162011\n",
      "Epoch [1/2], Iter [1998/3125], train_loss:0.168511\n",
      "Epoch [1/2], Iter [1999/3125], train_loss:0.156590\n",
      "Epoch [1/2], Iter [2000/3125], train_loss:0.151475\n",
      "Epoch [1/2], Iter [2001/3125], train_loss:0.172778\n",
      "Epoch [1/2], Iter [2002/3125], train_loss:0.174170\n",
      "Epoch [1/2], Iter [2003/3125], train_loss:0.172485\n",
      "Epoch [1/2], Iter [2004/3125], train_loss:0.151658\n",
      "Epoch [1/2], Iter [2005/3125], train_loss:0.165962\n",
      "Epoch [1/2], Iter [2006/3125], train_loss:0.143169\n",
      "Epoch [1/2], Iter [2007/3125], train_loss:0.170595\n",
      "Epoch [1/2], Iter [2008/3125], train_loss:0.200333\n",
      "Epoch [1/2], Iter [2009/3125], train_loss:0.163445\n",
      "Epoch [1/2], Iter [2010/3125], train_loss:0.150004\n",
      "Epoch [1/2], Iter [2011/3125], train_loss:0.157552\n",
      "Epoch [1/2], Iter [2012/3125], train_loss:0.168187\n",
      "Epoch [1/2], Iter [2013/3125], train_loss:0.153843\n",
      "Epoch [1/2], Iter [2014/3125], train_loss:0.169956\n",
      "Epoch [1/2], Iter [2015/3125], train_loss:0.171310\n",
      "Epoch [1/2], Iter [2016/3125], train_loss:0.152466\n",
      "Epoch [1/2], Iter [2017/3125], train_loss:0.173650\n",
      "Epoch [1/2], Iter [2018/3125], train_loss:0.162068\n",
      "Epoch [1/2], Iter [2019/3125], train_loss:0.130321\n",
      "Epoch [1/2], Iter [2020/3125], train_loss:0.124815\n",
      "Epoch [1/2], Iter [2021/3125], train_loss:0.145361\n",
      "Epoch [1/2], Iter [2022/3125], train_loss:0.146677\n",
      "Epoch [1/2], Iter [2023/3125], train_loss:0.165708\n",
      "Epoch [1/2], Iter [2024/3125], train_loss:0.176067\n",
      "Epoch [1/2], Iter [2025/3125], train_loss:0.168302\n",
      "Epoch [1/2], Iter [2026/3125], train_loss:0.154875\n",
      "Epoch [1/2], Iter [2027/3125], train_loss:0.164601\n",
      "Epoch [1/2], Iter [2028/3125], train_loss:0.171662\n",
      "Epoch [1/2], Iter [2029/3125], train_loss:0.151342\n",
      "Epoch [1/2], Iter [2030/3125], train_loss:0.162905\n",
      "Epoch [1/2], Iter [2031/3125], train_loss:0.155055\n",
      "Epoch [1/2], Iter [2032/3125], train_loss:0.133530\n",
      "Epoch [1/2], Iter [2033/3125], train_loss:0.145367\n",
      "Epoch [1/2], Iter [2034/3125], train_loss:0.140172\n",
      "Epoch [1/2], Iter [2035/3125], train_loss:0.166013\n",
      "Epoch [1/2], Iter [2036/3125], train_loss:0.160138\n",
      "Epoch [1/2], Iter [2037/3125], train_loss:0.149895\n",
      "Epoch [1/2], Iter [2038/3125], train_loss:0.158618\n",
      "Epoch [1/2], Iter [2039/3125], train_loss:0.182976\n",
      "Epoch [1/2], Iter [2040/3125], train_loss:0.163650\n",
      "Epoch [1/2], Iter [2041/3125], train_loss:0.156669\n",
      "Epoch [1/2], Iter [2042/3125], train_loss:0.161290\n",
      "Epoch [1/2], Iter [2043/3125], train_loss:0.162484\n",
      "Epoch [1/2], Iter [2044/3125], train_loss:0.167114\n",
      "Epoch [1/2], Iter [2045/3125], train_loss:0.170945\n",
      "Epoch [1/2], Iter [2046/3125], train_loss:0.155789\n",
      "Epoch [1/2], Iter [2047/3125], train_loss:0.164060\n",
      "Epoch [1/2], Iter [2048/3125], train_loss:0.186333\n",
      "Epoch [1/2], Iter [2049/3125], train_loss:0.160162\n",
      "Epoch [1/2], Iter [2050/3125], train_loss:0.159823\n",
      "Epoch [1/2], Iter [2051/3125], train_loss:0.158371\n",
      "Epoch [1/2], Iter [2052/3125], train_loss:0.159072\n",
      "Epoch [1/2], Iter [2053/3125], train_loss:0.173952\n",
      "Epoch [1/2], Iter [2054/3125], train_loss:0.161498\n",
      "Epoch [1/2], Iter [2055/3125], train_loss:0.147181\n",
      "Epoch [1/2], Iter [2056/3125], train_loss:0.176381\n",
      "Epoch [1/2], Iter [2057/3125], train_loss:0.133942\n",
      "Epoch [1/2], Iter [2058/3125], train_loss:0.144585\n",
      "Epoch [1/2], Iter [2059/3125], train_loss:0.162973\n",
      "Epoch [1/2], Iter [2060/3125], train_loss:0.165241\n",
      "Epoch [1/2], Iter [2061/3125], train_loss:0.174846\n",
      "Epoch [1/2], Iter [2062/3125], train_loss:0.180418\n",
      "Epoch [1/2], Iter [2063/3125], train_loss:0.182369\n",
      "Epoch [1/2], Iter [2064/3125], train_loss:0.148855\n",
      "Epoch [1/2], Iter [2065/3125], train_loss:0.180047\n",
      "Epoch [1/2], Iter [2066/3125], train_loss:0.131797\n",
      "Epoch [1/2], Iter [2067/3125], train_loss:0.161162\n",
      "Epoch [1/2], Iter [2068/3125], train_loss:0.153623\n",
      "Epoch [1/2], Iter [2069/3125], train_loss:0.177079\n",
      "Epoch [1/2], Iter [2070/3125], train_loss:0.166252\n",
      "Epoch [1/2], Iter [2071/3125], train_loss:0.167907\n",
      "Epoch [1/2], Iter [2072/3125], train_loss:0.168837\n",
      "Epoch [1/2], Iter [2073/3125], train_loss:0.178388\n",
      "Epoch [1/2], Iter [2074/3125], train_loss:0.167471\n",
      "Epoch [1/2], Iter [2075/3125], train_loss:0.182263\n",
      "Epoch [1/2], Iter [2076/3125], train_loss:0.164933\n",
      "Epoch [1/2], Iter [2077/3125], train_loss:0.159932\n",
      "Epoch [1/2], Iter [2078/3125], train_loss:0.165879\n",
      "Epoch [1/2], Iter [2079/3125], train_loss:0.168112\n",
      "Epoch [1/2], Iter [2080/3125], train_loss:0.164080\n",
      "Epoch [1/2], Iter [2081/3125], train_loss:0.177289\n",
      "Epoch [1/2], Iter [2082/3125], train_loss:0.156052\n",
      "Epoch [1/2], Iter [2083/3125], train_loss:0.150370\n",
      "Epoch [1/2], Iter [2084/3125], train_loss:0.157389\n",
      "Epoch [1/2], Iter [2085/3125], train_loss:0.164571\n",
      "Epoch [1/2], Iter [2086/3125], train_loss:0.165030\n",
      "Epoch [1/2], Iter [2087/3125], train_loss:0.165491\n",
      "Epoch [1/2], Iter [2088/3125], train_loss:0.157076\n",
      "Epoch [1/2], Iter [2089/3125], train_loss:0.157584\n",
      "Epoch [1/2], Iter [2090/3125], train_loss:0.142475\n",
      "Epoch [1/2], Iter [2091/3125], train_loss:0.161959\n",
      "Epoch [1/2], Iter [2092/3125], train_loss:0.150067\n",
      "Epoch [1/2], Iter [2093/3125], train_loss:0.169877\n",
      "Epoch [1/2], Iter [2094/3125], train_loss:0.175256\n",
      "Epoch [1/2], Iter [2095/3125], train_loss:0.150007\n",
      "Epoch [1/2], Iter [2096/3125], train_loss:0.175035\n",
      "Epoch [1/2], Iter [2097/3125], train_loss:0.143745\n",
      "Epoch [1/2], Iter [2098/3125], train_loss:0.175930\n",
      "Epoch [1/2], Iter [2099/3125], train_loss:0.148834\n",
      "Epoch [1/2], Iter [2100/3125], train_loss:0.165045\n",
      "Epoch [1/2], Iter [2101/3125], train_loss:0.142969\n",
      "Epoch [1/2], Iter [2102/3125], train_loss:0.147515\n",
      "Epoch [1/2], Iter [2103/3125], train_loss:0.144696\n",
      "Epoch [1/2], Iter [2104/3125], train_loss:0.170307\n",
      "Epoch [1/2], Iter [2105/3125], train_loss:0.153275\n",
      "Epoch [1/2], Iter [2106/3125], train_loss:0.174566\n",
      "Epoch [1/2], Iter [2107/3125], train_loss:0.168739\n",
      "Epoch [1/2], Iter [2108/3125], train_loss:0.168275\n",
      "Epoch [1/2], Iter [2109/3125], train_loss:0.156382\n",
      "Epoch [1/2], Iter [2110/3125], train_loss:0.180446\n",
      "Epoch [1/2], Iter [2111/3125], train_loss:0.168478\n",
      "Epoch [1/2], Iter [2112/3125], train_loss:0.161389\n",
      "Epoch [1/2], Iter [2113/3125], train_loss:0.166829\n",
      "Epoch [1/2], Iter [2114/3125], train_loss:0.144316\n",
      "Epoch [1/2], Iter [2115/3125], train_loss:0.180950\n",
      "Epoch [1/2], Iter [2116/3125], train_loss:0.160766\n",
      "Epoch [1/2], Iter [2117/3125], train_loss:0.134064\n",
      "Epoch [1/2], Iter [2118/3125], train_loss:0.133301\n",
      "Epoch [1/2], Iter [2119/3125], train_loss:0.156353\n",
      "Epoch [1/2], Iter [2120/3125], train_loss:0.155335\n",
      "Epoch [1/2], Iter [2121/3125], train_loss:0.156238\n",
      "Epoch [1/2], Iter [2122/3125], train_loss:0.167666\n",
      "Epoch [1/2], Iter [2123/3125], train_loss:0.139103\n",
      "Epoch [1/2], Iter [2124/3125], train_loss:0.164919\n",
      "Epoch [1/2], Iter [2125/3125], train_loss:0.172402\n",
      "Epoch [1/2], Iter [2126/3125], train_loss:0.156982\n",
      "Epoch [1/2], Iter [2127/3125], train_loss:0.174418\n",
      "Epoch [1/2], Iter [2128/3125], train_loss:0.163564\n",
      "Epoch [1/2], Iter [2129/3125], train_loss:0.155914\n",
      "Epoch [1/2], Iter [2130/3125], train_loss:0.155929\n",
      "Epoch [1/2], Iter [2131/3125], train_loss:0.164747\n",
      "Epoch [1/2], Iter [2132/3125], train_loss:0.169162\n",
      "Epoch [1/2], Iter [2133/3125], train_loss:0.176287\n",
      "Epoch [1/2], Iter [2134/3125], train_loss:0.145140\n",
      "Epoch [1/2], Iter [2135/3125], train_loss:0.172772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [2136/3125], train_loss:0.172442\n",
      "Epoch [1/2], Iter [2137/3125], train_loss:0.166545\n",
      "Epoch [1/2], Iter [2138/3125], train_loss:0.155658\n",
      "Epoch [1/2], Iter [2139/3125], train_loss:0.144825\n",
      "Epoch [1/2], Iter [2140/3125], train_loss:0.165197\n",
      "Epoch [1/2], Iter [2141/3125], train_loss:0.179990\n",
      "Epoch [1/2], Iter [2142/3125], train_loss:0.155233\n",
      "Epoch [1/2], Iter [2143/3125], train_loss:0.162739\n",
      "Epoch [1/2], Iter [2144/3125], train_loss:0.156480\n",
      "Epoch [1/2], Iter [2145/3125], train_loss:0.155214\n",
      "Epoch [1/2], Iter [2146/3125], train_loss:0.162011\n",
      "Epoch [1/2], Iter [2147/3125], train_loss:0.163268\n",
      "Epoch [1/2], Iter [2148/3125], train_loss:0.180236\n",
      "Epoch [1/2], Iter [2149/3125], train_loss:0.173788\n",
      "Epoch [1/2], Iter [2150/3125], train_loss:0.155130\n",
      "Epoch [1/2], Iter [2151/3125], train_loss:0.165528\n",
      "Epoch [1/2], Iter [2152/3125], train_loss:0.176281\n",
      "Epoch [1/2], Iter [2153/3125], train_loss:0.151886\n",
      "Epoch [1/2], Iter [2154/3125], train_loss:0.145217\n",
      "Epoch [1/2], Iter [2155/3125], train_loss:0.162727\n",
      "Epoch [1/2], Iter [2156/3125], train_loss:0.167274\n",
      "Epoch [1/2], Iter [2157/3125], train_loss:0.192076\n",
      "Epoch [1/2], Iter [2158/3125], train_loss:0.163333\n",
      "Epoch [1/2], Iter [2159/3125], train_loss:0.162825\n",
      "Epoch [1/2], Iter [2160/3125], train_loss:0.187321\n",
      "Epoch [1/2], Iter [2161/3125], train_loss:0.158406\n",
      "Epoch [1/2], Iter [2162/3125], train_loss:0.179870\n",
      "Epoch [1/2], Iter [2163/3125], train_loss:0.138683\n",
      "Epoch [1/2], Iter [2164/3125], train_loss:0.150967\n",
      "Epoch [1/2], Iter [2165/3125], train_loss:0.131095\n",
      "Epoch [1/2], Iter [2166/3125], train_loss:0.183638\n",
      "Epoch [1/2], Iter [2167/3125], train_loss:0.159978\n",
      "Epoch [1/2], Iter [2168/3125], train_loss:0.186739\n",
      "Epoch [1/2], Iter [2169/3125], train_loss:0.181425\n",
      "Epoch [1/2], Iter [2170/3125], train_loss:0.168422\n",
      "Epoch [1/2], Iter [2171/3125], train_loss:0.167889\n",
      "Epoch [1/2], Iter [2172/3125], train_loss:0.140880\n",
      "Epoch [1/2], Iter [2173/3125], train_loss:0.181237\n",
      "Epoch [1/2], Iter [2174/3125], train_loss:0.159820\n",
      "Epoch [1/2], Iter [2175/3125], train_loss:0.157872\n",
      "Epoch [1/2], Iter [2176/3125], train_loss:0.158261\n",
      "Epoch [1/2], Iter [2177/3125], train_loss:0.142904\n",
      "Epoch [1/2], Iter [2178/3125], train_loss:0.172463\n",
      "Epoch [1/2], Iter [2179/3125], train_loss:0.149298\n",
      "Epoch [1/2], Iter [2180/3125], train_loss:0.159796\n",
      "Epoch [1/2], Iter [2181/3125], train_loss:0.169302\n",
      "Epoch [1/2], Iter [2182/3125], train_loss:0.185946\n",
      "Epoch [1/2], Iter [2183/3125], train_loss:0.158634\n",
      "Epoch [1/2], Iter [2184/3125], train_loss:0.163283\n",
      "Epoch [1/2], Iter [2185/3125], train_loss:0.147155\n",
      "Epoch [1/2], Iter [2186/3125], train_loss:0.169214\n",
      "Epoch [1/2], Iter [2187/3125], train_loss:0.170750\n",
      "Epoch [1/2], Iter [2188/3125], train_loss:0.164639\n",
      "Epoch [1/2], Iter [2189/3125], train_loss:0.167140\n",
      "Epoch [1/2], Iter [2190/3125], train_loss:0.165556\n",
      "Epoch [1/2], Iter [2191/3125], train_loss:0.173164\n",
      "Epoch [1/2], Iter [2192/3125], train_loss:0.158743\n",
      "Epoch [1/2], Iter [2193/3125], train_loss:0.165279\n",
      "Epoch [1/2], Iter [2194/3125], train_loss:0.151960\n",
      "Epoch [1/2], Iter [2195/3125], train_loss:0.149383\n",
      "Epoch [1/2], Iter [2196/3125], train_loss:0.157849\n",
      "Epoch [1/2], Iter [2197/3125], train_loss:0.168340\n",
      "Epoch [1/2], Iter [2198/3125], train_loss:0.156435\n",
      "Epoch [1/2], Iter [2199/3125], train_loss:0.139338\n",
      "Epoch [1/2], Iter [2200/3125], train_loss:0.160937\n",
      "Epoch [1/2], Iter [2201/3125], train_loss:0.155327\n",
      "Epoch [1/2], Iter [2202/3125], train_loss:0.177210\n",
      "Epoch [1/2], Iter [2203/3125], train_loss:0.178461\n",
      "Epoch [1/2], Iter [2204/3125], train_loss:0.171101\n",
      "Epoch [1/2], Iter [2205/3125], train_loss:0.184354\n",
      "Epoch [1/2], Iter [2206/3125], train_loss:0.144931\n",
      "Epoch [1/2], Iter [2207/3125], train_loss:0.163896\n",
      "Epoch [1/2], Iter [2208/3125], train_loss:0.169595\n",
      "Epoch [1/2], Iter [2209/3125], train_loss:0.157569\n",
      "Epoch [1/2], Iter [2210/3125], train_loss:0.178770\n",
      "Epoch [1/2], Iter [2211/3125], train_loss:0.143887\n",
      "Epoch [1/2], Iter [2212/3125], train_loss:0.161863\n",
      "Epoch [1/2], Iter [2213/3125], train_loss:0.141911\n",
      "Epoch [1/2], Iter [2214/3125], train_loss:0.141126\n",
      "Epoch [1/2], Iter [2215/3125], train_loss:0.181017\n",
      "Epoch [1/2], Iter [2216/3125], train_loss:0.147786\n",
      "Epoch [1/2], Iter [2217/3125], train_loss:0.141503\n",
      "Epoch [1/2], Iter [2218/3125], train_loss:0.157903\n",
      "Epoch [1/2], Iter [2219/3125], train_loss:0.154843\n",
      "Epoch [1/2], Iter [2220/3125], train_loss:0.148844\n",
      "Epoch [1/2], Iter [2221/3125], train_loss:0.161168\n",
      "Epoch [1/2], Iter [2222/3125], train_loss:0.171695\n",
      "Epoch [1/2], Iter [2223/3125], train_loss:0.163227\n",
      "Epoch [1/2], Iter [2224/3125], train_loss:0.159965\n",
      "Epoch [1/2], Iter [2225/3125], train_loss:0.162049\n",
      "Epoch [1/2], Iter [2226/3125], train_loss:0.172635\n",
      "Epoch [1/2], Iter [2227/3125], train_loss:0.152669\n",
      "Epoch [1/2], Iter [2228/3125], train_loss:0.154830\n",
      "Epoch [1/2], Iter [2229/3125], train_loss:0.163990\n",
      "Epoch [1/2], Iter [2230/3125], train_loss:0.168742\n",
      "Epoch [1/2], Iter [2231/3125], train_loss:0.183449\n",
      "Epoch [1/2], Iter [2232/3125], train_loss:0.148132\n",
      "Epoch [1/2], Iter [2233/3125], train_loss:0.175107\n",
      "Epoch [1/2], Iter [2234/3125], train_loss:0.157387\n",
      "Epoch [1/2], Iter [2235/3125], train_loss:0.150439\n",
      "Epoch [1/2], Iter [2236/3125], train_loss:0.141313\n",
      "Epoch [1/2], Iter [2237/3125], train_loss:0.150460\n",
      "Epoch [1/2], Iter [2238/3125], train_loss:0.157583\n",
      "Epoch [1/2], Iter [2239/3125], train_loss:0.160917\n",
      "Epoch [1/2], Iter [2240/3125], train_loss:0.175020\n",
      "Epoch [1/2], Iter [2241/3125], train_loss:0.172231\n",
      "Epoch [1/2], Iter [2242/3125], train_loss:0.158164\n",
      "Epoch [1/2], Iter [2243/3125], train_loss:0.149750\n",
      "Epoch [1/2], Iter [2244/3125], train_loss:0.160434\n",
      "Epoch [1/2], Iter [2245/3125], train_loss:0.163752\n",
      "Epoch [1/2], Iter [2246/3125], train_loss:0.146884\n",
      "Epoch [1/2], Iter [2247/3125], train_loss:0.158364\n",
      "Epoch [1/2], Iter [2248/3125], train_loss:0.156011\n",
      "Epoch [1/2], Iter [2249/3125], train_loss:0.173126\n",
      "Epoch [1/2], Iter [2250/3125], train_loss:0.193422\n",
      "Epoch [1/2], Iter [2251/3125], train_loss:0.158470\n",
      "Epoch [1/2], Iter [2252/3125], train_loss:0.151245\n",
      "Epoch [1/2], Iter [2253/3125], train_loss:0.158039\n",
      "Epoch [1/2], Iter [2254/3125], train_loss:0.152211\n",
      "Epoch [1/2], Iter [2255/3125], train_loss:0.167252\n",
      "Epoch [1/2], Iter [2256/3125], train_loss:0.156284\n",
      "Epoch [1/2], Iter [2257/3125], train_loss:0.157557\n",
      "Epoch [1/2], Iter [2258/3125], train_loss:0.149407\n",
      "Epoch [1/2], Iter [2259/3125], train_loss:0.166932\n",
      "Epoch [1/2], Iter [2260/3125], train_loss:0.174253\n",
      "Epoch [1/2], Iter [2261/3125], train_loss:0.171375\n",
      "Epoch [1/2], Iter [2262/3125], train_loss:0.166366\n",
      "Epoch [1/2], Iter [2263/3125], train_loss:0.149717\n",
      "Epoch [1/2], Iter [2264/3125], train_loss:0.166810\n",
      "Epoch [1/2], Iter [2265/3125], train_loss:0.162488\n",
      "Epoch [1/2], Iter [2266/3125], train_loss:0.165728\n",
      "Epoch [1/2], Iter [2267/3125], train_loss:0.168702\n",
      "Epoch [1/2], Iter [2268/3125], train_loss:0.143795\n",
      "Epoch [1/2], Iter [2269/3125], train_loss:0.125662\n",
      "Epoch [1/2], Iter [2270/3125], train_loss:0.152566\n",
      "Epoch [1/2], Iter [2271/3125], train_loss:0.166331\n",
      "Epoch [1/2], Iter [2272/3125], train_loss:0.146904\n",
      "Epoch [1/2], Iter [2273/3125], train_loss:0.176470\n",
      "Epoch [1/2], Iter [2274/3125], train_loss:0.166159\n",
      "Epoch [1/2], Iter [2275/3125], train_loss:0.164638\n",
      "Epoch [1/2], Iter [2276/3125], train_loss:0.174697\n",
      "Epoch [1/2], Iter [2277/3125], train_loss:0.172518\n",
      "Epoch [1/2], Iter [2278/3125], train_loss:0.179059\n",
      "Epoch [1/2], Iter [2279/3125], train_loss:0.153997\n",
      "Epoch [1/2], Iter [2280/3125], train_loss:0.164288\n",
      "Epoch [1/2], Iter [2281/3125], train_loss:0.156835\n",
      "Epoch [1/2], Iter [2282/3125], train_loss:0.172427\n",
      "Epoch [1/2], Iter [2283/3125], train_loss:0.140807\n",
      "Epoch [1/2], Iter [2284/3125], train_loss:0.176298\n",
      "Epoch [1/2], Iter [2285/3125], train_loss:0.167197\n",
      "Epoch [1/2], Iter [2286/3125], train_loss:0.155124\n",
      "Epoch [1/2], Iter [2287/3125], train_loss:0.168967\n",
      "Epoch [1/2], Iter [2288/3125], train_loss:0.155021\n",
      "Epoch [1/2], Iter [2289/3125], train_loss:0.200430\n",
      "Epoch [1/2], Iter [2290/3125], train_loss:0.168794\n",
      "Epoch [1/2], Iter [2291/3125], train_loss:0.180748\n",
      "Epoch [1/2], Iter [2292/3125], train_loss:0.151308\n",
      "Epoch [1/2], Iter [2293/3125], train_loss:0.168426\n",
      "Epoch [1/2], Iter [2294/3125], train_loss:0.160170\n",
      "Epoch [1/2], Iter [2295/3125], train_loss:0.170112\n",
      "Epoch [1/2], Iter [2296/3125], train_loss:0.182302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [2297/3125], train_loss:0.165573\n",
      "Epoch [1/2], Iter [2298/3125], train_loss:0.154088\n",
      "Epoch [1/2], Iter [2299/3125], train_loss:0.157324\n",
      "Epoch [1/2], Iter [2300/3125], train_loss:0.186557\n",
      "Epoch [1/2], Iter [2301/3125], train_loss:0.159513\n",
      "Epoch [1/2], Iter [2302/3125], train_loss:0.159842\n",
      "Epoch [1/2], Iter [2303/3125], train_loss:0.196757\n",
      "Epoch [1/2], Iter [2304/3125], train_loss:0.164728\n",
      "Epoch [1/2], Iter [2305/3125], train_loss:0.159394\n",
      "Epoch [1/2], Iter [2306/3125], train_loss:0.162070\n",
      "Epoch [1/2], Iter [2307/3125], train_loss:0.150942\n",
      "Epoch [1/2], Iter [2308/3125], train_loss:0.178885\n",
      "Epoch [1/2], Iter [2309/3125], train_loss:0.167701\n",
      "Epoch [1/2], Iter [2310/3125], train_loss:0.172832\n",
      "Epoch [1/2], Iter [2311/3125], train_loss:0.151420\n",
      "Epoch [1/2], Iter [2312/3125], train_loss:0.177722\n",
      "Epoch [1/2], Iter [2313/3125], train_loss:0.152966\n",
      "Epoch [1/2], Iter [2314/3125], train_loss:0.144942\n",
      "Epoch [1/2], Iter [2315/3125], train_loss:0.166451\n",
      "Epoch [1/2], Iter [2316/3125], train_loss:0.167570\n",
      "Epoch [1/2], Iter [2317/3125], train_loss:0.173486\n",
      "Epoch [1/2], Iter [2318/3125], train_loss:0.167726\n",
      "Epoch [1/2], Iter [2319/3125], train_loss:0.150083\n",
      "Epoch [1/2], Iter [2320/3125], train_loss:0.161335\n",
      "Epoch [1/2], Iter [2321/3125], train_loss:0.163541\n",
      "Epoch [1/2], Iter [2322/3125], train_loss:0.139134\n",
      "Epoch [1/2], Iter [2323/3125], train_loss:0.172992\n",
      "Epoch [1/2], Iter [2324/3125], train_loss:0.166975\n",
      "Epoch [1/2], Iter [2325/3125], train_loss:0.161279\n",
      "Epoch [1/2], Iter [2326/3125], train_loss:0.152028\n",
      "Epoch [1/2], Iter [2327/3125], train_loss:0.157792\n",
      "Epoch [1/2], Iter [2328/3125], train_loss:0.146232\n",
      "Epoch [1/2], Iter [2329/3125], train_loss:0.169053\n",
      "Epoch [1/2], Iter [2330/3125], train_loss:0.137772\n",
      "Epoch [1/2], Iter [2331/3125], train_loss:0.153836\n",
      "Epoch [1/2], Iter [2332/3125], train_loss:0.173346\n",
      "Epoch [1/2], Iter [2333/3125], train_loss:0.170181\n",
      "Epoch [1/2], Iter [2334/3125], train_loss:0.153624\n",
      "Epoch [1/2], Iter [2335/3125], train_loss:0.164155\n",
      "Epoch [1/2], Iter [2336/3125], train_loss:0.162456\n",
      "Epoch [1/2], Iter [2337/3125], train_loss:0.165626\n",
      "Epoch [1/2], Iter [2338/3125], train_loss:0.165643\n",
      "Epoch [1/2], Iter [2339/3125], train_loss:0.152838\n",
      "Epoch [1/2], Iter [2340/3125], train_loss:0.166339\n",
      "Epoch [1/2], Iter [2341/3125], train_loss:0.162481\n",
      "Epoch [1/2], Iter [2342/3125], train_loss:0.155828\n",
      "Epoch [1/2], Iter [2343/3125], train_loss:0.180035\n",
      "Epoch [1/2], Iter [2344/3125], train_loss:0.155793\n",
      "Epoch [1/2], Iter [2345/3125], train_loss:0.141963\n",
      "Epoch [1/2], Iter [2346/3125], train_loss:0.175218\n",
      "Epoch [1/2], Iter [2347/3125], train_loss:0.172332\n",
      "Epoch [1/2], Iter [2348/3125], train_loss:0.170206\n",
      "Epoch [1/2], Iter [2349/3125], train_loss:0.158258\n",
      "Epoch [1/2], Iter [2350/3125], train_loss:0.135423\n",
      "Epoch [1/2], Iter [2351/3125], train_loss:0.158765\n",
      "Epoch [1/2], Iter [2352/3125], train_loss:0.161856\n",
      "Epoch [1/2], Iter [2353/3125], train_loss:0.165698\n",
      "Epoch [1/2], Iter [2354/3125], train_loss:0.166844\n",
      "Epoch [1/2], Iter [2355/3125], train_loss:0.167199\n",
      "Epoch [1/2], Iter [2356/3125], train_loss:0.168643\n",
      "Epoch [1/2], Iter [2357/3125], train_loss:0.145062\n",
      "Epoch [1/2], Iter [2358/3125], train_loss:0.159673\n",
      "Epoch [1/2], Iter [2359/3125], train_loss:0.172321\n",
      "Epoch [1/2], Iter [2360/3125], train_loss:0.162261\n",
      "Epoch [1/2], Iter [2361/3125], train_loss:0.160964\n",
      "Epoch [1/2], Iter [2362/3125], train_loss:0.170365\n",
      "Epoch [1/2], Iter [2363/3125], train_loss:0.158219\n",
      "Epoch [1/2], Iter [2364/3125], train_loss:0.151682\n",
      "Epoch [1/2], Iter [2365/3125], train_loss:0.173451\n",
      "Epoch [1/2], Iter [2366/3125], train_loss:0.186411\n",
      "Epoch [1/2], Iter [2367/3125], train_loss:0.151850\n",
      "Epoch [1/2], Iter [2368/3125], train_loss:0.153410\n",
      "Epoch [1/2], Iter [2369/3125], train_loss:0.150387\n",
      "Epoch [1/2], Iter [2370/3125], train_loss:0.151061\n",
      "Epoch [1/2], Iter [2371/3125], train_loss:0.155576\n",
      "Epoch [1/2], Iter [2372/3125], train_loss:0.171615\n",
      "Epoch [1/2], Iter [2373/3125], train_loss:0.152891\n",
      "Epoch [1/2], Iter [2374/3125], train_loss:0.173333\n",
      "Epoch [1/2], Iter [2375/3125], train_loss:0.178193\n",
      "Epoch [1/2], Iter [2376/3125], train_loss:0.158169\n",
      "Epoch [1/2], Iter [2377/3125], train_loss:0.171027\n",
      "Epoch [1/2], Iter [2378/3125], train_loss:0.183264\n",
      "Epoch [1/2], Iter [2379/3125], train_loss:0.153622\n",
      "Epoch [1/2], Iter [2380/3125], train_loss:0.167066\n",
      "Epoch [1/2], Iter [2381/3125], train_loss:0.151149\n",
      "Epoch [1/2], Iter [2382/3125], train_loss:0.149457\n",
      "Epoch [1/2], Iter [2383/3125], train_loss:0.151908\n",
      "Epoch [1/2], Iter [2384/3125], train_loss:0.167173\n",
      "Epoch [1/2], Iter [2385/3125], train_loss:0.146533\n",
      "Epoch [1/2], Iter [2386/3125], train_loss:0.140869\n",
      "Epoch [1/2], Iter [2387/3125], train_loss:0.161093\n",
      "Epoch [1/2], Iter [2388/3125], train_loss:0.174047\n",
      "Epoch [1/2], Iter [2389/3125], train_loss:0.169243\n",
      "Epoch [1/2], Iter [2390/3125], train_loss:0.153055\n",
      "Epoch [1/2], Iter [2391/3125], train_loss:0.166778\n",
      "Epoch [1/2], Iter [2392/3125], train_loss:0.171477\n",
      "Epoch [1/2], Iter [2393/3125], train_loss:0.148076\n",
      "Epoch [1/2], Iter [2394/3125], train_loss:0.174037\n",
      "Epoch [1/2], Iter [2395/3125], train_loss:0.152578\n",
      "Epoch [1/2], Iter [2396/3125], train_loss:0.184196\n",
      "Epoch [1/2], Iter [2397/3125], train_loss:0.167483\n",
      "Epoch [1/2], Iter [2398/3125], train_loss:0.164854\n",
      "Epoch [1/2], Iter [2399/3125], train_loss:0.173233\n",
      "Epoch [1/2], Iter [2400/3125], train_loss:0.138813\n",
      "Epoch [1/2], Iter [2401/3125], train_loss:0.152254\n",
      "Epoch [1/2], Iter [2402/3125], train_loss:0.168025\n",
      "Epoch [1/2], Iter [2403/3125], train_loss:0.157279\n",
      "Epoch [1/2], Iter [2404/3125], train_loss:0.148963\n",
      "Epoch [1/2], Iter [2405/3125], train_loss:0.144112\n",
      "Epoch [1/2], Iter [2406/3125], train_loss:0.169978\n",
      "Epoch [1/2], Iter [2407/3125], train_loss:0.153412\n",
      "Epoch [1/2], Iter [2408/3125], train_loss:0.173826\n",
      "Epoch [1/2], Iter [2409/3125], train_loss:0.169680\n",
      "Epoch [1/2], Iter [2410/3125], train_loss:0.162930\n",
      "Epoch [1/2], Iter [2411/3125], train_loss:0.139202\n",
      "Epoch [1/2], Iter [2412/3125], train_loss:0.154762\n",
      "Epoch [1/2], Iter [2413/3125], train_loss:0.154299\n",
      "Epoch [1/2], Iter [2414/3125], train_loss:0.167414\n",
      "Epoch [1/2], Iter [2415/3125], train_loss:0.178091\n",
      "Epoch [1/2], Iter [2416/3125], train_loss:0.173954\n",
      "Epoch [1/2], Iter [2417/3125], train_loss:0.166982\n",
      "Epoch [1/2], Iter [2418/3125], train_loss:0.170560\n",
      "Epoch [1/2], Iter [2419/3125], train_loss:0.170997\n",
      "Epoch [1/2], Iter [2420/3125], train_loss:0.153861\n",
      "Epoch [1/2], Iter [2421/3125], train_loss:0.177754\n",
      "Epoch [1/2], Iter [2422/3125], train_loss:0.168872\n",
      "Epoch [1/2], Iter [2423/3125], train_loss:0.144303\n",
      "Epoch [1/2], Iter [2424/3125], train_loss:0.164720\n",
      "Epoch [1/2], Iter [2425/3125], train_loss:0.186620\n",
      "Epoch [1/2], Iter [2426/3125], train_loss:0.158638\n",
      "Epoch [1/2], Iter [2427/3125], train_loss:0.172386\n",
      "Epoch [1/2], Iter [2428/3125], train_loss:0.167100\n",
      "Epoch [1/2], Iter [2429/3125], train_loss:0.167147\n",
      "Epoch [1/2], Iter [2430/3125], train_loss:0.182128\n",
      "Epoch [1/2], Iter [2431/3125], train_loss:0.165804\n",
      "Epoch [1/2], Iter [2432/3125], train_loss:0.180088\n",
      "Epoch [1/2], Iter [2433/3125], train_loss:0.165245\n",
      "Epoch [1/2], Iter [2434/3125], train_loss:0.159391\n",
      "Epoch [1/2], Iter [2435/3125], train_loss:0.152686\n",
      "Epoch [1/2], Iter [2436/3125], train_loss:0.161874\n",
      "Epoch [1/2], Iter [2437/3125], train_loss:0.165142\n",
      "Epoch [1/2], Iter [2438/3125], train_loss:0.160963\n",
      "Epoch [1/2], Iter [2439/3125], train_loss:0.166472\n",
      "Epoch [1/2], Iter [2440/3125], train_loss:0.158173\n",
      "Epoch [1/2], Iter [2441/3125], train_loss:0.173994\n",
      "Epoch [1/2], Iter [2442/3125], train_loss:0.151297\n",
      "Epoch [1/2], Iter [2443/3125], train_loss:0.152010\n",
      "Epoch [1/2], Iter [2444/3125], train_loss:0.160982\n",
      "Epoch [1/2], Iter [2445/3125], train_loss:0.182511\n",
      "Epoch [1/2], Iter [2446/3125], train_loss:0.171740\n",
      "Epoch [1/2], Iter [2447/3125], train_loss:0.169194\n",
      "Epoch [1/2], Iter [2448/3125], train_loss:0.160217\n",
      "Epoch [1/2], Iter [2449/3125], train_loss:0.170634\n",
      "Epoch [1/2], Iter [2450/3125], train_loss:0.174725\n",
      "Epoch [1/2], Iter [2451/3125], train_loss:0.162844\n",
      "Epoch [1/2], Iter [2452/3125], train_loss:0.179684\n",
      "Epoch [1/2], Iter [2453/3125], train_loss:0.165793\n",
      "Epoch [1/2], Iter [2454/3125], train_loss:0.147170\n",
      "Epoch [1/2], Iter [2455/3125], train_loss:0.167428\n",
      "Epoch [1/2], Iter [2456/3125], train_loss:0.156832\n",
      "Epoch [1/2], Iter [2457/3125], train_loss:0.163711\n",
      "Epoch [1/2], Iter [2458/3125], train_loss:0.163635\n",
      "Epoch [1/2], Iter [2459/3125], train_loss:0.169788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [2460/3125], train_loss:0.161291\n",
      "Epoch [1/2], Iter [2461/3125], train_loss:0.176288\n",
      "Epoch [1/2], Iter [2462/3125], train_loss:0.173527\n",
      "Epoch [1/2], Iter [2463/3125], train_loss:0.198670\n",
      "Epoch [1/2], Iter [2464/3125], train_loss:0.163765\n",
      "Epoch [1/2], Iter [2465/3125], train_loss:0.155121\n",
      "Epoch [1/2], Iter [2466/3125], train_loss:0.157210\n",
      "Epoch [1/2], Iter [2467/3125], train_loss:0.158318\n",
      "Epoch [1/2], Iter [2468/3125], train_loss:0.190069\n",
      "Epoch [1/2], Iter [2469/3125], train_loss:0.157674\n",
      "Epoch [1/2], Iter [2470/3125], train_loss:0.153022\n",
      "Epoch [1/2], Iter [2471/3125], train_loss:0.178211\n",
      "Epoch [1/2], Iter [2472/3125], train_loss:0.165668\n",
      "Epoch [1/2], Iter [2473/3125], train_loss:0.170597\n",
      "Epoch [1/2], Iter [2474/3125], train_loss:0.148514\n",
      "Epoch [1/2], Iter [2475/3125], train_loss:0.161165\n",
      "Epoch [1/2], Iter [2476/3125], train_loss:0.159940\n",
      "Epoch [1/2], Iter [2477/3125], train_loss:0.163364\n",
      "Epoch [1/2], Iter [2478/3125], train_loss:0.160939\n",
      "Epoch [1/2], Iter [2479/3125], train_loss:0.188242\n",
      "Epoch [1/2], Iter [2480/3125], train_loss:0.170161\n",
      "Epoch [1/2], Iter [2481/3125], train_loss:0.166997\n",
      "Epoch [1/2], Iter [2482/3125], train_loss:0.173182\n",
      "Epoch [1/2], Iter [2483/3125], train_loss:0.156736\n",
      "Epoch [1/2], Iter [2484/3125], train_loss:0.162785\n",
      "Epoch [1/2], Iter [2485/3125], train_loss:0.159454\n",
      "Epoch [1/2], Iter [2486/3125], train_loss:0.172418\n",
      "Epoch [1/2], Iter [2487/3125], train_loss:0.166055\n",
      "Epoch [1/2], Iter [2488/3125], train_loss:0.166522\n",
      "Epoch [1/2], Iter [2489/3125], train_loss:0.157236\n",
      "Epoch [1/2], Iter [2490/3125], train_loss:0.173360\n",
      "Epoch [1/2], Iter [2491/3125], train_loss:0.147073\n",
      "Epoch [1/2], Iter [2492/3125], train_loss:0.154806\n",
      "Epoch [1/2], Iter [2493/3125], train_loss:0.159782\n",
      "Epoch [1/2], Iter [2494/3125], train_loss:0.175359\n",
      "Epoch [1/2], Iter [2495/3125], train_loss:0.152874\n",
      "Epoch [1/2], Iter [2496/3125], train_loss:0.175603\n",
      "Epoch [1/2], Iter [2497/3125], train_loss:0.151182\n",
      "Epoch [1/2], Iter [2498/3125], train_loss:0.133273\n",
      "Epoch [1/2], Iter [2499/3125], train_loss:0.162480\n",
      "Epoch [1/2], Iter [2500/3125], train_loss:0.172038\n",
      "Epoch [1/2], Iter [2501/3125], train_loss:0.163592\n",
      "Epoch [1/2], Iter [2502/3125], train_loss:0.168842\n",
      "Epoch [1/2], Iter [2503/3125], train_loss:0.167579\n",
      "Epoch [1/2], Iter [2504/3125], train_loss:0.169892\n",
      "Epoch [1/2], Iter [2505/3125], train_loss:0.184179\n",
      "Epoch [1/2], Iter [2506/3125], train_loss:0.172049\n",
      "Epoch [1/2], Iter [2507/3125], train_loss:0.181183\n",
      "Epoch [1/2], Iter [2508/3125], train_loss:0.157703\n",
      "Epoch [1/2], Iter [2509/3125], train_loss:0.156251\n",
      "Epoch [1/2], Iter [2510/3125], train_loss:0.140083\n",
      "Epoch [1/2], Iter [2511/3125], train_loss:0.155766\n",
      "Epoch [1/2], Iter [2512/3125], train_loss:0.171320\n",
      "Epoch [1/2], Iter [2513/3125], train_loss:0.165249\n",
      "Epoch [1/2], Iter [2514/3125], train_loss:0.144336\n",
      "Epoch [1/2], Iter [2515/3125], train_loss:0.169332\n",
      "Epoch [1/2], Iter [2516/3125], train_loss:0.152470\n",
      "Epoch [1/2], Iter [2517/3125], train_loss:0.161122\n",
      "Epoch [1/2], Iter [2518/3125], train_loss:0.182971\n",
      "Epoch [1/2], Iter [2519/3125], train_loss:0.164621\n",
      "Epoch [1/2], Iter [2520/3125], train_loss:0.175796\n",
      "Epoch [1/2], Iter [2521/3125], train_loss:0.176611\n",
      "Epoch [1/2], Iter [2522/3125], train_loss:0.161589\n",
      "Epoch [1/2], Iter [2523/3125], train_loss:0.153558\n",
      "Epoch [1/2], Iter [2524/3125], train_loss:0.177934\n",
      "Epoch [1/2], Iter [2525/3125], train_loss:0.140108\n",
      "Epoch [1/2], Iter [2526/3125], train_loss:0.170537\n",
      "Epoch [1/2], Iter [2527/3125], train_loss:0.190064\n",
      "Epoch [1/2], Iter [2528/3125], train_loss:0.150987\n",
      "Epoch [1/2], Iter [2529/3125], train_loss:0.153076\n",
      "Epoch [1/2], Iter [2530/3125], train_loss:0.153231\n",
      "Epoch [1/2], Iter [2531/3125], train_loss:0.151433\n",
      "Epoch [1/2], Iter [2532/3125], train_loss:0.165380\n",
      "Epoch [1/2], Iter [2533/3125], train_loss:0.154326\n",
      "Epoch [1/2], Iter [2534/3125], train_loss:0.148860\n",
      "Epoch [1/2], Iter [2535/3125], train_loss:0.182532\n",
      "Epoch [1/2], Iter [2536/3125], train_loss:0.184858\n",
      "Epoch [1/2], Iter [2537/3125], train_loss:0.144190\n",
      "Epoch [1/2], Iter [2538/3125], train_loss:0.160582\n",
      "Epoch [1/2], Iter [2539/3125], train_loss:0.150244\n",
      "Epoch [1/2], Iter [2540/3125], train_loss:0.163084\n",
      "Epoch [1/2], Iter [2541/3125], train_loss:0.173798\n",
      "Epoch [1/2], Iter [2542/3125], train_loss:0.180224\n",
      "Epoch [1/2], Iter [2543/3125], train_loss:0.171645\n",
      "Epoch [1/2], Iter [2544/3125], train_loss:0.170542\n",
      "Epoch [1/2], Iter [2545/3125], train_loss:0.150921\n",
      "Epoch [1/2], Iter [2546/3125], train_loss:0.141499\n",
      "Epoch [1/2], Iter [2547/3125], train_loss:0.154087\n",
      "Epoch [1/2], Iter [2548/3125], train_loss:0.146057\n",
      "Epoch [1/2], Iter [2549/3125], train_loss:0.179915\n",
      "Epoch [1/2], Iter [2550/3125], train_loss:0.178421\n",
      "Epoch [1/2], Iter [2551/3125], train_loss:0.162338\n",
      "Epoch [1/2], Iter [2552/3125], train_loss:0.159943\n",
      "Epoch [1/2], Iter [2553/3125], train_loss:0.166942\n",
      "Epoch [1/2], Iter [2554/3125], train_loss:0.161777\n",
      "Epoch [1/2], Iter [2555/3125], train_loss:0.173371\n",
      "Epoch [1/2], Iter [2556/3125], train_loss:0.149645\n",
      "Epoch [1/2], Iter [2557/3125], train_loss:0.150998\n",
      "Epoch [1/2], Iter [2558/3125], train_loss:0.168478\n",
      "Epoch [1/2], Iter [2559/3125], train_loss:0.161073\n",
      "Epoch [1/2], Iter [2560/3125], train_loss:0.153746\n",
      "Epoch [1/2], Iter [2561/3125], train_loss:0.156996\n",
      "Epoch [1/2], Iter [2562/3125], train_loss:0.175018\n",
      "Epoch [1/2], Iter [2563/3125], train_loss:0.161457\n",
      "Epoch [1/2], Iter [2564/3125], train_loss:0.181512\n",
      "Epoch [1/2], Iter [2565/3125], train_loss:0.159499\n",
      "Epoch [1/2], Iter [2566/3125], train_loss:0.155685\n",
      "Epoch [1/2], Iter [2567/3125], train_loss:0.160816\n",
      "Epoch [1/2], Iter [2568/3125], train_loss:0.167257\n",
      "Epoch [1/2], Iter [2569/3125], train_loss:0.168003\n",
      "Epoch [1/2], Iter [2570/3125], train_loss:0.156276\n",
      "Epoch [1/2], Iter [2571/3125], train_loss:0.166197\n",
      "Epoch [1/2], Iter [2572/3125], train_loss:0.171228\n",
      "Epoch [1/2], Iter [2573/3125], train_loss:0.169274\n",
      "Epoch [1/2], Iter [2574/3125], train_loss:0.178607\n",
      "Epoch [1/2], Iter [2575/3125], train_loss:0.180143\n",
      "Epoch [1/2], Iter [2576/3125], train_loss:0.165496\n",
      "Epoch [1/2], Iter [2577/3125], train_loss:0.164666\n",
      "Epoch [1/2], Iter [2578/3125], train_loss:0.172761\n",
      "Epoch [1/2], Iter [2579/3125], train_loss:0.142597\n",
      "Epoch [1/2], Iter [2580/3125], train_loss:0.166856\n",
      "Epoch [1/2], Iter [2581/3125], train_loss:0.180629\n",
      "Epoch [1/2], Iter [2582/3125], train_loss:0.155988\n",
      "Epoch [1/2], Iter [2583/3125], train_loss:0.190004\n",
      "Epoch [1/2], Iter [2584/3125], train_loss:0.153131\n",
      "Epoch [1/2], Iter [2585/3125], train_loss:0.149209\n",
      "Epoch [1/2], Iter [2586/3125], train_loss:0.182763\n",
      "Epoch [1/2], Iter [2587/3125], train_loss:0.163803\n",
      "Epoch [1/2], Iter [2588/3125], train_loss:0.164377\n",
      "Epoch [1/2], Iter [2589/3125], train_loss:0.165225\n",
      "Epoch [1/2], Iter [2590/3125], train_loss:0.132286\n",
      "Epoch [1/2], Iter [2591/3125], train_loss:0.157618\n",
      "Epoch [1/2], Iter [2592/3125], train_loss:0.180062\n",
      "Epoch [1/2], Iter [2593/3125], train_loss:0.149064\n",
      "Epoch [1/2], Iter [2594/3125], train_loss:0.182419\n",
      "Epoch [1/2], Iter [2595/3125], train_loss:0.152154\n",
      "Epoch [1/2], Iter [2596/3125], train_loss:0.156817\n",
      "Epoch [1/2], Iter [2597/3125], train_loss:0.158894\n",
      "Epoch [1/2], Iter [2598/3125], train_loss:0.174006\n",
      "Epoch [1/2], Iter [2599/3125], train_loss:0.170469\n",
      "Epoch [1/2], Iter [2600/3125], train_loss:0.163272\n",
      "Epoch [1/2], Iter [2601/3125], train_loss:0.165293\n",
      "Epoch [1/2], Iter [2602/3125], train_loss:0.132606\n",
      "Epoch [1/2], Iter [2603/3125], train_loss:0.181648\n",
      "Epoch [1/2], Iter [2604/3125], train_loss:0.172091\n",
      "Epoch [1/2], Iter [2605/3125], train_loss:0.145725\n",
      "Epoch [1/2], Iter [2606/3125], train_loss:0.159542\n",
      "Epoch [1/2], Iter [2607/3125], train_loss:0.166341\n",
      "Epoch [1/2], Iter [2608/3125], train_loss:0.144378\n",
      "Epoch [1/2], Iter [2609/3125], train_loss:0.174001\n",
      "Epoch [1/2], Iter [2610/3125], train_loss:0.154200\n",
      "Epoch [1/2], Iter [2611/3125], train_loss:0.168938\n",
      "Epoch [1/2], Iter [2612/3125], train_loss:0.151330\n",
      "Epoch [1/2], Iter [2613/3125], train_loss:0.158763\n",
      "Epoch [1/2], Iter [2614/3125], train_loss:0.154259\n",
      "Epoch [1/2], Iter [2615/3125], train_loss:0.155223\n",
      "Epoch [1/2], Iter [2616/3125], train_loss:0.173738\n",
      "Epoch [1/2], Iter [2617/3125], train_loss:0.164574\n",
      "Epoch [1/2], Iter [2618/3125], train_loss:0.171280\n",
      "Epoch [1/2], Iter [2619/3125], train_loss:0.167967\n",
      "Epoch [1/2], Iter [2620/3125], train_loss:0.165825\n",
      "Epoch [1/2], Iter [2621/3125], train_loss:0.163001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [2622/3125], train_loss:0.166808\n",
      "Epoch [1/2], Iter [2623/3125], train_loss:0.158262\n",
      "Epoch [1/2], Iter [2624/3125], train_loss:0.152927\n",
      "Epoch [1/2], Iter [2625/3125], train_loss:0.151799\n",
      "Epoch [1/2], Iter [2626/3125], train_loss:0.153348\n",
      "Epoch [1/2], Iter [2627/3125], train_loss:0.145824\n",
      "Epoch [1/2], Iter [2628/3125], train_loss:0.149315\n",
      "Epoch [1/2], Iter [2629/3125], train_loss:0.183911\n",
      "Epoch [1/2], Iter [2630/3125], train_loss:0.153068\n",
      "Epoch [1/2], Iter [2631/3125], train_loss:0.163764\n",
      "Epoch [1/2], Iter [2632/3125], train_loss:0.161556\n",
      "Epoch [1/2], Iter [2633/3125], train_loss:0.177212\n",
      "Epoch [1/2], Iter [2634/3125], train_loss:0.149619\n",
      "Epoch [1/2], Iter [2635/3125], train_loss:0.160023\n",
      "Epoch [1/2], Iter [2636/3125], train_loss:0.169547\n",
      "Epoch [1/2], Iter [2637/3125], train_loss:0.147591\n",
      "Epoch [1/2], Iter [2638/3125], train_loss:0.156738\n",
      "Epoch [1/2], Iter [2639/3125], train_loss:0.148298\n",
      "Epoch [1/2], Iter [2640/3125], train_loss:0.161786\n",
      "Epoch [1/2], Iter [2641/3125], train_loss:0.162544\n",
      "Epoch [1/2], Iter [2642/3125], train_loss:0.168581\n",
      "Epoch [1/2], Iter [2643/3125], train_loss:0.167225\n",
      "Epoch [1/2], Iter [2644/3125], train_loss:0.160467\n",
      "Epoch [1/2], Iter [2645/3125], train_loss:0.166200\n",
      "Epoch [1/2], Iter [2646/3125], train_loss:0.167931\n",
      "Epoch [1/2], Iter [2647/3125], train_loss:0.157258\n",
      "Epoch [1/2], Iter [2648/3125], train_loss:0.142979\n",
      "Epoch [1/2], Iter [2649/3125], train_loss:0.169719\n",
      "Epoch [1/2], Iter [2650/3125], train_loss:0.179859\n",
      "Epoch [1/2], Iter [2651/3125], train_loss:0.154542\n",
      "Epoch [1/2], Iter [2652/3125], train_loss:0.157200\n",
      "Epoch [1/2], Iter [2653/3125], train_loss:0.178602\n",
      "Epoch [1/2], Iter [2654/3125], train_loss:0.145348\n",
      "Epoch [1/2], Iter [2655/3125], train_loss:0.156349\n",
      "Epoch [1/2], Iter [2656/3125], train_loss:0.148944\n",
      "Epoch [1/2], Iter [2657/3125], train_loss:0.157309\n",
      "Epoch [1/2], Iter [2658/3125], train_loss:0.162670\n",
      "Epoch [1/2], Iter [2659/3125], train_loss:0.150020\n",
      "Epoch [1/2], Iter [2660/3125], train_loss:0.157252\n",
      "Epoch [1/2], Iter [2661/3125], train_loss:0.166470\n",
      "Epoch [1/2], Iter [2662/3125], train_loss:0.178597\n",
      "Epoch [1/2], Iter [2663/3125], train_loss:0.145679\n",
      "Epoch [1/2], Iter [2664/3125], train_loss:0.142497\n",
      "Epoch [1/2], Iter [2665/3125], train_loss:0.153192\n",
      "Epoch [1/2], Iter [2666/3125], train_loss:0.155716\n",
      "Epoch [1/2], Iter [2667/3125], train_loss:0.174556\n",
      "Epoch [1/2], Iter [2668/3125], train_loss:0.152721\n",
      "Epoch [1/2], Iter [2669/3125], train_loss:0.169619\n",
      "Epoch [1/2], Iter [2670/3125], train_loss:0.167028\n",
      "Epoch [1/2], Iter [2671/3125], train_loss:0.154183\n",
      "Epoch [1/2], Iter [2672/3125], train_loss:0.175002\n",
      "Epoch [1/2], Iter [2673/3125], train_loss:0.139364\n",
      "Epoch [1/2], Iter [2674/3125], train_loss:0.162451\n",
      "Epoch [1/2], Iter [2675/3125], train_loss:0.157143\n",
      "Epoch [1/2], Iter [2676/3125], train_loss:0.166282\n",
      "Epoch [1/2], Iter [2677/3125], train_loss:0.150420\n",
      "Epoch [1/2], Iter [2678/3125], train_loss:0.172134\n",
      "Epoch [1/2], Iter [2679/3125], train_loss:0.170172\n",
      "Epoch [1/2], Iter [2680/3125], train_loss:0.188591\n",
      "Epoch [1/2], Iter [2681/3125], train_loss:0.133006\n",
      "Epoch [1/2], Iter [2682/3125], train_loss:0.154428\n",
      "Epoch [1/2], Iter [2683/3125], train_loss:0.146256\n",
      "Epoch [1/2], Iter [2684/3125], train_loss:0.140180\n",
      "Epoch [1/2], Iter [2685/3125], train_loss:0.150448\n",
      "Epoch [1/2], Iter [2686/3125], train_loss:0.166966\n",
      "Epoch [1/2], Iter [2687/3125], train_loss:0.163846\n",
      "Epoch [1/2], Iter [2688/3125], train_loss:0.151998\n",
      "Epoch [1/2], Iter [2689/3125], train_loss:0.177917\n",
      "Epoch [1/2], Iter [2690/3125], train_loss:0.164405\n",
      "Epoch [1/2], Iter [2691/3125], train_loss:0.149646\n",
      "Epoch [1/2], Iter [2692/3125], train_loss:0.155895\n",
      "Epoch [1/2], Iter [2693/3125], train_loss:0.133467\n",
      "Epoch [1/2], Iter [2694/3125], train_loss:0.181978\n",
      "Epoch [1/2], Iter [2695/3125], train_loss:0.178019\n",
      "Epoch [1/2], Iter [2696/3125], train_loss:0.164970\n",
      "Epoch [1/2], Iter [2697/3125], train_loss:0.153656\n",
      "Epoch [1/2], Iter [2698/3125], train_loss:0.158283\n",
      "Epoch [1/2], Iter [2699/3125], train_loss:0.166151\n",
      "Epoch [1/2], Iter [2700/3125], train_loss:0.152899\n",
      "Epoch [1/2], Iter [2701/3125], train_loss:0.150675\n",
      "Epoch [1/2], Iter [2702/3125], train_loss:0.161370\n",
      "Epoch [1/2], Iter [2703/3125], train_loss:0.162690\n",
      "Epoch [1/2], Iter [2704/3125], train_loss:0.146854\n",
      "Epoch [1/2], Iter [2705/3125], train_loss:0.168728\n",
      "Epoch [1/2], Iter [2706/3125], train_loss:0.156361\n",
      "Epoch [1/2], Iter [2707/3125], train_loss:0.162295\n",
      "Epoch [1/2], Iter [2708/3125], train_loss:0.154698\n",
      "Epoch [1/2], Iter [2709/3125], train_loss:0.162639\n",
      "Epoch [1/2], Iter [2710/3125], train_loss:0.170419\n",
      "Epoch [1/2], Iter [2711/3125], train_loss:0.182608\n",
      "Epoch [1/2], Iter [2712/3125], train_loss:0.174881\n",
      "Epoch [1/2], Iter [2713/3125], train_loss:0.163568\n",
      "Epoch [1/2], Iter [2714/3125], train_loss:0.172464\n",
      "Epoch [1/2], Iter [2715/3125], train_loss:0.152963\n",
      "Epoch [1/2], Iter [2716/3125], train_loss:0.174935\n",
      "Epoch [1/2], Iter [2717/3125], train_loss:0.163978\n",
      "Epoch [1/2], Iter [2718/3125], train_loss:0.149811\n",
      "Epoch [1/2], Iter [2719/3125], train_loss:0.168551\n",
      "Epoch [1/2], Iter [2720/3125], train_loss:0.187687\n",
      "Epoch [1/2], Iter [2721/3125], train_loss:0.170561\n",
      "Epoch [1/2], Iter [2722/3125], train_loss:0.157643\n",
      "Epoch [1/2], Iter [2723/3125], train_loss:0.183448\n",
      "Epoch [1/2], Iter [2724/3125], train_loss:0.156940\n",
      "Epoch [1/2], Iter [2725/3125], train_loss:0.176922\n",
      "Epoch [1/2], Iter [2726/3125], train_loss:0.170941\n",
      "Epoch [1/2], Iter [2727/3125], train_loss:0.161215\n",
      "Epoch [1/2], Iter [2728/3125], train_loss:0.157638\n",
      "Epoch [1/2], Iter [2729/3125], train_loss:0.146765\n",
      "Epoch [1/2], Iter [2730/3125], train_loss:0.186415\n",
      "Epoch [1/2], Iter [2731/3125], train_loss:0.179016\n",
      "Epoch [1/2], Iter [2732/3125], train_loss:0.146862\n",
      "Epoch [1/2], Iter [2733/3125], train_loss:0.160904\n",
      "Epoch [1/2], Iter [2734/3125], train_loss:0.184066\n",
      "Epoch [1/2], Iter [2735/3125], train_loss:0.170018\n",
      "Epoch [1/2], Iter [2736/3125], train_loss:0.151466\n",
      "Epoch [1/2], Iter [2737/3125], train_loss:0.155503\n",
      "Epoch [1/2], Iter [2738/3125], train_loss:0.178504\n",
      "Epoch [1/2], Iter [2739/3125], train_loss:0.182733\n",
      "Epoch [1/2], Iter [2740/3125], train_loss:0.178885\n",
      "Epoch [1/2], Iter [2741/3125], train_loss:0.158115\n",
      "Epoch [1/2], Iter [2742/3125], train_loss:0.166074\n",
      "Epoch [1/2], Iter [2743/3125], train_loss:0.175153\n",
      "Epoch [1/2], Iter [2744/3125], train_loss:0.173695\n",
      "Epoch [1/2], Iter [2745/3125], train_loss:0.140103\n",
      "Epoch [1/2], Iter [2746/3125], train_loss:0.164165\n",
      "Epoch [1/2], Iter [2747/3125], train_loss:0.195799\n",
      "Epoch [1/2], Iter [2748/3125], train_loss:0.165051\n",
      "Epoch [1/2], Iter [2749/3125], train_loss:0.168219\n",
      "Epoch [1/2], Iter [2750/3125], train_loss:0.145761\n",
      "Epoch [1/2], Iter [2751/3125], train_loss:0.184619\n",
      "Epoch [1/2], Iter [2752/3125], train_loss:0.183593\n",
      "Epoch [1/2], Iter [2753/3125], train_loss:0.161479\n",
      "Epoch [1/2], Iter [2754/3125], train_loss:0.165525\n",
      "Epoch [1/2], Iter [2755/3125], train_loss:0.152368\n",
      "Epoch [1/2], Iter [2756/3125], train_loss:0.156252\n",
      "Epoch [1/2], Iter [2757/3125], train_loss:0.160543\n",
      "Epoch [1/2], Iter [2758/3125], train_loss:0.169057\n",
      "Epoch [1/2], Iter [2759/3125], train_loss:0.185539\n",
      "Epoch [1/2], Iter [2760/3125], train_loss:0.150664\n",
      "Epoch [1/2], Iter [2761/3125], train_loss:0.168148\n",
      "Epoch [1/2], Iter [2762/3125], train_loss:0.150886\n",
      "Epoch [1/2], Iter [2763/3125], train_loss:0.153608\n",
      "Epoch [1/2], Iter [2764/3125], train_loss:0.173608\n",
      "Epoch [1/2], Iter [2765/3125], train_loss:0.156316\n",
      "Epoch [1/2], Iter [2766/3125], train_loss:0.155580\n",
      "Epoch [1/2], Iter [2767/3125], train_loss:0.170365\n",
      "Epoch [1/2], Iter [2768/3125], train_loss:0.160952\n",
      "Epoch [1/2], Iter [2769/3125], train_loss:0.178418\n",
      "Epoch [1/2], Iter [2770/3125], train_loss:0.161754\n",
      "Epoch [1/2], Iter [2771/3125], train_loss:0.175010\n",
      "Epoch [1/2], Iter [2772/3125], train_loss:0.177170\n",
      "Epoch [1/2], Iter [2773/3125], train_loss:0.156224\n",
      "Epoch [1/2], Iter [2774/3125], train_loss:0.171853\n",
      "Epoch [1/2], Iter [2775/3125], train_loss:0.175113\n",
      "Epoch [1/2], Iter [2776/3125], train_loss:0.153226\n",
      "Epoch [1/2], Iter [2777/3125], train_loss:0.167736\n",
      "Epoch [1/2], Iter [2778/3125], train_loss:0.160811\n",
      "Epoch [1/2], Iter [2779/3125], train_loss:0.174287\n",
      "Epoch [1/2], Iter [2780/3125], train_loss:0.158126\n",
      "Epoch [1/2], Iter [2781/3125], train_loss:0.170792\n",
      "Epoch [1/2], Iter [2782/3125], train_loss:0.165518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [2783/3125], train_loss:0.162349\n",
      "Epoch [1/2], Iter [2784/3125], train_loss:0.145470\n",
      "Epoch [1/2], Iter [2785/3125], train_loss:0.159157\n",
      "Epoch [1/2], Iter [2786/3125], train_loss:0.147954\n",
      "Epoch [1/2], Iter [2787/3125], train_loss:0.170489\n",
      "Epoch [1/2], Iter [2788/3125], train_loss:0.165043\n",
      "Epoch [1/2], Iter [2789/3125], train_loss:0.163622\n",
      "Epoch [1/2], Iter [2790/3125], train_loss:0.154899\n",
      "Epoch [1/2], Iter [2791/3125], train_loss:0.160961\n",
      "Epoch [1/2], Iter [2792/3125], train_loss:0.165133\n",
      "Epoch [1/2], Iter [2793/3125], train_loss:0.183820\n",
      "Epoch [1/2], Iter [2794/3125], train_loss:0.170000\n",
      "Epoch [1/2], Iter [2795/3125], train_loss:0.164589\n",
      "Epoch [1/2], Iter [2796/3125], train_loss:0.180219\n",
      "Epoch [1/2], Iter [2797/3125], train_loss:0.144782\n",
      "Epoch [1/2], Iter [2798/3125], train_loss:0.175786\n",
      "Epoch [1/2], Iter [2799/3125], train_loss:0.128005\n",
      "Epoch [1/2], Iter [2800/3125], train_loss:0.156003\n",
      "Epoch [1/2], Iter [2801/3125], train_loss:0.151638\n",
      "Epoch [1/2], Iter [2802/3125], train_loss:0.162846\n",
      "Epoch [1/2], Iter [2803/3125], train_loss:0.162985\n",
      "Epoch [1/2], Iter [2804/3125], train_loss:0.160361\n",
      "Epoch [1/2], Iter [2805/3125], train_loss:0.151148\n",
      "Epoch [1/2], Iter [2806/3125], train_loss:0.164542\n",
      "Epoch [1/2], Iter [2807/3125], train_loss:0.142881\n",
      "Epoch [1/2], Iter [2808/3125], train_loss:0.156098\n",
      "Epoch [1/2], Iter [2809/3125], train_loss:0.133754\n",
      "Epoch [1/2], Iter [2810/3125], train_loss:0.170719\n",
      "Epoch [1/2], Iter [2811/3125], train_loss:0.149624\n",
      "Epoch [1/2], Iter [2812/3125], train_loss:0.175666\n",
      "Epoch [1/2], Iter [2813/3125], train_loss:0.178650\n",
      "Epoch [1/2], Iter [2814/3125], train_loss:0.160231\n",
      "Epoch [1/2], Iter [2815/3125], train_loss:0.181755\n",
      "Epoch [1/2], Iter [2816/3125], train_loss:0.177022\n",
      "Epoch [1/2], Iter [2817/3125], train_loss:0.143955\n",
      "Epoch [1/2], Iter [2818/3125], train_loss:0.182202\n",
      "Epoch [1/2], Iter [2819/3125], train_loss:0.156804\n",
      "Epoch [1/2], Iter [2820/3125], train_loss:0.158852\n",
      "Epoch [1/2], Iter [2821/3125], train_loss:0.159252\n",
      "Epoch [1/2], Iter [2822/3125], train_loss:0.159138\n",
      "Epoch [1/2], Iter [2823/3125], train_loss:0.158014\n",
      "Epoch [1/2], Iter [2824/3125], train_loss:0.173861\n",
      "Epoch [1/2], Iter [2825/3125], train_loss:0.163103\n",
      "Epoch [1/2], Iter [2826/3125], train_loss:0.169961\n",
      "Epoch [1/2], Iter [2827/3125], train_loss:0.160450\n",
      "Epoch [1/2], Iter [2828/3125], train_loss:0.168754\n",
      "Epoch [1/2], Iter [2829/3125], train_loss:0.145734\n",
      "Epoch [1/2], Iter [2830/3125], train_loss:0.171105\n",
      "Epoch [1/2], Iter [2831/3125], train_loss:0.149704\n",
      "Epoch [1/2], Iter [2832/3125], train_loss:0.157235\n",
      "Epoch [1/2], Iter [2833/3125], train_loss:0.168647\n",
      "Epoch [1/2], Iter [2834/3125], train_loss:0.170278\n",
      "Epoch [1/2], Iter [2835/3125], train_loss:0.164118\n",
      "Epoch [1/2], Iter [2836/3125], train_loss:0.160487\n",
      "Epoch [1/2], Iter [2837/3125], train_loss:0.170349\n",
      "Epoch [1/2], Iter [2838/3125], train_loss:0.153062\n",
      "Epoch [1/2], Iter [2839/3125], train_loss:0.179919\n",
      "Epoch [1/2], Iter [2840/3125], train_loss:0.165033\n",
      "Epoch [1/2], Iter [2841/3125], train_loss:0.159011\n",
      "Epoch [1/2], Iter [2842/3125], train_loss:0.141699\n",
      "Epoch [1/2], Iter [2843/3125], train_loss:0.155806\n",
      "Epoch [1/2], Iter [2844/3125], train_loss:0.180037\n",
      "Epoch [1/2], Iter [2845/3125], train_loss:0.172654\n",
      "Epoch [1/2], Iter [2846/3125], train_loss:0.162126\n",
      "Epoch [1/2], Iter [2847/3125], train_loss:0.174910\n",
      "Epoch [1/2], Iter [2848/3125], train_loss:0.190180\n",
      "Epoch [1/2], Iter [2849/3125], train_loss:0.167382\n",
      "Epoch [1/2], Iter [2850/3125], train_loss:0.140893\n",
      "Epoch [1/2], Iter [2851/3125], train_loss:0.169695\n",
      "Epoch [1/2], Iter [2852/3125], train_loss:0.149698\n",
      "Epoch [1/2], Iter [2853/3125], train_loss:0.150947\n",
      "Epoch [1/2], Iter [2854/3125], train_loss:0.160250\n",
      "Epoch [1/2], Iter [2855/3125], train_loss:0.167571\n",
      "Epoch [1/2], Iter [2856/3125], train_loss:0.158384\n",
      "Epoch [1/2], Iter [2857/3125], train_loss:0.137086\n",
      "Epoch [1/2], Iter [2858/3125], train_loss:0.177784\n",
      "Epoch [1/2], Iter [2859/3125], train_loss:0.172647\n",
      "Epoch [1/2], Iter [2860/3125], train_loss:0.169255\n",
      "Epoch [1/2], Iter [2861/3125], train_loss:0.169094\n",
      "Epoch [1/2], Iter [2862/3125], train_loss:0.159690\n",
      "Epoch [1/2], Iter [2863/3125], train_loss:0.162201\n",
      "Epoch [1/2], Iter [2864/3125], train_loss:0.167594\n",
      "Epoch [1/2], Iter [2865/3125], train_loss:0.167401\n",
      "Epoch [1/2], Iter [2866/3125], train_loss:0.164989\n",
      "Epoch [1/2], Iter [2867/3125], train_loss:0.138895\n",
      "Epoch [1/2], Iter [2868/3125], train_loss:0.155665\n",
      "Epoch [1/2], Iter [2869/3125], train_loss:0.178687\n",
      "Epoch [1/2], Iter [2870/3125], train_loss:0.142473\n",
      "Epoch [1/2], Iter [2871/3125], train_loss:0.167332\n",
      "Epoch [1/2], Iter [2872/3125], train_loss:0.179365\n",
      "Epoch [1/2], Iter [2873/3125], train_loss:0.167223\n",
      "Epoch [1/2], Iter [2874/3125], train_loss:0.178953\n",
      "Epoch [1/2], Iter [2875/3125], train_loss:0.157346\n",
      "Epoch [1/2], Iter [2876/3125], train_loss:0.182048\n",
      "Epoch [1/2], Iter [2877/3125], train_loss:0.172396\n",
      "Epoch [1/2], Iter [2878/3125], train_loss:0.175423\n",
      "Epoch [1/2], Iter [2879/3125], train_loss:0.161872\n",
      "Epoch [1/2], Iter [2880/3125], train_loss:0.169045\n",
      "Epoch [1/2], Iter [2881/3125], train_loss:0.169418\n",
      "Epoch [1/2], Iter [2882/3125], train_loss:0.160182\n",
      "Epoch [1/2], Iter [2883/3125], train_loss:0.186741\n",
      "Epoch [1/2], Iter [2884/3125], train_loss:0.157193\n",
      "Epoch [1/2], Iter [2885/3125], train_loss:0.138638\n",
      "Epoch [1/2], Iter [2886/3125], train_loss:0.150510\n",
      "Epoch [1/2], Iter [2887/3125], train_loss:0.176207\n",
      "Epoch [1/2], Iter [2888/3125], train_loss:0.155249\n",
      "Epoch [1/2], Iter [2889/3125], train_loss:0.159106\n",
      "Epoch [1/2], Iter [2890/3125], train_loss:0.162412\n",
      "Epoch [1/2], Iter [2891/3125], train_loss:0.152091\n",
      "Epoch [1/2], Iter [2892/3125], train_loss:0.176883\n",
      "Epoch [1/2], Iter [2893/3125], train_loss:0.146511\n",
      "Epoch [1/2], Iter [2894/3125], train_loss:0.163757\n",
      "Epoch [1/2], Iter [2895/3125], train_loss:0.160787\n",
      "Epoch [1/2], Iter [2896/3125], train_loss:0.160858\n",
      "Epoch [1/2], Iter [2897/3125], train_loss:0.155350\n",
      "Epoch [1/2], Iter [2898/3125], train_loss:0.169348\n",
      "Epoch [1/2], Iter [2899/3125], train_loss:0.144282\n",
      "Epoch [1/2], Iter [2900/3125], train_loss:0.167706\n",
      "Epoch [1/2], Iter [2901/3125], train_loss:0.182318\n",
      "Epoch [1/2], Iter [2902/3125], train_loss:0.171248\n",
      "Epoch [1/2], Iter [2903/3125], train_loss:0.165353\n",
      "Epoch [1/2], Iter [2904/3125], train_loss:0.151637\n",
      "Epoch [1/2], Iter [2905/3125], train_loss:0.161721\n",
      "Epoch [1/2], Iter [2906/3125], train_loss:0.153006\n",
      "Epoch [1/2], Iter [2907/3125], train_loss:0.161867\n",
      "Epoch [1/2], Iter [2908/3125], train_loss:0.156607\n",
      "Epoch [1/2], Iter [2909/3125], train_loss:0.178779\n",
      "Epoch [1/2], Iter [2910/3125], train_loss:0.192463\n",
      "Epoch [1/2], Iter [2911/3125], train_loss:0.148583\n",
      "Epoch [1/2], Iter [2912/3125], train_loss:0.170696\n",
      "Epoch [1/2], Iter [2913/3125], train_loss:0.168631\n",
      "Epoch [1/2], Iter [2914/3125], train_loss:0.168608\n",
      "Epoch [1/2], Iter [2915/3125], train_loss:0.166084\n",
      "Epoch [1/2], Iter [2916/3125], train_loss:0.164468\n",
      "Epoch [1/2], Iter [2917/3125], train_loss:0.154483\n",
      "Epoch [1/2], Iter [2918/3125], train_loss:0.166607\n",
      "Epoch [1/2], Iter [2919/3125], train_loss:0.175541\n",
      "Epoch [1/2], Iter [2920/3125], train_loss:0.146106\n",
      "Epoch [1/2], Iter [2921/3125], train_loss:0.186289\n",
      "Epoch [1/2], Iter [2922/3125], train_loss:0.148206\n",
      "Epoch [1/2], Iter [2923/3125], train_loss:0.180759\n",
      "Epoch [1/2], Iter [2924/3125], train_loss:0.148458\n",
      "Epoch [1/2], Iter [2925/3125], train_loss:0.153044\n",
      "Epoch [1/2], Iter [2926/3125], train_loss:0.173843\n",
      "Epoch [1/2], Iter [2927/3125], train_loss:0.173281\n",
      "Epoch [1/2], Iter [2928/3125], train_loss:0.173701\n",
      "Epoch [1/2], Iter [2929/3125], train_loss:0.165718\n",
      "Epoch [1/2], Iter [2930/3125], train_loss:0.173092\n",
      "Epoch [1/2], Iter [2931/3125], train_loss:0.171520\n",
      "Epoch [1/2], Iter [2932/3125], train_loss:0.148433\n",
      "Epoch [1/2], Iter [2933/3125], train_loss:0.149291\n",
      "Epoch [1/2], Iter [2934/3125], train_loss:0.173039\n",
      "Epoch [1/2], Iter [2935/3125], train_loss:0.167303\n",
      "Epoch [1/2], Iter [2936/3125], train_loss:0.148045\n",
      "Epoch [1/2], Iter [2937/3125], train_loss:0.160600\n",
      "Epoch [1/2], Iter [2938/3125], train_loss:0.175791\n",
      "Epoch [1/2], Iter [2939/3125], train_loss:0.170290\n",
      "Epoch [1/2], Iter [2940/3125], train_loss:0.168750\n",
      "Epoch [1/2], Iter [2941/3125], train_loss:0.174851\n",
      "Epoch [1/2], Iter [2942/3125], train_loss:0.167067\n",
      "Epoch [1/2], Iter [2943/3125], train_loss:0.147908\n",
      "Epoch [1/2], Iter [2944/3125], train_loss:0.161702\n",
      "Epoch [1/2], Iter [2945/3125], train_loss:0.166226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [2946/3125], train_loss:0.152965\n",
      "Epoch [1/2], Iter [2947/3125], train_loss:0.151126\n",
      "Epoch [1/2], Iter [2948/3125], train_loss:0.159228\n",
      "Epoch [1/2], Iter [2949/3125], train_loss:0.147525\n",
      "Epoch [1/2], Iter [2950/3125], train_loss:0.186010\n",
      "Epoch [1/2], Iter [2951/3125], train_loss:0.144456\n",
      "Epoch [1/2], Iter [2952/3125], train_loss:0.144571\n",
      "Epoch [1/2], Iter [2953/3125], train_loss:0.149504\n",
      "Epoch [1/2], Iter [2954/3125], train_loss:0.155754\n",
      "Epoch [1/2], Iter [2955/3125], train_loss:0.157044\n",
      "Epoch [1/2], Iter [2956/3125], train_loss:0.164638\n",
      "Epoch [1/2], Iter [2957/3125], train_loss:0.161717\n",
      "Epoch [1/2], Iter [2958/3125], train_loss:0.150048\n",
      "Epoch [1/2], Iter [2959/3125], train_loss:0.161040\n",
      "Epoch [1/2], Iter [2960/3125], train_loss:0.147002\n",
      "Epoch [1/2], Iter [2961/3125], train_loss:0.168605\n",
      "Epoch [1/2], Iter [2962/3125], train_loss:0.160989\n",
      "Epoch [1/2], Iter [2963/3125], train_loss:0.179867\n",
      "Epoch [1/2], Iter [2964/3125], train_loss:0.173219\n",
      "Epoch [1/2], Iter [2965/3125], train_loss:0.166897\n",
      "Epoch [1/2], Iter [2966/3125], train_loss:0.160661\n",
      "Epoch [1/2], Iter [2967/3125], train_loss:0.161262\n",
      "Epoch [1/2], Iter [2968/3125], train_loss:0.164723\n",
      "Epoch [1/2], Iter [2969/3125], train_loss:0.142853\n",
      "Epoch [1/2], Iter [2970/3125], train_loss:0.171715\n",
      "Epoch [1/2], Iter [2971/3125], train_loss:0.158447\n",
      "Epoch [1/2], Iter [2972/3125], train_loss:0.164181\n",
      "Epoch [1/2], Iter [2973/3125], train_loss:0.177048\n",
      "Epoch [1/2], Iter [2974/3125], train_loss:0.167190\n",
      "Epoch [1/2], Iter [2975/3125], train_loss:0.158204\n",
      "Epoch [1/2], Iter [2976/3125], train_loss:0.151028\n",
      "Epoch [1/2], Iter [2977/3125], train_loss:0.162853\n",
      "Epoch [1/2], Iter [2978/3125], train_loss:0.165735\n",
      "Epoch [1/2], Iter [2979/3125], train_loss:0.173848\n",
      "Epoch [1/2], Iter [2980/3125], train_loss:0.149452\n",
      "Epoch [1/2], Iter [2981/3125], train_loss:0.152468\n",
      "Epoch [1/2], Iter [2982/3125], train_loss:0.168138\n",
      "Epoch [1/2], Iter [2983/3125], train_loss:0.163172\n",
      "Epoch [1/2], Iter [2984/3125], train_loss:0.162576\n",
      "Epoch [1/2], Iter [2985/3125], train_loss:0.188783\n",
      "Epoch [1/2], Iter [2986/3125], train_loss:0.161452\n",
      "Epoch [1/2], Iter [2987/3125], train_loss:0.136657\n",
      "Epoch [1/2], Iter [2988/3125], train_loss:0.145196\n",
      "Epoch [1/2], Iter [2989/3125], train_loss:0.183863\n",
      "Epoch [1/2], Iter [2990/3125], train_loss:0.170865\n",
      "Epoch [1/2], Iter [2991/3125], train_loss:0.155084\n",
      "Epoch [1/2], Iter [2992/3125], train_loss:0.175260\n",
      "Epoch [1/2], Iter [2993/3125], train_loss:0.177893\n",
      "Epoch [1/2], Iter [2994/3125], train_loss:0.171074\n",
      "Epoch [1/2], Iter [2995/3125], train_loss:0.166262\n",
      "Epoch [1/2], Iter [2996/3125], train_loss:0.168631\n",
      "Epoch [1/2], Iter [2997/3125], train_loss:0.142343\n",
      "Epoch [1/2], Iter [2998/3125], train_loss:0.176656\n",
      "Epoch [1/2], Iter [2999/3125], train_loss:0.181024\n",
      "Epoch [1/2], Iter [3000/3125], train_loss:0.164563\n",
      "Epoch [1/2], Iter [3001/3125], train_loss:0.181617\n",
      "Epoch [1/2], Iter [3002/3125], train_loss:0.172865\n",
      "Epoch [1/2], Iter [3003/3125], train_loss:0.179876\n",
      "Epoch [1/2], Iter [3004/3125], train_loss:0.165719\n",
      "Epoch [1/2], Iter [3005/3125], train_loss:0.177486\n",
      "Epoch [1/2], Iter [3006/3125], train_loss:0.176950\n",
      "Epoch [1/2], Iter [3007/3125], train_loss:0.178203\n",
      "Epoch [1/2], Iter [3008/3125], train_loss:0.178196\n",
      "Epoch [1/2], Iter [3009/3125], train_loss:0.171647\n",
      "Epoch [1/2], Iter [3010/3125], train_loss:0.173414\n",
      "Epoch [1/2], Iter [3011/3125], train_loss:0.164811\n",
      "Epoch [1/2], Iter [3012/3125], train_loss:0.147020\n",
      "Epoch [1/2], Iter [3013/3125], train_loss:0.166289\n",
      "Epoch [1/2], Iter [3014/3125], train_loss:0.161090\n",
      "Epoch [1/2], Iter [3015/3125], train_loss:0.162289\n",
      "Epoch [1/2], Iter [3016/3125], train_loss:0.130393\n",
      "Epoch [1/2], Iter [3017/3125], train_loss:0.132035\n",
      "Epoch [1/2], Iter [3018/3125], train_loss:0.174404\n",
      "Epoch [1/2], Iter [3019/3125], train_loss:0.157980\n",
      "Epoch [1/2], Iter [3020/3125], train_loss:0.158861\n",
      "Epoch [1/2], Iter [3021/3125], train_loss:0.182830\n",
      "Epoch [1/2], Iter [3022/3125], train_loss:0.158150\n",
      "Epoch [1/2], Iter [3023/3125], train_loss:0.156165\n",
      "Epoch [1/2], Iter [3024/3125], train_loss:0.145425\n",
      "Epoch [1/2], Iter [3025/3125], train_loss:0.176111\n",
      "Epoch [1/2], Iter [3026/3125], train_loss:0.186718\n",
      "Epoch [1/2], Iter [3027/3125], train_loss:0.150117\n",
      "Epoch [1/2], Iter [3028/3125], train_loss:0.173456\n",
      "Epoch [1/2], Iter [3029/3125], train_loss:0.156002\n",
      "Epoch [1/2], Iter [3030/3125], train_loss:0.175069\n",
      "Epoch [1/2], Iter [3031/3125], train_loss:0.150203\n",
      "Epoch [1/2], Iter [3032/3125], train_loss:0.170119\n",
      "Epoch [1/2], Iter [3033/3125], train_loss:0.161877\n",
      "Epoch [1/2], Iter [3034/3125], train_loss:0.154505\n",
      "Epoch [1/2], Iter [3035/3125], train_loss:0.170968\n",
      "Epoch [1/2], Iter [3036/3125], train_loss:0.143941\n",
      "Epoch [1/2], Iter [3037/3125], train_loss:0.171731\n",
      "Epoch [1/2], Iter [3038/3125], train_loss:0.150052\n",
      "Epoch [1/2], Iter [3039/3125], train_loss:0.155370\n",
      "Epoch [1/2], Iter [3040/3125], train_loss:0.154070\n",
      "Epoch [1/2], Iter [3041/3125], train_loss:0.169434\n",
      "Epoch [1/2], Iter [3042/3125], train_loss:0.153931\n",
      "Epoch [1/2], Iter [3043/3125], train_loss:0.167334\n",
      "Epoch [1/2], Iter [3044/3125], train_loss:0.160416\n",
      "Epoch [1/2], Iter [3045/3125], train_loss:0.161101\n",
      "Epoch [1/2], Iter [3046/3125], train_loss:0.153652\n",
      "Epoch [1/2], Iter [3047/3125], train_loss:0.166452\n",
      "Epoch [1/2], Iter [3048/3125], train_loss:0.148719\n",
      "Epoch [1/2], Iter [3049/3125], train_loss:0.153907\n",
      "Epoch [1/2], Iter [3050/3125], train_loss:0.165748\n",
      "Epoch [1/2], Iter [3051/3125], train_loss:0.177738\n",
      "Epoch [1/2], Iter [3052/3125], train_loss:0.162658\n",
      "Epoch [1/2], Iter [3053/3125], train_loss:0.157725\n",
      "Epoch [1/2], Iter [3054/3125], train_loss:0.168763\n",
      "Epoch [1/2], Iter [3055/3125], train_loss:0.169479\n",
      "Epoch [1/2], Iter [3056/3125], train_loss:0.160464\n",
      "Epoch [1/2], Iter [3057/3125], train_loss:0.165181\n",
      "Epoch [1/2], Iter [3058/3125], train_loss:0.158833\n",
      "Epoch [1/2], Iter [3059/3125], train_loss:0.174259\n",
      "Epoch [1/2], Iter [3060/3125], train_loss:0.197122\n",
      "Epoch [1/2], Iter [3061/3125], train_loss:0.157540\n",
      "Epoch [1/2], Iter [3062/3125], train_loss:0.153574\n",
      "Epoch [1/2], Iter [3063/3125], train_loss:0.158650\n",
      "Epoch [1/2], Iter [3064/3125], train_loss:0.159368\n",
      "Epoch [1/2], Iter [3065/3125], train_loss:0.126841\n",
      "Epoch [1/2], Iter [3066/3125], train_loss:0.190723\n",
      "Epoch [1/2], Iter [3067/3125], train_loss:0.161133\n",
      "Epoch [1/2], Iter [3068/3125], train_loss:0.147794\n",
      "Epoch [1/2], Iter [3069/3125], train_loss:0.154277\n",
      "Epoch [1/2], Iter [3070/3125], train_loss:0.160044\n",
      "Epoch [1/2], Iter [3071/3125], train_loss:0.157531\n",
      "Epoch [1/2], Iter [3072/3125], train_loss:0.168389\n",
      "Epoch [1/2], Iter [3073/3125], train_loss:0.172469\n",
      "Epoch [1/2], Iter [3074/3125], train_loss:0.155994\n",
      "Epoch [1/2], Iter [3075/3125], train_loss:0.147720\n",
      "Epoch [1/2], Iter [3076/3125], train_loss:0.137509\n",
      "Epoch [1/2], Iter [3077/3125], train_loss:0.181711\n",
      "Epoch [1/2], Iter [3078/3125], train_loss:0.177348\n",
      "Epoch [1/2], Iter [3079/3125], train_loss:0.148808\n",
      "Epoch [1/2], Iter [3080/3125], train_loss:0.175595\n",
      "Epoch [1/2], Iter [3081/3125], train_loss:0.165768\n",
      "Epoch [1/2], Iter [3082/3125], train_loss:0.142488\n",
      "Epoch [1/2], Iter [3083/3125], train_loss:0.147224\n",
      "Epoch [1/2], Iter [3084/3125], train_loss:0.168570\n",
      "Epoch [1/2], Iter [3085/3125], train_loss:0.155916\n",
      "Epoch [1/2], Iter [3086/3125], train_loss:0.169448\n",
      "Epoch [1/2], Iter [3087/3125], train_loss:0.148978\n",
      "Epoch [1/2], Iter [3088/3125], train_loss:0.158718\n",
      "Epoch [1/2], Iter [3089/3125], train_loss:0.139569\n",
      "Epoch [1/2], Iter [3090/3125], train_loss:0.179602\n",
      "Epoch [1/2], Iter [3091/3125], train_loss:0.172581\n",
      "Epoch [1/2], Iter [3092/3125], train_loss:0.172989\n",
      "Epoch [1/2], Iter [3093/3125], train_loss:0.174835\n",
      "Epoch [1/2], Iter [3094/3125], train_loss:0.162024\n",
      "Epoch [1/2], Iter [3095/3125], train_loss:0.149372\n",
      "Epoch [1/2], Iter [3096/3125], train_loss:0.182143\n",
      "Epoch [1/2], Iter [3097/3125], train_loss:0.173537\n",
      "Epoch [1/2], Iter [3098/3125], train_loss:0.180467\n",
      "Epoch [1/2], Iter [3099/3125], train_loss:0.138658\n",
      "Epoch [1/2], Iter [3100/3125], train_loss:0.167943\n",
      "Epoch [1/2], Iter [3101/3125], train_loss:0.179498\n",
      "Epoch [1/2], Iter [3102/3125], train_loss:0.168319\n",
      "Epoch [1/2], Iter [3103/3125], train_loss:0.159227\n",
      "Epoch [1/2], Iter [3104/3125], train_loss:0.143851\n",
      "Epoch [1/2], Iter [3105/3125], train_loss:0.162043\n",
      "Epoch [1/2], Iter [3106/3125], train_loss:0.173713\n",
      "Epoch [1/2], Iter [3107/3125], train_loss:0.160019\n",
      "Epoch [1/2], Iter [3108/3125], train_loss:0.187196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [3109/3125], train_loss:0.178457\n",
      "Epoch [1/2], Iter [3110/3125], train_loss:0.166758\n",
      "Epoch [1/2], Iter [3111/3125], train_loss:0.162495\n",
      "Epoch [1/2], Iter [3112/3125], train_loss:0.144868\n",
      "Epoch [1/2], Iter [3113/3125], train_loss:0.170601\n",
      "Epoch [1/2], Iter [3114/3125], train_loss:0.152794\n",
      "Epoch [1/2], Iter [3115/3125], train_loss:0.166172\n",
      "Epoch [1/2], Iter [3116/3125], train_loss:0.150413\n",
      "Epoch [1/2], Iter [3117/3125], train_loss:0.146555\n",
      "Epoch [1/2], Iter [3118/3125], train_loss:0.158817\n",
      "Epoch [1/2], Iter [3119/3125], train_loss:0.179008\n",
      "Epoch [1/2], Iter [3120/3125], train_loss:0.183372\n",
      "Epoch [1/2], Iter [3121/3125], train_loss:0.165688\n",
      "Epoch [1/2], Iter [3122/3125], train_loss:0.151766\n",
      "Epoch [1/2], Iter [3123/3125], train_loss:0.147575\n",
      "Epoch [1/2], Iter [3124/3125], train_loss:0.140461\n",
      "Epoch [1/2], Iter [3125/3125], train_loss:0.166029\n",
      "Epoch [1/2], train_loss:0.1625, train_acc:9.7080%, test_loss:0.1695, test_acc:10.6200%\n",
      "Epoch [2/2], Iter [1/3125], train_loss:0.146202\n",
      "Epoch [2/2], Iter [2/3125], train_loss:0.173672\n",
      "Epoch [2/2], Iter [3/3125], train_loss:0.165151\n",
      "Epoch [2/2], Iter [4/3125], train_loss:0.158770\n",
      "Epoch [2/2], Iter [5/3125], train_loss:0.175999\n",
      "Epoch [2/2], Iter [6/3125], train_loss:0.163998\n",
      "Epoch [2/2], Iter [7/3125], train_loss:0.165410\n",
      "Epoch [2/2], Iter [8/3125], train_loss:0.161637\n",
      "Epoch [2/2], Iter [9/3125], train_loss:0.148239\n",
      "Epoch [2/2], Iter [10/3125], train_loss:0.162426\n",
      "Epoch [2/2], Iter [11/3125], train_loss:0.168900\n",
      "Epoch [2/2], Iter [12/3125], train_loss:0.149848\n",
      "Epoch [2/2], Iter [13/3125], train_loss:0.147608\n",
      "Epoch [2/2], Iter [14/3125], train_loss:0.160673\n",
      "Epoch [2/2], Iter [15/3125], train_loss:0.172021\n",
      "Epoch [2/2], Iter [16/3125], train_loss:0.162101\n",
      "Epoch [2/2], Iter [17/3125], train_loss:0.150480\n",
      "Epoch [2/2], Iter [18/3125], train_loss:0.154776\n",
      "Epoch [2/2], Iter [19/3125], train_loss:0.163754\n",
      "Epoch [2/2], Iter [20/3125], train_loss:0.177525\n",
      "Epoch [2/2], Iter [21/3125], train_loss:0.168097\n",
      "Epoch [2/2], Iter [22/3125], train_loss:0.156192\n",
      "Epoch [2/2], Iter [23/3125], train_loss:0.166126\n",
      "Epoch [2/2], Iter [24/3125], train_loss:0.147863\n",
      "Epoch [2/2], Iter [25/3125], train_loss:0.176202\n",
      "Epoch [2/2], Iter [26/3125], train_loss:0.159570\n",
      "Epoch [2/2], Iter [27/3125], train_loss:0.168702\n",
      "Epoch [2/2], Iter [28/3125], train_loss:0.151392\n",
      "Epoch [2/2], Iter [29/3125], train_loss:0.162362\n",
      "Epoch [2/2], Iter [30/3125], train_loss:0.147167\n",
      "Epoch [2/2], Iter [31/3125], train_loss:0.155992\n",
      "Epoch [2/2], Iter [32/3125], train_loss:0.143932\n",
      "Epoch [2/2], Iter [33/3125], train_loss:0.167568\n",
      "Epoch [2/2], Iter [34/3125], train_loss:0.156876\n",
      "Epoch [2/2], Iter [35/3125], train_loss:0.149783\n",
      "Epoch [2/2], Iter [36/3125], train_loss:0.184439\n",
      "Epoch [2/2], Iter [37/3125], train_loss:0.162946\n",
      "Epoch [2/2], Iter [38/3125], train_loss:0.148541\n",
      "Epoch [2/2], Iter [39/3125], train_loss:0.165627\n",
      "Epoch [2/2], Iter [40/3125], train_loss:0.169342\n",
      "Epoch [2/2], Iter [41/3125], train_loss:0.165507\n",
      "Epoch [2/2], Iter [42/3125], train_loss:0.166825\n",
      "Epoch [2/2], Iter [43/3125], train_loss:0.180178\n",
      "Epoch [2/2], Iter [44/3125], train_loss:0.174066\n",
      "Epoch [2/2], Iter [45/3125], train_loss:0.175319\n",
      "Epoch [2/2], Iter [46/3125], train_loss:0.159672\n",
      "Epoch [2/2], Iter [47/3125], train_loss:0.155855\n",
      "Epoch [2/2], Iter [48/3125], train_loss:0.166862\n",
      "Epoch [2/2], Iter [49/3125], train_loss:0.157197\n",
      "Epoch [2/2], Iter [50/3125], train_loss:0.154708\n",
      "Epoch [2/2], Iter [51/3125], train_loss:0.169141\n",
      "Epoch [2/2], Iter [52/3125], train_loss:0.189146\n",
      "Epoch [2/2], Iter [53/3125], train_loss:0.147940\n",
      "Epoch [2/2], Iter [54/3125], train_loss:0.173229\n",
      "Epoch [2/2], Iter [55/3125], train_loss:0.147851\n",
      "Epoch [2/2], Iter [56/3125], train_loss:0.166568\n",
      "Epoch [2/2], Iter [57/3125], train_loss:0.157517\n",
      "Epoch [2/2], Iter [58/3125], train_loss:0.157088\n",
      "Epoch [2/2], Iter [59/3125], train_loss:0.170904\n",
      "Epoch [2/2], Iter [60/3125], train_loss:0.130077\n",
      "Epoch [2/2], Iter [61/3125], train_loss:0.162462\n",
      "Epoch [2/2], Iter [62/3125], train_loss:0.167202\n",
      "Epoch [2/2], Iter [63/3125], train_loss:0.144449\n",
      "Epoch [2/2], Iter [64/3125], train_loss:0.147543\n",
      "Epoch [2/2], Iter [65/3125], train_loss:0.178345\n",
      "Epoch [2/2], Iter [66/3125], train_loss:0.171756\n",
      "Epoch [2/2], Iter [67/3125], train_loss:0.182125\n",
      "Epoch [2/2], Iter [68/3125], train_loss:0.163568\n",
      "Epoch [2/2], Iter [69/3125], train_loss:0.168720\n",
      "Epoch [2/2], Iter [70/3125], train_loss:0.166233\n",
      "Epoch [2/2], Iter [71/3125], train_loss:0.165497\n",
      "Epoch [2/2], Iter [72/3125], train_loss:0.158568\n",
      "Epoch [2/2], Iter [73/3125], train_loss:0.158017\n",
      "Epoch [2/2], Iter [74/3125], train_loss:0.146704\n",
      "Epoch [2/2], Iter [75/3125], train_loss:0.168960\n",
      "Epoch [2/2], Iter [76/3125], train_loss:0.176339\n",
      "Epoch [2/2], Iter [77/3125], train_loss:0.157601\n",
      "Epoch [2/2], Iter [78/3125], train_loss:0.150234\n",
      "Epoch [2/2], Iter [79/3125], train_loss:0.171131\n",
      "Epoch [2/2], Iter [80/3125], train_loss:0.168470\n",
      "Epoch [2/2], Iter [81/3125], train_loss:0.165504\n",
      "Epoch [2/2], Iter [82/3125], train_loss:0.182929\n",
      "Epoch [2/2], Iter [83/3125], train_loss:0.149121\n",
      "Epoch [2/2], Iter [84/3125], train_loss:0.170251\n",
      "Epoch [2/2], Iter [85/3125], train_loss:0.176452\n",
      "Epoch [2/2], Iter [86/3125], train_loss:0.163143\n",
      "Epoch [2/2], Iter [87/3125], train_loss:0.149888\n",
      "Epoch [2/2], Iter [88/3125], train_loss:0.158223\n",
      "Epoch [2/2], Iter [89/3125], train_loss:0.165219\n",
      "Epoch [2/2], Iter [90/3125], train_loss:0.175566\n",
      "Epoch [2/2], Iter [91/3125], train_loss:0.172680\n",
      "Epoch [2/2], Iter [92/3125], train_loss:0.157610\n",
      "Epoch [2/2], Iter [93/3125], train_loss:0.149683\n",
      "Epoch [2/2], Iter [94/3125], train_loss:0.150491\n",
      "Epoch [2/2], Iter [95/3125], train_loss:0.143823\n",
      "Epoch [2/2], Iter [96/3125], train_loss:0.147380\n",
      "Epoch [2/2], Iter [97/3125], train_loss:0.162991\n",
      "Epoch [2/2], Iter [98/3125], train_loss:0.142088\n",
      "Epoch [2/2], Iter [99/3125], train_loss:0.165098\n",
      "Epoch [2/2], Iter [100/3125], train_loss:0.142414\n",
      "Epoch [2/2], Iter [101/3125], train_loss:0.171030\n",
      "Epoch [2/2], Iter [102/3125], train_loss:0.164070\n",
      "Epoch [2/2], Iter [103/3125], train_loss:0.155812\n",
      "Epoch [2/2], Iter [104/3125], train_loss:0.166394\n",
      "Epoch [2/2], Iter [105/3125], train_loss:0.162388\n",
      "Epoch [2/2], Iter [106/3125], train_loss:0.156700\n",
      "Epoch [2/2], Iter [107/3125], train_loss:0.153787\n",
      "Epoch [2/2], Iter [108/3125], train_loss:0.146724\n",
      "Epoch [2/2], Iter [109/3125], train_loss:0.146993\n",
      "Epoch [2/2], Iter [110/3125], train_loss:0.161078\n",
      "Epoch [2/2], Iter [111/3125], train_loss:0.141862\n",
      "Epoch [2/2], Iter [112/3125], train_loss:0.164413\n",
      "Epoch [2/2], Iter [113/3125], train_loss:0.172509\n",
      "Epoch [2/2], Iter [114/3125], train_loss:0.133704\n",
      "Epoch [2/2], Iter [115/3125], train_loss:0.156570\n",
      "Epoch [2/2], Iter [116/3125], train_loss:0.149274\n",
      "Epoch [2/2], Iter [117/3125], train_loss:0.172428\n",
      "Epoch [2/2], Iter [118/3125], train_loss:0.158011\n",
      "Epoch [2/2], Iter [119/3125], train_loss:0.180269\n",
      "Epoch [2/2], Iter [120/3125], train_loss:0.133947\n",
      "Epoch [2/2], Iter [121/3125], train_loss:0.160919\n",
      "Epoch [2/2], Iter [122/3125], train_loss:0.160910\n",
      "Epoch [2/2], Iter [123/3125], train_loss:0.156073\n",
      "Epoch [2/2], Iter [124/3125], train_loss:0.170647\n",
      "Epoch [2/2], Iter [125/3125], train_loss:0.168909\n",
      "Epoch [2/2], Iter [126/3125], train_loss:0.163942\n",
      "Epoch [2/2], Iter [127/3125], train_loss:0.185147\n",
      "Epoch [2/2], Iter [128/3125], train_loss:0.147694\n",
      "Epoch [2/2], Iter [129/3125], train_loss:0.154867\n",
      "Epoch [2/2], Iter [130/3125], train_loss:0.156400\n",
      "Epoch [2/2], Iter [131/3125], train_loss:0.159859\n",
      "Epoch [2/2], Iter [132/3125], train_loss:0.163676\n",
      "Epoch [2/2], Iter [133/3125], train_loss:0.164885\n",
      "Epoch [2/2], Iter [134/3125], train_loss:0.157290\n",
      "Epoch [2/2], Iter [135/3125], train_loss:0.153076\n",
      "Epoch [2/2], Iter [136/3125], train_loss:0.170953\n",
      "Epoch [2/2], Iter [137/3125], train_loss:0.161285\n",
      "Epoch [2/2], Iter [138/3125], train_loss:0.176708\n",
      "Epoch [2/2], Iter [139/3125], train_loss:0.164216\n",
      "Epoch [2/2], Iter [140/3125], train_loss:0.157998\n",
      "Epoch [2/2], Iter [141/3125], train_loss:0.161874\n",
      "Epoch [2/2], Iter [142/3125], train_loss:0.165788\n",
      "Epoch [2/2], Iter [143/3125], train_loss:0.147918\n",
      "Epoch [2/2], Iter [144/3125], train_loss:0.168310\n",
      "Epoch [2/2], Iter [145/3125], train_loss:0.157749\n",
      "Epoch [2/2], Iter [146/3125], train_loss:0.170075\n",
      "Epoch [2/2], Iter [147/3125], train_loss:0.162752\n",
      "Epoch [2/2], Iter [148/3125], train_loss:0.170934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [149/3125], train_loss:0.184253\n",
      "Epoch [2/2], Iter [150/3125], train_loss:0.178670\n",
      "Epoch [2/2], Iter [151/3125], train_loss:0.168679\n",
      "Epoch [2/2], Iter [152/3125], train_loss:0.175516\n",
      "Epoch [2/2], Iter [153/3125], train_loss:0.155538\n",
      "Epoch [2/2], Iter [154/3125], train_loss:0.161324\n",
      "Epoch [2/2], Iter [155/3125], train_loss:0.156795\n",
      "Epoch [2/2], Iter [156/3125], train_loss:0.154852\n",
      "Epoch [2/2], Iter [157/3125], train_loss:0.156921\n",
      "Epoch [2/2], Iter [158/3125], train_loss:0.163482\n",
      "Epoch [2/2], Iter [159/3125], train_loss:0.173362\n",
      "Epoch [2/2], Iter [160/3125], train_loss:0.167319\n",
      "Epoch [2/2], Iter [161/3125], train_loss:0.173615\n",
      "Epoch [2/2], Iter [162/3125], train_loss:0.160354\n",
      "Epoch [2/2], Iter [163/3125], train_loss:0.167696\n",
      "Epoch [2/2], Iter [164/3125], train_loss:0.161250\n",
      "Epoch [2/2], Iter [165/3125], train_loss:0.160384\n",
      "Epoch [2/2], Iter [166/3125], train_loss:0.164563\n",
      "Epoch [2/2], Iter [167/3125], train_loss:0.161137\n",
      "Epoch [2/2], Iter [168/3125], train_loss:0.169574\n",
      "Epoch [2/2], Iter [169/3125], train_loss:0.175531\n",
      "Epoch [2/2], Iter [170/3125], train_loss:0.169590\n",
      "Epoch [2/2], Iter [171/3125], train_loss:0.157394\n",
      "Epoch [2/2], Iter [172/3125], train_loss:0.156446\n",
      "Epoch [2/2], Iter [173/3125], train_loss:0.176099\n",
      "Epoch [2/2], Iter [174/3125], train_loss:0.169188\n",
      "Epoch [2/2], Iter [175/3125], train_loss:0.181089\n",
      "Epoch [2/2], Iter [176/3125], train_loss:0.157710\n",
      "Epoch [2/2], Iter [177/3125], train_loss:0.154907\n",
      "Epoch [2/2], Iter [178/3125], train_loss:0.139118\n",
      "Epoch [2/2], Iter [179/3125], train_loss:0.148639\n",
      "Epoch [2/2], Iter [180/3125], train_loss:0.149552\n",
      "Epoch [2/2], Iter [181/3125], train_loss:0.181338\n",
      "Epoch [2/2], Iter [182/3125], train_loss:0.162902\n",
      "Epoch [2/2], Iter [183/3125], train_loss:0.173415\n",
      "Epoch [2/2], Iter [184/3125], train_loss:0.163751\n",
      "Epoch [2/2], Iter [185/3125], train_loss:0.148597\n",
      "Epoch [2/2], Iter [186/3125], train_loss:0.174917\n",
      "Epoch [2/2], Iter [187/3125], train_loss:0.182508\n",
      "Epoch [2/2], Iter [188/3125], train_loss:0.152830\n",
      "Epoch [2/2], Iter [189/3125], train_loss:0.153870\n",
      "Epoch [2/2], Iter [190/3125], train_loss:0.163149\n",
      "Epoch [2/2], Iter [191/3125], train_loss:0.148616\n",
      "Epoch [2/2], Iter [192/3125], train_loss:0.148913\n",
      "Epoch [2/2], Iter [193/3125], train_loss:0.187292\n",
      "Epoch [2/2], Iter [194/3125], train_loss:0.163163\n",
      "Epoch [2/2], Iter [195/3125], train_loss:0.157831\n",
      "Epoch [2/2], Iter [196/3125], train_loss:0.183797\n",
      "Epoch [2/2], Iter [197/3125], train_loss:0.171313\n",
      "Epoch [2/2], Iter [198/3125], train_loss:0.157854\n",
      "Epoch [2/2], Iter [199/3125], train_loss:0.162880\n",
      "Epoch [2/2], Iter [200/3125], train_loss:0.176139\n",
      "Epoch [2/2], Iter [201/3125], train_loss:0.170941\n",
      "Epoch [2/2], Iter [202/3125], train_loss:0.177162\n",
      "Epoch [2/2], Iter [203/3125], train_loss:0.150648\n",
      "Epoch [2/2], Iter [204/3125], train_loss:0.171486\n",
      "Epoch [2/2], Iter [205/3125], train_loss:0.150289\n",
      "Epoch [2/2], Iter [206/3125], train_loss:0.168230\n",
      "Epoch [2/2], Iter [207/3125], train_loss:0.163843\n",
      "Epoch [2/2], Iter [208/3125], train_loss:0.162255\n",
      "Epoch [2/2], Iter [209/3125], train_loss:0.162224\n",
      "Epoch [2/2], Iter [210/3125], train_loss:0.147608\n",
      "Epoch [2/2], Iter [211/3125], train_loss:0.153870\n",
      "Epoch [2/2], Iter [212/3125], train_loss:0.141862\n",
      "Epoch [2/2], Iter [213/3125], train_loss:0.148429\n",
      "Epoch [2/2], Iter [214/3125], train_loss:0.156956\n",
      "Epoch [2/2], Iter [215/3125], train_loss:0.160064\n",
      "Epoch [2/2], Iter [216/3125], train_loss:0.155396\n",
      "Epoch [2/2], Iter [217/3125], train_loss:0.158974\n",
      "Epoch [2/2], Iter [218/3125], train_loss:0.164166\n",
      "Epoch [2/2], Iter [219/3125], train_loss:0.150157\n",
      "Epoch [2/2], Iter [220/3125], train_loss:0.159278\n",
      "Epoch [2/2], Iter [221/3125], train_loss:0.145524\n",
      "Epoch [2/2], Iter [222/3125], train_loss:0.153799\n",
      "Epoch [2/2], Iter [223/3125], train_loss:0.156198\n",
      "Epoch [2/2], Iter [224/3125], train_loss:0.161148\n",
      "Epoch [2/2], Iter [225/3125], train_loss:0.142585\n",
      "Epoch [2/2], Iter [226/3125], train_loss:0.146489\n",
      "Epoch [2/2], Iter [227/3125], train_loss:0.172975\n",
      "Epoch [2/2], Iter [228/3125], train_loss:0.194386\n",
      "Epoch [2/2], Iter [229/3125], train_loss:0.172534\n",
      "Epoch [2/2], Iter [230/3125], train_loss:0.147119\n",
      "Epoch [2/2], Iter [231/3125], train_loss:0.153974\n",
      "Epoch [2/2], Iter [232/3125], train_loss:0.156483\n",
      "Epoch [2/2], Iter [233/3125], train_loss:0.153530\n",
      "Epoch [2/2], Iter [234/3125], train_loss:0.164038\n",
      "Epoch [2/2], Iter [235/3125], train_loss:0.173976\n",
      "Epoch [2/2], Iter [236/3125], train_loss:0.174818\n",
      "Epoch [2/2], Iter [237/3125], train_loss:0.156790\n",
      "Epoch [2/2], Iter [238/3125], train_loss:0.164833\n",
      "Epoch [2/2], Iter [239/3125], train_loss:0.142041\n",
      "Epoch [2/2], Iter [240/3125], train_loss:0.151814\n",
      "Epoch [2/2], Iter [241/3125], train_loss:0.178047\n",
      "Epoch [2/2], Iter [242/3125], train_loss:0.177161\n",
      "Epoch [2/2], Iter [243/3125], train_loss:0.183264\n",
      "Epoch [2/2], Iter [244/3125], train_loss:0.149528\n",
      "Epoch [2/2], Iter [245/3125], train_loss:0.148756\n",
      "Epoch [2/2], Iter [246/3125], train_loss:0.190471\n",
      "Epoch [2/2], Iter [247/3125], train_loss:0.176104\n",
      "Epoch [2/2], Iter [248/3125], train_loss:0.156350\n",
      "Epoch [2/2], Iter [249/3125], train_loss:0.142632\n",
      "Epoch [2/2], Iter [250/3125], train_loss:0.174584\n",
      "Epoch [2/2], Iter [251/3125], train_loss:0.154501\n",
      "Epoch [2/2], Iter [252/3125], train_loss:0.163151\n",
      "Epoch [2/2], Iter [253/3125], train_loss:0.166830\n",
      "Epoch [2/2], Iter [254/3125], train_loss:0.151940\n",
      "Epoch [2/2], Iter [255/3125], train_loss:0.172570\n",
      "Epoch [2/2], Iter [256/3125], train_loss:0.149426\n",
      "Epoch [2/2], Iter [257/3125], train_loss:0.167744\n",
      "Epoch [2/2], Iter [258/3125], train_loss:0.167243\n",
      "Epoch [2/2], Iter [259/3125], train_loss:0.150426\n",
      "Epoch [2/2], Iter [260/3125], train_loss:0.143742\n",
      "Epoch [2/2], Iter [261/3125], train_loss:0.154619\n",
      "Epoch [2/2], Iter [262/3125], train_loss:0.177493\n",
      "Epoch [2/2], Iter [263/3125], train_loss:0.149127\n",
      "Epoch [2/2], Iter [264/3125], train_loss:0.145748\n",
      "Epoch [2/2], Iter [265/3125], train_loss:0.159908\n",
      "Epoch [2/2], Iter [266/3125], train_loss:0.173237\n",
      "Epoch [2/2], Iter [267/3125], train_loss:0.148302\n",
      "Epoch [2/2], Iter [268/3125], train_loss:0.153039\n",
      "Epoch [2/2], Iter [269/3125], train_loss:0.153943\n",
      "Epoch [2/2], Iter [270/3125], train_loss:0.159962\n",
      "Epoch [2/2], Iter [271/3125], train_loss:0.168486\n",
      "Epoch [2/2], Iter [272/3125], train_loss:0.174194\n",
      "Epoch [2/2], Iter [273/3125], train_loss:0.177417\n",
      "Epoch [2/2], Iter [274/3125], train_loss:0.169610\n",
      "Epoch [2/2], Iter [275/3125], train_loss:0.153916\n",
      "Epoch [2/2], Iter [276/3125], train_loss:0.162009\n",
      "Epoch [2/2], Iter [277/3125], train_loss:0.173930\n",
      "Epoch [2/2], Iter [278/3125], train_loss:0.154844\n",
      "Epoch [2/2], Iter [279/3125], train_loss:0.144510\n",
      "Epoch [2/2], Iter [280/3125], train_loss:0.174670\n",
      "Epoch [2/2], Iter [281/3125], train_loss:0.147663\n",
      "Epoch [2/2], Iter [282/3125], train_loss:0.161231\n",
      "Epoch [2/2], Iter [283/3125], train_loss:0.164567\n",
      "Epoch [2/2], Iter [284/3125], train_loss:0.148298\n",
      "Epoch [2/2], Iter [285/3125], train_loss:0.174240\n",
      "Epoch [2/2], Iter [286/3125], train_loss:0.151915\n",
      "Epoch [2/2], Iter [287/3125], train_loss:0.164254\n",
      "Epoch [2/2], Iter [288/3125], train_loss:0.174495\n",
      "Epoch [2/2], Iter [289/3125], train_loss:0.142919\n",
      "Epoch [2/2], Iter [290/3125], train_loss:0.164818\n",
      "Epoch [2/2], Iter [291/3125], train_loss:0.148046\n",
      "Epoch [2/2], Iter [292/3125], train_loss:0.133363\n",
      "Epoch [2/2], Iter [293/3125], train_loss:0.160022\n",
      "Epoch [2/2], Iter [294/3125], train_loss:0.155773\n",
      "Epoch [2/2], Iter [295/3125], train_loss:0.176180\n",
      "Epoch [2/2], Iter [296/3125], train_loss:0.164451\n",
      "Epoch [2/2], Iter [297/3125], train_loss:0.167795\n",
      "Epoch [2/2], Iter [298/3125], train_loss:0.165779\n",
      "Epoch [2/2], Iter [299/3125], train_loss:0.176171\n",
      "Epoch [2/2], Iter [300/3125], train_loss:0.171345\n",
      "Epoch [2/2], Iter [301/3125], train_loss:0.184329\n",
      "Epoch [2/2], Iter [302/3125], train_loss:0.172903\n",
      "Epoch [2/2], Iter [303/3125], train_loss:0.178375\n",
      "Epoch [2/2], Iter [304/3125], train_loss:0.155158\n",
      "Epoch [2/2], Iter [305/3125], train_loss:0.171172\n",
      "Epoch [2/2], Iter [306/3125], train_loss:0.154146\n",
      "Epoch [2/2], Iter [307/3125], train_loss:0.162431\n",
      "Epoch [2/2], Iter [308/3125], train_loss:0.163887\n",
      "Epoch [2/2], Iter [309/3125], train_loss:0.174687\n",
      "Epoch [2/2], Iter [310/3125], train_loss:0.165460\n",
      "Epoch [2/2], Iter [311/3125], train_loss:0.181555\n",
      "Epoch [2/2], Iter [312/3125], train_loss:0.150162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [313/3125], train_loss:0.153412\n",
      "Epoch [2/2], Iter [314/3125], train_loss:0.149629\n",
      "Epoch [2/2], Iter [315/3125], train_loss:0.158892\n",
      "Epoch [2/2], Iter [316/3125], train_loss:0.156130\n",
      "Epoch [2/2], Iter [317/3125], train_loss:0.187546\n",
      "Epoch [2/2], Iter [318/3125], train_loss:0.153912\n",
      "Epoch [2/2], Iter [319/3125], train_loss:0.151770\n",
      "Epoch [2/2], Iter [320/3125], train_loss:0.176303\n",
      "Epoch [2/2], Iter [321/3125], train_loss:0.167846\n",
      "Epoch [2/2], Iter [322/3125], train_loss:0.150853\n",
      "Epoch [2/2], Iter [323/3125], train_loss:0.174334\n",
      "Epoch [2/2], Iter [324/3125], train_loss:0.152363\n",
      "Epoch [2/2], Iter [325/3125], train_loss:0.182887\n",
      "Epoch [2/2], Iter [326/3125], train_loss:0.149897\n",
      "Epoch [2/2], Iter [327/3125], train_loss:0.170501\n",
      "Epoch [2/2], Iter [328/3125], train_loss:0.186834\n",
      "Epoch [2/2], Iter [329/3125], train_loss:0.163417\n",
      "Epoch [2/2], Iter [330/3125], train_loss:0.182607\n",
      "Epoch [2/2], Iter [331/3125], train_loss:0.167527\n",
      "Epoch [2/2], Iter [332/3125], train_loss:0.171005\n",
      "Epoch [2/2], Iter [333/3125], train_loss:0.162520\n",
      "Epoch [2/2], Iter [334/3125], train_loss:0.160567\n",
      "Epoch [2/2], Iter [335/3125], train_loss:0.165600\n",
      "Epoch [2/2], Iter [336/3125], train_loss:0.155164\n",
      "Epoch [2/2], Iter [337/3125], train_loss:0.175315\n",
      "Epoch [2/2], Iter [338/3125], train_loss:0.171219\n",
      "Epoch [2/2], Iter [339/3125], train_loss:0.162644\n",
      "Epoch [2/2], Iter [340/3125], train_loss:0.159048\n",
      "Epoch [2/2], Iter [341/3125], train_loss:0.162782\n",
      "Epoch [2/2], Iter [342/3125], train_loss:0.165438\n",
      "Epoch [2/2], Iter [343/3125], train_loss:0.153910\n",
      "Epoch [2/2], Iter [344/3125], train_loss:0.174372\n",
      "Epoch [2/2], Iter [345/3125], train_loss:0.177340\n",
      "Epoch [2/2], Iter [346/3125], train_loss:0.177186\n",
      "Epoch [2/2], Iter [347/3125], train_loss:0.163347\n",
      "Epoch [2/2], Iter [348/3125], train_loss:0.164975\n",
      "Epoch [2/2], Iter [349/3125], train_loss:0.202241\n",
      "Epoch [2/2], Iter [350/3125], train_loss:0.176461\n",
      "Epoch [2/2], Iter [351/3125], train_loss:0.155909\n",
      "Epoch [2/2], Iter [352/3125], train_loss:0.161746\n",
      "Epoch [2/2], Iter [353/3125], train_loss:0.161433\n",
      "Epoch [2/2], Iter [354/3125], train_loss:0.161199\n",
      "Epoch [2/2], Iter [355/3125], train_loss:0.176037\n",
      "Epoch [2/2], Iter [356/3125], train_loss:0.165718\n",
      "Epoch [2/2], Iter [357/3125], train_loss:0.144140\n",
      "Epoch [2/2], Iter [358/3125], train_loss:0.142182\n",
      "Epoch [2/2], Iter [359/3125], train_loss:0.151589\n",
      "Epoch [2/2], Iter [360/3125], train_loss:0.170065\n",
      "Epoch [2/2], Iter [361/3125], train_loss:0.155288\n",
      "Epoch [2/2], Iter [362/3125], train_loss:0.153488\n",
      "Epoch [2/2], Iter [363/3125], train_loss:0.156576\n",
      "Epoch [2/2], Iter [364/3125], train_loss:0.161076\n",
      "Epoch [2/2], Iter [365/3125], train_loss:0.161203\n",
      "Epoch [2/2], Iter [366/3125], train_loss:0.164802\n",
      "Epoch [2/2], Iter [367/3125], train_loss:0.166324\n",
      "Epoch [2/2], Iter [368/3125], train_loss:0.178081\n",
      "Epoch [2/2], Iter [369/3125], train_loss:0.144357\n",
      "Epoch [2/2], Iter [370/3125], train_loss:0.174453\n",
      "Epoch [2/2], Iter [371/3125], train_loss:0.168766\n",
      "Epoch [2/2], Iter [372/3125], train_loss:0.147773\n",
      "Epoch [2/2], Iter [373/3125], train_loss:0.143407\n",
      "Epoch [2/2], Iter [374/3125], train_loss:0.154440\n",
      "Epoch [2/2], Iter [375/3125], train_loss:0.144308\n",
      "Epoch [2/2], Iter [376/3125], train_loss:0.146517\n",
      "Epoch [2/2], Iter [377/3125], train_loss:0.168994\n",
      "Epoch [2/2], Iter [378/3125], train_loss:0.155020\n",
      "Epoch [2/2], Iter [379/3125], train_loss:0.136322\n",
      "Epoch [2/2], Iter [380/3125], train_loss:0.165164\n",
      "Epoch [2/2], Iter [381/3125], train_loss:0.165966\n",
      "Epoch [2/2], Iter [382/3125], train_loss:0.149831\n",
      "Epoch [2/2], Iter [383/3125], train_loss:0.153939\n",
      "Epoch [2/2], Iter [384/3125], train_loss:0.150713\n",
      "Epoch [2/2], Iter [385/3125], train_loss:0.149525\n",
      "Epoch [2/2], Iter [386/3125], train_loss:0.186537\n",
      "Epoch [2/2], Iter [387/3125], train_loss:0.155550\n",
      "Epoch [2/2], Iter [388/3125], train_loss:0.130376\n",
      "Epoch [2/2], Iter [389/3125], train_loss:0.168143\n",
      "Epoch [2/2], Iter [390/3125], train_loss:0.153200\n",
      "Epoch [2/2], Iter [391/3125], train_loss:0.156268\n",
      "Epoch [2/2], Iter [392/3125], train_loss:0.138514\n",
      "Epoch [2/2], Iter [393/3125], train_loss:0.186347\n",
      "Epoch [2/2], Iter [394/3125], train_loss:0.167708\n",
      "Epoch [2/2], Iter [395/3125], train_loss:0.156236\n",
      "Epoch [2/2], Iter [396/3125], train_loss:0.161214\n",
      "Epoch [2/2], Iter [397/3125], train_loss:0.164827\n",
      "Epoch [2/2], Iter [398/3125], train_loss:0.162833\n",
      "Epoch [2/2], Iter [399/3125], train_loss:0.148330\n",
      "Epoch [2/2], Iter [400/3125], train_loss:0.151244\n",
      "Epoch [2/2], Iter [401/3125], train_loss:0.175030\n",
      "Epoch [2/2], Iter [402/3125], train_loss:0.167966\n",
      "Epoch [2/2], Iter [403/3125], train_loss:0.174009\n",
      "Epoch [2/2], Iter [404/3125], train_loss:0.133342\n",
      "Epoch [2/2], Iter [405/3125], train_loss:0.160444\n",
      "Epoch [2/2], Iter [406/3125], train_loss:0.173592\n",
      "Epoch [2/2], Iter [407/3125], train_loss:0.176786\n",
      "Epoch [2/2], Iter [408/3125], train_loss:0.161026\n",
      "Epoch [2/2], Iter [409/3125], train_loss:0.173543\n",
      "Epoch [2/2], Iter [410/3125], train_loss:0.147663\n",
      "Epoch [2/2], Iter [411/3125], train_loss:0.170319\n",
      "Epoch [2/2], Iter [412/3125], train_loss:0.185939\n",
      "Epoch [2/2], Iter [413/3125], train_loss:0.165246\n",
      "Epoch [2/2], Iter [414/3125], train_loss:0.185627\n",
      "Epoch [2/2], Iter [415/3125], train_loss:0.131443\n",
      "Epoch [2/2], Iter [416/3125], train_loss:0.150096\n",
      "Epoch [2/2], Iter [417/3125], train_loss:0.143120\n",
      "Epoch [2/2], Iter [418/3125], train_loss:0.193534\n",
      "Epoch [2/2], Iter [419/3125], train_loss:0.152602\n",
      "Epoch [2/2], Iter [420/3125], train_loss:0.170830\n",
      "Epoch [2/2], Iter [421/3125], train_loss:0.174716\n",
      "Epoch [2/2], Iter [422/3125], train_loss:0.174463\n",
      "Epoch [2/2], Iter [423/3125], train_loss:0.169858\n",
      "Epoch [2/2], Iter [424/3125], train_loss:0.142388\n",
      "Epoch [2/2], Iter [425/3125], train_loss:0.172615\n",
      "Epoch [2/2], Iter [426/3125], train_loss:0.177286\n",
      "Epoch [2/2], Iter [427/3125], train_loss:0.167227\n",
      "Epoch [2/2], Iter [428/3125], train_loss:0.157363\n",
      "Epoch [2/2], Iter [429/3125], train_loss:0.166516\n",
      "Epoch [2/2], Iter [430/3125], train_loss:0.172313\n",
      "Epoch [2/2], Iter [431/3125], train_loss:0.161539\n",
      "Epoch [2/2], Iter [432/3125], train_loss:0.163159\n",
      "Epoch [2/2], Iter [433/3125], train_loss:0.144575\n",
      "Epoch [2/2], Iter [434/3125], train_loss:0.168186\n",
      "Epoch [2/2], Iter [435/3125], train_loss:0.157193\n",
      "Epoch [2/2], Iter [436/3125], train_loss:0.161615\n",
      "Epoch [2/2], Iter [437/3125], train_loss:0.169740\n",
      "Epoch [2/2], Iter [438/3125], train_loss:0.165369\n",
      "Epoch [2/2], Iter [439/3125], train_loss:0.171216\n",
      "Epoch [2/2], Iter [440/3125], train_loss:0.162590\n",
      "Epoch [2/2], Iter [441/3125], train_loss:0.185242\n",
      "Epoch [2/2], Iter [442/3125], train_loss:0.161350\n",
      "Epoch [2/2], Iter [443/3125], train_loss:0.160137\n",
      "Epoch [2/2], Iter [444/3125], train_loss:0.151255\n",
      "Epoch [2/2], Iter [445/3125], train_loss:0.174243\n",
      "Epoch [2/2], Iter [446/3125], train_loss:0.163636\n",
      "Epoch [2/2], Iter [447/3125], train_loss:0.155706\n",
      "Epoch [2/2], Iter [448/3125], train_loss:0.165992\n",
      "Epoch [2/2], Iter [449/3125], train_loss:0.157281\n",
      "Epoch [2/2], Iter [450/3125], train_loss:0.180386\n",
      "Epoch [2/2], Iter [451/3125], train_loss:0.180637\n",
      "Epoch [2/2], Iter [452/3125], train_loss:0.159181\n",
      "Epoch [2/2], Iter [453/3125], train_loss:0.167303\n",
      "Epoch [2/2], Iter [454/3125], train_loss:0.161755\n",
      "Epoch [2/2], Iter [455/3125], train_loss:0.154677\n",
      "Epoch [2/2], Iter [456/3125], train_loss:0.167636\n",
      "Epoch [2/2], Iter [457/3125], train_loss:0.180807\n",
      "Epoch [2/2], Iter [458/3125], train_loss:0.139945\n",
      "Epoch [2/2], Iter [459/3125], train_loss:0.165975\n",
      "Epoch [2/2], Iter [460/3125], train_loss:0.153326\n",
      "Epoch [2/2], Iter [461/3125], train_loss:0.187807\n",
      "Epoch [2/2], Iter [462/3125], train_loss:0.166080\n",
      "Epoch [2/2], Iter [463/3125], train_loss:0.164084\n",
      "Epoch [2/2], Iter [464/3125], train_loss:0.178732\n",
      "Epoch [2/2], Iter [465/3125], train_loss:0.139112\n",
      "Epoch [2/2], Iter [466/3125], train_loss:0.154262\n",
      "Epoch [2/2], Iter [467/3125], train_loss:0.156984\n",
      "Epoch [2/2], Iter [468/3125], train_loss:0.153696\n",
      "Epoch [2/2], Iter [469/3125], train_loss:0.167890\n",
      "Epoch [2/2], Iter [470/3125], train_loss:0.146530\n",
      "Epoch [2/2], Iter [471/3125], train_loss:0.173568\n",
      "Epoch [2/2], Iter [472/3125], train_loss:0.172920\n",
      "Epoch [2/2], Iter [473/3125], train_loss:0.172191\n",
      "Epoch [2/2], Iter [474/3125], train_loss:0.177066\n",
      "Epoch [2/2], Iter [475/3125], train_loss:0.166096\n",
      "Epoch [2/2], Iter [476/3125], train_loss:0.145177\n",
      "Epoch [2/2], Iter [477/3125], train_loss:0.154965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [478/3125], train_loss:0.154901\n",
      "Epoch [2/2], Iter [479/3125], train_loss:0.161373\n",
      "Epoch [2/2], Iter [480/3125], train_loss:0.164218\n",
      "Epoch [2/2], Iter [481/3125], train_loss:0.163394\n",
      "Epoch [2/2], Iter [482/3125], train_loss:0.179960\n",
      "Epoch [2/2], Iter [483/3125], train_loss:0.152761\n",
      "Epoch [2/2], Iter [484/3125], train_loss:0.148085\n",
      "Epoch [2/2], Iter [485/3125], train_loss:0.158129\n",
      "Epoch [2/2], Iter [486/3125], train_loss:0.164468\n",
      "Epoch [2/2], Iter [487/3125], train_loss:0.140875\n",
      "Epoch [2/2], Iter [488/3125], train_loss:0.153898\n",
      "Epoch [2/2], Iter [489/3125], train_loss:0.183179\n",
      "Epoch [2/2], Iter [490/3125], train_loss:0.159658\n",
      "Epoch [2/2], Iter [491/3125], train_loss:0.149543\n",
      "Epoch [2/2], Iter [492/3125], train_loss:0.162857\n",
      "Epoch [2/2], Iter [493/3125], train_loss:0.146819\n",
      "Epoch [2/2], Iter [494/3125], train_loss:0.162568\n",
      "Epoch [2/2], Iter [495/3125], train_loss:0.186698\n",
      "Epoch [2/2], Iter [496/3125], train_loss:0.152870\n",
      "Epoch [2/2], Iter [497/3125], train_loss:0.160796\n",
      "Epoch [2/2], Iter [498/3125], train_loss:0.150789\n",
      "Epoch [2/2], Iter [499/3125], train_loss:0.143901\n",
      "Epoch [2/2], Iter [500/3125], train_loss:0.146307\n",
      "Epoch [2/2], Iter [501/3125], train_loss:0.156505\n",
      "Epoch [2/2], Iter [502/3125], train_loss:0.170537\n",
      "Epoch [2/2], Iter [503/3125], train_loss:0.165219\n",
      "Epoch [2/2], Iter [504/3125], train_loss:0.131376\n",
      "Epoch [2/2], Iter [505/3125], train_loss:0.150592\n",
      "Epoch [2/2], Iter [506/3125], train_loss:0.154510\n",
      "Epoch [2/2], Iter [507/3125], train_loss:0.185317\n",
      "Epoch [2/2], Iter [508/3125], train_loss:0.155880\n",
      "Epoch [2/2], Iter [509/3125], train_loss:0.166343\n",
      "Epoch [2/2], Iter [510/3125], train_loss:0.170775\n",
      "Epoch [2/2], Iter [511/3125], train_loss:0.158124\n",
      "Epoch [2/2], Iter [512/3125], train_loss:0.162436\n",
      "Epoch [2/2], Iter [513/3125], train_loss:0.171975\n",
      "Epoch [2/2], Iter [514/3125], train_loss:0.158008\n",
      "Epoch [2/2], Iter [515/3125], train_loss:0.180108\n",
      "Epoch [2/2], Iter [516/3125], train_loss:0.166079\n",
      "Epoch [2/2], Iter [517/3125], train_loss:0.187777\n",
      "Epoch [2/2], Iter [518/3125], train_loss:0.179959\n",
      "Epoch [2/2], Iter [519/3125], train_loss:0.174720\n",
      "Epoch [2/2], Iter [520/3125], train_loss:0.159333\n",
      "Epoch [2/2], Iter [521/3125], train_loss:0.170574\n",
      "Epoch [2/2], Iter [522/3125], train_loss:0.162373\n",
      "Epoch [2/2], Iter [523/3125], train_loss:0.165549\n",
      "Epoch [2/2], Iter [524/3125], train_loss:0.171584\n",
      "Epoch [2/2], Iter [525/3125], train_loss:0.174756\n",
      "Epoch [2/2], Iter [526/3125], train_loss:0.161434\n",
      "Epoch [2/2], Iter [527/3125], train_loss:0.168083\n",
      "Epoch [2/2], Iter [528/3125], train_loss:0.167138\n",
      "Epoch [2/2], Iter [529/3125], train_loss:0.140973\n",
      "Epoch [2/2], Iter [530/3125], train_loss:0.159618\n",
      "Epoch [2/2], Iter [531/3125], train_loss:0.176200\n",
      "Epoch [2/2], Iter [532/3125], train_loss:0.162572\n",
      "Epoch [2/2], Iter [533/3125], train_loss:0.168972\n",
      "Epoch [2/2], Iter [534/3125], train_loss:0.173325\n",
      "Epoch [2/2], Iter [535/3125], train_loss:0.163866\n",
      "Epoch [2/2], Iter [536/3125], train_loss:0.163720\n",
      "Epoch [2/2], Iter [537/3125], train_loss:0.168137\n",
      "Epoch [2/2], Iter [538/3125], train_loss:0.175345\n",
      "Epoch [2/2], Iter [539/3125], train_loss:0.158390\n",
      "Epoch [2/2], Iter [540/3125], train_loss:0.159162\n",
      "Epoch [2/2], Iter [541/3125], train_loss:0.144704\n",
      "Epoch [2/2], Iter [542/3125], train_loss:0.149428\n",
      "Epoch [2/2], Iter [543/3125], train_loss:0.158572\n",
      "Epoch [2/2], Iter [544/3125], train_loss:0.172126\n",
      "Epoch [2/2], Iter [545/3125], train_loss:0.176276\n",
      "Epoch [2/2], Iter [546/3125], train_loss:0.177032\n",
      "Epoch [2/2], Iter [547/3125], train_loss:0.173978\n",
      "Epoch [2/2], Iter [548/3125], train_loss:0.164149\n",
      "Epoch [2/2], Iter [549/3125], train_loss:0.160977\n",
      "Epoch [2/2], Iter [550/3125], train_loss:0.141250\n",
      "Epoch [2/2], Iter [551/3125], train_loss:0.167351\n",
      "Epoch [2/2], Iter [552/3125], train_loss:0.154863\n",
      "Epoch [2/2], Iter [553/3125], train_loss:0.176878\n",
      "Epoch [2/2], Iter [554/3125], train_loss:0.152597\n",
      "Epoch [2/2], Iter [555/3125], train_loss:0.173390\n",
      "Epoch [2/2], Iter [556/3125], train_loss:0.163720\n",
      "Epoch [2/2], Iter [557/3125], train_loss:0.160260\n",
      "Epoch [2/2], Iter [558/3125], train_loss:0.178257\n",
      "Epoch [2/2], Iter [559/3125], train_loss:0.175589\n",
      "Epoch [2/2], Iter [560/3125], train_loss:0.148475\n",
      "Epoch [2/2], Iter [561/3125], train_loss:0.173594\n",
      "Epoch [2/2], Iter [562/3125], train_loss:0.165406\n",
      "Epoch [2/2], Iter [563/3125], train_loss:0.171584\n",
      "Epoch [2/2], Iter [564/3125], train_loss:0.167694\n",
      "Epoch [2/2], Iter [565/3125], train_loss:0.163094\n",
      "Epoch [2/2], Iter [566/3125], train_loss:0.157451\n",
      "Epoch [2/2], Iter [567/3125], train_loss:0.163195\n",
      "Epoch [2/2], Iter [568/3125], train_loss:0.145743\n",
      "Epoch [2/2], Iter [569/3125], train_loss:0.165041\n",
      "Epoch [2/2], Iter [570/3125], train_loss:0.155912\n",
      "Epoch [2/2], Iter [571/3125], train_loss:0.150290\n",
      "Epoch [2/2], Iter [572/3125], train_loss:0.162542\n",
      "Epoch [2/2], Iter [573/3125], train_loss:0.147671\n",
      "Epoch [2/2], Iter [574/3125], train_loss:0.153121\n",
      "Epoch [2/2], Iter [575/3125], train_loss:0.151718\n",
      "Epoch [2/2], Iter [576/3125], train_loss:0.167825\n",
      "Epoch [2/2], Iter [577/3125], train_loss:0.148835\n",
      "Epoch [2/2], Iter [578/3125], train_loss:0.151512\n",
      "Epoch [2/2], Iter [579/3125], train_loss:0.187779\n",
      "Epoch [2/2], Iter [580/3125], train_loss:0.157333\n",
      "Epoch [2/2], Iter [581/3125], train_loss:0.165742\n",
      "Epoch [2/2], Iter [582/3125], train_loss:0.167597\n",
      "Epoch [2/2], Iter [583/3125], train_loss:0.163270\n",
      "Epoch [2/2], Iter [584/3125], train_loss:0.144670\n",
      "Epoch [2/2], Iter [585/3125], train_loss:0.149435\n",
      "Epoch [2/2], Iter [586/3125], train_loss:0.170580\n",
      "Epoch [2/2], Iter [587/3125], train_loss:0.160914\n",
      "Epoch [2/2], Iter [588/3125], train_loss:0.151355\n",
      "Epoch [2/2], Iter [589/3125], train_loss:0.167059\n",
      "Epoch [2/2], Iter [590/3125], train_loss:0.151443\n",
      "Epoch [2/2], Iter [591/3125], train_loss:0.147637\n",
      "Epoch [2/2], Iter [592/3125], train_loss:0.173933\n",
      "Epoch [2/2], Iter [593/3125], train_loss:0.157407\n",
      "Epoch [2/2], Iter [594/3125], train_loss:0.169269\n",
      "Epoch [2/2], Iter [595/3125], train_loss:0.155772\n",
      "Epoch [2/2], Iter [596/3125], train_loss:0.189058\n",
      "Epoch [2/2], Iter [597/3125], train_loss:0.147937\n",
      "Epoch [2/2], Iter [598/3125], train_loss:0.179247\n",
      "Epoch [2/2], Iter [599/3125], train_loss:0.167485\n",
      "Epoch [2/2], Iter [600/3125], train_loss:0.153575\n",
      "Epoch [2/2], Iter [601/3125], train_loss:0.143053\n",
      "Epoch [2/2], Iter [602/3125], train_loss:0.150471\n",
      "Epoch [2/2], Iter [603/3125], train_loss:0.143764\n",
      "Epoch [2/2], Iter [604/3125], train_loss:0.161357\n",
      "Epoch [2/2], Iter [605/3125], train_loss:0.177912\n",
      "Epoch [2/2], Iter [606/3125], train_loss:0.193015\n",
      "Epoch [2/2], Iter [607/3125], train_loss:0.165355\n",
      "Epoch [2/2], Iter [608/3125], train_loss:0.160645\n",
      "Epoch [2/2], Iter [609/3125], train_loss:0.153148\n",
      "Epoch [2/2], Iter [610/3125], train_loss:0.161745\n",
      "Epoch [2/2], Iter [611/3125], train_loss:0.177804\n",
      "Epoch [2/2], Iter [612/3125], train_loss:0.169567\n",
      "Epoch [2/2], Iter [613/3125], train_loss:0.163330\n",
      "Epoch [2/2], Iter [614/3125], train_loss:0.156796\n",
      "Epoch [2/2], Iter [615/3125], train_loss:0.176123\n",
      "Epoch [2/2], Iter [616/3125], train_loss:0.154425\n",
      "Epoch [2/2], Iter [617/3125], train_loss:0.152680\n",
      "Epoch [2/2], Iter [618/3125], train_loss:0.150936\n",
      "Epoch [2/2], Iter [619/3125], train_loss:0.174734\n",
      "Epoch [2/2], Iter [620/3125], train_loss:0.164248\n",
      "Epoch [2/2], Iter [621/3125], train_loss:0.154376\n",
      "Epoch [2/2], Iter [622/3125], train_loss:0.181289\n",
      "Epoch [2/2], Iter [623/3125], train_loss:0.154710\n",
      "Epoch [2/2], Iter [624/3125], train_loss:0.173619\n",
      "Epoch [2/2], Iter [625/3125], train_loss:0.160207\n",
      "Epoch [2/2], Iter [626/3125], train_loss:0.164651\n",
      "Epoch [2/2], Iter [627/3125], train_loss:0.168672\n",
      "Epoch [2/2], Iter [628/3125], train_loss:0.152033\n",
      "Epoch [2/2], Iter [629/3125], train_loss:0.145318\n",
      "Epoch [2/2], Iter [630/3125], train_loss:0.153201\n",
      "Epoch [2/2], Iter [631/3125], train_loss:0.136641\n",
      "Epoch [2/2], Iter [632/3125], train_loss:0.165298\n",
      "Epoch [2/2], Iter [633/3125], train_loss:0.146980\n",
      "Epoch [2/2], Iter [634/3125], train_loss:0.157089\n",
      "Epoch [2/2], Iter [635/3125], train_loss:0.153481\n",
      "Epoch [2/2], Iter [636/3125], train_loss:0.180023\n",
      "Epoch [2/2], Iter [637/3125], train_loss:0.177965\n",
      "Epoch [2/2], Iter [638/3125], train_loss:0.168382\n",
      "Epoch [2/2], Iter [639/3125], train_loss:0.170590\n",
      "Epoch [2/2], Iter [640/3125], train_loss:0.146684\n",
      "Epoch [2/2], Iter [641/3125], train_loss:0.154656\n",
      "Epoch [2/2], Iter [642/3125], train_loss:0.148962\n",
      "Epoch [2/2], Iter [643/3125], train_loss:0.162826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [644/3125], train_loss:0.154299\n",
      "Epoch [2/2], Iter [645/3125], train_loss:0.140432\n",
      "Epoch [2/2], Iter [646/3125], train_loss:0.169591\n",
      "Epoch [2/2], Iter [647/3125], train_loss:0.160964\n",
      "Epoch [2/2], Iter [648/3125], train_loss:0.163820\n",
      "Epoch [2/2], Iter [649/3125], train_loss:0.180686\n",
      "Epoch [2/2], Iter [650/3125], train_loss:0.149200\n",
      "Epoch [2/2], Iter [651/3125], train_loss:0.165878\n",
      "Epoch [2/2], Iter [652/3125], train_loss:0.153168\n",
      "Epoch [2/2], Iter [653/3125], train_loss:0.158429\n",
      "Epoch [2/2], Iter [654/3125], train_loss:0.164462\n",
      "Epoch [2/2], Iter [655/3125], train_loss:0.173659\n",
      "Epoch [2/2], Iter [656/3125], train_loss:0.158212\n",
      "Epoch [2/2], Iter [657/3125], train_loss:0.147685\n",
      "Epoch [2/2], Iter [658/3125], train_loss:0.165053\n",
      "Epoch [2/2], Iter [659/3125], train_loss:0.147815\n",
      "Epoch [2/2], Iter [660/3125], train_loss:0.156994\n",
      "Epoch [2/2], Iter [661/3125], train_loss:0.166037\n",
      "Epoch [2/2], Iter [662/3125], train_loss:0.172137\n",
      "Epoch [2/2], Iter [663/3125], train_loss:0.164935\n",
      "Epoch [2/2], Iter [664/3125], train_loss:0.135215\n",
      "Epoch [2/2], Iter [665/3125], train_loss:0.158562\n",
      "Epoch [2/2], Iter [666/3125], train_loss:0.160104\n",
      "Epoch [2/2], Iter [667/3125], train_loss:0.151053\n",
      "Epoch [2/2], Iter [668/3125], train_loss:0.170116\n",
      "Epoch [2/2], Iter [669/3125], train_loss:0.137139\n",
      "Epoch [2/2], Iter [670/3125], train_loss:0.157071\n",
      "Epoch [2/2], Iter [671/3125], train_loss:0.188446\n",
      "Epoch [2/2], Iter [672/3125], train_loss:0.161760\n",
      "Epoch [2/2], Iter [673/3125], train_loss:0.155279\n",
      "Epoch [2/2], Iter [674/3125], train_loss:0.179824\n",
      "Epoch [2/2], Iter [675/3125], train_loss:0.167790\n",
      "Epoch [2/2], Iter [676/3125], train_loss:0.146095\n",
      "Epoch [2/2], Iter [677/3125], train_loss:0.177003\n",
      "Epoch [2/2], Iter [678/3125], train_loss:0.148537\n",
      "Epoch [2/2], Iter [679/3125], train_loss:0.152893\n",
      "Epoch [2/2], Iter [680/3125], train_loss:0.159080\n",
      "Epoch [2/2], Iter [681/3125], train_loss:0.156266\n",
      "Epoch [2/2], Iter [682/3125], train_loss:0.166901\n",
      "Epoch [2/2], Iter [683/3125], train_loss:0.168217\n",
      "Epoch [2/2], Iter [684/3125], train_loss:0.169070\n",
      "Epoch [2/2], Iter [685/3125], train_loss:0.162491\n",
      "Epoch [2/2], Iter [686/3125], train_loss:0.168951\n",
      "Epoch [2/2], Iter [687/3125], train_loss:0.125869\n",
      "Epoch [2/2], Iter [688/3125], train_loss:0.181195\n",
      "Epoch [2/2], Iter [689/3125], train_loss:0.177369\n",
      "Epoch [2/2], Iter [690/3125], train_loss:0.161117\n",
      "Epoch [2/2], Iter [691/3125], train_loss:0.157555\n",
      "Epoch [2/2], Iter [692/3125], train_loss:0.159016\n",
      "Epoch [2/2], Iter [693/3125], train_loss:0.157256\n",
      "Epoch [2/2], Iter [694/3125], train_loss:0.164547\n",
      "Epoch [2/2], Iter [695/3125], train_loss:0.165163\n",
      "Epoch [2/2], Iter [696/3125], train_loss:0.168598\n",
      "Epoch [2/2], Iter [697/3125], train_loss:0.167152\n",
      "Epoch [2/2], Iter [698/3125], train_loss:0.174982\n",
      "Epoch [2/2], Iter [699/3125], train_loss:0.150731\n",
      "Epoch [2/2], Iter [700/3125], train_loss:0.144726\n",
      "Epoch [2/2], Iter [701/3125], train_loss:0.161515\n",
      "Epoch [2/2], Iter [702/3125], train_loss:0.168019\n",
      "Epoch [2/2], Iter [703/3125], train_loss:0.151221\n",
      "Epoch [2/2], Iter [704/3125], train_loss:0.155330\n",
      "Epoch [2/2], Iter [705/3125], train_loss:0.162497\n",
      "Epoch [2/2], Iter [706/3125], train_loss:0.146891\n",
      "Epoch [2/2], Iter [707/3125], train_loss:0.144152\n",
      "Epoch [2/2], Iter [708/3125], train_loss:0.169863\n",
      "Epoch [2/2], Iter [709/3125], train_loss:0.151497\n",
      "Epoch [2/2], Iter [710/3125], train_loss:0.171949\n",
      "Epoch [2/2], Iter [711/3125], train_loss:0.144536\n",
      "Epoch [2/2], Iter [712/3125], train_loss:0.174258\n",
      "Epoch [2/2], Iter [713/3125], train_loss:0.156956\n",
      "Epoch [2/2], Iter [714/3125], train_loss:0.143885\n",
      "Epoch [2/2], Iter [715/3125], train_loss:0.154764\n",
      "Epoch [2/2], Iter [716/3125], train_loss:0.158947\n",
      "Epoch [2/2], Iter [717/3125], train_loss:0.169612\n",
      "Epoch [2/2], Iter [718/3125], train_loss:0.183921\n",
      "Epoch [2/2], Iter [719/3125], train_loss:0.164853\n",
      "Epoch [2/2], Iter [720/3125], train_loss:0.152667\n",
      "Epoch [2/2], Iter [721/3125], train_loss:0.164879\n",
      "Epoch [2/2], Iter [722/3125], train_loss:0.162339\n",
      "Epoch [2/2], Iter [723/3125], train_loss:0.155902\n",
      "Epoch [2/2], Iter [724/3125], train_loss:0.166309\n",
      "Epoch [2/2], Iter [725/3125], train_loss:0.169535\n",
      "Epoch [2/2], Iter [726/3125], train_loss:0.157821\n",
      "Epoch [2/2], Iter [727/3125], train_loss:0.177206\n",
      "Epoch [2/2], Iter [728/3125], train_loss:0.161878\n",
      "Epoch [2/2], Iter [729/3125], train_loss:0.165634\n",
      "Epoch [2/2], Iter [730/3125], train_loss:0.162080\n",
      "Epoch [2/2], Iter [731/3125], train_loss:0.149615\n",
      "Epoch [2/2], Iter [732/3125], train_loss:0.157824\n",
      "Epoch [2/2], Iter [733/3125], train_loss:0.160058\n",
      "Epoch [2/2], Iter [734/3125], train_loss:0.164464\n",
      "Epoch [2/2], Iter [735/3125], train_loss:0.173593\n",
      "Epoch [2/2], Iter [736/3125], train_loss:0.177152\n",
      "Epoch [2/2], Iter [737/3125], train_loss:0.185746\n",
      "Epoch [2/2], Iter [738/3125], train_loss:0.161387\n",
      "Epoch [2/2], Iter [739/3125], train_loss:0.163264\n",
      "Epoch [2/2], Iter [740/3125], train_loss:0.165813\n",
      "Epoch [2/2], Iter [741/3125], train_loss:0.172456\n",
      "Epoch [2/2], Iter [742/3125], train_loss:0.173366\n",
      "Epoch [2/2], Iter [743/3125], train_loss:0.167722\n",
      "Epoch [2/2], Iter [744/3125], train_loss:0.152204\n",
      "Epoch [2/2], Iter [745/3125], train_loss:0.162796\n",
      "Epoch [2/2], Iter [746/3125], train_loss:0.148085\n",
      "Epoch [2/2], Iter [747/3125], train_loss:0.138988\n",
      "Epoch [2/2], Iter [748/3125], train_loss:0.165154\n",
      "Epoch [2/2], Iter [749/3125], train_loss:0.163704\n",
      "Epoch [2/2], Iter [750/3125], train_loss:0.139482\n",
      "Epoch [2/2], Iter [751/3125], train_loss:0.146638\n",
      "Epoch [2/2], Iter [752/3125], train_loss:0.179230\n",
      "Epoch [2/2], Iter [753/3125], train_loss:0.168096\n",
      "Epoch [2/2], Iter [754/3125], train_loss:0.157946\n",
      "Epoch [2/2], Iter [755/3125], train_loss:0.121326\n",
      "Epoch [2/2], Iter [756/3125], train_loss:0.160800\n",
      "Epoch [2/2], Iter [757/3125], train_loss:0.143741\n",
      "Epoch [2/2], Iter [758/3125], train_loss:0.164546\n",
      "Epoch [2/2], Iter [759/3125], train_loss:0.153188\n",
      "Epoch [2/2], Iter [760/3125], train_loss:0.153755\n",
      "Epoch [2/2], Iter [761/3125], train_loss:0.156617\n",
      "Epoch [2/2], Iter [762/3125], train_loss:0.165343\n",
      "Epoch [2/2], Iter [763/3125], train_loss:0.152439\n",
      "Epoch [2/2], Iter [764/3125], train_loss:0.150895\n",
      "Epoch [2/2], Iter [765/3125], train_loss:0.171088\n",
      "Epoch [2/2], Iter [766/3125], train_loss:0.152008\n",
      "Epoch [2/2], Iter [767/3125], train_loss:0.159565\n",
      "Epoch [2/2], Iter [768/3125], train_loss:0.141178\n",
      "Epoch [2/2], Iter [769/3125], train_loss:0.151271\n",
      "Epoch [2/2], Iter [770/3125], train_loss:0.141239\n",
      "Epoch [2/2], Iter [771/3125], train_loss:0.178049\n",
      "Epoch [2/2], Iter [772/3125], train_loss:0.181188\n",
      "Epoch [2/2], Iter [773/3125], train_loss:0.173826\n",
      "Epoch [2/2], Iter [774/3125], train_loss:0.175326\n",
      "Epoch [2/2], Iter [775/3125], train_loss:0.167236\n",
      "Epoch [2/2], Iter [776/3125], train_loss:0.149285\n",
      "Epoch [2/2], Iter [777/3125], train_loss:0.153321\n",
      "Epoch [2/2], Iter [778/3125], train_loss:0.149725\n",
      "Epoch [2/2], Iter [779/3125], train_loss:0.142043\n",
      "Epoch [2/2], Iter [780/3125], train_loss:0.169607\n",
      "Epoch [2/2], Iter [781/3125], train_loss:0.159767\n",
      "Epoch [2/2], Iter [782/3125], train_loss:0.165921\n",
      "Epoch [2/2], Iter [783/3125], train_loss:0.177517\n",
      "Epoch [2/2], Iter [784/3125], train_loss:0.172011\n",
      "Epoch [2/2], Iter [785/3125], train_loss:0.165636\n",
      "Epoch [2/2], Iter [786/3125], train_loss:0.182836\n",
      "Epoch [2/2], Iter [787/3125], train_loss:0.155442\n",
      "Epoch [2/2], Iter [788/3125], train_loss:0.152997\n",
      "Epoch [2/2], Iter [789/3125], train_loss:0.173366\n",
      "Epoch [2/2], Iter [790/3125], train_loss:0.169295\n",
      "Epoch [2/2], Iter [791/3125], train_loss:0.136513\n",
      "Epoch [2/2], Iter [792/3125], train_loss:0.172275\n",
      "Epoch [2/2], Iter [793/3125], train_loss:0.172193\n",
      "Epoch [2/2], Iter [794/3125], train_loss:0.173066\n",
      "Epoch [2/2], Iter [795/3125], train_loss:0.144812\n",
      "Epoch [2/2], Iter [796/3125], train_loss:0.150171\n",
      "Epoch [2/2], Iter [797/3125], train_loss:0.153731\n",
      "Epoch [2/2], Iter [798/3125], train_loss:0.151424\n",
      "Epoch [2/2], Iter [799/3125], train_loss:0.154041\n",
      "Epoch [2/2], Iter [800/3125], train_loss:0.146820\n",
      "Epoch [2/2], Iter [801/3125], train_loss:0.162678\n",
      "Epoch [2/2], Iter [802/3125], train_loss:0.166951\n",
      "Epoch [2/2], Iter [803/3125], train_loss:0.146033\n",
      "Epoch [2/2], Iter [804/3125], train_loss:0.174534\n",
      "Epoch [2/2], Iter [805/3125], train_loss:0.151255\n",
      "Epoch [2/2], Iter [806/3125], train_loss:0.152914\n",
      "Epoch [2/2], Iter [807/3125], train_loss:0.161758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [808/3125], train_loss:0.168109\n",
      "Epoch [2/2], Iter [809/3125], train_loss:0.167769\n",
      "Epoch [2/2], Iter [810/3125], train_loss:0.164397\n",
      "Epoch [2/2], Iter [811/3125], train_loss:0.156441\n",
      "Epoch [2/2], Iter [812/3125], train_loss:0.129703\n",
      "Epoch [2/2], Iter [813/3125], train_loss:0.133674\n",
      "Epoch [2/2], Iter [814/3125], train_loss:0.163769\n",
      "Epoch [2/2], Iter [815/3125], train_loss:0.185708\n",
      "Epoch [2/2], Iter [816/3125], train_loss:0.148028\n",
      "Epoch [2/2], Iter [817/3125], train_loss:0.158787\n",
      "Epoch [2/2], Iter [818/3125], train_loss:0.168785\n",
      "Epoch [2/2], Iter [819/3125], train_loss:0.171409\n",
      "Epoch [2/2], Iter [820/3125], train_loss:0.168109\n",
      "Epoch [2/2], Iter [821/3125], train_loss:0.160211\n",
      "Epoch [2/2], Iter [822/3125], train_loss:0.182132\n",
      "Epoch [2/2], Iter [823/3125], train_loss:0.155263\n",
      "Epoch [2/2], Iter [824/3125], train_loss:0.166263\n",
      "Epoch [2/2], Iter [825/3125], train_loss:0.159538\n",
      "Epoch [2/2], Iter [826/3125], train_loss:0.166468\n",
      "Epoch [2/2], Iter [827/3125], train_loss:0.180897\n",
      "Epoch [2/2], Iter [828/3125], train_loss:0.163072\n",
      "Epoch [2/2], Iter [829/3125], train_loss:0.162532\n",
      "Epoch [2/2], Iter [830/3125], train_loss:0.157262\n",
      "Epoch [2/2], Iter [831/3125], train_loss:0.149578\n",
      "Epoch [2/2], Iter [832/3125], train_loss:0.155040\n",
      "Epoch [2/2], Iter [833/3125], train_loss:0.169790\n",
      "Epoch [2/2], Iter [834/3125], train_loss:0.184853\n",
      "Epoch [2/2], Iter [835/3125], train_loss:0.154249\n",
      "Epoch [2/2], Iter [836/3125], train_loss:0.169785\n",
      "Epoch [2/2], Iter [837/3125], train_loss:0.155462\n",
      "Epoch [2/2], Iter [838/3125], train_loss:0.178458\n",
      "Epoch [2/2], Iter [839/3125], train_loss:0.178526\n",
      "Epoch [2/2], Iter [840/3125], train_loss:0.153598\n",
      "Epoch [2/2], Iter [841/3125], train_loss:0.155480\n",
      "Epoch [2/2], Iter [842/3125], train_loss:0.168151\n",
      "Epoch [2/2], Iter [843/3125], train_loss:0.162481\n",
      "Epoch [2/2], Iter [844/3125], train_loss:0.163357\n",
      "Epoch [2/2], Iter [845/3125], train_loss:0.154588\n",
      "Epoch [2/2], Iter [846/3125], train_loss:0.164990\n",
      "Epoch [2/2], Iter [847/3125], train_loss:0.179786\n",
      "Epoch [2/2], Iter [848/3125], train_loss:0.152225\n",
      "Epoch [2/2], Iter [849/3125], train_loss:0.170434\n",
      "Epoch [2/2], Iter [850/3125], train_loss:0.169234\n",
      "Epoch [2/2], Iter [851/3125], train_loss:0.155938\n",
      "Epoch [2/2], Iter [852/3125], train_loss:0.159078\n",
      "Epoch [2/2], Iter [853/3125], train_loss:0.153539\n",
      "Epoch [2/2], Iter [854/3125], train_loss:0.153816\n",
      "Epoch [2/2], Iter [855/3125], train_loss:0.150923\n",
      "Epoch [2/2], Iter [856/3125], train_loss:0.146076\n",
      "Epoch [2/2], Iter [857/3125], train_loss:0.181592\n",
      "Epoch [2/2], Iter [858/3125], train_loss:0.149732\n",
      "Epoch [2/2], Iter [859/3125], train_loss:0.171731\n",
      "Epoch [2/2], Iter [860/3125], train_loss:0.176791\n",
      "Epoch [2/2], Iter [861/3125], train_loss:0.168146\n",
      "Epoch [2/2], Iter [862/3125], train_loss:0.164639\n",
      "Epoch [2/2], Iter [863/3125], train_loss:0.152723\n",
      "Epoch [2/2], Iter [864/3125], train_loss:0.163010\n",
      "Epoch [2/2], Iter [865/3125], train_loss:0.171877\n",
      "Epoch [2/2], Iter [866/3125], train_loss:0.159963\n",
      "Epoch [2/2], Iter [867/3125], train_loss:0.174265\n",
      "Epoch [2/2], Iter [868/3125], train_loss:0.162839\n",
      "Epoch [2/2], Iter [869/3125], train_loss:0.158850\n",
      "Epoch [2/2], Iter [870/3125], train_loss:0.147720\n",
      "Epoch [2/2], Iter [871/3125], train_loss:0.166036\n",
      "Epoch [2/2], Iter [872/3125], train_loss:0.145884\n",
      "Epoch [2/2], Iter [873/3125], train_loss:0.181906\n",
      "Epoch [2/2], Iter [874/3125], train_loss:0.172810\n",
      "Epoch [2/2], Iter [875/3125], train_loss:0.162292\n",
      "Epoch [2/2], Iter [876/3125], train_loss:0.150175\n",
      "Epoch [2/2], Iter [877/3125], train_loss:0.159696\n",
      "Epoch [2/2], Iter [878/3125], train_loss:0.182728\n",
      "Epoch [2/2], Iter [879/3125], train_loss:0.168535\n",
      "Epoch [2/2], Iter [880/3125], train_loss:0.146784\n",
      "Epoch [2/2], Iter [881/3125], train_loss:0.155928\n",
      "Epoch [2/2], Iter [882/3125], train_loss:0.160126\n",
      "Epoch [2/2], Iter [883/3125], train_loss:0.146958\n",
      "Epoch [2/2], Iter [884/3125], train_loss:0.164028\n",
      "Epoch [2/2], Iter [885/3125], train_loss:0.153675\n",
      "Epoch [2/2], Iter [886/3125], train_loss:0.168849\n",
      "Epoch [2/2], Iter [887/3125], train_loss:0.159146\n",
      "Epoch [2/2], Iter [888/3125], train_loss:0.164231\n",
      "Epoch [2/2], Iter [889/3125], train_loss:0.148224\n",
      "Epoch [2/2], Iter [890/3125], train_loss:0.191026\n",
      "Epoch [2/2], Iter [891/3125], train_loss:0.170115\n",
      "Epoch [2/2], Iter [892/3125], train_loss:0.161883\n",
      "Epoch [2/2], Iter [893/3125], train_loss:0.148661\n",
      "Epoch [2/2], Iter [894/3125], train_loss:0.186188\n",
      "Epoch [2/2], Iter [895/3125], train_loss:0.164686\n",
      "Epoch [2/2], Iter [896/3125], train_loss:0.166552\n",
      "Epoch [2/2], Iter [897/3125], train_loss:0.143936\n",
      "Epoch [2/2], Iter [898/3125], train_loss:0.165379\n",
      "Epoch [2/2], Iter [899/3125], train_loss:0.167553\n",
      "Epoch [2/2], Iter [900/3125], train_loss:0.164026\n",
      "Epoch [2/2], Iter [901/3125], train_loss:0.158453\n",
      "Epoch [2/2], Iter [902/3125], train_loss:0.165897\n",
      "Epoch [2/2], Iter [903/3125], train_loss:0.176101\n",
      "Epoch [2/2], Iter [904/3125], train_loss:0.182763\n",
      "Epoch [2/2], Iter [905/3125], train_loss:0.142893\n",
      "Epoch [2/2], Iter [906/3125], train_loss:0.162312\n",
      "Epoch [2/2], Iter [907/3125], train_loss:0.163721\n",
      "Epoch [2/2], Iter [908/3125], train_loss:0.163776\n",
      "Epoch [2/2], Iter [909/3125], train_loss:0.153530\n",
      "Epoch [2/2], Iter [910/3125], train_loss:0.162529\n",
      "Epoch [2/2], Iter [911/3125], train_loss:0.169922\n",
      "Epoch [2/2], Iter [912/3125], train_loss:0.160391\n",
      "Epoch [2/2], Iter [913/3125], train_loss:0.157418\n",
      "Epoch [2/2], Iter [914/3125], train_loss:0.167199\n",
      "Epoch [2/2], Iter [915/3125], train_loss:0.182277\n",
      "Epoch [2/2], Iter [916/3125], train_loss:0.163823\n",
      "Epoch [2/2], Iter [917/3125], train_loss:0.154207\n",
      "Epoch [2/2], Iter [918/3125], train_loss:0.150860\n",
      "Epoch [2/2], Iter [919/3125], train_loss:0.179584\n",
      "Epoch [2/2], Iter [920/3125], train_loss:0.145573\n",
      "Epoch [2/2], Iter [921/3125], train_loss:0.158257\n",
      "Epoch [2/2], Iter [922/3125], train_loss:0.160891\n",
      "Epoch [2/2], Iter [923/3125], train_loss:0.138845\n",
      "Epoch [2/2], Iter [924/3125], train_loss:0.146661\n",
      "Epoch [2/2], Iter [925/3125], train_loss:0.179409\n",
      "Epoch [2/2], Iter [926/3125], train_loss:0.164716\n",
      "Epoch [2/2], Iter [927/3125], train_loss:0.164125\n",
      "Epoch [2/2], Iter [928/3125], train_loss:0.157553\n",
      "Epoch [2/2], Iter [929/3125], train_loss:0.159311\n",
      "Epoch [2/2], Iter [930/3125], train_loss:0.183081\n",
      "Epoch [2/2], Iter [931/3125], train_loss:0.171617\n",
      "Epoch [2/2], Iter [932/3125], train_loss:0.145633\n",
      "Epoch [2/2], Iter [933/3125], train_loss:0.150144\n",
      "Epoch [2/2], Iter [934/3125], train_loss:0.175905\n",
      "Epoch [2/2], Iter [935/3125], train_loss:0.169417\n",
      "Epoch [2/2], Iter [936/3125], train_loss:0.159753\n",
      "Epoch [2/2], Iter [937/3125], train_loss:0.177034\n",
      "Epoch [2/2], Iter [938/3125], train_loss:0.152142\n",
      "Epoch [2/2], Iter [939/3125], train_loss:0.162613\n",
      "Epoch [2/2], Iter [940/3125], train_loss:0.164120\n",
      "Epoch [2/2], Iter [941/3125], train_loss:0.174846\n",
      "Epoch [2/2], Iter [942/3125], train_loss:0.150846\n",
      "Epoch [2/2], Iter [943/3125], train_loss:0.168710\n",
      "Epoch [2/2], Iter [944/3125], train_loss:0.184468\n",
      "Epoch [2/2], Iter [945/3125], train_loss:0.153751\n",
      "Epoch [2/2], Iter [946/3125], train_loss:0.163857\n",
      "Epoch [2/2], Iter [947/3125], train_loss:0.167490\n",
      "Epoch [2/2], Iter [948/3125], train_loss:0.163964\n",
      "Epoch [2/2], Iter [949/3125], train_loss:0.157843\n",
      "Epoch [2/2], Iter [950/3125], train_loss:0.171620\n",
      "Epoch [2/2], Iter [951/3125], train_loss:0.158963\n",
      "Epoch [2/2], Iter [952/3125], train_loss:0.145316\n",
      "Epoch [2/2], Iter [953/3125], train_loss:0.173244\n",
      "Epoch [2/2], Iter [954/3125], train_loss:0.149252\n",
      "Epoch [2/2], Iter [955/3125], train_loss:0.160078\n",
      "Epoch [2/2], Iter [956/3125], train_loss:0.146418\n",
      "Epoch [2/2], Iter [957/3125], train_loss:0.185556\n",
      "Epoch [2/2], Iter [958/3125], train_loss:0.170112\n",
      "Epoch [2/2], Iter [959/3125], train_loss:0.162447\n",
      "Epoch [2/2], Iter [960/3125], train_loss:0.146005\n",
      "Epoch [2/2], Iter [961/3125], train_loss:0.152330\n",
      "Epoch [2/2], Iter [962/3125], train_loss:0.159543\n",
      "Epoch [2/2], Iter [963/3125], train_loss:0.164612\n",
      "Epoch [2/2], Iter [964/3125], train_loss:0.161661\n",
      "Epoch [2/2], Iter [965/3125], train_loss:0.161440\n",
      "Epoch [2/2], Iter [966/3125], train_loss:0.164208\n",
      "Epoch [2/2], Iter [967/3125], train_loss:0.149589\n",
      "Epoch [2/2], Iter [968/3125], train_loss:0.139842\n",
      "Epoch [2/2], Iter [969/3125], train_loss:0.159436\n",
      "Epoch [2/2], Iter [970/3125], train_loss:0.174319\n",
      "Epoch [2/2], Iter [971/3125], train_loss:0.190806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [972/3125], train_loss:0.132737\n",
      "Epoch [2/2], Iter [973/3125], train_loss:0.162204\n",
      "Epoch [2/2], Iter [974/3125], train_loss:0.168722\n",
      "Epoch [2/2], Iter [975/3125], train_loss:0.162526\n",
      "Epoch [2/2], Iter [976/3125], train_loss:0.162467\n",
      "Epoch [2/2], Iter [977/3125], train_loss:0.156424\n",
      "Epoch [2/2], Iter [978/3125], train_loss:0.160412\n",
      "Epoch [2/2], Iter [979/3125], train_loss:0.158342\n",
      "Epoch [2/2], Iter [980/3125], train_loss:0.144113\n",
      "Epoch [2/2], Iter [981/3125], train_loss:0.152205\n",
      "Epoch [2/2], Iter [982/3125], train_loss:0.166542\n",
      "Epoch [2/2], Iter [983/3125], train_loss:0.155931\n",
      "Epoch [2/2], Iter [984/3125], train_loss:0.161623\n",
      "Epoch [2/2], Iter [985/3125], train_loss:0.159522\n",
      "Epoch [2/2], Iter [986/3125], train_loss:0.156305\n",
      "Epoch [2/2], Iter [987/3125], train_loss:0.173491\n",
      "Epoch [2/2], Iter [988/3125], train_loss:0.148876\n",
      "Epoch [2/2], Iter [989/3125], train_loss:0.150327\n",
      "Epoch [2/2], Iter [990/3125], train_loss:0.147359\n",
      "Epoch [2/2], Iter [991/3125], train_loss:0.168943\n",
      "Epoch [2/2], Iter [992/3125], train_loss:0.169182\n",
      "Epoch [2/2], Iter [993/3125], train_loss:0.173301\n",
      "Epoch [2/2], Iter [994/3125], train_loss:0.165827\n",
      "Epoch [2/2], Iter [995/3125], train_loss:0.185946\n",
      "Epoch [2/2], Iter [996/3125], train_loss:0.173343\n",
      "Epoch [2/2], Iter [997/3125], train_loss:0.176181\n",
      "Epoch [2/2], Iter [998/3125], train_loss:0.157136\n",
      "Epoch [2/2], Iter [999/3125], train_loss:0.160275\n",
      "Epoch [2/2], Iter [1000/3125], train_loss:0.170856\n",
      "Epoch [2/2], Iter [1001/3125], train_loss:0.172774\n",
      "Epoch [2/2], Iter [1002/3125], train_loss:0.162824\n",
      "Epoch [2/2], Iter [1003/3125], train_loss:0.155861\n",
      "Epoch [2/2], Iter [1004/3125], train_loss:0.156405\n",
      "Epoch [2/2], Iter [1005/3125], train_loss:0.163323\n",
      "Epoch [2/2], Iter [1006/3125], train_loss:0.186383\n",
      "Epoch [2/2], Iter [1007/3125], train_loss:0.144812\n",
      "Epoch [2/2], Iter [1008/3125], train_loss:0.175535\n",
      "Epoch [2/2], Iter [1009/3125], train_loss:0.159734\n",
      "Epoch [2/2], Iter [1010/3125], train_loss:0.159502\n",
      "Epoch [2/2], Iter [1011/3125], train_loss:0.144269\n",
      "Epoch [2/2], Iter [1012/3125], train_loss:0.151117\n",
      "Epoch [2/2], Iter [1013/3125], train_loss:0.170704\n",
      "Epoch [2/2], Iter [1014/3125], train_loss:0.162276\n",
      "Epoch [2/2], Iter [1015/3125], train_loss:0.171860\n",
      "Epoch [2/2], Iter [1016/3125], train_loss:0.153412\n",
      "Epoch [2/2], Iter [1017/3125], train_loss:0.171162\n",
      "Epoch [2/2], Iter [1018/3125], train_loss:0.170929\n",
      "Epoch [2/2], Iter [1019/3125], train_loss:0.177345\n",
      "Epoch [2/2], Iter [1020/3125], train_loss:0.166995\n",
      "Epoch [2/2], Iter [1021/3125], train_loss:0.153076\n",
      "Epoch [2/2], Iter [1022/3125], train_loss:0.154810\n",
      "Epoch [2/2], Iter [1023/3125], train_loss:0.170034\n",
      "Epoch [2/2], Iter [1024/3125], train_loss:0.162151\n",
      "Epoch [2/2], Iter [1025/3125], train_loss:0.163927\n",
      "Epoch [2/2], Iter [1026/3125], train_loss:0.133225\n",
      "Epoch [2/2], Iter [1027/3125], train_loss:0.169137\n",
      "Epoch [2/2], Iter [1028/3125], train_loss:0.170819\n",
      "Epoch [2/2], Iter [1029/3125], train_loss:0.193447\n",
      "Epoch [2/2], Iter [1030/3125], train_loss:0.157416\n",
      "Epoch [2/2], Iter [1031/3125], train_loss:0.187019\n",
      "Epoch [2/2], Iter [1032/3125], train_loss:0.154375\n",
      "Epoch [2/2], Iter [1033/3125], train_loss:0.158600\n",
      "Epoch [2/2], Iter [1034/3125], train_loss:0.173377\n",
      "Epoch [2/2], Iter [1035/3125], train_loss:0.175745\n",
      "Epoch [2/2], Iter [1036/3125], train_loss:0.167590\n",
      "Epoch [2/2], Iter [1037/3125], train_loss:0.178438\n",
      "Epoch [2/2], Iter [1038/3125], train_loss:0.161560\n",
      "Epoch [2/2], Iter [1039/3125], train_loss:0.155392\n",
      "Epoch [2/2], Iter [1040/3125], train_loss:0.166553\n",
      "Epoch [2/2], Iter [1041/3125], train_loss:0.138545\n",
      "Epoch [2/2], Iter [1042/3125], train_loss:0.155348\n",
      "Epoch [2/2], Iter [1043/3125], train_loss:0.174792\n",
      "Epoch [2/2], Iter [1044/3125], train_loss:0.149824\n",
      "Epoch [2/2], Iter [1045/3125], train_loss:0.171141\n",
      "Epoch [2/2], Iter [1046/3125], train_loss:0.156415\n",
      "Epoch [2/2], Iter [1047/3125], train_loss:0.174438\n",
      "Epoch [2/2], Iter [1048/3125], train_loss:0.149525\n",
      "Epoch [2/2], Iter [1049/3125], train_loss:0.188034\n",
      "Epoch [2/2], Iter [1050/3125], train_loss:0.167967\n",
      "Epoch [2/2], Iter [1051/3125], train_loss:0.157783\n",
      "Epoch [2/2], Iter [1052/3125], train_loss:0.150636\n",
      "Epoch [2/2], Iter [1053/3125], train_loss:0.162442\n",
      "Epoch [2/2], Iter [1054/3125], train_loss:0.164999\n",
      "Epoch [2/2], Iter [1055/3125], train_loss:0.152068\n",
      "Epoch [2/2], Iter [1056/3125], train_loss:0.158157\n",
      "Epoch [2/2], Iter [1057/3125], train_loss:0.169230\n",
      "Epoch [2/2], Iter [1058/3125], train_loss:0.157603\n",
      "Epoch [2/2], Iter [1059/3125], train_loss:0.176266\n",
      "Epoch [2/2], Iter [1060/3125], train_loss:0.144484\n",
      "Epoch [2/2], Iter [1061/3125], train_loss:0.158303\n",
      "Epoch [2/2], Iter [1062/3125], train_loss:0.138062\n",
      "Epoch [2/2], Iter [1063/3125], train_loss:0.183077\n",
      "Epoch [2/2], Iter [1064/3125], train_loss:0.175395\n",
      "Epoch [2/2], Iter [1065/3125], train_loss:0.147677\n",
      "Epoch [2/2], Iter [1066/3125], train_loss:0.146010\n",
      "Epoch [2/2], Iter [1067/3125], train_loss:0.160933\n",
      "Epoch [2/2], Iter [1068/3125], train_loss:0.140449\n",
      "Epoch [2/2], Iter [1069/3125], train_loss:0.141293\n",
      "Epoch [2/2], Iter [1070/3125], train_loss:0.156154\n",
      "Epoch [2/2], Iter [1071/3125], train_loss:0.164499\n",
      "Epoch [2/2], Iter [1072/3125], train_loss:0.183819\n",
      "Epoch [2/2], Iter [1073/3125], train_loss:0.156379\n",
      "Epoch [2/2], Iter [1074/3125], train_loss:0.184832\n",
      "Epoch [2/2], Iter [1075/3125], train_loss:0.178868\n",
      "Epoch [2/2], Iter [1076/3125], train_loss:0.161758\n",
      "Epoch [2/2], Iter [1077/3125], train_loss:0.166813\n",
      "Epoch [2/2], Iter [1078/3125], train_loss:0.152807\n",
      "Epoch [2/2], Iter [1079/3125], train_loss:0.188562\n",
      "Epoch [2/2], Iter [1080/3125], train_loss:0.178612\n",
      "Epoch [2/2], Iter [1081/3125], train_loss:0.169517\n",
      "Epoch [2/2], Iter [1082/3125], train_loss:0.158839\n",
      "Epoch [2/2], Iter [1083/3125], train_loss:0.169982\n",
      "Epoch [2/2], Iter [1084/3125], train_loss:0.161700\n",
      "Epoch [2/2], Iter [1085/3125], train_loss:0.167068\n",
      "Epoch [2/2], Iter [1086/3125], train_loss:0.161840\n",
      "Epoch [2/2], Iter [1087/3125], train_loss:0.197193\n",
      "Epoch [2/2], Iter [1088/3125], train_loss:0.176791\n",
      "Epoch [2/2], Iter [1089/3125], train_loss:0.160420\n",
      "Epoch [2/2], Iter [1090/3125], train_loss:0.172724\n",
      "Epoch [2/2], Iter [1091/3125], train_loss:0.163568\n",
      "Epoch [2/2], Iter [1092/3125], train_loss:0.171323\n",
      "Epoch [2/2], Iter [1093/3125], train_loss:0.169604\n",
      "Epoch [2/2], Iter [1094/3125], train_loss:0.145144\n",
      "Epoch [2/2], Iter [1095/3125], train_loss:0.176243\n",
      "Epoch [2/2], Iter [1096/3125], train_loss:0.143750\n",
      "Epoch [2/2], Iter [1097/3125], train_loss:0.169709\n",
      "Epoch [2/2], Iter [1098/3125], train_loss:0.158582\n",
      "Epoch [2/2], Iter [1099/3125], train_loss:0.154654\n",
      "Epoch [2/2], Iter [1100/3125], train_loss:0.174916\n",
      "Epoch [2/2], Iter [1101/3125], train_loss:0.161558\n",
      "Epoch [2/2], Iter [1102/3125], train_loss:0.180498\n",
      "Epoch [2/2], Iter [1103/3125], train_loss:0.156927\n",
      "Epoch [2/2], Iter [1104/3125], train_loss:0.156501\n",
      "Epoch [2/2], Iter [1105/3125], train_loss:0.150472\n",
      "Epoch [2/2], Iter [1106/3125], train_loss:0.150199\n",
      "Epoch [2/2], Iter [1107/3125], train_loss:0.159775\n",
      "Epoch [2/2], Iter [1108/3125], train_loss:0.154819\n",
      "Epoch [2/2], Iter [1109/3125], train_loss:0.162890\n",
      "Epoch [2/2], Iter [1110/3125], train_loss:0.147965\n",
      "Epoch [2/2], Iter [1111/3125], train_loss:0.164015\n",
      "Epoch [2/2], Iter [1112/3125], train_loss:0.168382\n",
      "Epoch [2/2], Iter [1113/3125], train_loss:0.163151\n",
      "Epoch [2/2], Iter [1114/3125], train_loss:0.157221\n",
      "Epoch [2/2], Iter [1115/3125], train_loss:0.168603\n",
      "Epoch [2/2], Iter [1116/3125], train_loss:0.155715\n",
      "Epoch [2/2], Iter [1117/3125], train_loss:0.166793\n",
      "Epoch [2/2], Iter [1118/3125], train_loss:0.142596\n",
      "Epoch [2/2], Iter [1119/3125], train_loss:0.143480\n",
      "Epoch [2/2], Iter [1120/3125], train_loss:0.169482\n",
      "Epoch [2/2], Iter [1121/3125], train_loss:0.181025\n",
      "Epoch [2/2], Iter [1122/3125], train_loss:0.170103\n",
      "Epoch [2/2], Iter [1123/3125], train_loss:0.154549\n",
      "Epoch [2/2], Iter [1124/3125], train_loss:0.189329\n",
      "Epoch [2/2], Iter [1125/3125], train_loss:0.178162\n",
      "Epoch [2/2], Iter [1126/3125], train_loss:0.150472\n",
      "Epoch [2/2], Iter [1127/3125], train_loss:0.152926\n",
      "Epoch [2/2], Iter [1128/3125], train_loss:0.176046\n",
      "Epoch [2/2], Iter [1129/3125], train_loss:0.162334\n",
      "Epoch [2/2], Iter [1130/3125], train_loss:0.154232\n",
      "Epoch [2/2], Iter [1131/3125], train_loss:0.157293\n",
      "Epoch [2/2], Iter [1132/3125], train_loss:0.156008\n",
      "Epoch [2/2], Iter [1133/3125], train_loss:0.162736\n",
      "Epoch [2/2], Iter [1134/3125], train_loss:0.140912\n",
      "Epoch [2/2], Iter [1135/3125], train_loss:0.168050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [1136/3125], train_loss:0.183583\n",
      "Epoch [2/2], Iter [1137/3125], train_loss:0.161725\n",
      "Epoch [2/2], Iter [1138/3125], train_loss:0.151099\n",
      "Epoch [2/2], Iter [1139/3125], train_loss:0.130716\n",
      "Epoch [2/2], Iter [1140/3125], train_loss:0.168318\n",
      "Epoch [2/2], Iter [1141/3125], train_loss:0.152064\n",
      "Epoch [2/2], Iter [1142/3125], train_loss:0.172143\n",
      "Epoch [2/2], Iter [1143/3125], train_loss:0.152954\n",
      "Epoch [2/2], Iter [1144/3125], train_loss:0.153355\n",
      "Epoch [2/2], Iter [1145/3125], train_loss:0.148028\n",
      "Epoch [2/2], Iter [1146/3125], train_loss:0.161896\n",
      "Epoch [2/2], Iter [1147/3125], train_loss:0.163705\n",
      "Epoch [2/2], Iter [1148/3125], train_loss:0.167898\n",
      "Epoch [2/2], Iter [1149/3125], train_loss:0.161064\n",
      "Epoch [2/2], Iter [1150/3125], train_loss:0.164270\n",
      "Epoch [2/2], Iter [1151/3125], train_loss:0.180339\n",
      "Epoch [2/2], Iter [1152/3125], train_loss:0.161365\n",
      "Epoch [2/2], Iter [1153/3125], train_loss:0.175764\n",
      "Epoch [2/2], Iter [1154/3125], train_loss:0.169996\n",
      "Epoch [2/2], Iter [1155/3125], train_loss:0.167045\n",
      "Epoch [2/2], Iter [1156/3125], train_loss:0.173716\n",
      "Epoch [2/2], Iter [1157/3125], train_loss:0.171089\n",
      "Epoch [2/2], Iter [1158/3125], train_loss:0.178231\n",
      "Epoch [2/2], Iter [1159/3125], train_loss:0.188366\n",
      "Epoch [2/2], Iter [1160/3125], train_loss:0.164643\n",
      "Epoch [2/2], Iter [1161/3125], train_loss:0.161060\n",
      "Epoch [2/2], Iter [1162/3125], train_loss:0.133637\n",
      "Epoch [2/2], Iter [1163/3125], train_loss:0.164900\n",
      "Epoch [2/2], Iter [1164/3125], train_loss:0.154659\n",
      "Epoch [2/2], Iter [1165/3125], train_loss:0.166482\n",
      "Epoch [2/2], Iter [1166/3125], train_loss:0.174840\n",
      "Epoch [2/2], Iter [1167/3125], train_loss:0.159675\n",
      "Epoch [2/2], Iter [1168/3125], train_loss:0.171341\n",
      "Epoch [2/2], Iter [1169/3125], train_loss:0.161449\n",
      "Epoch [2/2], Iter [1170/3125], train_loss:0.169251\n",
      "Epoch [2/2], Iter [1171/3125], train_loss:0.137083\n",
      "Epoch [2/2], Iter [1172/3125], train_loss:0.182085\n",
      "Epoch [2/2], Iter [1173/3125], train_loss:0.161653\n",
      "Epoch [2/2], Iter [1174/3125], train_loss:0.166378\n",
      "Epoch [2/2], Iter [1175/3125], train_loss:0.149325\n",
      "Epoch [2/2], Iter [1176/3125], train_loss:0.157818\n",
      "Epoch [2/2], Iter [1177/3125], train_loss:0.168894\n",
      "Epoch [2/2], Iter [1178/3125], train_loss:0.156494\n",
      "Epoch [2/2], Iter [1179/3125], train_loss:0.169069\n",
      "Epoch [2/2], Iter [1180/3125], train_loss:0.153213\n",
      "Epoch [2/2], Iter [1181/3125], train_loss:0.173552\n",
      "Epoch [2/2], Iter [1182/3125], train_loss:0.159144\n",
      "Epoch [2/2], Iter [1183/3125], train_loss:0.158202\n",
      "Epoch [2/2], Iter [1184/3125], train_loss:0.163871\n",
      "Epoch [2/2], Iter [1185/3125], train_loss:0.173604\n",
      "Epoch [2/2], Iter [1186/3125], train_loss:0.152674\n",
      "Epoch [2/2], Iter [1187/3125], train_loss:0.160175\n",
      "Epoch [2/2], Iter [1188/3125], train_loss:0.156207\n",
      "Epoch [2/2], Iter [1189/3125], train_loss:0.172094\n",
      "Epoch [2/2], Iter [1190/3125], train_loss:0.159429\n",
      "Epoch [2/2], Iter [1191/3125], train_loss:0.158091\n",
      "Epoch [2/2], Iter [1192/3125], train_loss:0.162421\n",
      "Epoch [2/2], Iter [1193/3125], train_loss:0.175131\n",
      "Epoch [2/2], Iter [1194/3125], train_loss:0.166639\n",
      "Epoch [2/2], Iter [1195/3125], train_loss:0.190166\n",
      "Epoch [2/2], Iter [1196/3125], train_loss:0.150228\n",
      "Epoch [2/2], Iter [1197/3125], train_loss:0.149197\n",
      "Epoch [2/2], Iter [1198/3125], train_loss:0.164747\n",
      "Epoch [2/2], Iter [1199/3125], train_loss:0.152114\n",
      "Epoch [2/2], Iter [1200/3125], train_loss:0.160189\n",
      "Epoch [2/2], Iter [1201/3125], train_loss:0.169123\n",
      "Epoch [2/2], Iter [1202/3125], train_loss:0.184243\n",
      "Epoch [2/2], Iter [1203/3125], train_loss:0.173901\n",
      "Epoch [2/2], Iter [1204/3125], train_loss:0.145923\n",
      "Epoch [2/2], Iter [1205/3125], train_loss:0.135535\n",
      "Epoch [2/2], Iter [1206/3125], train_loss:0.167992\n",
      "Epoch [2/2], Iter [1207/3125], train_loss:0.173060\n",
      "Epoch [2/2], Iter [1208/3125], train_loss:0.159673\n",
      "Epoch [2/2], Iter [1209/3125], train_loss:0.173016\n",
      "Epoch [2/2], Iter [1210/3125], train_loss:0.154534\n",
      "Epoch [2/2], Iter [1211/3125], train_loss:0.165103\n",
      "Epoch [2/2], Iter [1212/3125], train_loss:0.166492\n",
      "Epoch [2/2], Iter [1213/3125], train_loss:0.177256\n",
      "Epoch [2/2], Iter [1214/3125], train_loss:0.138522\n",
      "Epoch [2/2], Iter [1215/3125], train_loss:0.173040\n",
      "Epoch [2/2], Iter [1216/3125], train_loss:0.160836\n",
      "Epoch [2/2], Iter [1217/3125], train_loss:0.171410\n",
      "Epoch [2/2], Iter [1218/3125], train_loss:0.151528\n",
      "Epoch [2/2], Iter [1219/3125], train_loss:0.155641\n",
      "Epoch [2/2], Iter [1220/3125], train_loss:0.170059\n",
      "Epoch [2/2], Iter [1221/3125], train_loss:0.139546\n",
      "Epoch [2/2], Iter [1222/3125], train_loss:0.164667\n",
      "Epoch [2/2], Iter [1223/3125], train_loss:0.131796\n",
      "Epoch [2/2], Iter [1224/3125], train_loss:0.130843\n",
      "Epoch [2/2], Iter [1225/3125], train_loss:0.179394\n",
      "Epoch [2/2], Iter [1226/3125], train_loss:0.171075\n",
      "Epoch [2/2], Iter [1227/3125], train_loss:0.167901\n",
      "Epoch [2/2], Iter [1228/3125], train_loss:0.151537\n",
      "Epoch [2/2], Iter [1229/3125], train_loss:0.159267\n",
      "Epoch [2/2], Iter [1230/3125], train_loss:0.149763\n",
      "Epoch [2/2], Iter [1231/3125], train_loss:0.154899\n",
      "Epoch [2/2], Iter [1232/3125], train_loss:0.167239\n",
      "Epoch [2/2], Iter [1233/3125], train_loss:0.172060\n",
      "Epoch [2/2], Iter [1234/3125], train_loss:0.167790\n",
      "Epoch [2/2], Iter [1235/3125], train_loss:0.162423\n",
      "Epoch [2/2], Iter [1236/3125], train_loss:0.165569\n",
      "Epoch [2/2], Iter [1237/3125], train_loss:0.162490\n",
      "Epoch [2/2], Iter [1238/3125], train_loss:0.170146\n",
      "Epoch [2/2], Iter [1239/3125], train_loss:0.140093\n",
      "Epoch [2/2], Iter [1240/3125], train_loss:0.177397\n",
      "Epoch [2/2], Iter [1241/3125], train_loss:0.145430\n",
      "Epoch [2/2], Iter [1242/3125], train_loss:0.171714\n",
      "Epoch [2/2], Iter [1243/3125], train_loss:0.145300\n",
      "Epoch [2/2], Iter [1244/3125], train_loss:0.176454\n",
      "Epoch [2/2], Iter [1245/3125], train_loss:0.156179\n",
      "Epoch [2/2], Iter [1246/3125], train_loss:0.158399\n",
      "Epoch [2/2], Iter [1247/3125], train_loss:0.180703\n",
      "Epoch [2/2], Iter [1248/3125], train_loss:0.186594\n",
      "Epoch [2/2], Iter [1249/3125], train_loss:0.155831\n",
      "Epoch [2/2], Iter [1250/3125], train_loss:0.175276\n",
      "Epoch [2/2], Iter [1251/3125], train_loss:0.140585\n",
      "Epoch [2/2], Iter [1252/3125], train_loss:0.174710\n",
      "Epoch [2/2], Iter [1253/3125], train_loss:0.151340\n",
      "Epoch [2/2], Iter [1254/3125], train_loss:0.178389\n",
      "Epoch [2/2], Iter [1255/3125], train_loss:0.149121\n",
      "Epoch [2/2], Iter [1256/3125], train_loss:0.185348\n",
      "Epoch [2/2], Iter [1257/3125], train_loss:0.149603\n",
      "Epoch [2/2], Iter [1258/3125], train_loss:0.159399\n",
      "Epoch [2/2], Iter [1259/3125], train_loss:0.159870\n",
      "Epoch [2/2], Iter [1260/3125], train_loss:0.153415\n",
      "Epoch [2/2], Iter [1261/3125], train_loss:0.172202\n",
      "Epoch [2/2], Iter [1262/3125], train_loss:0.156571\n",
      "Epoch [2/2], Iter [1263/3125], train_loss:0.157553\n",
      "Epoch [2/2], Iter [1264/3125], train_loss:0.150412\n",
      "Epoch [2/2], Iter [1265/3125], train_loss:0.170007\n",
      "Epoch [2/2], Iter [1266/3125], train_loss:0.184801\n",
      "Epoch [2/2], Iter [1267/3125], train_loss:0.169624\n",
      "Epoch [2/2], Iter [1268/3125], train_loss:0.160603\n",
      "Epoch [2/2], Iter [1269/3125], train_loss:0.174301\n",
      "Epoch [2/2], Iter [1270/3125], train_loss:0.161539\n",
      "Epoch [2/2], Iter [1271/3125], train_loss:0.165669\n",
      "Epoch [2/2], Iter [1272/3125], train_loss:0.159396\n",
      "Epoch [2/2], Iter [1273/3125], train_loss:0.170856\n",
      "Epoch [2/2], Iter [1274/3125], train_loss:0.145106\n",
      "Epoch [2/2], Iter [1275/3125], train_loss:0.158106\n",
      "Epoch [2/2], Iter [1276/3125], train_loss:0.170758\n",
      "Epoch [2/2], Iter [1277/3125], train_loss:0.151868\n",
      "Epoch [2/2], Iter [1278/3125], train_loss:0.159160\n",
      "Epoch [2/2], Iter [1279/3125], train_loss:0.174219\n",
      "Epoch [2/2], Iter [1280/3125], train_loss:0.145328\n",
      "Epoch [2/2], Iter [1281/3125], train_loss:0.151753\n",
      "Epoch [2/2], Iter [1282/3125], train_loss:0.176097\n",
      "Epoch [2/2], Iter [1283/3125], train_loss:0.163653\n",
      "Epoch [2/2], Iter [1284/3125], train_loss:0.162465\n",
      "Epoch [2/2], Iter [1285/3125], train_loss:0.193091\n",
      "Epoch [2/2], Iter [1286/3125], train_loss:0.174989\n",
      "Epoch [2/2], Iter [1287/3125], train_loss:0.167597\n",
      "Epoch [2/2], Iter [1288/3125], train_loss:0.157328\n",
      "Epoch [2/2], Iter [1289/3125], train_loss:0.169358\n",
      "Epoch [2/2], Iter [1290/3125], train_loss:0.168082\n",
      "Epoch [2/2], Iter [1291/3125], train_loss:0.156105\n",
      "Epoch [2/2], Iter [1292/3125], train_loss:0.169177\n",
      "Epoch [2/2], Iter [1293/3125], train_loss:0.174420\n",
      "Epoch [2/2], Iter [1294/3125], train_loss:0.167050\n",
      "Epoch [2/2], Iter [1295/3125], train_loss:0.177213\n",
      "Epoch [2/2], Iter [1296/3125], train_loss:0.166818\n",
      "Epoch [2/2], Iter [1297/3125], train_loss:0.180003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [1298/3125], train_loss:0.158434\n",
      "Epoch [2/2], Iter [1299/3125], train_loss:0.188684\n",
      "Epoch [2/2], Iter [1300/3125], train_loss:0.180022\n",
      "Epoch [2/2], Iter [1301/3125], train_loss:0.152183\n",
      "Epoch [2/2], Iter [1302/3125], train_loss:0.155628\n",
      "Epoch [2/2], Iter [1303/3125], train_loss:0.154348\n",
      "Epoch [2/2], Iter [1304/3125], train_loss:0.162059\n",
      "Epoch [2/2], Iter [1305/3125], train_loss:0.149779\n",
      "Epoch [2/2], Iter [1306/3125], train_loss:0.174483\n",
      "Epoch [2/2], Iter [1307/3125], train_loss:0.163854\n",
      "Epoch [2/2], Iter [1308/3125], train_loss:0.166578\n",
      "Epoch [2/2], Iter [1309/3125], train_loss:0.153154\n",
      "Epoch [2/2], Iter [1310/3125], train_loss:0.163594\n",
      "Epoch [2/2], Iter [1311/3125], train_loss:0.172058\n",
      "Epoch [2/2], Iter [1312/3125], train_loss:0.148626\n",
      "Epoch [2/2], Iter [1313/3125], train_loss:0.146601\n",
      "Epoch [2/2], Iter [1314/3125], train_loss:0.174271\n",
      "Epoch [2/2], Iter [1315/3125], train_loss:0.187370\n",
      "Epoch [2/2], Iter [1316/3125], train_loss:0.172819\n",
      "Epoch [2/2], Iter [1317/3125], train_loss:0.153683\n",
      "Epoch [2/2], Iter [1318/3125], train_loss:0.161098\n",
      "Epoch [2/2], Iter [1319/3125], train_loss:0.177510\n",
      "Epoch [2/2], Iter [1320/3125], train_loss:0.162964\n",
      "Epoch [2/2], Iter [1321/3125], train_loss:0.173236\n",
      "Epoch [2/2], Iter [1322/3125], train_loss:0.181592\n",
      "Epoch [2/2], Iter [1323/3125], train_loss:0.171860\n",
      "Epoch [2/2], Iter [1324/3125], train_loss:0.177525\n",
      "Epoch [2/2], Iter [1325/3125], train_loss:0.150291\n",
      "Epoch [2/2], Iter [1326/3125], train_loss:0.159995\n",
      "Epoch [2/2], Iter [1327/3125], train_loss:0.157691\n",
      "Epoch [2/2], Iter [1328/3125], train_loss:0.161104\n",
      "Epoch [2/2], Iter [1329/3125], train_loss:0.176180\n",
      "Epoch [2/2], Iter [1330/3125], train_loss:0.163652\n",
      "Epoch [2/2], Iter [1331/3125], train_loss:0.168732\n",
      "Epoch [2/2], Iter [1332/3125], train_loss:0.162344\n",
      "Epoch [2/2], Iter [1333/3125], train_loss:0.149717\n",
      "Epoch [2/2], Iter [1334/3125], train_loss:0.170549\n",
      "Epoch [2/2], Iter [1335/3125], train_loss:0.145734\n",
      "Epoch [2/2], Iter [1336/3125], train_loss:0.189735\n",
      "Epoch [2/2], Iter [1337/3125], train_loss:0.154256\n",
      "Epoch [2/2], Iter [1338/3125], train_loss:0.159357\n",
      "Epoch [2/2], Iter [1339/3125], train_loss:0.175443\n",
      "Epoch [2/2], Iter [1340/3125], train_loss:0.160549\n",
      "Epoch [2/2], Iter [1341/3125], train_loss:0.154896\n",
      "Epoch [2/2], Iter [1342/3125], train_loss:0.141709\n",
      "Epoch [2/2], Iter [1343/3125], train_loss:0.148586\n",
      "Epoch [2/2], Iter [1344/3125], train_loss:0.155315\n",
      "Epoch [2/2], Iter [1345/3125], train_loss:0.148805\n",
      "Epoch [2/2], Iter [1346/3125], train_loss:0.162808\n",
      "Epoch [2/2], Iter [1347/3125], train_loss:0.159063\n",
      "Epoch [2/2], Iter [1348/3125], train_loss:0.161040\n",
      "Epoch [2/2], Iter [1349/3125], train_loss:0.165175\n",
      "Epoch [2/2], Iter [1350/3125], train_loss:0.155752\n",
      "Epoch [2/2], Iter [1351/3125], train_loss:0.156043\n",
      "Epoch [2/2], Iter [1352/3125], train_loss:0.177145\n",
      "Epoch [2/2], Iter [1353/3125], train_loss:0.147471\n",
      "Epoch [2/2], Iter [1354/3125], train_loss:0.163780\n",
      "Epoch [2/2], Iter [1355/3125], train_loss:0.170312\n",
      "Epoch [2/2], Iter [1356/3125], train_loss:0.173979\n",
      "Epoch [2/2], Iter [1357/3125], train_loss:0.171459\n",
      "Epoch [2/2], Iter [1358/3125], train_loss:0.156300\n",
      "Epoch [2/2], Iter [1359/3125], train_loss:0.152936\n",
      "Epoch [2/2], Iter [1360/3125], train_loss:0.161047\n",
      "Epoch [2/2], Iter [1361/3125], train_loss:0.155220\n",
      "Epoch [2/2], Iter [1362/3125], train_loss:0.156518\n",
      "Epoch [2/2], Iter [1363/3125], train_loss:0.166589\n",
      "Epoch [2/2], Iter [1364/3125], train_loss:0.161810\n",
      "Epoch [2/2], Iter [1365/3125], train_loss:0.151786\n",
      "Epoch [2/2], Iter [1366/3125], train_loss:0.161793\n",
      "Epoch [2/2], Iter [1367/3125], train_loss:0.177291\n",
      "Epoch [2/2], Iter [1368/3125], train_loss:0.146723\n",
      "Epoch [2/2], Iter [1369/3125], train_loss:0.171233\n",
      "Epoch [2/2], Iter [1370/3125], train_loss:0.169580\n",
      "Epoch [2/2], Iter [1371/3125], train_loss:0.161926\n",
      "Epoch [2/2], Iter [1372/3125], train_loss:0.183059\n",
      "Epoch [2/2], Iter [1373/3125], train_loss:0.176881\n",
      "Epoch [2/2], Iter [1374/3125], train_loss:0.157800\n",
      "Epoch [2/2], Iter [1375/3125], train_loss:0.187816\n",
      "Epoch [2/2], Iter [1376/3125], train_loss:0.135312\n",
      "Epoch [2/2], Iter [1377/3125], train_loss:0.150722\n",
      "Epoch [2/2], Iter [1378/3125], train_loss:0.168128\n",
      "Epoch [2/2], Iter [1379/3125], train_loss:0.159862\n",
      "Epoch [2/2], Iter [1380/3125], train_loss:0.153444\n",
      "Epoch [2/2], Iter [1381/3125], train_loss:0.176536\n",
      "Epoch [2/2], Iter [1382/3125], train_loss:0.158249\n",
      "Epoch [2/2], Iter [1383/3125], train_loss:0.186996\n",
      "Epoch [2/2], Iter [1384/3125], train_loss:0.172860\n",
      "Epoch [2/2], Iter [1385/3125], train_loss:0.175652\n",
      "Epoch [2/2], Iter [1386/3125], train_loss:0.159070\n",
      "Epoch [2/2], Iter [1387/3125], train_loss:0.154151\n",
      "Epoch [2/2], Iter [1388/3125], train_loss:0.172656\n",
      "Epoch [2/2], Iter [1389/3125], train_loss:0.160518\n",
      "Epoch [2/2], Iter [1390/3125], train_loss:0.176050\n",
      "Epoch [2/2], Iter [1391/3125], train_loss:0.152496\n",
      "Epoch [2/2], Iter [1392/3125], train_loss:0.190113\n",
      "Epoch [2/2], Iter [1393/3125], train_loss:0.184636\n",
      "Epoch [2/2], Iter [1394/3125], train_loss:0.171103\n",
      "Epoch [2/2], Iter [1395/3125], train_loss:0.140772\n",
      "Epoch [2/2], Iter [1396/3125], train_loss:0.161837\n",
      "Epoch [2/2], Iter [1397/3125], train_loss:0.154678\n",
      "Epoch [2/2], Iter [1398/3125], train_loss:0.176741\n",
      "Epoch [2/2], Iter [1399/3125], train_loss:0.153452\n",
      "Epoch [2/2], Iter [1400/3125], train_loss:0.167091\n",
      "Epoch [2/2], Iter [1401/3125], train_loss:0.170163\n",
      "Epoch [2/2], Iter [1402/3125], train_loss:0.170133\n",
      "Epoch [2/2], Iter [1403/3125], train_loss:0.148200\n",
      "Epoch [2/2], Iter [1404/3125], train_loss:0.152297\n",
      "Epoch [2/2], Iter [1405/3125], train_loss:0.147695\n",
      "Epoch [2/2], Iter [1406/3125], train_loss:0.180550\n",
      "Epoch [2/2], Iter [1407/3125], train_loss:0.170130\n",
      "Epoch [2/2], Iter [1408/3125], train_loss:0.177456\n",
      "Epoch [2/2], Iter [1409/3125], train_loss:0.162516\n",
      "Epoch [2/2], Iter [1410/3125], train_loss:0.175884\n",
      "Epoch [2/2], Iter [1411/3125], train_loss:0.171188\n",
      "Epoch [2/2], Iter [1412/3125], train_loss:0.161636\n",
      "Epoch [2/2], Iter [1413/3125], train_loss:0.149659\n",
      "Epoch [2/2], Iter [1414/3125], train_loss:0.148098\n",
      "Epoch [2/2], Iter [1415/3125], train_loss:0.162252\n",
      "Epoch [2/2], Iter [1416/3125], train_loss:0.162739\n",
      "Epoch [2/2], Iter [1417/3125], train_loss:0.139677\n",
      "Epoch [2/2], Iter [1418/3125], train_loss:0.180549\n",
      "Epoch [2/2], Iter [1419/3125], train_loss:0.146935\n",
      "Epoch [2/2], Iter [1420/3125], train_loss:0.152124\n",
      "Epoch [2/2], Iter [1421/3125], train_loss:0.155976\n",
      "Epoch [2/2], Iter [1422/3125], train_loss:0.180415\n",
      "Epoch [2/2], Iter [1423/3125], train_loss:0.176407\n",
      "Epoch [2/2], Iter [1424/3125], train_loss:0.167077\n",
      "Epoch [2/2], Iter [1425/3125], train_loss:0.163473\n",
      "Epoch [2/2], Iter [1426/3125], train_loss:0.183130\n",
      "Epoch [2/2], Iter [1427/3125], train_loss:0.174583\n",
      "Epoch [2/2], Iter [1428/3125], train_loss:0.210984\n",
      "Epoch [2/2], Iter [1429/3125], train_loss:0.153365\n",
      "Epoch [2/2], Iter [1430/3125], train_loss:0.161230\n",
      "Epoch [2/2], Iter [1431/3125], train_loss:0.153038\n",
      "Epoch [2/2], Iter [1432/3125], train_loss:0.165909\n",
      "Epoch [2/2], Iter [1433/3125], train_loss:0.180737\n",
      "Epoch [2/2], Iter [1434/3125], train_loss:0.137894\n",
      "Epoch [2/2], Iter [1435/3125], train_loss:0.168766\n",
      "Epoch [2/2], Iter [1436/3125], train_loss:0.154306\n",
      "Epoch [2/2], Iter [1437/3125], train_loss:0.145468\n",
      "Epoch [2/2], Iter [1438/3125], train_loss:0.153872\n",
      "Epoch [2/2], Iter [1439/3125], train_loss:0.160914\n",
      "Epoch [2/2], Iter [1440/3125], train_loss:0.177601\n",
      "Epoch [2/2], Iter [1441/3125], train_loss:0.140553\n",
      "Epoch [2/2], Iter [1442/3125], train_loss:0.152132\n",
      "Epoch [2/2], Iter [1443/3125], train_loss:0.167603\n",
      "Epoch [2/2], Iter [1444/3125], train_loss:0.160230\n",
      "Epoch [2/2], Iter [1445/3125], train_loss:0.166978\n",
      "Epoch [2/2], Iter [1446/3125], train_loss:0.154523\n",
      "Epoch [2/2], Iter [1447/3125], train_loss:0.150482\n",
      "Epoch [2/2], Iter [1448/3125], train_loss:0.176241\n",
      "Epoch [2/2], Iter [1449/3125], train_loss:0.169115\n",
      "Epoch [2/2], Iter [1450/3125], train_loss:0.162222\n",
      "Epoch [2/2], Iter [1451/3125], train_loss:0.165325\n",
      "Epoch [2/2], Iter [1452/3125], train_loss:0.174844\n",
      "Epoch [2/2], Iter [1453/3125], train_loss:0.157026\n",
      "Epoch [2/2], Iter [1454/3125], train_loss:0.190463\n",
      "Epoch [2/2], Iter [1455/3125], train_loss:0.151247\n",
      "Epoch [2/2], Iter [1456/3125], train_loss:0.175829\n",
      "Epoch [2/2], Iter [1457/3125], train_loss:0.149745\n",
      "Epoch [2/2], Iter [1458/3125], train_loss:0.170106\n",
      "Epoch [2/2], Iter [1459/3125], train_loss:0.153141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [1460/3125], train_loss:0.150076\n",
      "Epoch [2/2], Iter [1461/3125], train_loss:0.155543\n",
      "Epoch [2/2], Iter [1462/3125], train_loss:0.175568\n",
      "Epoch [2/2], Iter [1463/3125], train_loss:0.164598\n",
      "Epoch [2/2], Iter [1464/3125], train_loss:0.164032\n",
      "Epoch [2/2], Iter [1465/3125], train_loss:0.153218\n",
      "Epoch [2/2], Iter [1466/3125], train_loss:0.148877\n",
      "Epoch [2/2], Iter [1467/3125], train_loss:0.170388\n",
      "Epoch [2/2], Iter [1468/3125], train_loss:0.176349\n",
      "Epoch [2/2], Iter [1469/3125], train_loss:0.163880\n",
      "Epoch [2/2], Iter [1470/3125], train_loss:0.171145\n",
      "Epoch [2/2], Iter [1471/3125], train_loss:0.173416\n",
      "Epoch [2/2], Iter [1472/3125], train_loss:0.159819\n",
      "Epoch [2/2], Iter [1473/3125], train_loss:0.175912\n",
      "Epoch [2/2], Iter [1474/3125], train_loss:0.164334\n",
      "Epoch [2/2], Iter [1475/3125], train_loss:0.175759\n",
      "Epoch [2/2], Iter [1476/3125], train_loss:0.179214\n",
      "Epoch [2/2], Iter [1477/3125], train_loss:0.173877\n",
      "Epoch [2/2], Iter [1478/3125], train_loss:0.142671\n",
      "Epoch [2/2], Iter [1479/3125], train_loss:0.169050\n",
      "Epoch [2/2], Iter [1480/3125], train_loss:0.163624\n",
      "Epoch [2/2], Iter [1481/3125], train_loss:0.124397\n",
      "Epoch [2/2], Iter [1482/3125], train_loss:0.172139\n",
      "Epoch [2/2], Iter [1483/3125], train_loss:0.149972\n",
      "Epoch [2/2], Iter [1484/3125], train_loss:0.161740\n",
      "Epoch [2/2], Iter [1485/3125], train_loss:0.178524\n",
      "Epoch [2/2], Iter [1486/3125], train_loss:0.164522\n",
      "Epoch [2/2], Iter [1487/3125], train_loss:0.174727\n",
      "Epoch [2/2], Iter [1488/3125], train_loss:0.158368\n",
      "Epoch [2/2], Iter [1489/3125], train_loss:0.158420\n",
      "Epoch [2/2], Iter [1490/3125], train_loss:0.158298\n",
      "Epoch [2/2], Iter [1491/3125], train_loss:0.162050\n",
      "Epoch [2/2], Iter [1492/3125], train_loss:0.154621\n",
      "Epoch [2/2], Iter [1493/3125], train_loss:0.155056\n",
      "Epoch [2/2], Iter [1494/3125], train_loss:0.157235\n",
      "Epoch [2/2], Iter [1495/3125], train_loss:0.164029\n",
      "Epoch [2/2], Iter [1496/3125], train_loss:0.163754\n",
      "Epoch [2/2], Iter [1497/3125], train_loss:0.162731\n",
      "Epoch [2/2], Iter [1498/3125], train_loss:0.155964\n",
      "Epoch [2/2], Iter [1499/3125], train_loss:0.156570\n",
      "Epoch [2/2], Iter [1500/3125], train_loss:0.173360\n",
      "Epoch [2/2], Iter [1501/3125], train_loss:0.172767\n",
      "Epoch [2/2], Iter [1502/3125], train_loss:0.155064\n",
      "Epoch [2/2], Iter [1503/3125], train_loss:0.171995\n",
      "Epoch [2/2], Iter [1504/3125], train_loss:0.182060\n",
      "Epoch [2/2], Iter [1505/3125], train_loss:0.165437\n",
      "Epoch [2/2], Iter [1506/3125], train_loss:0.156042\n",
      "Epoch [2/2], Iter [1507/3125], train_loss:0.143774\n",
      "Epoch [2/2], Iter [1508/3125], train_loss:0.134632\n",
      "Epoch [2/2], Iter [1509/3125], train_loss:0.150117\n",
      "Epoch [2/2], Iter [1510/3125], train_loss:0.148472\n",
      "Epoch [2/2], Iter [1511/3125], train_loss:0.189553\n",
      "Epoch [2/2], Iter [1512/3125], train_loss:0.164381\n",
      "Epoch [2/2], Iter [1513/3125], train_loss:0.164976\n",
      "Epoch [2/2], Iter [1514/3125], train_loss:0.156565\n",
      "Epoch [2/2], Iter [1515/3125], train_loss:0.179596\n",
      "Epoch [2/2], Iter [1516/3125], train_loss:0.177745\n",
      "Epoch [2/2], Iter [1517/3125], train_loss:0.165961\n",
      "Epoch [2/2], Iter [1518/3125], train_loss:0.139753\n",
      "Epoch [2/2], Iter [1519/3125], train_loss:0.189203\n",
      "Epoch [2/2], Iter [1520/3125], train_loss:0.139068\n",
      "Epoch [2/2], Iter [1521/3125], train_loss:0.176371\n",
      "Epoch [2/2], Iter [1522/3125], train_loss:0.177996\n",
      "Epoch [2/2], Iter [1523/3125], train_loss:0.150551\n",
      "Epoch [2/2], Iter [1524/3125], train_loss:0.182913\n",
      "Epoch [2/2], Iter [1525/3125], train_loss:0.156942\n",
      "Epoch [2/2], Iter [1526/3125], train_loss:0.175098\n",
      "Epoch [2/2], Iter [1527/3125], train_loss:0.170003\n",
      "Epoch [2/2], Iter [1528/3125], train_loss:0.177167\n",
      "Epoch [2/2], Iter [1529/3125], train_loss:0.164812\n",
      "Epoch [2/2], Iter [1530/3125], train_loss:0.153913\n",
      "Epoch [2/2], Iter [1531/3125], train_loss:0.159904\n",
      "Epoch [2/2], Iter [1532/3125], train_loss:0.164228\n",
      "Epoch [2/2], Iter [1533/3125], train_loss:0.151631\n",
      "Epoch [2/2], Iter [1534/3125], train_loss:0.174893\n",
      "Epoch [2/2], Iter [1535/3125], train_loss:0.145256\n",
      "Epoch [2/2], Iter [1536/3125], train_loss:0.188057\n",
      "Epoch [2/2], Iter [1537/3125], train_loss:0.150733\n",
      "Epoch [2/2], Iter [1538/3125], train_loss:0.173468\n",
      "Epoch [2/2], Iter [1539/3125], train_loss:0.154280\n",
      "Epoch [2/2], Iter [1540/3125], train_loss:0.193638\n",
      "Epoch [2/2], Iter [1541/3125], train_loss:0.166240\n",
      "Epoch [2/2], Iter [1542/3125], train_loss:0.151932\n",
      "Epoch [2/2], Iter [1543/3125], train_loss:0.177635\n",
      "Epoch [2/2], Iter [1544/3125], train_loss:0.156271\n",
      "Epoch [2/2], Iter [1545/3125], train_loss:0.156302\n",
      "Epoch [2/2], Iter [1546/3125], train_loss:0.162147\n",
      "Epoch [2/2], Iter [1547/3125], train_loss:0.153694\n",
      "Epoch [2/2], Iter [1548/3125], train_loss:0.171542\n",
      "Epoch [2/2], Iter [1549/3125], train_loss:0.180775\n",
      "Epoch [2/2], Iter [1550/3125], train_loss:0.173611\n",
      "Epoch [2/2], Iter [1551/3125], train_loss:0.150828\n",
      "Epoch [2/2], Iter [1552/3125], train_loss:0.154307\n",
      "Epoch [2/2], Iter [1553/3125], train_loss:0.167718\n",
      "Epoch [2/2], Iter [1554/3125], train_loss:0.158616\n",
      "Epoch [2/2], Iter [1555/3125], train_loss:0.158968\n",
      "Epoch [2/2], Iter [1556/3125], train_loss:0.178772\n",
      "Epoch [2/2], Iter [1557/3125], train_loss:0.156037\n",
      "Epoch [2/2], Iter [1558/3125], train_loss:0.182647\n",
      "Epoch [2/2], Iter [1559/3125], train_loss:0.166879\n",
      "Epoch [2/2], Iter [1560/3125], train_loss:0.150276\n",
      "Epoch [2/2], Iter [1561/3125], train_loss:0.167408\n",
      "Epoch [2/2], Iter [1562/3125], train_loss:0.133499\n",
      "Epoch [2/2], Iter [1563/3125], train_loss:0.148331\n",
      "Epoch [2/2], Iter [1564/3125], train_loss:0.184361\n",
      "Epoch [2/2], Iter [1565/3125], train_loss:0.182212\n",
      "Epoch [2/2], Iter [1566/3125], train_loss:0.173345\n",
      "Epoch [2/2], Iter [1567/3125], train_loss:0.152805\n",
      "Epoch [2/2], Iter [1568/3125], train_loss:0.177073\n",
      "Epoch [2/2], Iter [1569/3125], train_loss:0.156461\n",
      "Epoch [2/2], Iter [1570/3125], train_loss:0.180138\n",
      "Epoch [2/2], Iter [1571/3125], train_loss:0.174113\n",
      "Epoch [2/2], Iter [1572/3125], train_loss:0.146895\n",
      "Epoch [2/2], Iter [1573/3125], train_loss:0.150620\n",
      "Epoch [2/2], Iter [1574/3125], train_loss:0.178030\n",
      "Epoch [2/2], Iter [1575/3125], train_loss:0.147083\n",
      "Epoch [2/2], Iter [1576/3125], train_loss:0.176818\n",
      "Epoch [2/2], Iter [1577/3125], train_loss:0.176552\n",
      "Epoch [2/2], Iter [1578/3125], train_loss:0.163424\n",
      "Epoch [2/2], Iter [1579/3125], train_loss:0.150029\n",
      "Epoch [2/2], Iter [1580/3125], train_loss:0.169055\n",
      "Epoch [2/2], Iter [1581/3125], train_loss:0.147174\n",
      "Epoch [2/2], Iter [1582/3125], train_loss:0.173712\n",
      "Epoch [2/2], Iter [1583/3125], train_loss:0.170797\n",
      "Epoch [2/2], Iter [1584/3125], train_loss:0.174648\n",
      "Epoch [2/2], Iter [1585/3125], train_loss:0.164838\n",
      "Epoch [2/2], Iter [1586/3125], train_loss:0.169103\n",
      "Epoch [2/2], Iter [1587/3125], train_loss:0.173731\n",
      "Epoch [2/2], Iter [1588/3125], train_loss:0.156027\n",
      "Epoch [2/2], Iter [1589/3125], train_loss:0.159374\n",
      "Epoch [2/2], Iter [1590/3125], train_loss:0.161394\n",
      "Epoch [2/2], Iter [1591/3125], train_loss:0.161930\n",
      "Epoch [2/2], Iter [1592/3125], train_loss:0.175878\n",
      "Epoch [2/2], Iter [1593/3125], train_loss:0.158797\n",
      "Epoch [2/2], Iter [1594/3125], train_loss:0.141702\n",
      "Epoch [2/2], Iter [1595/3125], train_loss:0.152575\n",
      "Epoch [2/2], Iter [1596/3125], train_loss:0.171752\n",
      "Epoch [2/2], Iter [1597/3125], train_loss:0.157716\n",
      "Epoch [2/2], Iter [1598/3125], train_loss:0.156043\n",
      "Epoch [2/2], Iter [1599/3125], train_loss:0.150653\n",
      "Epoch [2/2], Iter [1600/3125], train_loss:0.158851\n",
      "Epoch [2/2], Iter [1601/3125], train_loss:0.169789\n",
      "Epoch [2/2], Iter [1602/3125], train_loss:0.160451\n",
      "Epoch [2/2], Iter [1603/3125], train_loss:0.149276\n",
      "Epoch [2/2], Iter [1604/3125], train_loss:0.142822\n",
      "Epoch [2/2], Iter [1605/3125], train_loss:0.160311\n",
      "Epoch [2/2], Iter [1606/3125], train_loss:0.153576\n",
      "Epoch [2/2], Iter [1607/3125], train_loss:0.154003\n",
      "Epoch [2/2], Iter [1608/3125], train_loss:0.162005\n",
      "Epoch [2/2], Iter [1609/3125], train_loss:0.159320\n",
      "Epoch [2/2], Iter [1610/3125], train_loss:0.160449\n",
      "Epoch [2/2], Iter [1611/3125], train_loss:0.156940\n",
      "Epoch [2/2], Iter [1612/3125], train_loss:0.151442\n",
      "Epoch [2/2], Iter [1613/3125], train_loss:0.177216\n",
      "Epoch [2/2], Iter [1614/3125], train_loss:0.161342\n",
      "Epoch [2/2], Iter [1615/3125], train_loss:0.141846\n",
      "Epoch [2/2], Iter [1616/3125], train_loss:0.171737\n",
      "Epoch [2/2], Iter [1617/3125], train_loss:0.174684\n",
      "Epoch [2/2], Iter [1618/3125], train_loss:0.176624\n",
      "Epoch [2/2], Iter [1619/3125], train_loss:0.155852\n",
      "Epoch [2/2], Iter [1620/3125], train_loss:0.182513\n",
      "Epoch [2/2], Iter [1621/3125], train_loss:0.175660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [1622/3125], train_loss:0.183042\n",
      "Epoch [2/2], Iter [1623/3125], train_loss:0.161812\n",
      "Epoch [2/2], Iter [1624/3125], train_loss:0.174102\n",
      "Epoch [2/2], Iter [1625/3125], train_loss:0.158462\n",
      "Epoch [2/2], Iter [1626/3125], train_loss:0.179847\n",
      "Epoch [2/2], Iter [1627/3125], train_loss:0.163321\n",
      "Epoch [2/2], Iter [1628/3125], train_loss:0.168830\n",
      "Epoch [2/2], Iter [1629/3125], train_loss:0.167534\n",
      "Epoch [2/2], Iter [1630/3125], train_loss:0.163692\n",
      "Epoch [2/2], Iter [1631/3125], train_loss:0.156824\n",
      "Epoch [2/2], Iter [1632/3125], train_loss:0.169154\n",
      "Epoch [2/2], Iter [1633/3125], train_loss:0.152881\n",
      "Epoch [2/2], Iter [1634/3125], train_loss:0.176180\n",
      "Epoch [2/2], Iter [1635/3125], train_loss:0.149077\n",
      "Epoch [2/2], Iter [1636/3125], train_loss:0.141001\n",
      "Epoch [2/2], Iter [1637/3125], train_loss:0.168359\n",
      "Epoch [2/2], Iter [1638/3125], train_loss:0.187937\n",
      "Epoch [2/2], Iter [1639/3125], train_loss:0.138105\n",
      "Epoch [2/2], Iter [1640/3125], train_loss:0.174584\n",
      "Epoch [2/2], Iter [1641/3125], train_loss:0.165225\n",
      "Epoch [2/2], Iter [1642/3125], train_loss:0.158107\n",
      "Epoch [2/2], Iter [1643/3125], train_loss:0.156038\n",
      "Epoch [2/2], Iter [1644/3125], train_loss:0.165930\n",
      "Epoch [2/2], Iter [1645/3125], train_loss:0.157393\n",
      "Epoch [2/2], Iter [1646/3125], train_loss:0.162583\n",
      "Epoch [2/2], Iter [1647/3125], train_loss:0.163302\n",
      "Epoch [2/2], Iter [1648/3125], train_loss:0.162230\n",
      "Epoch [2/2], Iter [1649/3125], train_loss:0.164453\n",
      "Epoch [2/2], Iter [1650/3125], train_loss:0.179386\n",
      "Epoch [2/2], Iter [1651/3125], train_loss:0.170097\n",
      "Epoch [2/2], Iter [1652/3125], train_loss:0.150762\n",
      "Epoch [2/2], Iter [1653/3125], train_loss:0.158980\n",
      "Epoch [2/2], Iter [1654/3125], train_loss:0.151346\n",
      "Epoch [2/2], Iter [1655/3125], train_loss:0.174953\n",
      "Epoch [2/2], Iter [1656/3125], train_loss:0.174421\n",
      "Epoch [2/2], Iter [1657/3125], train_loss:0.170573\n",
      "Epoch [2/2], Iter [1658/3125], train_loss:0.153967\n",
      "Epoch [2/2], Iter [1659/3125], train_loss:0.151942\n",
      "Epoch [2/2], Iter [1660/3125], train_loss:0.152918\n",
      "Epoch [2/2], Iter [1661/3125], train_loss:0.165101\n",
      "Epoch [2/2], Iter [1662/3125], train_loss:0.188826\n",
      "Epoch [2/2], Iter [1663/3125], train_loss:0.134563\n",
      "Epoch [2/2], Iter [1664/3125], train_loss:0.154033\n",
      "Epoch [2/2], Iter [1665/3125], train_loss:0.175620\n",
      "Epoch [2/2], Iter [1666/3125], train_loss:0.180201\n",
      "Epoch [2/2], Iter [1667/3125], train_loss:0.140200\n",
      "Epoch [2/2], Iter [1668/3125], train_loss:0.166890\n",
      "Epoch [2/2], Iter [1669/3125], train_loss:0.176319\n",
      "Epoch [2/2], Iter [1670/3125], train_loss:0.158752\n",
      "Epoch [2/2], Iter [1671/3125], train_loss:0.184395\n",
      "Epoch [2/2], Iter [1672/3125], train_loss:0.174531\n",
      "Epoch [2/2], Iter [1673/3125], train_loss:0.173302\n",
      "Epoch [2/2], Iter [1674/3125], train_loss:0.158318\n",
      "Epoch [2/2], Iter [1675/3125], train_loss:0.173408\n",
      "Epoch [2/2], Iter [1676/3125], train_loss:0.155547\n",
      "Epoch [2/2], Iter [1677/3125], train_loss:0.176653\n",
      "Epoch [2/2], Iter [1678/3125], train_loss:0.158884\n",
      "Epoch [2/2], Iter [1679/3125], train_loss:0.165405\n",
      "Epoch [2/2], Iter [1680/3125], train_loss:0.182648\n",
      "Epoch [2/2], Iter [1681/3125], train_loss:0.154117\n",
      "Epoch [2/2], Iter [1682/3125], train_loss:0.163982\n",
      "Epoch [2/2], Iter [1683/3125], train_loss:0.186308\n",
      "Epoch [2/2], Iter [1684/3125], train_loss:0.169440\n",
      "Epoch [2/2], Iter [1685/3125], train_loss:0.191119\n",
      "Epoch [2/2], Iter [1686/3125], train_loss:0.170567\n",
      "Epoch [2/2], Iter [1687/3125], train_loss:0.163304\n",
      "Epoch [2/2], Iter [1688/3125], train_loss:0.164420\n",
      "Epoch [2/2], Iter [1689/3125], train_loss:0.154954\n",
      "Epoch [2/2], Iter [1690/3125], train_loss:0.158497\n",
      "Epoch [2/2], Iter [1691/3125], train_loss:0.167226\n",
      "Epoch [2/2], Iter [1692/3125], train_loss:0.169470\n",
      "Epoch [2/2], Iter [1693/3125], train_loss:0.164990\n",
      "Epoch [2/2], Iter [1694/3125], train_loss:0.173156\n",
      "Epoch [2/2], Iter [1695/3125], train_loss:0.166241\n",
      "Epoch [2/2], Iter [1696/3125], train_loss:0.164385\n",
      "Epoch [2/2], Iter [1697/3125], train_loss:0.170838\n",
      "Epoch [2/2], Iter [1698/3125], train_loss:0.145337\n",
      "Epoch [2/2], Iter [1699/3125], train_loss:0.149979\n",
      "Epoch [2/2], Iter [1700/3125], train_loss:0.164938\n",
      "Epoch [2/2], Iter [1701/3125], train_loss:0.155440\n",
      "Epoch [2/2], Iter [1702/3125], train_loss:0.164277\n",
      "Epoch [2/2], Iter [1703/3125], train_loss:0.181247\n",
      "Epoch [2/2], Iter [1704/3125], train_loss:0.151095\n",
      "Epoch [2/2], Iter [1705/3125], train_loss:0.150754\n",
      "Epoch [2/2], Iter [1706/3125], train_loss:0.168932\n",
      "Epoch [2/2], Iter [1707/3125], train_loss:0.157480\n",
      "Epoch [2/2], Iter [1708/3125], train_loss:0.173538\n",
      "Epoch [2/2], Iter [1709/3125], train_loss:0.156893\n",
      "Epoch [2/2], Iter [1710/3125], train_loss:0.169468\n",
      "Epoch [2/2], Iter [1711/3125], train_loss:0.175929\n",
      "Epoch [2/2], Iter [1712/3125], train_loss:0.144938\n",
      "Epoch [2/2], Iter [1713/3125], train_loss:0.170830\n",
      "Epoch [2/2], Iter [1714/3125], train_loss:0.151004\n",
      "Epoch [2/2], Iter [1715/3125], train_loss:0.155489\n",
      "Epoch [2/2], Iter [1716/3125], train_loss:0.131155\n",
      "Epoch [2/2], Iter [1717/3125], train_loss:0.176367\n",
      "Epoch [2/2], Iter [1718/3125], train_loss:0.168629\n",
      "Epoch [2/2], Iter [1719/3125], train_loss:0.142866\n",
      "Epoch [2/2], Iter [1720/3125], train_loss:0.164650\n",
      "Epoch [2/2], Iter [1721/3125], train_loss:0.169023\n",
      "Epoch [2/2], Iter [1722/3125], train_loss:0.159135\n",
      "Epoch [2/2], Iter [1723/3125], train_loss:0.137995\n",
      "Epoch [2/2], Iter [1724/3125], train_loss:0.156657\n",
      "Epoch [2/2], Iter [1725/3125], train_loss:0.160624\n",
      "Epoch [2/2], Iter [1726/3125], train_loss:0.153684\n",
      "Epoch [2/2], Iter [1727/3125], train_loss:0.154906\n",
      "Epoch [2/2], Iter [1728/3125], train_loss:0.166444\n",
      "Epoch [2/2], Iter [1729/3125], train_loss:0.152205\n",
      "Epoch [2/2], Iter [1730/3125], train_loss:0.164705\n",
      "Epoch [2/2], Iter [1731/3125], train_loss:0.145863\n",
      "Epoch [2/2], Iter [1732/3125], train_loss:0.167643\n",
      "Epoch [2/2], Iter [1733/3125], train_loss:0.159026\n",
      "Epoch [2/2], Iter [1734/3125], train_loss:0.168009\n",
      "Epoch [2/2], Iter [1735/3125], train_loss:0.187538\n",
      "Epoch [2/2], Iter [1736/3125], train_loss:0.155958\n",
      "Epoch [2/2], Iter [1737/3125], train_loss:0.177401\n",
      "Epoch [2/2], Iter [1738/3125], train_loss:0.150959\n",
      "Epoch [2/2], Iter [1739/3125], train_loss:0.170937\n",
      "Epoch [2/2], Iter [1740/3125], train_loss:0.189211\n",
      "Epoch [2/2], Iter [1741/3125], train_loss:0.160411\n",
      "Epoch [2/2], Iter [1742/3125], train_loss:0.171641\n",
      "Epoch [2/2], Iter [1743/3125], train_loss:0.177642\n",
      "Epoch [2/2], Iter [1744/3125], train_loss:0.154779\n",
      "Epoch [2/2], Iter [1745/3125], train_loss:0.184219\n",
      "Epoch [2/2], Iter [1746/3125], train_loss:0.161954\n",
      "Epoch [2/2], Iter [1747/3125], train_loss:0.158577\n",
      "Epoch [2/2], Iter [1748/3125], train_loss:0.179367\n",
      "Epoch [2/2], Iter [1749/3125], train_loss:0.174863\n",
      "Epoch [2/2], Iter [1750/3125], train_loss:0.151088\n",
      "Epoch [2/2], Iter [1751/3125], train_loss:0.156479\n",
      "Epoch [2/2], Iter [1752/3125], train_loss:0.166301\n",
      "Epoch [2/2], Iter [1753/3125], train_loss:0.170395\n",
      "Epoch [2/2], Iter [1754/3125], train_loss:0.161548\n",
      "Epoch [2/2], Iter [1755/3125], train_loss:0.158841\n",
      "Epoch [2/2], Iter [1756/3125], train_loss:0.155362\n",
      "Epoch [2/2], Iter [1757/3125], train_loss:0.168355\n",
      "Epoch [2/2], Iter [1758/3125], train_loss:0.161983\n",
      "Epoch [2/2], Iter [1759/3125], train_loss:0.153512\n",
      "Epoch [2/2], Iter [1760/3125], train_loss:0.149586\n",
      "Epoch [2/2], Iter [1761/3125], train_loss:0.182413\n",
      "Epoch [2/2], Iter [1762/3125], train_loss:0.169026\n",
      "Epoch [2/2], Iter [1763/3125], train_loss:0.160726\n",
      "Epoch [2/2], Iter [1764/3125], train_loss:0.162798\n",
      "Epoch [2/2], Iter [1765/3125], train_loss:0.182664\n",
      "Epoch [2/2], Iter [1766/3125], train_loss:0.164735\n",
      "Epoch [2/2], Iter [1767/3125], train_loss:0.152154\n",
      "Epoch [2/2], Iter [1768/3125], train_loss:0.169890\n",
      "Epoch [2/2], Iter [1769/3125], train_loss:0.153528\n",
      "Epoch [2/2], Iter [1770/3125], train_loss:0.157118\n",
      "Epoch [2/2], Iter [1771/3125], train_loss:0.162324\n",
      "Epoch [2/2], Iter [1772/3125], train_loss:0.153705\n",
      "Epoch [2/2], Iter [1773/3125], train_loss:0.161531\n",
      "Epoch [2/2], Iter [1774/3125], train_loss:0.163773\n",
      "Epoch [2/2], Iter [1775/3125], train_loss:0.152823\n",
      "Epoch [2/2], Iter [1776/3125], train_loss:0.156777\n",
      "Epoch [2/2], Iter [1777/3125], train_loss:0.163406\n",
      "Epoch [2/2], Iter [1778/3125], train_loss:0.153583\n",
      "Epoch [2/2], Iter [1779/3125], train_loss:0.149578\n",
      "Epoch [2/2], Iter [1780/3125], train_loss:0.153773\n",
      "Epoch [2/2], Iter [1781/3125], train_loss:0.198961\n",
      "Epoch [2/2], Iter [1782/3125], train_loss:0.179213\n",
      "Epoch [2/2], Iter [1783/3125], train_loss:0.142646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [1784/3125], train_loss:0.165732\n",
      "Epoch [2/2], Iter [1785/3125], train_loss:0.156346\n",
      "Epoch [2/2], Iter [1786/3125], train_loss:0.182671\n",
      "Epoch [2/2], Iter [1787/3125], train_loss:0.180120\n",
      "Epoch [2/2], Iter [1788/3125], train_loss:0.138661\n",
      "Epoch [2/2], Iter [1789/3125], train_loss:0.169887\n",
      "Epoch [2/2], Iter [1790/3125], train_loss:0.143717\n",
      "Epoch [2/2], Iter [1791/3125], train_loss:0.146461\n",
      "Epoch [2/2], Iter [1792/3125], train_loss:0.154155\n",
      "Epoch [2/2], Iter [1793/3125], train_loss:0.153876\n",
      "Epoch [2/2], Iter [1794/3125], train_loss:0.157684\n",
      "Epoch [2/2], Iter [1795/3125], train_loss:0.155527\n",
      "Epoch [2/2], Iter [1796/3125], train_loss:0.178476\n",
      "Epoch [2/2], Iter [1797/3125], train_loss:0.155293\n",
      "Epoch [2/2], Iter [1798/3125], train_loss:0.153590\n",
      "Epoch [2/2], Iter [1799/3125], train_loss:0.170735\n",
      "Epoch [2/2], Iter [1800/3125], train_loss:0.165564\n",
      "Epoch [2/2], Iter [1801/3125], train_loss:0.158861\n",
      "Epoch [2/2], Iter [1802/3125], train_loss:0.158139\n",
      "Epoch [2/2], Iter [1803/3125], train_loss:0.150116\n",
      "Epoch [2/2], Iter [1804/3125], train_loss:0.172332\n",
      "Epoch [2/2], Iter [1805/3125], train_loss:0.157270\n",
      "Epoch [2/2], Iter [1806/3125], train_loss:0.164020\n",
      "Epoch [2/2], Iter [1807/3125], train_loss:0.172421\n",
      "Epoch [2/2], Iter [1808/3125], train_loss:0.161917\n",
      "Epoch [2/2], Iter [1809/3125], train_loss:0.171783\n",
      "Epoch [2/2], Iter [1810/3125], train_loss:0.187792\n",
      "Epoch [2/2], Iter [1811/3125], train_loss:0.161928\n",
      "Epoch [2/2], Iter [1812/3125], train_loss:0.167572\n",
      "Epoch [2/2], Iter [1813/3125], train_loss:0.178536\n",
      "Epoch [2/2], Iter [1814/3125], train_loss:0.151012\n",
      "Epoch [2/2], Iter [1815/3125], train_loss:0.147008\n",
      "Epoch [2/2], Iter [1816/3125], train_loss:0.162467\n",
      "Epoch [2/2], Iter [1817/3125], train_loss:0.158529\n",
      "Epoch [2/2], Iter [1818/3125], train_loss:0.176594\n",
      "Epoch [2/2], Iter [1819/3125], train_loss:0.179330\n",
      "Epoch [2/2], Iter [1820/3125], train_loss:0.169498\n",
      "Epoch [2/2], Iter [1821/3125], train_loss:0.191122\n",
      "Epoch [2/2], Iter [1822/3125], train_loss:0.157868\n",
      "Epoch [2/2], Iter [1823/3125], train_loss:0.179268\n",
      "Epoch [2/2], Iter [1824/3125], train_loss:0.144822\n",
      "Epoch [2/2], Iter [1825/3125], train_loss:0.147100\n",
      "Epoch [2/2], Iter [1826/3125], train_loss:0.147429\n",
      "Epoch [2/2], Iter [1827/3125], train_loss:0.162331\n",
      "Epoch [2/2], Iter [1828/3125], train_loss:0.163165\n",
      "Epoch [2/2], Iter [1829/3125], train_loss:0.157384\n",
      "Epoch [2/2], Iter [1830/3125], train_loss:0.142142\n",
      "Epoch [2/2], Iter [1831/3125], train_loss:0.159299\n",
      "Epoch [2/2], Iter [1832/3125], train_loss:0.172134\n",
      "Epoch [2/2], Iter [1833/3125], train_loss:0.141858\n",
      "Epoch [2/2], Iter [1834/3125], train_loss:0.157944\n",
      "Epoch [2/2], Iter [1835/3125], train_loss:0.158656\n",
      "Epoch [2/2], Iter [1836/3125], train_loss:0.161304\n",
      "Epoch [2/2], Iter [1837/3125], train_loss:0.156902\n",
      "Epoch [2/2], Iter [1838/3125], train_loss:0.161900\n",
      "Epoch [2/2], Iter [1839/3125], train_loss:0.193456\n",
      "Epoch [2/2], Iter [1840/3125], train_loss:0.166382\n",
      "Epoch [2/2], Iter [1841/3125], train_loss:0.156756\n",
      "Epoch [2/2], Iter [1842/3125], train_loss:0.152251\n",
      "Epoch [2/2], Iter [1843/3125], train_loss:0.156093\n",
      "Epoch [2/2], Iter [1844/3125], train_loss:0.158821\n",
      "Epoch [2/2], Iter [1845/3125], train_loss:0.175326\n",
      "Epoch [2/2], Iter [1846/3125], train_loss:0.159824\n",
      "Epoch [2/2], Iter [1847/3125], train_loss:0.152216\n",
      "Epoch [2/2], Iter [1848/3125], train_loss:0.178006\n",
      "Epoch [2/2], Iter [1849/3125], train_loss:0.175719\n",
      "Epoch [2/2], Iter [1850/3125], train_loss:0.184333\n",
      "Epoch [2/2], Iter [1851/3125], train_loss:0.168155\n",
      "Epoch [2/2], Iter [1852/3125], train_loss:0.172759\n",
      "Epoch [2/2], Iter [1853/3125], train_loss:0.164556\n",
      "Epoch [2/2], Iter [1854/3125], train_loss:0.184463\n",
      "Epoch [2/2], Iter [1855/3125], train_loss:0.171237\n",
      "Epoch [2/2], Iter [1856/3125], train_loss:0.163145\n",
      "Epoch [2/2], Iter [1857/3125], train_loss:0.139911\n",
      "Epoch [2/2], Iter [1858/3125], train_loss:0.162202\n",
      "Epoch [2/2], Iter [1859/3125], train_loss:0.173948\n",
      "Epoch [2/2], Iter [1860/3125], train_loss:0.160033\n",
      "Epoch [2/2], Iter [1861/3125], train_loss:0.154245\n",
      "Epoch [2/2], Iter [1862/3125], train_loss:0.159419\n",
      "Epoch [2/2], Iter [1863/3125], train_loss:0.161766\n",
      "Epoch [2/2], Iter [1864/3125], train_loss:0.142233\n",
      "Epoch [2/2], Iter [1865/3125], train_loss:0.156243\n",
      "Epoch [2/2], Iter [1866/3125], train_loss:0.148887\n",
      "Epoch [2/2], Iter [1867/3125], train_loss:0.150069\n",
      "Epoch [2/2], Iter [1868/3125], train_loss:0.171475\n",
      "Epoch [2/2], Iter [1869/3125], train_loss:0.158728\n",
      "Epoch [2/2], Iter [1870/3125], train_loss:0.167767\n",
      "Epoch [2/2], Iter [1871/3125], train_loss:0.160463\n",
      "Epoch [2/2], Iter [1872/3125], train_loss:0.152658\n",
      "Epoch [2/2], Iter [1873/3125], train_loss:0.180189\n",
      "Epoch [2/2], Iter [1874/3125], train_loss:0.139144\n",
      "Epoch [2/2], Iter [1875/3125], train_loss:0.168600\n",
      "Epoch [2/2], Iter [1876/3125], train_loss:0.153786\n",
      "Epoch [2/2], Iter [1877/3125], train_loss:0.147320\n",
      "Epoch [2/2], Iter [1878/3125], train_loss:0.144383\n",
      "Epoch [2/2], Iter [1879/3125], train_loss:0.202018\n",
      "Epoch [2/2], Iter [1880/3125], train_loss:0.152897\n",
      "Epoch [2/2], Iter [1881/3125], train_loss:0.161939\n",
      "Epoch [2/2], Iter [1882/3125], train_loss:0.155497\n",
      "Epoch [2/2], Iter [1883/3125], train_loss:0.158795\n",
      "Epoch [2/2], Iter [1884/3125], train_loss:0.147537\n",
      "Epoch [2/2], Iter [1885/3125], train_loss:0.179441\n",
      "Epoch [2/2], Iter [1886/3125], train_loss:0.136867\n",
      "Epoch [2/2], Iter [1887/3125], train_loss:0.142624\n",
      "Epoch [2/2], Iter [1888/3125], train_loss:0.159405\n",
      "Epoch [2/2], Iter [1889/3125], train_loss:0.155485\n",
      "Epoch [2/2], Iter [1890/3125], train_loss:0.155945\n",
      "Epoch [2/2], Iter [1891/3125], train_loss:0.172686\n",
      "Epoch [2/2], Iter [1892/3125], train_loss:0.166272\n",
      "Epoch [2/2], Iter [1893/3125], train_loss:0.160618\n",
      "Epoch [2/2], Iter [1894/3125], train_loss:0.174494\n",
      "Epoch [2/2], Iter [1895/3125], train_loss:0.178385\n",
      "Epoch [2/2], Iter [1896/3125], train_loss:0.161723\n",
      "Epoch [2/2], Iter [1897/3125], train_loss:0.171826\n",
      "Epoch [2/2], Iter [1898/3125], train_loss:0.169633\n",
      "Epoch [2/2], Iter [1899/3125], train_loss:0.153027\n",
      "Epoch [2/2], Iter [1900/3125], train_loss:0.167125\n",
      "Epoch [2/2], Iter [1901/3125], train_loss:0.166883\n",
      "Epoch [2/2], Iter [1902/3125], train_loss:0.158857\n",
      "Epoch [2/2], Iter [1903/3125], train_loss:0.160501\n",
      "Epoch [2/2], Iter [1904/3125], train_loss:0.169766\n",
      "Epoch [2/2], Iter [1905/3125], train_loss:0.177153\n",
      "Epoch [2/2], Iter [1906/3125], train_loss:0.166280\n",
      "Epoch [2/2], Iter [1907/3125], train_loss:0.144895\n",
      "Epoch [2/2], Iter [1908/3125], train_loss:0.166454\n",
      "Epoch [2/2], Iter [1909/3125], train_loss:0.148849\n",
      "Epoch [2/2], Iter [1910/3125], train_loss:0.146370\n",
      "Epoch [2/2], Iter [1911/3125], train_loss:0.153806\n",
      "Epoch [2/2], Iter [1912/3125], train_loss:0.177768\n",
      "Epoch [2/2], Iter [1913/3125], train_loss:0.158340\n",
      "Epoch [2/2], Iter [1914/3125], train_loss:0.160970\n",
      "Epoch [2/2], Iter [1915/3125], train_loss:0.175725\n",
      "Epoch [2/2], Iter [1916/3125], train_loss:0.174795\n",
      "Epoch [2/2], Iter [1917/3125], train_loss:0.166120\n",
      "Epoch [2/2], Iter [1918/3125], train_loss:0.159042\n",
      "Epoch [2/2], Iter [1919/3125], train_loss:0.158724\n",
      "Epoch [2/2], Iter [1920/3125], train_loss:0.176892\n",
      "Epoch [2/2], Iter [1921/3125], train_loss:0.161805\n",
      "Epoch [2/2], Iter [1922/3125], train_loss:0.152278\n",
      "Epoch [2/2], Iter [1923/3125], train_loss:0.156059\n",
      "Epoch [2/2], Iter [1924/3125], train_loss:0.158039\n",
      "Epoch [2/2], Iter [1925/3125], train_loss:0.174717\n",
      "Epoch [2/2], Iter [1926/3125], train_loss:0.172393\n",
      "Epoch [2/2], Iter [1927/3125], train_loss:0.151700\n",
      "Epoch [2/2], Iter [1928/3125], train_loss:0.173616\n",
      "Epoch [2/2], Iter [1929/3125], train_loss:0.177794\n",
      "Epoch [2/2], Iter [1930/3125], train_loss:0.128388\n",
      "Epoch [2/2], Iter [1931/3125], train_loss:0.155016\n",
      "Epoch [2/2], Iter [1932/3125], train_loss:0.174339\n",
      "Epoch [2/2], Iter [1933/3125], train_loss:0.146059\n",
      "Epoch [2/2], Iter [1934/3125], train_loss:0.158222\n",
      "Epoch [2/2], Iter [1935/3125], train_loss:0.164874\n",
      "Epoch [2/2], Iter [1936/3125], train_loss:0.164384\n",
      "Epoch [2/2], Iter [1937/3125], train_loss:0.161730\n",
      "Epoch [2/2], Iter [1938/3125], train_loss:0.159183\n",
      "Epoch [2/2], Iter [1939/3125], train_loss:0.167060\n",
      "Epoch [2/2], Iter [1940/3125], train_loss:0.145759\n",
      "Epoch [2/2], Iter [1941/3125], train_loss:0.168441\n",
      "Epoch [2/2], Iter [1942/3125], train_loss:0.163606\n",
      "Epoch [2/2], Iter [1943/3125], train_loss:0.153537\n",
      "Epoch [2/2], Iter [1944/3125], train_loss:0.157014\n",
      "Epoch [2/2], Iter [1945/3125], train_loss:0.188883\n",
      "Epoch [2/2], Iter [1946/3125], train_loss:0.165493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [1947/3125], train_loss:0.180028\n",
      "Epoch [2/2], Iter [1948/3125], train_loss:0.161596\n",
      "Epoch [2/2], Iter [1949/3125], train_loss:0.144876\n",
      "Epoch [2/2], Iter [1950/3125], train_loss:0.154152\n",
      "Epoch [2/2], Iter [1951/3125], train_loss:0.148542\n",
      "Epoch [2/2], Iter [1952/3125], train_loss:0.158239\n",
      "Epoch [2/2], Iter [1953/3125], train_loss:0.175057\n",
      "Epoch [2/2], Iter [1954/3125], train_loss:0.167876\n",
      "Epoch [2/2], Iter [1955/3125], train_loss:0.183877\n",
      "Epoch [2/2], Iter [1956/3125], train_loss:0.164742\n",
      "Epoch [2/2], Iter [1957/3125], train_loss:0.171079\n",
      "Epoch [2/2], Iter [1958/3125], train_loss:0.173020\n",
      "Epoch [2/2], Iter [1959/3125], train_loss:0.176229\n",
      "Epoch [2/2], Iter [1960/3125], train_loss:0.172803\n",
      "Epoch [2/2], Iter [1961/3125], train_loss:0.171086\n",
      "Epoch [2/2], Iter [1962/3125], train_loss:0.164022\n",
      "Epoch [2/2], Iter [1963/3125], train_loss:0.149423\n",
      "Epoch [2/2], Iter [1964/3125], train_loss:0.148664\n",
      "Epoch [2/2], Iter [1965/3125], train_loss:0.163915\n",
      "Epoch [2/2], Iter [1966/3125], train_loss:0.144695\n",
      "Epoch [2/2], Iter [1967/3125], train_loss:0.164735\n",
      "Epoch [2/2], Iter [1968/3125], train_loss:0.149334\n",
      "Epoch [2/2], Iter [1969/3125], train_loss:0.176195\n",
      "Epoch [2/2], Iter [1970/3125], train_loss:0.145745\n",
      "Epoch [2/2], Iter [1971/3125], train_loss:0.154337\n",
      "Epoch [2/2], Iter [1972/3125], train_loss:0.182863\n",
      "Epoch [2/2], Iter [1973/3125], train_loss:0.168520\n",
      "Epoch [2/2], Iter [1974/3125], train_loss:0.133800\n",
      "Epoch [2/2], Iter [1975/3125], train_loss:0.162926\n",
      "Epoch [2/2], Iter [1976/3125], train_loss:0.183089\n",
      "Epoch [2/2], Iter [1977/3125], train_loss:0.186240\n",
      "Epoch [2/2], Iter [1978/3125], train_loss:0.155863\n",
      "Epoch [2/2], Iter [1979/3125], train_loss:0.139210\n",
      "Epoch [2/2], Iter [1980/3125], train_loss:0.153233\n",
      "Epoch [2/2], Iter [1981/3125], train_loss:0.161005\n",
      "Epoch [2/2], Iter [1982/3125], train_loss:0.165533\n",
      "Epoch [2/2], Iter [1983/3125], train_loss:0.160974\n",
      "Epoch [2/2], Iter [1984/3125], train_loss:0.163204\n",
      "Epoch [2/2], Iter [1985/3125], train_loss:0.168157\n",
      "Epoch [2/2], Iter [1986/3125], train_loss:0.156440\n",
      "Epoch [2/2], Iter [1987/3125], train_loss:0.161103\n",
      "Epoch [2/2], Iter [1988/3125], train_loss:0.185964\n",
      "Epoch [2/2], Iter [1989/3125], train_loss:0.179274\n",
      "Epoch [2/2], Iter [1990/3125], train_loss:0.169398\n",
      "Epoch [2/2], Iter [1991/3125], train_loss:0.166009\n",
      "Epoch [2/2], Iter [1992/3125], train_loss:0.153788\n",
      "Epoch [2/2], Iter [1993/3125], train_loss:0.180169\n",
      "Epoch [2/2], Iter [1994/3125], train_loss:0.181081\n",
      "Epoch [2/2], Iter [1995/3125], train_loss:0.165236\n",
      "Epoch [2/2], Iter [1996/3125], train_loss:0.176801\n",
      "Epoch [2/2], Iter [1997/3125], train_loss:0.154971\n",
      "Epoch [2/2], Iter [1998/3125], train_loss:0.150749\n",
      "Epoch [2/2], Iter [1999/3125], train_loss:0.165702\n",
      "Epoch [2/2], Iter [2000/3125], train_loss:0.172721\n",
      "Epoch [2/2], Iter [2001/3125], train_loss:0.176618\n",
      "Epoch [2/2], Iter [2002/3125], train_loss:0.161856\n",
      "Epoch [2/2], Iter [2003/3125], train_loss:0.150962\n",
      "Epoch [2/2], Iter [2004/3125], train_loss:0.149772\n",
      "Epoch [2/2], Iter [2005/3125], train_loss:0.172245\n",
      "Epoch [2/2], Iter [2006/3125], train_loss:0.141880\n",
      "Epoch [2/2], Iter [2007/3125], train_loss:0.154477\n",
      "Epoch [2/2], Iter [2008/3125], train_loss:0.159015\n",
      "Epoch [2/2], Iter [2009/3125], train_loss:0.167600\n",
      "Epoch [2/2], Iter [2010/3125], train_loss:0.144316\n",
      "Epoch [2/2], Iter [2011/3125], train_loss:0.156956\n",
      "Epoch [2/2], Iter [2012/3125], train_loss:0.148177\n",
      "Epoch [2/2], Iter [2013/3125], train_loss:0.166715\n",
      "Epoch [2/2], Iter [2014/3125], train_loss:0.159968\n",
      "Epoch [2/2], Iter [2015/3125], train_loss:0.154341\n",
      "Epoch [2/2], Iter [2016/3125], train_loss:0.170865\n",
      "Epoch [2/2], Iter [2017/3125], train_loss:0.171444\n",
      "Epoch [2/2], Iter [2018/3125], train_loss:0.177334\n",
      "Epoch [2/2], Iter [2019/3125], train_loss:0.164350\n",
      "Epoch [2/2], Iter [2020/3125], train_loss:0.144198\n",
      "Epoch [2/2], Iter [2021/3125], train_loss:0.149919\n",
      "Epoch [2/2], Iter [2022/3125], train_loss:0.170717\n",
      "Epoch [2/2], Iter [2023/3125], train_loss:0.157067\n",
      "Epoch [2/2], Iter [2024/3125], train_loss:0.141565\n",
      "Epoch [2/2], Iter [2025/3125], train_loss:0.165010\n",
      "Epoch [2/2], Iter [2026/3125], train_loss:0.155903\n",
      "Epoch [2/2], Iter [2027/3125], train_loss:0.135687\n",
      "Epoch [2/2], Iter [2028/3125], train_loss:0.160885\n",
      "Epoch [2/2], Iter [2029/3125], train_loss:0.163240\n",
      "Epoch [2/2], Iter [2030/3125], train_loss:0.181522\n",
      "Epoch [2/2], Iter [2031/3125], train_loss:0.171928\n",
      "Epoch [2/2], Iter [2032/3125], train_loss:0.140798\n",
      "Epoch [2/2], Iter [2033/3125], train_loss:0.161923\n",
      "Epoch [2/2], Iter [2034/3125], train_loss:0.167764\n",
      "Epoch [2/2], Iter [2035/3125], train_loss:0.166693\n",
      "Epoch [2/2], Iter [2036/3125], train_loss:0.159257\n",
      "Epoch [2/2], Iter [2037/3125], train_loss:0.132273\n",
      "Epoch [2/2], Iter [2038/3125], train_loss:0.154843\n",
      "Epoch [2/2], Iter [2039/3125], train_loss:0.160001\n",
      "Epoch [2/2], Iter [2040/3125], train_loss:0.169370\n",
      "Epoch [2/2], Iter [2041/3125], train_loss:0.137417\n",
      "Epoch [2/2], Iter [2042/3125], train_loss:0.153828\n",
      "Epoch [2/2], Iter [2043/3125], train_loss:0.157937\n",
      "Epoch [2/2], Iter [2044/3125], train_loss:0.158066\n",
      "Epoch [2/2], Iter [2045/3125], train_loss:0.151211\n",
      "Epoch [2/2], Iter [2046/3125], train_loss:0.152202\n",
      "Epoch [2/2], Iter [2047/3125], train_loss:0.169663\n",
      "Epoch [2/2], Iter [2048/3125], train_loss:0.179915\n",
      "Epoch [2/2], Iter [2049/3125], train_loss:0.159464\n",
      "Epoch [2/2], Iter [2050/3125], train_loss:0.164572\n",
      "Epoch [2/2], Iter [2051/3125], train_loss:0.172964\n",
      "Epoch [2/2], Iter [2052/3125], train_loss:0.163196\n",
      "Epoch [2/2], Iter [2053/3125], train_loss:0.152330\n",
      "Epoch [2/2], Iter [2054/3125], train_loss:0.171318\n",
      "Epoch [2/2], Iter [2055/3125], train_loss:0.124172\n",
      "Epoch [2/2], Iter [2056/3125], train_loss:0.167775\n",
      "Epoch [2/2], Iter [2057/3125], train_loss:0.157939\n",
      "Epoch [2/2], Iter [2058/3125], train_loss:0.167246\n",
      "Epoch [2/2], Iter [2059/3125], train_loss:0.153001\n",
      "Epoch [2/2], Iter [2060/3125], train_loss:0.166760\n",
      "Epoch [2/2], Iter [2061/3125], train_loss:0.159746\n",
      "Epoch [2/2], Iter [2062/3125], train_loss:0.176237\n",
      "Epoch [2/2], Iter [2063/3125], train_loss:0.163693\n",
      "Epoch [2/2], Iter [2064/3125], train_loss:0.140758\n",
      "Epoch [2/2], Iter [2065/3125], train_loss:0.164871\n",
      "Epoch [2/2], Iter [2066/3125], train_loss:0.153728\n",
      "Epoch [2/2], Iter [2067/3125], train_loss:0.172908\n",
      "Epoch [2/2], Iter [2068/3125], train_loss:0.168809\n",
      "Epoch [2/2], Iter [2069/3125], train_loss:0.175920\n",
      "Epoch [2/2], Iter [2070/3125], train_loss:0.172078\n",
      "Epoch [2/2], Iter [2071/3125], train_loss:0.170283\n",
      "Epoch [2/2], Iter [2072/3125], train_loss:0.150231\n",
      "Epoch [2/2], Iter [2073/3125], train_loss:0.168228\n",
      "Epoch [2/2], Iter [2074/3125], train_loss:0.153722\n",
      "Epoch [2/2], Iter [2075/3125], train_loss:0.124572\n",
      "Epoch [2/2], Iter [2076/3125], train_loss:0.173196\n",
      "Epoch [2/2], Iter [2077/3125], train_loss:0.168445\n",
      "Epoch [2/2], Iter [2078/3125], train_loss:0.144143\n",
      "Epoch [2/2], Iter [2079/3125], train_loss:0.157129\n",
      "Epoch [2/2], Iter [2080/3125], train_loss:0.162381\n",
      "Epoch [2/2], Iter [2081/3125], train_loss:0.173241\n",
      "Epoch [2/2], Iter [2082/3125], train_loss:0.166227\n",
      "Epoch [2/2], Iter [2083/3125], train_loss:0.180616\n",
      "Epoch [2/2], Iter [2084/3125], train_loss:0.161231\n",
      "Epoch [2/2], Iter [2085/3125], train_loss:0.175722\n",
      "Epoch [2/2], Iter [2086/3125], train_loss:0.160612\n",
      "Epoch [2/2], Iter [2087/3125], train_loss:0.148946\n",
      "Epoch [2/2], Iter [2088/3125], train_loss:0.175673\n",
      "Epoch [2/2], Iter [2089/3125], train_loss:0.154421\n",
      "Epoch [2/2], Iter [2090/3125], train_loss:0.189738\n",
      "Epoch [2/2], Iter [2091/3125], train_loss:0.159660\n",
      "Epoch [2/2], Iter [2092/3125], train_loss:0.175166\n",
      "Epoch [2/2], Iter [2093/3125], train_loss:0.162408\n",
      "Epoch [2/2], Iter [2094/3125], train_loss:0.153354\n",
      "Epoch [2/2], Iter [2095/3125], train_loss:0.163397\n",
      "Epoch [2/2], Iter [2096/3125], train_loss:0.180191\n",
      "Epoch [2/2], Iter [2097/3125], train_loss:0.155417\n",
      "Epoch [2/2], Iter [2098/3125], train_loss:0.160626\n",
      "Epoch [2/2], Iter [2099/3125], train_loss:0.134788\n",
      "Epoch [2/2], Iter [2100/3125], train_loss:0.170685\n",
      "Epoch [2/2], Iter [2101/3125], train_loss:0.145300\n",
      "Epoch [2/2], Iter [2102/3125], train_loss:0.156688\n",
      "Epoch [2/2], Iter [2103/3125], train_loss:0.162053\n",
      "Epoch [2/2], Iter [2104/3125], train_loss:0.155611\n",
      "Epoch [2/2], Iter [2105/3125], train_loss:0.170411\n",
      "Epoch [2/2], Iter [2106/3125], train_loss:0.165385\n",
      "Epoch [2/2], Iter [2107/3125], train_loss:0.156872\n",
      "Epoch [2/2], Iter [2108/3125], train_loss:0.170230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [2109/3125], train_loss:0.153298\n",
      "Epoch [2/2], Iter [2110/3125], train_loss:0.159897\n",
      "Epoch [2/2], Iter [2111/3125], train_loss:0.175777\n",
      "Epoch [2/2], Iter [2112/3125], train_loss:0.159928\n",
      "Epoch [2/2], Iter [2113/3125], train_loss:0.149211\n",
      "Epoch [2/2], Iter [2114/3125], train_loss:0.152474\n",
      "Epoch [2/2], Iter [2115/3125], train_loss:0.163601\n",
      "Epoch [2/2], Iter [2116/3125], train_loss:0.165352\n",
      "Epoch [2/2], Iter [2117/3125], train_loss:0.172963\n",
      "Epoch [2/2], Iter [2118/3125], train_loss:0.141813\n",
      "Epoch [2/2], Iter [2119/3125], train_loss:0.172568\n",
      "Epoch [2/2], Iter [2120/3125], train_loss:0.167235\n",
      "Epoch [2/2], Iter [2121/3125], train_loss:0.148218\n",
      "Epoch [2/2], Iter [2122/3125], train_loss:0.168823\n",
      "Epoch [2/2], Iter [2123/3125], train_loss:0.159240\n",
      "Epoch [2/2], Iter [2124/3125], train_loss:0.166298\n",
      "Epoch [2/2], Iter [2125/3125], train_loss:0.161805\n",
      "Epoch [2/2], Iter [2126/3125], train_loss:0.157425\n",
      "Epoch [2/2], Iter [2127/3125], train_loss:0.166371\n",
      "Epoch [2/2], Iter [2128/3125], train_loss:0.150383\n",
      "Epoch [2/2], Iter [2129/3125], train_loss:0.189382\n",
      "Epoch [2/2], Iter [2130/3125], train_loss:0.141227\n",
      "Epoch [2/2], Iter [2131/3125], train_loss:0.163152\n",
      "Epoch [2/2], Iter [2132/3125], train_loss:0.168573\n",
      "Epoch [2/2], Iter [2133/3125], train_loss:0.151125\n",
      "Epoch [2/2], Iter [2134/3125], train_loss:0.151523\n",
      "Epoch [2/2], Iter [2135/3125], train_loss:0.155856\n",
      "Epoch [2/2], Iter [2136/3125], train_loss:0.166104\n",
      "Epoch [2/2], Iter [2137/3125], train_loss:0.154768\n",
      "Epoch [2/2], Iter [2138/3125], train_loss:0.169897\n",
      "Epoch [2/2], Iter [2139/3125], train_loss:0.159011\n",
      "Epoch [2/2], Iter [2140/3125], train_loss:0.149802\n",
      "Epoch [2/2], Iter [2141/3125], train_loss:0.152360\n",
      "Epoch [2/2], Iter [2142/3125], train_loss:0.156276\n",
      "Epoch [2/2], Iter [2143/3125], train_loss:0.150287\n",
      "Epoch [2/2], Iter [2144/3125], train_loss:0.155394\n",
      "Epoch [2/2], Iter [2145/3125], train_loss:0.152331\n",
      "Epoch [2/2], Iter [2146/3125], train_loss:0.163458\n",
      "Epoch [2/2], Iter [2147/3125], train_loss:0.158456\n",
      "Epoch [2/2], Iter [2148/3125], train_loss:0.173169\n",
      "Epoch [2/2], Iter [2149/3125], train_loss:0.168656\n",
      "Epoch [2/2], Iter [2150/3125], train_loss:0.140080\n",
      "Epoch [2/2], Iter [2151/3125], train_loss:0.149988\n",
      "Epoch [2/2], Iter [2152/3125], train_loss:0.160727\n",
      "Epoch [2/2], Iter [2153/3125], train_loss:0.193008\n",
      "Epoch [2/2], Iter [2154/3125], train_loss:0.154883\n",
      "Epoch [2/2], Iter [2155/3125], train_loss:0.151641\n",
      "Epoch [2/2], Iter [2156/3125], train_loss:0.164066\n",
      "Epoch [2/2], Iter [2157/3125], train_loss:0.176007\n",
      "Epoch [2/2], Iter [2158/3125], train_loss:0.168998\n",
      "Epoch [2/2], Iter [2159/3125], train_loss:0.165017\n",
      "Epoch [2/2], Iter [2160/3125], train_loss:0.170541\n",
      "Epoch [2/2], Iter [2161/3125], train_loss:0.142471\n",
      "Epoch [2/2], Iter [2162/3125], train_loss:0.169082\n",
      "Epoch [2/2], Iter [2163/3125], train_loss:0.135703\n",
      "Epoch [2/2], Iter [2164/3125], train_loss:0.138326\n",
      "Epoch [2/2], Iter [2165/3125], train_loss:0.165513\n",
      "Epoch [2/2], Iter [2166/3125], train_loss:0.150124\n",
      "Epoch [2/2], Iter [2167/3125], train_loss:0.165601\n",
      "Epoch [2/2], Iter [2168/3125], train_loss:0.159596\n",
      "Epoch [2/2], Iter [2169/3125], train_loss:0.159565\n",
      "Epoch [2/2], Iter [2170/3125], train_loss:0.172603\n",
      "Epoch [2/2], Iter [2171/3125], train_loss:0.168073\n",
      "Epoch [2/2], Iter [2172/3125], train_loss:0.160502\n",
      "Epoch [2/2], Iter [2173/3125], train_loss:0.179282\n",
      "Epoch [2/2], Iter [2174/3125], train_loss:0.155037\n",
      "Epoch [2/2], Iter [2175/3125], train_loss:0.142881\n",
      "Epoch [2/2], Iter [2176/3125], train_loss:0.179025\n",
      "Epoch [2/2], Iter [2177/3125], train_loss:0.162583\n",
      "Epoch [2/2], Iter [2178/3125], train_loss:0.182549\n",
      "Epoch [2/2], Iter [2179/3125], train_loss:0.179652\n",
      "Epoch [2/2], Iter [2180/3125], train_loss:0.154185\n",
      "Epoch [2/2], Iter [2181/3125], train_loss:0.170685\n",
      "Epoch [2/2], Iter [2182/3125], train_loss:0.177103\n",
      "Epoch [2/2], Iter [2183/3125], train_loss:0.163943\n",
      "Epoch [2/2], Iter [2184/3125], train_loss:0.161410\n",
      "Epoch [2/2], Iter [2185/3125], train_loss:0.165867\n",
      "Epoch [2/2], Iter [2186/3125], train_loss:0.172730\n",
      "Epoch [2/2], Iter [2187/3125], train_loss:0.174963\n",
      "Epoch [2/2], Iter [2188/3125], train_loss:0.150415\n",
      "Epoch [2/2], Iter [2189/3125], train_loss:0.167423\n",
      "Epoch [2/2], Iter [2190/3125], train_loss:0.179667\n",
      "Epoch [2/2], Iter [2191/3125], train_loss:0.144989\n",
      "Epoch [2/2], Iter [2192/3125], train_loss:0.170623\n",
      "Epoch [2/2], Iter [2193/3125], train_loss:0.163760\n",
      "Epoch [2/2], Iter [2194/3125], train_loss:0.144343\n",
      "Epoch [2/2], Iter [2195/3125], train_loss:0.185983\n",
      "Epoch [2/2], Iter [2196/3125], train_loss:0.144810\n",
      "Epoch [2/2], Iter [2197/3125], train_loss:0.172368\n",
      "Epoch [2/2], Iter [2198/3125], train_loss:0.172640\n",
      "Epoch [2/2], Iter [2199/3125], train_loss:0.183595\n",
      "Epoch [2/2], Iter [2200/3125], train_loss:0.175563\n",
      "Epoch [2/2], Iter [2201/3125], train_loss:0.182149\n",
      "Epoch [2/2], Iter [2202/3125], train_loss:0.167946\n",
      "Epoch [2/2], Iter [2203/3125], train_loss:0.176487\n",
      "Epoch [2/2], Iter [2204/3125], train_loss:0.165609\n",
      "Epoch [2/2], Iter [2205/3125], train_loss:0.172582\n",
      "Epoch [2/2], Iter [2206/3125], train_loss:0.169191\n",
      "Epoch [2/2], Iter [2207/3125], train_loss:0.160859\n",
      "Epoch [2/2], Iter [2208/3125], train_loss:0.170653\n",
      "Epoch [2/2], Iter [2209/3125], train_loss:0.164513\n",
      "Epoch [2/2], Iter [2210/3125], train_loss:0.168084\n",
      "Epoch [2/2], Iter [2211/3125], train_loss:0.149407\n",
      "Epoch [2/2], Iter [2212/3125], train_loss:0.163764\n",
      "Epoch [2/2], Iter [2213/3125], train_loss:0.155157\n",
      "Epoch [2/2], Iter [2214/3125], train_loss:0.167690\n",
      "Epoch [2/2], Iter [2215/3125], train_loss:0.159606\n",
      "Epoch [2/2], Iter [2216/3125], train_loss:0.180033\n",
      "Epoch [2/2], Iter [2217/3125], train_loss:0.179293\n",
      "Epoch [2/2], Iter [2218/3125], train_loss:0.172474\n",
      "Epoch [2/2], Iter [2219/3125], train_loss:0.162028\n",
      "Epoch [2/2], Iter [2220/3125], train_loss:0.150233\n",
      "Epoch [2/2], Iter [2221/3125], train_loss:0.174028\n",
      "Epoch [2/2], Iter [2222/3125], train_loss:0.140808\n",
      "Epoch [2/2], Iter [2223/3125], train_loss:0.187053\n",
      "Epoch [2/2], Iter [2224/3125], train_loss:0.163188\n",
      "Epoch [2/2], Iter [2225/3125], train_loss:0.164417\n",
      "Epoch [2/2], Iter [2226/3125], train_loss:0.164051\n",
      "Epoch [2/2], Iter [2227/3125], train_loss:0.177484\n",
      "Epoch [2/2], Iter [2228/3125], train_loss:0.185002\n",
      "Epoch [2/2], Iter [2229/3125], train_loss:0.157433\n",
      "Epoch [2/2], Iter [2230/3125], train_loss:0.142206\n",
      "Epoch [2/2], Iter [2231/3125], train_loss:0.167933\n",
      "Epoch [2/2], Iter [2232/3125], train_loss:0.173172\n",
      "Epoch [2/2], Iter [2233/3125], train_loss:0.169588\n",
      "Epoch [2/2], Iter [2234/3125], train_loss:0.153352\n",
      "Epoch [2/2], Iter [2235/3125], train_loss:0.146648\n",
      "Epoch [2/2], Iter [2236/3125], train_loss:0.162161\n",
      "Epoch [2/2], Iter [2237/3125], train_loss:0.156153\n",
      "Epoch [2/2], Iter [2238/3125], train_loss:0.161633\n",
      "Epoch [2/2], Iter [2239/3125], train_loss:0.149163\n",
      "Epoch [2/2], Iter [2240/3125], train_loss:0.162931\n",
      "Epoch [2/2], Iter [2241/3125], train_loss:0.167972\n",
      "Epoch [2/2], Iter [2242/3125], train_loss:0.157005\n",
      "Epoch [2/2], Iter [2243/3125], train_loss:0.155327\n",
      "Epoch [2/2], Iter [2244/3125], train_loss:0.164582\n",
      "Epoch [2/2], Iter [2245/3125], train_loss:0.158263\n",
      "Epoch [2/2], Iter [2246/3125], train_loss:0.147388\n",
      "Epoch [2/2], Iter [2247/3125], train_loss:0.177447\n",
      "Epoch [2/2], Iter [2248/3125], train_loss:0.156269\n",
      "Epoch [2/2], Iter [2249/3125], train_loss:0.149238\n",
      "Epoch [2/2], Iter [2250/3125], train_loss:0.164078\n",
      "Epoch [2/2], Iter [2251/3125], train_loss:0.180017\n",
      "Epoch [2/2], Iter [2252/3125], train_loss:0.147652\n",
      "Epoch [2/2], Iter [2253/3125], train_loss:0.155566\n",
      "Epoch [2/2], Iter [2254/3125], train_loss:0.142095\n",
      "Epoch [2/2], Iter [2255/3125], train_loss:0.157922\n",
      "Epoch [2/2], Iter [2256/3125], train_loss:0.163744\n",
      "Epoch [2/2], Iter [2257/3125], train_loss:0.165388\n",
      "Epoch [2/2], Iter [2258/3125], train_loss:0.154182\n",
      "Epoch [2/2], Iter [2259/3125], train_loss:0.154416\n",
      "Epoch [2/2], Iter [2260/3125], train_loss:0.161227\n",
      "Epoch [2/2], Iter [2261/3125], train_loss:0.172152\n",
      "Epoch [2/2], Iter [2262/3125], train_loss:0.155861\n",
      "Epoch [2/2], Iter [2263/3125], train_loss:0.165570\n",
      "Epoch [2/2], Iter [2264/3125], train_loss:0.173334\n",
      "Epoch [2/2], Iter [2265/3125], train_loss:0.166959\n",
      "Epoch [2/2], Iter [2266/3125], train_loss:0.157098\n",
      "Epoch [2/2], Iter [2267/3125], train_loss:0.151130\n",
      "Epoch [2/2], Iter [2268/3125], train_loss:0.141538\n",
      "Epoch [2/2], Iter [2269/3125], train_loss:0.165015\n",
      "Epoch [2/2], Iter [2270/3125], train_loss:0.163451\n",
      "Epoch [2/2], Iter [2271/3125], train_loss:0.132454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [2272/3125], train_loss:0.179656\n",
      "Epoch [2/2], Iter [2273/3125], train_loss:0.165350\n",
      "Epoch [2/2], Iter [2274/3125], train_loss:0.173948\n",
      "Epoch [2/2], Iter [2275/3125], train_loss:0.165396\n",
      "Epoch [2/2], Iter [2276/3125], train_loss:0.161036\n",
      "Epoch [2/2], Iter [2277/3125], train_loss:0.161929\n",
      "Epoch [2/2], Iter [2278/3125], train_loss:0.180764\n",
      "Epoch [2/2], Iter [2279/3125], train_loss:0.161236\n",
      "Epoch [2/2], Iter [2280/3125], train_loss:0.177436\n",
      "Epoch [2/2], Iter [2281/3125], train_loss:0.161804\n",
      "Epoch [2/2], Iter [2282/3125], train_loss:0.158168\n",
      "Epoch [2/2], Iter [2283/3125], train_loss:0.152075\n",
      "Epoch [2/2], Iter [2284/3125], train_loss:0.154599\n",
      "Epoch [2/2], Iter [2285/3125], train_loss:0.162115\n",
      "Epoch [2/2], Iter [2286/3125], train_loss:0.153788\n",
      "Epoch [2/2], Iter [2287/3125], train_loss:0.172900\n",
      "Epoch [2/2], Iter [2288/3125], train_loss:0.142647\n",
      "Epoch [2/2], Iter [2289/3125], train_loss:0.174687\n",
      "Epoch [2/2], Iter [2290/3125], train_loss:0.146076\n",
      "Epoch [2/2], Iter [2291/3125], train_loss:0.167392\n",
      "Epoch [2/2], Iter [2292/3125], train_loss:0.126217\n",
      "Epoch [2/2], Iter [2293/3125], train_loss:0.167279\n",
      "Epoch [2/2], Iter [2294/3125], train_loss:0.169861\n",
      "Epoch [2/2], Iter [2295/3125], train_loss:0.165739\n",
      "Epoch [2/2], Iter [2296/3125], train_loss:0.157497\n",
      "Epoch [2/2], Iter [2297/3125], train_loss:0.149060\n",
      "Epoch [2/2], Iter [2298/3125], train_loss:0.172407\n",
      "Epoch [2/2], Iter [2299/3125], train_loss:0.164659\n",
      "Epoch [2/2], Iter [2300/3125], train_loss:0.162021\n",
      "Epoch [2/2], Iter [2301/3125], train_loss:0.171397\n",
      "Epoch [2/2], Iter [2302/3125], train_loss:0.161657\n",
      "Epoch [2/2], Iter [2303/3125], train_loss:0.151041\n",
      "Epoch [2/2], Iter [2304/3125], train_loss:0.162483\n",
      "Epoch [2/2], Iter [2305/3125], train_loss:0.156574\n",
      "Epoch [2/2], Iter [2306/3125], train_loss:0.143564\n",
      "Epoch [2/2], Iter [2307/3125], train_loss:0.176516\n",
      "Epoch [2/2], Iter [2308/3125], train_loss:0.162103\n",
      "Epoch [2/2], Iter [2309/3125], train_loss:0.172555\n",
      "Epoch [2/2], Iter [2310/3125], train_loss:0.172221\n",
      "Epoch [2/2], Iter [2311/3125], train_loss:0.163328\n",
      "Epoch [2/2], Iter [2312/3125], train_loss:0.173653\n",
      "Epoch [2/2], Iter [2313/3125], train_loss:0.148548\n",
      "Epoch [2/2], Iter [2314/3125], train_loss:0.160302\n",
      "Epoch [2/2], Iter [2315/3125], train_loss:0.174374\n",
      "Epoch [2/2], Iter [2316/3125], train_loss:0.160826\n",
      "Epoch [2/2], Iter [2317/3125], train_loss:0.145671\n",
      "Epoch [2/2], Iter [2318/3125], train_loss:0.145656\n",
      "Epoch [2/2], Iter [2319/3125], train_loss:0.146249\n",
      "Epoch [2/2], Iter [2320/3125], train_loss:0.181882\n",
      "Epoch [2/2], Iter [2321/3125], train_loss:0.185629\n",
      "Epoch [2/2], Iter [2322/3125], train_loss:0.160940\n",
      "Epoch [2/2], Iter [2323/3125], train_loss:0.163196\n",
      "Epoch [2/2], Iter [2324/3125], train_loss:0.183124\n",
      "Epoch [2/2], Iter [2325/3125], train_loss:0.161234\n",
      "Epoch [2/2], Iter [2326/3125], train_loss:0.152681\n",
      "Epoch [2/2], Iter [2327/3125], train_loss:0.163183\n",
      "Epoch [2/2], Iter [2328/3125], train_loss:0.169489\n",
      "Epoch [2/2], Iter [2329/3125], train_loss:0.149107\n",
      "Epoch [2/2], Iter [2330/3125], train_loss:0.175521\n",
      "Epoch [2/2], Iter [2331/3125], train_loss:0.169179\n",
      "Epoch [2/2], Iter [2332/3125], train_loss:0.145850\n",
      "Epoch [2/2], Iter [2333/3125], train_loss:0.164425\n",
      "Epoch [2/2], Iter [2334/3125], train_loss:0.172473\n",
      "Epoch [2/2], Iter [2335/3125], train_loss:0.159768\n",
      "Epoch [2/2], Iter [2336/3125], train_loss:0.146140\n",
      "Epoch [2/2], Iter [2337/3125], train_loss:0.171419\n",
      "Epoch [2/2], Iter [2338/3125], train_loss:0.158307\n",
      "Epoch [2/2], Iter [2339/3125], train_loss:0.146750\n",
      "Epoch [2/2], Iter [2340/3125], train_loss:0.175859\n",
      "Epoch [2/2], Iter [2341/3125], train_loss:0.147112\n",
      "Epoch [2/2], Iter [2342/3125], train_loss:0.169059\n",
      "Epoch [2/2], Iter [2343/3125], train_loss:0.164907\n",
      "Epoch [2/2], Iter [2344/3125], train_loss:0.150151\n",
      "Epoch [2/2], Iter [2345/3125], train_loss:0.178080\n",
      "Epoch [2/2], Iter [2346/3125], train_loss:0.161397\n",
      "Epoch [2/2], Iter [2347/3125], train_loss:0.153209\n",
      "Epoch [2/2], Iter [2348/3125], train_loss:0.147120\n",
      "Epoch [2/2], Iter [2349/3125], train_loss:0.154900\n",
      "Epoch [2/2], Iter [2350/3125], train_loss:0.167632\n",
      "Epoch [2/2], Iter [2351/3125], train_loss:0.156230\n",
      "Epoch [2/2], Iter [2352/3125], train_loss:0.152148\n",
      "Epoch [2/2], Iter [2353/3125], train_loss:0.156689\n",
      "Epoch [2/2], Iter [2354/3125], train_loss:0.179915\n",
      "Epoch [2/2], Iter [2355/3125], train_loss:0.185902\n",
      "Epoch [2/2], Iter [2356/3125], train_loss:0.156220\n",
      "Epoch [2/2], Iter [2357/3125], train_loss:0.160710\n",
      "Epoch [2/2], Iter [2358/3125], train_loss:0.130129\n",
      "Epoch [2/2], Iter [2359/3125], train_loss:0.167148\n",
      "Epoch [2/2], Iter [2360/3125], train_loss:0.168769\n",
      "Epoch [2/2], Iter [2361/3125], train_loss:0.150730\n",
      "Epoch [2/2], Iter [2362/3125], train_loss:0.175907\n",
      "Epoch [2/2], Iter [2363/3125], train_loss:0.164773\n",
      "Epoch [2/2], Iter [2364/3125], train_loss:0.164829\n",
      "Epoch [2/2], Iter [2365/3125], train_loss:0.167832\n",
      "Epoch [2/2], Iter [2366/3125], train_loss:0.162342\n",
      "Epoch [2/2], Iter [2367/3125], train_loss:0.161834\n",
      "Epoch [2/2], Iter [2368/3125], train_loss:0.169494\n",
      "Epoch [2/2], Iter [2369/3125], train_loss:0.146952\n",
      "Epoch [2/2], Iter [2370/3125], train_loss:0.170177\n",
      "Epoch [2/2], Iter [2371/3125], train_loss:0.160389\n",
      "Epoch [2/2], Iter [2372/3125], train_loss:0.147826\n",
      "Epoch [2/2], Iter [2373/3125], train_loss:0.163476\n",
      "Epoch [2/2], Iter [2374/3125], train_loss:0.170639\n",
      "Epoch [2/2], Iter [2375/3125], train_loss:0.167875\n",
      "Epoch [2/2], Iter [2376/3125], train_loss:0.155708\n",
      "Epoch [2/2], Iter [2377/3125], train_loss:0.160606\n",
      "Epoch [2/2], Iter [2378/3125], train_loss:0.153278\n",
      "Epoch [2/2], Iter [2379/3125], train_loss:0.153735\n",
      "Epoch [2/2], Iter [2380/3125], train_loss:0.142940\n",
      "Epoch [2/2], Iter [2381/3125], train_loss:0.162398\n",
      "Epoch [2/2], Iter [2382/3125], train_loss:0.180805\n",
      "Epoch [2/2], Iter [2383/3125], train_loss:0.145855\n",
      "Epoch [2/2], Iter [2384/3125], train_loss:0.152199\n",
      "Epoch [2/2], Iter [2385/3125], train_loss:0.178506\n",
      "Epoch [2/2], Iter [2386/3125], train_loss:0.174369\n",
      "Epoch [2/2], Iter [2387/3125], train_loss:0.164620\n",
      "Epoch [2/2], Iter [2388/3125], train_loss:0.181220\n",
      "Epoch [2/2], Iter [2389/3125], train_loss:0.162148\n",
      "Epoch [2/2], Iter [2390/3125], train_loss:0.140538\n",
      "Epoch [2/2], Iter [2391/3125], train_loss:0.154489\n",
      "Epoch [2/2], Iter [2392/3125], train_loss:0.164215\n",
      "Epoch [2/2], Iter [2393/3125], train_loss:0.154179\n",
      "Epoch [2/2], Iter [2394/3125], train_loss:0.167471\n",
      "Epoch [2/2], Iter [2395/3125], train_loss:0.146942\n",
      "Epoch [2/2], Iter [2396/3125], train_loss:0.187956\n",
      "Epoch [2/2], Iter [2397/3125], train_loss:0.159557\n",
      "Epoch [2/2], Iter [2398/3125], train_loss:0.155411\n",
      "Epoch [2/2], Iter [2399/3125], train_loss:0.166520\n",
      "Epoch [2/2], Iter [2400/3125], train_loss:0.146367\n",
      "Epoch [2/2], Iter [2401/3125], train_loss:0.161354\n",
      "Epoch [2/2], Iter [2402/3125], train_loss:0.157196\n",
      "Epoch [2/2], Iter [2403/3125], train_loss:0.169658\n",
      "Epoch [2/2], Iter [2404/3125], train_loss:0.157953\n",
      "Epoch [2/2], Iter [2405/3125], train_loss:0.167446\n",
      "Epoch [2/2], Iter [2406/3125], train_loss:0.161896\n",
      "Epoch [2/2], Iter [2407/3125], train_loss:0.151799\n",
      "Epoch [2/2], Iter [2408/3125], train_loss:0.138387\n",
      "Epoch [2/2], Iter [2409/3125], train_loss:0.133491\n",
      "Epoch [2/2], Iter [2410/3125], train_loss:0.166304\n",
      "Epoch [2/2], Iter [2411/3125], train_loss:0.160304\n",
      "Epoch [2/2], Iter [2412/3125], train_loss:0.176723\n",
      "Epoch [2/2], Iter [2413/3125], train_loss:0.163471\n",
      "Epoch [2/2], Iter [2414/3125], train_loss:0.160211\n",
      "Epoch [2/2], Iter [2415/3125], train_loss:0.167721\n",
      "Epoch [2/2], Iter [2416/3125], train_loss:0.162389\n",
      "Epoch [2/2], Iter [2417/3125], train_loss:0.153439\n",
      "Epoch [2/2], Iter [2418/3125], train_loss:0.156623\n",
      "Epoch [2/2], Iter [2419/3125], train_loss:0.187032\n",
      "Epoch [2/2], Iter [2420/3125], train_loss:0.168476\n",
      "Epoch [2/2], Iter [2421/3125], train_loss:0.156764\n",
      "Epoch [2/2], Iter [2422/3125], train_loss:0.166041\n",
      "Epoch [2/2], Iter [2423/3125], train_loss:0.167909\n",
      "Epoch [2/2], Iter [2424/3125], train_loss:0.169344\n",
      "Epoch [2/2], Iter [2425/3125], train_loss:0.167340\n",
      "Epoch [2/2], Iter [2426/3125], train_loss:0.168933\n",
      "Epoch [2/2], Iter [2427/3125], train_loss:0.162444\n",
      "Epoch [2/2], Iter [2428/3125], train_loss:0.158304\n",
      "Epoch [2/2], Iter [2429/3125], train_loss:0.166113\n",
      "Epoch [2/2], Iter [2430/3125], train_loss:0.152064\n",
      "Epoch [2/2], Iter [2431/3125], train_loss:0.170470\n",
      "Epoch [2/2], Iter [2432/3125], train_loss:0.158352\n",
      "Epoch [2/2], Iter [2433/3125], train_loss:0.154174\n",
      "Epoch [2/2], Iter [2434/3125], train_loss:0.141791\n",
      "Epoch [2/2], Iter [2435/3125], train_loss:0.166201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [2436/3125], train_loss:0.178838\n",
      "Epoch [2/2], Iter [2437/3125], train_loss:0.163674\n",
      "Epoch [2/2], Iter [2438/3125], train_loss:0.144030\n",
      "Epoch [2/2], Iter [2439/3125], train_loss:0.162588\n",
      "Epoch [2/2], Iter [2440/3125], train_loss:0.185782\n",
      "Epoch [2/2], Iter [2441/3125], train_loss:0.174072\n",
      "Epoch [2/2], Iter [2442/3125], train_loss:0.168195\n",
      "Epoch [2/2], Iter [2443/3125], train_loss:0.170184\n",
      "Epoch [2/2], Iter [2444/3125], train_loss:0.167486\n",
      "Epoch [2/2], Iter [2445/3125], train_loss:0.164903\n",
      "Epoch [2/2], Iter [2446/3125], train_loss:0.158505\n",
      "Epoch [2/2], Iter [2447/3125], train_loss:0.166823\n",
      "Epoch [2/2], Iter [2448/3125], train_loss:0.157774\n",
      "Epoch [2/2], Iter [2449/3125], train_loss:0.159175\n",
      "Epoch [2/2], Iter [2450/3125], train_loss:0.163472\n",
      "Epoch [2/2], Iter [2451/3125], train_loss:0.129329\n",
      "Epoch [2/2], Iter [2452/3125], train_loss:0.181139\n",
      "Epoch [2/2], Iter [2453/3125], train_loss:0.164345\n",
      "Epoch [2/2], Iter [2454/3125], train_loss:0.137399\n",
      "Epoch [2/2], Iter [2455/3125], train_loss:0.140558\n",
      "Epoch [2/2], Iter [2456/3125], train_loss:0.161424\n",
      "Epoch [2/2], Iter [2457/3125], train_loss:0.159964\n",
      "Epoch [2/2], Iter [2458/3125], train_loss:0.169869\n",
      "Epoch [2/2], Iter [2459/3125], train_loss:0.156475\n",
      "Epoch [2/2], Iter [2460/3125], train_loss:0.174744\n",
      "Epoch [2/2], Iter [2461/3125], train_loss:0.157972\n",
      "Epoch [2/2], Iter [2462/3125], train_loss:0.160576\n",
      "Epoch [2/2], Iter [2463/3125], train_loss:0.163872\n",
      "Epoch [2/2], Iter [2464/3125], train_loss:0.167456\n",
      "Epoch [2/2], Iter [2465/3125], train_loss:0.164010\n",
      "Epoch [2/2], Iter [2466/3125], train_loss:0.168963\n",
      "Epoch [2/2], Iter [2467/3125], train_loss:0.161042\n",
      "Epoch [2/2], Iter [2468/3125], train_loss:0.151104\n",
      "Epoch [2/2], Iter [2469/3125], train_loss:0.147858\n",
      "Epoch [2/2], Iter [2470/3125], train_loss:0.172590\n",
      "Epoch [2/2], Iter [2471/3125], train_loss:0.167041\n",
      "Epoch [2/2], Iter [2472/3125], train_loss:0.177647\n",
      "Epoch [2/2], Iter [2473/3125], train_loss:0.171343\n",
      "Epoch [2/2], Iter [2474/3125], train_loss:0.152598\n",
      "Epoch [2/2], Iter [2475/3125], train_loss:0.167099\n",
      "Epoch [2/2], Iter [2476/3125], train_loss:0.136522\n",
      "Epoch [2/2], Iter [2477/3125], train_loss:0.158785\n",
      "Epoch [2/2], Iter [2478/3125], train_loss:0.168830\n",
      "Epoch [2/2], Iter [2479/3125], train_loss:0.156640\n",
      "Epoch [2/2], Iter [2480/3125], train_loss:0.147470\n",
      "Epoch [2/2], Iter [2481/3125], train_loss:0.153880\n",
      "Epoch [2/2], Iter [2482/3125], train_loss:0.176592\n",
      "Epoch [2/2], Iter [2483/3125], train_loss:0.151817\n",
      "Epoch [2/2], Iter [2484/3125], train_loss:0.150594\n",
      "Epoch [2/2], Iter [2485/3125], train_loss:0.154481\n",
      "Epoch [2/2], Iter [2486/3125], train_loss:0.125179\n",
      "Epoch [2/2], Iter [2487/3125], train_loss:0.153085\n",
      "Epoch [2/2], Iter [2488/3125], train_loss:0.177543\n",
      "Epoch [2/2], Iter [2489/3125], train_loss:0.157523\n",
      "Epoch [2/2], Iter [2490/3125], train_loss:0.161568\n",
      "Epoch [2/2], Iter [2491/3125], train_loss:0.144093\n",
      "Epoch [2/2], Iter [2492/3125], train_loss:0.161751\n",
      "Epoch [2/2], Iter [2493/3125], train_loss:0.149538\n",
      "Epoch [2/2], Iter [2494/3125], train_loss:0.145325\n",
      "Epoch [2/2], Iter [2495/3125], train_loss:0.169753\n",
      "Epoch [2/2], Iter [2496/3125], train_loss:0.165459\n",
      "Epoch [2/2], Iter [2497/3125], train_loss:0.166542\n",
      "Epoch [2/2], Iter [2498/3125], train_loss:0.165219\n",
      "Epoch [2/2], Iter [2499/3125], train_loss:0.146950\n",
      "Epoch [2/2], Iter [2500/3125], train_loss:0.171042\n",
      "Epoch [2/2], Iter [2501/3125], train_loss:0.153215\n",
      "Epoch [2/2], Iter [2502/3125], train_loss:0.145607\n",
      "Epoch [2/2], Iter [2503/3125], train_loss:0.146470\n",
      "Epoch [2/2], Iter [2504/3125], train_loss:0.162611\n",
      "Epoch [2/2], Iter [2505/3125], train_loss:0.160559\n",
      "Epoch [2/2], Iter [2506/3125], train_loss:0.166567\n",
      "Epoch [2/2], Iter [2507/3125], train_loss:0.151539\n",
      "Epoch [2/2], Iter [2508/3125], train_loss:0.182587\n",
      "Epoch [2/2], Iter [2509/3125], train_loss:0.148856\n",
      "Epoch [2/2], Iter [2510/3125], train_loss:0.168973\n",
      "Epoch [2/2], Iter [2511/3125], train_loss:0.173698\n",
      "Epoch [2/2], Iter [2512/3125], train_loss:0.185366\n",
      "Epoch [2/2], Iter [2513/3125], train_loss:0.168066\n",
      "Epoch [2/2], Iter [2514/3125], train_loss:0.162118\n",
      "Epoch [2/2], Iter [2515/3125], train_loss:0.171975\n",
      "Epoch [2/2], Iter [2516/3125], train_loss:0.176671\n",
      "Epoch [2/2], Iter [2517/3125], train_loss:0.169476\n",
      "Epoch [2/2], Iter [2518/3125], train_loss:0.161178\n",
      "Epoch [2/2], Iter [2519/3125], train_loss:0.148003\n",
      "Epoch [2/2], Iter [2520/3125], train_loss:0.188104\n",
      "Epoch [2/2], Iter [2521/3125], train_loss:0.179982\n",
      "Epoch [2/2], Iter [2522/3125], train_loss:0.173674\n",
      "Epoch [2/2], Iter [2523/3125], train_loss:0.176613\n",
      "Epoch [2/2], Iter [2524/3125], train_loss:0.174389\n",
      "Epoch [2/2], Iter [2525/3125], train_loss:0.159004\n",
      "Epoch [2/2], Iter [2526/3125], train_loss:0.169532\n",
      "Epoch [2/2], Iter [2527/3125], train_loss:0.170724\n",
      "Epoch [2/2], Iter [2528/3125], train_loss:0.164399\n",
      "Epoch [2/2], Iter [2529/3125], train_loss:0.142247\n",
      "Epoch [2/2], Iter [2530/3125], train_loss:0.183250\n",
      "Epoch [2/2], Iter [2531/3125], train_loss:0.169419\n",
      "Epoch [2/2], Iter [2532/3125], train_loss:0.151291\n",
      "Epoch [2/2], Iter [2533/3125], train_loss:0.160534\n",
      "Epoch [2/2], Iter [2534/3125], train_loss:0.155752\n",
      "Epoch [2/2], Iter [2535/3125], train_loss:0.178192\n",
      "Epoch [2/2], Iter [2536/3125], train_loss:0.175591\n",
      "Epoch [2/2], Iter [2537/3125], train_loss:0.175769\n",
      "Epoch [2/2], Iter [2538/3125], train_loss:0.178659\n",
      "Epoch [2/2], Iter [2539/3125], train_loss:0.165177\n",
      "Epoch [2/2], Iter [2540/3125], train_loss:0.184796\n",
      "Epoch [2/2], Iter [2541/3125], train_loss:0.175275\n",
      "Epoch [2/2], Iter [2542/3125], train_loss:0.156886\n",
      "Epoch [2/2], Iter [2543/3125], train_loss:0.163508\n",
      "Epoch [2/2], Iter [2544/3125], train_loss:0.155953\n",
      "Epoch [2/2], Iter [2545/3125], train_loss:0.171652\n",
      "Epoch [2/2], Iter [2546/3125], train_loss:0.165038\n",
      "Epoch [2/2], Iter [2547/3125], train_loss:0.168319\n",
      "Epoch [2/2], Iter [2548/3125], train_loss:0.147511\n",
      "Epoch [2/2], Iter [2549/3125], train_loss:0.149381\n",
      "Epoch [2/2], Iter [2550/3125], train_loss:0.171831\n",
      "Epoch [2/2], Iter [2551/3125], train_loss:0.192971\n",
      "Epoch [2/2], Iter [2552/3125], train_loss:0.172654\n",
      "Epoch [2/2], Iter [2553/3125], train_loss:0.167669\n",
      "Epoch [2/2], Iter [2554/3125], train_loss:0.164548\n",
      "Epoch [2/2], Iter [2555/3125], train_loss:0.162967\n",
      "Epoch [2/2], Iter [2556/3125], train_loss:0.176214\n",
      "Epoch [2/2], Iter [2557/3125], train_loss:0.149028\n",
      "Epoch [2/2], Iter [2558/3125], train_loss:0.171806\n",
      "Epoch [2/2], Iter [2559/3125], train_loss:0.164163\n",
      "Epoch [2/2], Iter [2560/3125], train_loss:0.175309\n",
      "Epoch [2/2], Iter [2561/3125], train_loss:0.145689\n",
      "Epoch [2/2], Iter [2562/3125], train_loss:0.164917\n",
      "Epoch [2/2], Iter [2563/3125], train_loss:0.189363\n",
      "Epoch [2/2], Iter [2564/3125], train_loss:0.165136\n",
      "Epoch [2/2], Iter [2565/3125], train_loss:0.202254\n",
      "Epoch [2/2], Iter [2566/3125], train_loss:0.144646\n",
      "Epoch [2/2], Iter [2567/3125], train_loss:0.154321\n",
      "Epoch [2/2], Iter [2568/3125], train_loss:0.163388\n",
      "Epoch [2/2], Iter [2569/3125], train_loss:0.164784\n",
      "Epoch [2/2], Iter [2570/3125], train_loss:0.161147\n",
      "Epoch [2/2], Iter [2571/3125], train_loss:0.160846\n",
      "Epoch [2/2], Iter [2572/3125], train_loss:0.154127\n",
      "Epoch [2/2], Iter [2573/3125], train_loss:0.173245\n",
      "Epoch [2/2], Iter [2574/3125], train_loss:0.161198\n",
      "Epoch [2/2], Iter [2575/3125], train_loss:0.160172\n",
      "Epoch [2/2], Iter [2576/3125], train_loss:0.168941\n",
      "Epoch [2/2], Iter [2577/3125], train_loss:0.170229\n",
      "Epoch [2/2], Iter [2578/3125], train_loss:0.152900\n",
      "Epoch [2/2], Iter [2579/3125], train_loss:0.180721\n",
      "Epoch [2/2], Iter [2580/3125], train_loss:0.160612\n",
      "Epoch [2/2], Iter [2581/3125], train_loss:0.144458\n",
      "Epoch [2/2], Iter [2582/3125], train_loss:0.157828\n",
      "Epoch [2/2], Iter [2583/3125], train_loss:0.148316\n",
      "Epoch [2/2], Iter [2584/3125], train_loss:0.158147\n",
      "Epoch [2/2], Iter [2585/3125], train_loss:0.154030\n",
      "Epoch [2/2], Iter [2586/3125], train_loss:0.186240\n",
      "Epoch [2/2], Iter [2587/3125], train_loss:0.152709\n",
      "Epoch [2/2], Iter [2588/3125], train_loss:0.166093\n",
      "Epoch [2/2], Iter [2589/3125], train_loss:0.177659\n",
      "Epoch [2/2], Iter [2590/3125], train_loss:0.169674\n",
      "Epoch [2/2], Iter [2591/3125], train_loss:0.165300\n",
      "Epoch [2/2], Iter [2592/3125], train_loss:0.164618\n",
      "Epoch [2/2], Iter [2593/3125], train_loss:0.163311\n",
      "Epoch [2/2], Iter [2594/3125], train_loss:0.150937\n",
      "Epoch [2/2], Iter [2595/3125], train_loss:0.171134\n",
      "Epoch [2/2], Iter [2596/3125], train_loss:0.186088\n",
      "Epoch [2/2], Iter [2597/3125], train_loss:0.158259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [2598/3125], train_loss:0.186223\n",
      "Epoch [2/2], Iter [2599/3125], train_loss:0.158247\n",
      "Epoch [2/2], Iter [2600/3125], train_loss:0.143599\n",
      "Epoch [2/2], Iter [2601/3125], train_loss:0.164938\n",
      "Epoch [2/2], Iter [2602/3125], train_loss:0.153980\n",
      "Epoch [2/2], Iter [2603/3125], train_loss:0.145374\n",
      "Epoch [2/2], Iter [2604/3125], train_loss:0.134261\n",
      "Epoch [2/2], Iter [2605/3125], train_loss:0.160393\n",
      "Epoch [2/2], Iter [2606/3125], train_loss:0.157758\n",
      "Epoch [2/2], Iter [2607/3125], train_loss:0.161622\n",
      "Epoch [2/2], Iter [2608/3125], train_loss:0.175198\n",
      "Epoch [2/2], Iter [2609/3125], train_loss:0.163234\n",
      "Epoch [2/2], Iter [2610/3125], train_loss:0.177956\n",
      "Epoch [2/2], Iter [2611/3125], train_loss:0.157955\n",
      "Epoch [2/2], Iter [2612/3125], train_loss:0.177434\n",
      "Epoch [2/2], Iter [2613/3125], train_loss:0.171269\n",
      "Epoch [2/2], Iter [2614/3125], train_loss:0.176528\n",
      "Epoch [2/2], Iter [2615/3125], train_loss:0.188333\n",
      "Epoch [2/2], Iter [2616/3125], train_loss:0.166107\n",
      "Epoch [2/2], Iter [2617/3125], train_loss:0.164200\n",
      "Epoch [2/2], Iter [2618/3125], train_loss:0.157757\n",
      "Epoch [2/2], Iter [2619/3125], train_loss:0.156536\n",
      "Epoch [2/2], Iter [2620/3125], train_loss:0.173649\n",
      "Epoch [2/2], Iter [2621/3125], train_loss:0.169787\n",
      "Epoch [2/2], Iter [2622/3125], train_loss:0.132538\n",
      "Epoch [2/2], Iter [2623/3125], train_loss:0.166802\n",
      "Epoch [2/2], Iter [2624/3125], train_loss:0.196434\n",
      "Epoch [2/2], Iter [2625/3125], train_loss:0.158484\n",
      "Epoch [2/2], Iter [2626/3125], train_loss:0.163884\n",
      "Epoch [2/2], Iter [2627/3125], train_loss:0.154781\n",
      "Epoch [2/2], Iter [2628/3125], train_loss:0.158023\n",
      "Epoch [2/2], Iter [2629/3125], train_loss:0.159455\n",
      "Epoch [2/2], Iter [2630/3125], train_loss:0.185399\n",
      "Epoch [2/2], Iter [2631/3125], train_loss:0.150990\n",
      "Epoch [2/2], Iter [2632/3125], train_loss:0.144713\n",
      "Epoch [2/2], Iter [2633/3125], train_loss:0.143513\n",
      "Epoch [2/2], Iter [2634/3125], train_loss:0.177108\n",
      "Epoch [2/2], Iter [2635/3125], train_loss:0.171940\n",
      "Epoch [2/2], Iter [2636/3125], train_loss:0.179217\n",
      "Epoch [2/2], Iter [2637/3125], train_loss:0.162607\n",
      "Epoch [2/2], Iter [2638/3125], train_loss:0.163143\n",
      "Epoch [2/2], Iter [2639/3125], train_loss:0.156024\n",
      "Epoch [2/2], Iter [2640/3125], train_loss:0.160066\n",
      "Epoch [2/2], Iter [2641/3125], train_loss:0.167599\n",
      "Epoch [2/2], Iter [2642/3125], train_loss:0.164384\n",
      "Epoch [2/2], Iter [2643/3125], train_loss:0.140341\n",
      "Epoch [2/2], Iter [2644/3125], train_loss:0.166354\n",
      "Epoch [2/2], Iter [2645/3125], train_loss:0.171829\n",
      "Epoch [2/2], Iter [2646/3125], train_loss:0.151231\n",
      "Epoch [2/2], Iter [2647/3125], train_loss:0.170107\n",
      "Epoch [2/2], Iter [2648/3125], train_loss:0.171566\n",
      "Epoch [2/2], Iter [2649/3125], train_loss:0.149776\n",
      "Epoch [2/2], Iter [2650/3125], train_loss:0.186303\n",
      "Epoch [2/2], Iter [2651/3125], train_loss:0.149496\n",
      "Epoch [2/2], Iter [2652/3125], train_loss:0.178861\n",
      "Epoch [2/2], Iter [2653/3125], train_loss:0.167878\n",
      "Epoch [2/2], Iter [2654/3125], train_loss:0.158702\n",
      "Epoch [2/2], Iter [2655/3125], train_loss:0.168265\n",
      "Epoch [2/2], Iter [2656/3125], train_loss:0.167554\n",
      "Epoch [2/2], Iter [2657/3125], train_loss:0.163851\n",
      "Epoch [2/2], Iter [2658/3125], train_loss:0.195701\n",
      "Epoch [2/2], Iter [2659/3125], train_loss:0.156232\n",
      "Epoch [2/2], Iter [2660/3125], train_loss:0.177123\n",
      "Epoch [2/2], Iter [2661/3125], train_loss:0.163065\n",
      "Epoch [2/2], Iter [2662/3125], train_loss:0.149611\n",
      "Epoch [2/2], Iter [2663/3125], train_loss:0.201891\n",
      "Epoch [2/2], Iter [2664/3125], train_loss:0.150382\n",
      "Epoch [2/2], Iter [2665/3125], train_loss:0.176466\n",
      "Epoch [2/2], Iter [2666/3125], train_loss:0.138187\n",
      "Epoch [2/2], Iter [2667/3125], train_loss:0.168699\n",
      "Epoch [2/2], Iter [2668/3125], train_loss:0.154663\n",
      "Epoch [2/2], Iter [2669/3125], train_loss:0.149903\n",
      "Epoch [2/2], Iter [2670/3125], train_loss:0.157193\n",
      "Epoch [2/2], Iter [2671/3125], train_loss:0.152473\n",
      "Epoch [2/2], Iter [2672/3125], train_loss:0.152353\n",
      "Epoch [2/2], Iter [2673/3125], train_loss:0.169504\n",
      "Epoch [2/2], Iter [2674/3125], train_loss:0.173006\n",
      "Epoch [2/2], Iter [2675/3125], train_loss:0.161640\n",
      "Epoch [2/2], Iter [2676/3125], train_loss:0.158599\n",
      "Epoch [2/2], Iter [2677/3125], train_loss:0.167394\n",
      "Epoch [2/2], Iter [2678/3125], train_loss:0.142114\n",
      "Epoch [2/2], Iter [2679/3125], train_loss:0.165136\n",
      "Epoch [2/2], Iter [2680/3125], train_loss:0.160006\n",
      "Epoch [2/2], Iter [2681/3125], train_loss:0.156247\n",
      "Epoch [2/2], Iter [2682/3125], train_loss:0.151866\n",
      "Epoch [2/2], Iter [2683/3125], train_loss:0.161879\n",
      "Epoch [2/2], Iter [2684/3125], train_loss:0.159820\n",
      "Epoch [2/2], Iter [2685/3125], train_loss:0.158494\n",
      "Epoch [2/2], Iter [2686/3125], train_loss:0.171028\n",
      "Epoch [2/2], Iter [2687/3125], train_loss:0.201381\n",
      "Epoch [2/2], Iter [2688/3125], train_loss:0.175127\n",
      "Epoch [2/2], Iter [2689/3125], train_loss:0.153466\n",
      "Epoch [2/2], Iter [2690/3125], train_loss:0.151868\n",
      "Epoch [2/2], Iter [2691/3125], train_loss:0.164084\n",
      "Epoch [2/2], Iter [2692/3125], train_loss:0.169495\n",
      "Epoch [2/2], Iter [2693/3125], train_loss:0.149444\n",
      "Epoch [2/2], Iter [2694/3125], train_loss:0.146471\n",
      "Epoch [2/2], Iter [2695/3125], train_loss:0.151534\n",
      "Epoch [2/2], Iter [2696/3125], train_loss:0.149030\n",
      "Epoch [2/2], Iter [2697/3125], train_loss:0.167356\n",
      "Epoch [2/2], Iter [2698/3125], train_loss:0.176633\n",
      "Epoch [2/2], Iter [2699/3125], train_loss:0.163601\n",
      "Epoch [2/2], Iter [2700/3125], train_loss:0.172377\n",
      "Epoch [2/2], Iter [2701/3125], train_loss:0.168414\n",
      "Epoch [2/2], Iter [2702/3125], train_loss:0.146065\n",
      "Epoch [2/2], Iter [2703/3125], train_loss:0.160828\n",
      "Epoch [2/2], Iter [2704/3125], train_loss:0.158439\n",
      "Epoch [2/2], Iter [2705/3125], train_loss:0.164862\n",
      "Epoch [2/2], Iter [2706/3125], train_loss:0.182165\n",
      "Epoch [2/2], Iter [2707/3125], train_loss:0.147213\n",
      "Epoch [2/2], Iter [2708/3125], train_loss:0.179835\n",
      "Epoch [2/2], Iter [2709/3125], train_loss:0.170419\n",
      "Epoch [2/2], Iter [2710/3125], train_loss:0.172028\n",
      "Epoch [2/2], Iter [2711/3125], train_loss:0.151886\n",
      "Epoch [2/2], Iter [2712/3125], train_loss:0.168349\n",
      "Epoch [2/2], Iter [2713/3125], train_loss:0.179319\n",
      "Epoch [2/2], Iter [2714/3125], train_loss:0.176893\n",
      "Epoch [2/2], Iter [2715/3125], train_loss:0.152150\n",
      "Epoch [2/2], Iter [2716/3125], train_loss:0.172679\n",
      "Epoch [2/2], Iter [2717/3125], train_loss:0.146866\n",
      "Epoch [2/2], Iter [2718/3125], train_loss:0.163885\n",
      "Epoch [2/2], Iter [2719/3125], train_loss:0.173881\n",
      "Epoch [2/2], Iter [2720/3125], train_loss:0.157909\n",
      "Epoch [2/2], Iter [2721/3125], train_loss:0.133622\n",
      "Epoch [2/2], Iter [2722/3125], train_loss:0.135244\n",
      "Epoch [2/2], Iter [2723/3125], train_loss:0.174720\n",
      "Epoch [2/2], Iter [2724/3125], train_loss:0.149727\n",
      "Epoch [2/2], Iter [2725/3125], train_loss:0.162896\n",
      "Epoch [2/2], Iter [2726/3125], train_loss:0.162694\n",
      "Epoch [2/2], Iter [2727/3125], train_loss:0.170609\n",
      "Epoch [2/2], Iter [2728/3125], train_loss:0.182324\n",
      "Epoch [2/2], Iter [2729/3125], train_loss:0.175062\n",
      "Epoch [2/2], Iter [2730/3125], train_loss:0.170757\n",
      "Epoch [2/2], Iter [2731/3125], train_loss:0.169345\n",
      "Epoch [2/2], Iter [2732/3125], train_loss:0.177226\n",
      "Epoch [2/2], Iter [2733/3125], train_loss:0.154160\n",
      "Epoch [2/2], Iter [2734/3125], train_loss:0.172414\n",
      "Epoch [2/2], Iter [2735/3125], train_loss:0.186841\n",
      "Epoch [2/2], Iter [2736/3125], train_loss:0.170810\n",
      "Epoch [2/2], Iter [2737/3125], train_loss:0.158073\n",
      "Epoch [2/2], Iter [2738/3125], train_loss:0.170265\n",
      "Epoch [2/2], Iter [2739/3125], train_loss:0.160741\n",
      "Epoch [2/2], Iter [2740/3125], train_loss:0.169707\n",
      "Epoch [2/2], Iter [2741/3125], train_loss:0.155187\n",
      "Epoch [2/2], Iter [2742/3125], train_loss:0.168650\n",
      "Epoch [2/2], Iter [2743/3125], train_loss:0.169651\n",
      "Epoch [2/2], Iter [2744/3125], train_loss:0.173759\n",
      "Epoch [2/2], Iter [2745/3125], train_loss:0.147266\n",
      "Epoch [2/2], Iter [2746/3125], train_loss:0.154070\n",
      "Epoch [2/2], Iter [2747/3125], train_loss:0.161216\n",
      "Epoch [2/2], Iter [2748/3125], train_loss:0.156341\n",
      "Epoch [2/2], Iter [2749/3125], train_loss:0.157595\n",
      "Epoch [2/2], Iter [2750/3125], train_loss:0.175937\n",
      "Epoch [2/2], Iter [2751/3125], train_loss:0.162876\n",
      "Epoch [2/2], Iter [2752/3125], train_loss:0.152828\n",
      "Epoch [2/2], Iter [2753/3125], train_loss:0.152857\n",
      "Epoch [2/2], Iter [2754/3125], train_loss:0.164010\n",
      "Epoch [2/2], Iter [2755/3125], train_loss:0.176729\n",
      "Epoch [2/2], Iter [2756/3125], train_loss:0.151234\n",
      "Epoch [2/2], Iter [2757/3125], train_loss:0.181626\n",
      "Epoch [2/2], Iter [2758/3125], train_loss:0.152767\n",
      "Epoch [2/2], Iter [2759/3125], train_loss:0.168365\n",
      "Epoch [2/2], Iter [2760/3125], train_loss:0.141571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [2761/3125], train_loss:0.134242\n",
      "Epoch [2/2], Iter [2762/3125], train_loss:0.143686\n",
      "Epoch [2/2], Iter [2763/3125], train_loss:0.168156\n",
      "Epoch [2/2], Iter [2764/3125], train_loss:0.169553\n",
      "Epoch [2/2], Iter [2765/3125], train_loss:0.160746\n",
      "Epoch [2/2], Iter [2766/3125], train_loss:0.146952\n",
      "Epoch [2/2], Iter [2767/3125], train_loss:0.177888\n",
      "Epoch [2/2], Iter [2768/3125], train_loss:0.162018\n",
      "Epoch [2/2], Iter [2769/3125], train_loss:0.163139\n",
      "Epoch [2/2], Iter [2770/3125], train_loss:0.150329\n",
      "Epoch [2/2], Iter [2771/3125], train_loss:0.151441\n",
      "Epoch [2/2], Iter [2772/3125], train_loss:0.162271\n",
      "Epoch [2/2], Iter [2773/3125], train_loss:0.170683\n",
      "Epoch [2/2], Iter [2774/3125], train_loss:0.165567\n",
      "Epoch [2/2], Iter [2775/3125], train_loss:0.159544\n",
      "Epoch [2/2], Iter [2776/3125], train_loss:0.159724\n",
      "Epoch [2/2], Iter [2777/3125], train_loss:0.168196\n",
      "Epoch [2/2], Iter [2778/3125], train_loss:0.175923\n",
      "Epoch [2/2], Iter [2779/3125], train_loss:0.164778\n",
      "Epoch [2/2], Iter [2780/3125], train_loss:0.141005\n",
      "Epoch [2/2], Iter [2781/3125], train_loss:0.152021\n",
      "Epoch [2/2], Iter [2782/3125], train_loss:0.171066\n",
      "Epoch [2/2], Iter [2783/3125], train_loss:0.164640\n",
      "Epoch [2/2], Iter [2784/3125], train_loss:0.143741\n",
      "Epoch [2/2], Iter [2785/3125], train_loss:0.157212\n",
      "Epoch [2/2], Iter [2786/3125], train_loss:0.160184\n",
      "Epoch [2/2], Iter [2787/3125], train_loss:0.160213\n",
      "Epoch [2/2], Iter [2788/3125], train_loss:0.172784\n",
      "Epoch [2/2], Iter [2789/3125], train_loss:0.165040\n",
      "Epoch [2/2], Iter [2790/3125], train_loss:0.159758\n",
      "Epoch [2/2], Iter [2791/3125], train_loss:0.140523\n",
      "Epoch [2/2], Iter [2792/3125], train_loss:0.159209\n",
      "Epoch [2/2], Iter [2793/3125], train_loss:0.160627\n",
      "Epoch [2/2], Iter [2794/3125], train_loss:0.153922\n",
      "Epoch [2/2], Iter [2795/3125], train_loss:0.162577\n",
      "Epoch [2/2], Iter [2796/3125], train_loss:0.163929\n",
      "Epoch [2/2], Iter [2797/3125], train_loss:0.165793\n",
      "Epoch [2/2], Iter [2798/3125], train_loss:0.160750\n",
      "Epoch [2/2], Iter [2799/3125], train_loss:0.180087\n",
      "Epoch [2/2], Iter [2800/3125], train_loss:0.156790\n",
      "Epoch [2/2], Iter [2801/3125], train_loss:0.179635\n",
      "Epoch [2/2], Iter [2802/3125], train_loss:0.165732\n",
      "Epoch [2/2], Iter [2803/3125], train_loss:0.146403\n",
      "Epoch [2/2], Iter [2804/3125], train_loss:0.163374\n",
      "Epoch [2/2], Iter [2805/3125], train_loss:0.153037\n",
      "Epoch [2/2], Iter [2806/3125], train_loss:0.162454\n",
      "Epoch [2/2], Iter [2807/3125], train_loss:0.172889\n",
      "Epoch [2/2], Iter [2808/3125], train_loss:0.173636\n",
      "Epoch [2/2], Iter [2809/3125], train_loss:0.178904\n",
      "Epoch [2/2], Iter [2810/3125], train_loss:0.155920\n",
      "Epoch [2/2], Iter [2811/3125], train_loss:0.167945\n",
      "Epoch [2/2], Iter [2812/3125], train_loss:0.166576\n",
      "Epoch [2/2], Iter [2813/3125], train_loss:0.137098\n",
      "Epoch [2/2], Iter [2814/3125], train_loss:0.183507\n",
      "Epoch [2/2], Iter [2815/3125], train_loss:0.150817\n",
      "Epoch [2/2], Iter [2816/3125], train_loss:0.164395\n",
      "Epoch [2/2], Iter [2817/3125], train_loss:0.160834\n",
      "Epoch [2/2], Iter [2818/3125], train_loss:0.159037\n",
      "Epoch [2/2], Iter [2819/3125], train_loss:0.166901\n",
      "Epoch [2/2], Iter [2820/3125], train_loss:0.169885\n",
      "Epoch [2/2], Iter [2821/3125], train_loss:0.167164\n",
      "Epoch [2/2], Iter [2822/3125], train_loss:0.166339\n",
      "Epoch [2/2], Iter [2823/3125], train_loss:0.148157\n",
      "Epoch [2/2], Iter [2824/3125], train_loss:0.163777\n",
      "Epoch [2/2], Iter [2825/3125], train_loss:0.163534\n",
      "Epoch [2/2], Iter [2826/3125], train_loss:0.157273\n",
      "Epoch [2/2], Iter [2827/3125], train_loss:0.167655\n",
      "Epoch [2/2], Iter [2828/3125], train_loss:0.156075\n",
      "Epoch [2/2], Iter [2829/3125], train_loss:0.188314\n",
      "Epoch [2/2], Iter [2830/3125], train_loss:0.174712\n",
      "Epoch [2/2], Iter [2831/3125], train_loss:0.185394\n",
      "Epoch [2/2], Iter [2832/3125], train_loss:0.146399\n",
      "Epoch [2/2], Iter [2833/3125], train_loss:0.167018\n",
      "Epoch [2/2], Iter [2834/3125], train_loss:0.176304\n",
      "Epoch [2/2], Iter [2835/3125], train_loss:0.159601\n",
      "Epoch [2/2], Iter [2836/3125], train_loss:0.162702\n",
      "Epoch [2/2], Iter [2837/3125], train_loss:0.166671\n",
      "Epoch [2/2], Iter [2838/3125], train_loss:0.188345\n",
      "Epoch [2/2], Iter [2839/3125], train_loss:0.163878\n",
      "Epoch [2/2], Iter [2840/3125], train_loss:0.165695\n",
      "Epoch [2/2], Iter [2841/3125], train_loss:0.159474\n",
      "Epoch [2/2], Iter [2842/3125], train_loss:0.173746\n",
      "Epoch [2/2], Iter [2843/3125], train_loss:0.175083\n",
      "Epoch [2/2], Iter [2844/3125], train_loss:0.174091\n",
      "Epoch [2/2], Iter [2845/3125], train_loss:0.162581\n",
      "Epoch [2/2], Iter [2846/3125], train_loss:0.153189\n",
      "Epoch [2/2], Iter [2847/3125], train_loss:0.142540\n",
      "Epoch [2/2], Iter [2848/3125], train_loss:0.153402\n",
      "Epoch [2/2], Iter [2849/3125], train_loss:0.159401\n",
      "Epoch [2/2], Iter [2850/3125], train_loss:0.148642\n",
      "Epoch [2/2], Iter [2851/3125], train_loss:0.162553\n",
      "Epoch [2/2], Iter [2852/3125], train_loss:0.164649\n",
      "Epoch [2/2], Iter [2853/3125], train_loss:0.154048\n",
      "Epoch [2/2], Iter [2854/3125], train_loss:0.145193\n",
      "Epoch [2/2], Iter [2855/3125], train_loss:0.167669\n",
      "Epoch [2/2], Iter [2856/3125], train_loss:0.146600\n",
      "Epoch [2/2], Iter [2857/3125], train_loss:0.177588\n",
      "Epoch [2/2], Iter [2858/3125], train_loss:0.157502\n",
      "Epoch [2/2], Iter [2859/3125], train_loss:0.143772\n",
      "Epoch [2/2], Iter [2860/3125], train_loss:0.170858\n",
      "Epoch [2/2], Iter [2861/3125], train_loss:0.157444\n",
      "Epoch [2/2], Iter [2862/3125], train_loss:0.147604\n",
      "Epoch [2/2], Iter [2863/3125], train_loss:0.158207\n",
      "Epoch [2/2], Iter [2864/3125], train_loss:0.139868\n",
      "Epoch [2/2], Iter [2865/3125], train_loss:0.161690\n",
      "Epoch [2/2], Iter [2866/3125], train_loss:0.174047\n",
      "Epoch [2/2], Iter [2867/3125], train_loss:0.154822\n",
      "Epoch [2/2], Iter [2868/3125], train_loss:0.155281\n",
      "Epoch [2/2], Iter [2869/3125], train_loss:0.164962\n",
      "Epoch [2/2], Iter [2870/3125], train_loss:0.158610\n",
      "Epoch [2/2], Iter [2871/3125], train_loss:0.146368\n",
      "Epoch [2/2], Iter [2872/3125], train_loss:0.182185\n",
      "Epoch [2/2], Iter [2873/3125], train_loss:0.153709\n",
      "Epoch [2/2], Iter [2874/3125], train_loss:0.173236\n",
      "Epoch [2/2], Iter [2875/3125], train_loss:0.169797\n",
      "Epoch [2/2], Iter [2876/3125], train_loss:0.176348\n",
      "Epoch [2/2], Iter [2877/3125], train_loss:0.160542\n",
      "Epoch [2/2], Iter [2878/3125], train_loss:0.176903\n",
      "Epoch [2/2], Iter [2879/3125], train_loss:0.150074\n",
      "Epoch [2/2], Iter [2880/3125], train_loss:0.156486\n",
      "Epoch [2/2], Iter [2881/3125], train_loss:0.192247\n",
      "Epoch [2/2], Iter [2882/3125], train_loss:0.178376\n",
      "Epoch [2/2], Iter [2883/3125], train_loss:0.147873\n",
      "Epoch [2/2], Iter [2884/3125], train_loss:0.166523\n",
      "Epoch [2/2], Iter [2885/3125], train_loss:0.158246\n",
      "Epoch [2/2], Iter [2886/3125], train_loss:0.148255\n",
      "Epoch [2/2], Iter [2887/3125], train_loss:0.156203\n",
      "Epoch [2/2], Iter [2888/3125], train_loss:0.153266\n",
      "Epoch [2/2], Iter [2889/3125], train_loss:0.162456\n",
      "Epoch [2/2], Iter [2890/3125], train_loss:0.160024\n",
      "Epoch [2/2], Iter [2891/3125], train_loss:0.170155\n",
      "Epoch [2/2], Iter [2892/3125], train_loss:0.181271\n",
      "Epoch [2/2], Iter [2893/3125], train_loss:0.132468\n",
      "Epoch [2/2], Iter [2894/3125], train_loss:0.160413\n",
      "Epoch [2/2], Iter [2895/3125], train_loss:0.151537\n",
      "Epoch [2/2], Iter [2896/3125], train_loss:0.147045\n",
      "Epoch [2/2], Iter [2897/3125], train_loss:0.153873\n",
      "Epoch [2/2], Iter [2898/3125], train_loss:0.153628\n",
      "Epoch [2/2], Iter [2899/3125], train_loss:0.150455\n",
      "Epoch [2/2], Iter [2900/3125], train_loss:0.160462\n",
      "Epoch [2/2], Iter [2901/3125], train_loss:0.183698\n",
      "Epoch [2/2], Iter [2902/3125], train_loss:0.176941\n",
      "Epoch [2/2], Iter [2903/3125], train_loss:0.167408\n",
      "Epoch [2/2], Iter [2904/3125], train_loss:0.170397\n",
      "Epoch [2/2], Iter [2905/3125], train_loss:0.151711\n",
      "Epoch [2/2], Iter [2906/3125], train_loss:0.164683\n",
      "Epoch [2/2], Iter [2907/3125], train_loss:0.161227\n",
      "Epoch [2/2], Iter [2908/3125], train_loss:0.160540\n",
      "Epoch [2/2], Iter [2909/3125], train_loss:0.173059\n",
      "Epoch [2/2], Iter [2910/3125], train_loss:0.159541\n",
      "Epoch [2/2], Iter [2911/3125], train_loss:0.155270\n",
      "Epoch [2/2], Iter [2912/3125], train_loss:0.154482\n",
      "Epoch [2/2], Iter [2913/3125], train_loss:0.169800\n",
      "Epoch [2/2], Iter [2914/3125], train_loss:0.169865\n",
      "Epoch [2/2], Iter [2915/3125], train_loss:0.165599\n",
      "Epoch [2/2], Iter [2916/3125], train_loss:0.168178\n",
      "Epoch [2/2], Iter [2917/3125], train_loss:0.154284\n",
      "Epoch [2/2], Iter [2918/3125], train_loss:0.160195\n",
      "Epoch [2/2], Iter [2919/3125], train_loss:0.157074\n",
      "Epoch [2/2], Iter [2920/3125], train_loss:0.173277\n",
      "Epoch [2/2], Iter [2921/3125], train_loss:0.164456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [2922/3125], train_loss:0.148137\n",
      "Epoch [2/2], Iter [2923/3125], train_loss:0.167377\n",
      "Epoch [2/2], Iter [2924/3125], train_loss:0.145941\n",
      "Epoch [2/2], Iter [2925/3125], train_loss:0.171216\n",
      "Epoch [2/2], Iter [2926/3125], train_loss:0.158290\n",
      "Epoch [2/2], Iter [2927/3125], train_loss:0.150866\n",
      "Epoch [2/2], Iter [2928/3125], train_loss:0.132241\n",
      "Epoch [2/2], Iter [2929/3125], train_loss:0.172130\n",
      "Epoch [2/2], Iter [2930/3125], train_loss:0.150257\n",
      "Epoch [2/2], Iter [2931/3125], train_loss:0.176096\n",
      "Epoch [2/2], Iter [2932/3125], train_loss:0.177389\n",
      "Epoch [2/2], Iter [2933/3125], train_loss:0.159001\n",
      "Epoch [2/2], Iter [2934/3125], train_loss:0.170307\n",
      "Epoch [2/2], Iter [2935/3125], train_loss:0.155522\n",
      "Epoch [2/2], Iter [2936/3125], train_loss:0.135596\n",
      "Epoch [2/2], Iter [2937/3125], train_loss:0.169773\n",
      "Epoch [2/2], Iter [2938/3125], train_loss:0.170379\n",
      "Epoch [2/2], Iter [2939/3125], train_loss:0.184938\n",
      "Epoch [2/2], Iter [2940/3125], train_loss:0.158976\n",
      "Epoch [2/2], Iter [2941/3125], train_loss:0.164497\n",
      "Epoch [2/2], Iter [2942/3125], train_loss:0.177057\n",
      "Epoch [2/2], Iter [2943/3125], train_loss:0.165116\n",
      "Epoch [2/2], Iter [2944/3125], train_loss:0.175181\n",
      "Epoch [2/2], Iter [2945/3125], train_loss:0.155839\n",
      "Epoch [2/2], Iter [2946/3125], train_loss:0.162712\n",
      "Epoch [2/2], Iter [2947/3125], train_loss:0.171080\n",
      "Epoch [2/2], Iter [2948/3125], train_loss:0.172934\n",
      "Epoch [2/2], Iter [2949/3125], train_loss:0.181341\n",
      "Epoch [2/2], Iter [2950/3125], train_loss:0.174521\n",
      "Epoch [2/2], Iter [2951/3125], train_loss:0.163658\n",
      "Epoch [2/2], Iter [2952/3125], train_loss:0.163447\n",
      "Epoch [2/2], Iter [2953/3125], train_loss:0.151142\n",
      "Epoch [2/2], Iter [2954/3125], train_loss:0.181032\n",
      "Epoch [2/2], Iter [2955/3125], train_loss:0.165285\n",
      "Epoch [2/2], Iter [2956/3125], train_loss:0.161844\n",
      "Epoch [2/2], Iter [2957/3125], train_loss:0.139572\n",
      "Epoch [2/2], Iter [2958/3125], train_loss:0.163080\n",
      "Epoch [2/2], Iter [2959/3125], train_loss:0.151158\n",
      "Epoch [2/2], Iter [2960/3125], train_loss:0.179443\n",
      "Epoch [2/2], Iter [2961/3125], train_loss:0.151788\n",
      "Epoch [2/2], Iter [2962/3125], train_loss:0.171754\n",
      "Epoch [2/2], Iter [2963/3125], train_loss:0.179424\n",
      "Epoch [2/2], Iter [2964/3125], train_loss:0.175354\n",
      "Epoch [2/2], Iter [2965/3125], train_loss:0.164513\n",
      "Epoch [2/2], Iter [2966/3125], train_loss:0.152275\n",
      "Epoch [2/2], Iter [2967/3125], train_loss:0.137993\n",
      "Epoch [2/2], Iter [2968/3125], train_loss:0.158773\n",
      "Epoch [2/2], Iter [2969/3125], train_loss:0.178356\n",
      "Epoch [2/2], Iter [2970/3125], train_loss:0.161313\n",
      "Epoch [2/2], Iter [2971/3125], train_loss:0.160383\n",
      "Epoch [2/2], Iter [2972/3125], train_loss:0.162995\n",
      "Epoch [2/2], Iter [2973/3125], train_loss:0.140652\n",
      "Epoch [2/2], Iter [2974/3125], train_loss:0.168911\n",
      "Epoch [2/2], Iter [2975/3125], train_loss:0.174064\n",
      "Epoch [2/2], Iter [2976/3125], train_loss:0.151445\n",
      "Epoch [2/2], Iter [2977/3125], train_loss:0.180211\n",
      "Epoch [2/2], Iter [2978/3125], train_loss:0.156135\n",
      "Epoch [2/2], Iter [2979/3125], train_loss:0.164800\n",
      "Epoch [2/2], Iter [2980/3125], train_loss:0.175958\n",
      "Epoch [2/2], Iter [2981/3125], train_loss:0.169673\n",
      "Epoch [2/2], Iter [2982/3125], train_loss:0.160345\n",
      "Epoch [2/2], Iter [2983/3125], train_loss:0.137590\n",
      "Epoch [2/2], Iter [2984/3125], train_loss:0.144318\n",
      "Epoch [2/2], Iter [2985/3125], train_loss:0.159594\n",
      "Epoch [2/2], Iter [2986/3125], train_loss:0.150696\n",
      "Epoch [2/2], Iter [2987/3125], train_loss:0.150195\n",
      "Epoch [2/2], Iter [2988/3125], train_loss:0.192949\n",
      "Epoch [2/2], Iter [2989/3125], train_loss:0.189933\n",
      "Epoch [2/2], Iter [2990/3125], train_loss:0.159382\n",
      "Epoch [2/2], Iter [2991/3125], train_loss:0.170370\n",
      "Epoch [2/2], Iter [2992/3125], train_loss:0.144884\n",
      "Epoch [2/2], Iter [2993/3125], train_loss:0.168784\n",
      "Epoch [2/2], Iter [2994/3125], train_loss:0.142037\n",
      "Epoch [2/2], Iter [2995/3125], train_loss:0.145175\n",
      "Epoch [2/2], Iter [2996/3125], train_loss:0.189571\n",
      "Epoch [2/2], Iter [2997/3125], train_loss:0.156100\n",
      "Epoch [2/2], Iter [2998/3125], train_loss:0.163920\n",
      "Epoch [2/2], Iter [2999/3125], train_loss:0.160600\n",
      "Epoch [2/2], Iter [3000/3125], train_loss:0.158297\n",
      "Epoch [2/2], Iter [3001/3125], train_loss:0.139392\n",
      "Epoch [2/2], Iter [3002/3125], train_loss:0.164092\n",
      "Epoch [2/2], Iter [3003/3125], train_loss:0.175358\n",
      "Epoch [2/2], Iter [3004/3125], train_loss:0.150730\n",
      "Epoch [2/2], Iter [3005/3125], train_loss:0.147098\n",
      "Epoch [2/2], Iter [3006/3125], train_loss:0.170033\n",
      "Epoch [2/2], Iter [3007/3125], train_loss:0.171837\n",
      "Epoch [2/2], Iter [3008/3125], train_loss:0.170248\n",
      "Epoch [2/2], Iter [3009/3125], train_loss:0.148773\n",
      "Epoch [2/2], Iter [3010/3125], train_loss:0.154308\n",
      "Epoch [2/2], Iter [3011/3125], train_loss:0.172404\n",
      "Epoch [2/2], Iter [3012/3125], train_loss:0.173570\n",
      "Epoch [2/2], Iter [3013/3125], train_loss:0.149814\n",
      "Epoch [2/2], Iter [3014/3125], train_loss:0.148879\n",
      "Epoch [2/2], Iter [3015/3125], train_loss:0.161163\n",
      "Epoch [2/2], Iter [3016/3125], train_loss:0.155940\n",
      "Epoch [2/2], Iter [3017/3125], train_loss:0.174913\n",
      "Epoch [2/2], Iter [3018/3125], train_loss:0.158918\n",
      "Epoch [2/2], Iter [3019/3125], train_loss:0.160641\n",
      "Epoch [2/2], Iter [3020/3125], train_loss:0.174827\n",
      "Epoch [2/2], Iter [3021/3125], train_loss:0.164053\n",
      "Epoch [2/2], Iter [3022/3125], train_loss:0.162513\n",
      "Epoch [2/2], Iter [3023/3125], train_loss:0.152277\n",
      "Epoch [2/2], Iter [3024/3125], train_loss:0.162739\n",
      "Epoch [2/2], Iter [3025/3125], train_loss:0.183433\n",
      "Epoch [2/2], Iter [3026/3125], train_loss:0.155047\n",
      "Epoch [2/2], Iter [3027/3125], train_loss:0.139509\n",
      "Epoch [2/2], Iter [3028/3125], train_loss:0.137149\n",
      "Epoch [2/2], Iter [3029/3125], train_loss:0.176699\n",
      "Epoch [2/2], Iter [3030/3125], train_loss:0.173633\n",
      "Epoch [2/2], Iter [3031/3125], train_loss:0.150467\n",
      "Epoch [2/2], Iter [3032/3125], train_loss:0.141472\n",
      "Epoch [2/2], Iter [3033/3125], train_loss:0.169833\n",
      "Epoch [2/2], Iter [3034/3125], train_loss:0.169371\n",
      "Epoch [2/2], Iter [3035/3125], train_loss:0.171618\n",
      "Epoch [2/2], Iter [3036/3125], train_loss:0.144319\n",
      "Epoch [2/2], Iter [3037/3125], train_loss:0.184146\n",
      "Epoch [2/2], Iter [3038/3125], train_loss:0.170013\n",
      "Epoch [2/2], Iter [3039/3125], train_loss:0.180004\n",
      "Epoch [2/2], Iter [3040/3125], train_loss:0.158758\n",
      "Epoch [2/2], Iter [3041/3125], train_loss:0.159272\n",
      "Epoch [2/2], Iter [3042/3125], train_loss:0.166228\n",
      "Epoch [2/2], Iter [3043/3125], train_loss:0.176483\n",
      "Epoch [2/2], Iter [3044/3125], train_loss:0.152040\n",
      "Epoch [2/2], Iter [3045/3125], train_loss:0.146877\n",
      "Epoch [2/2], Iter [3046/3125], train_loss:0.159885\n",
      "Epoch [2/2], Iter [3047/3125], train_loss:0.156319\n",
      "Epoch [2/2], Iter [3048/3125], train_loss:0.168223\n",
      "Epoch [2/2], Iter [3049/3125], train_loss:0.158093\n",
      "Epoch [2/2], Iter [3050/3125], train_loss:0.170124\n",
      "Epoch [2/2], Iter [3051/3125], train_loss:0.166554\n",
      "Epoch [2/2], Iter [3052/3125], train_loss:0.144276\n",
      "Epoch [2/2], Iter [3053/3125], train_loss:0.169479\n",
      "Epoch [2/2], Iter [3054/3125], train_loss:0.151451\n",
      "Epoch [2/2], Iter [3055/3125], train_loss:0.167853\n",
      "Epoch [2/2], Iter [3056/3125], train_loss:0.179770\n",
      "Epoch [2/2], Iter [3057/3125], train_loss:0.146305\n",
      "Epoch [2/2], Iter [3058/3125], train_loss:0.180743\n",
      "Epoch [2/2], Iter [3059/3125], train_loss:0.161189\n",
      "Epoch [2/2], Iter [3060/3125], train_loss:0.160382\n",
      "Epoch [2/2], Iter [3061/3125], train_loss:0.148967\n",
      "Epoch [2/2], Iter [3062/3125], train_loss:0.177655\n",
      "Epoch [2/2], Iter [3063/3125], train_loss:0.164013\n",
      "Epoch [2/2], Iter [3064/3125], train_loss:0.175087\n",
      "Epoch [2/2], Iter [3065/3125], train_loss:0.136911\n",
      "Epoch [2/2], Iter [3066/3125], train_loss:0.161118\n",
      "Epoch [2/2], Iter [3067/3125], train_loss:0.166344\n",
      "Epoch [2/2], Iter [3068/3125], train_loss:0.162421\n",
      "Epoch [2/2], Iter [3069/3125], train_loss:0.165272\n",
      "Epoch [2/2], Iter [3070/3125], train_loss:0.160847\n",
      "Epoch [2/2], Iter [3071/3125], train_loss:0.161318\n",
      "Epoch [2/2], Iter [3072/3125], train_loss:0.153302\n",
      "Epoch [2/2], Iter [3073/3125], train_loss:0.140120\n",
      "Epoch [2/2], Iter [3074/3125], train_loss:0.170845\n",
      "Epoch [2/2], Iter [3075/3125], train_loss:0.172288\n",
      "Epoch [2/2], Iter [3076/3125], train_loss:0.164029\n",
      "Epoch [2/2], Iter [3077/3125], train_loss:0.156605\n",
      "Epoch [2/2], Iter [3078/3125], train_loss:0.174232\n",
      "Epoch [2/2], Iter [3079/3125], train_loss:0.147738\n",
      "Epoch [2/2], Iter [3080/3125], train_loss:0.160955\n",
      "Epoch [2/2], Iter [3081/3125], train_loss:0.184766\n",
      "Epoch [2/2], Iter [3082/3125], train_loss:0.163715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [3083/3125], train_loss:0.178222\n",
      "Epoch [2/2], Iter [3084/3125], train_loss:0.168303\n",
      "Epoch [2/2], Iter [3085/3125], train_loss:0.160606\n",
      "Epoch [2/2], Iter [3086/3125], train_loss:0.162113\n",
      "Epoch [2/2], Iter [3087/3125], train_loss:0.164078\n",
      "Epoch [2/2], Iter [3088/3125], train_loss:0.175713\n",
      "Epoch [2/2], Iter [3089/3125], train_loss:0.159605\n",
      "Epoch [2/2], Iter [3090/3125], train_loss:0.164134\n",
      "Epoch [2/2], Iter [3091/3125], train_loss:0.182119\n",
      "Epoch [2/2], Iter [3092/3125], train_loss:0.170747\n",
      "Epoch [2/2], Iter [3093/3125], train_loss:0.187317\n",
      "Epoch [2/2], Iter [3094/3125], train_loss:0.127922\n",
      "Epoch [2/2], Iter [3095/3125], train_loss:0.167841\n",
      "Epoch [2/2], Iter [3096/3125], train_loss:0.149758\n",
      "Epoch [2/2], Iter [3097/3125], train_loss:0.152296\n",
      "Epoch [2/2], Iter [3098/3125], train_loss:0.168645\n",
      "Epoch [2/2], Iter [3099/3125], train_loss:0.145692\n",
      "Epoch [2/2], Iter [3100/3125], train_loss:0.171244\n",
      "Epoch [2/2], Iter [3101/3125], train_loss:0.162070\n",
      "Epoch [2/2], Iter [3102/3125], train_loss:0.161848\n",
      "Epoch [2/2], Iter [3103/3125], train_loss:0.154854\n",
      "Epoch [2/2], Iter [3104/3125], train_loss:0.157933\n",
      "Epoch [2/2], Iter [3105/3125], train_loss:0.149885\n",
      "Epoch [2/2], Iter [3106/3125], train_loss:0.168066\n",
      "Epoch [2/2], Iter [3107/3125], train_loss:0.148450\n",
      "Epoch [2/2], Iter [3108/3125], train_loss:0.179795\n",
      "Epoch [2/2], Iter [3109/3125], train_loss:0.164234\n",
      "Epoch [2/2], Iter [3110/3125], train_loss:0.166129\n",
      "Epoch [2/2], Iter [3111/3125], train_loss:0.153614\n",
      "Epoch [2/2], Iter [3112/3125], train_loss:0.188610\n",
      "Epoch [2/2], Iter [3113/3125], train_loss:0.152544\n",
      "Epoch [2/2], Iter [3114/3125], train_loss:0.175411\n",
      "Epoch [2/2], Iter [3115/3125], train_loss:0.158485\n",
      "Epoch [2/2], Iter [3116/3125], train_loss:0.162955\n",
      "Epoch [2/2], Iter [3117/3125], train_loss:0.165514\n",
      "Epoch [2/2], Iter [3118/3125], train_loss:0.165987\n",
      "Epoch [2/2], Iter [3119/3125], train_loss:0.163669\n",
      "Epoch [2/2], Iter [3120/3125], train_loss:0.161127\n",
      "Epoch [2/2], Iter [3121/3125], train_loss:0.170561\n",
      "Epoch [2/2], Iter [3122/3125], train_loss:0.151392\n",
      "Epoch [2/2], Iter [3123/3125], train_loss:0.166281\n",
      "Epoch [2/2], Iter [3124/3125], train_loss:0.151050\n",
      "Epoch [2/2], Iter [3125/3125], train_loss:0.165706\n",
      "Epoch [2/2], train_loss:0.1625, train_acc:9.7480%, test_loss:0.1716, test_acc:9.5400%\n"
     ]
    }
   ],
   "source": [
    "#训练&验证\n",
    "Resnet34_new = new_model.to(device)\n",
    "# 定义损失函数和优化器\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# 损失函数：自定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 优化器\n",
    "optimizer = torch.optim.Adam(Resnet50_new.parameters(), lr=lr)\n",
    "epoch = max_epochs\n",
    "\n",
    "total_step = len(train_loader)\n",
    "train_all_loss = []\n",
    "test_all_loss = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    Resnet34_new.train()\n",
    "    train_total_loss = 0\n",
    "    train_total_num = 0\n",
    "    train_total_correct = 0\n",
    "\n",
    "    for iter, (images,labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = Resnet34_new(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        train_total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        \n",
    "        #backword\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_total_num += labels.shape[0]\n",
    "        train_total_loss += loss.item()\n",
    "        print(\"Epoch [{}/{}], Iter [{}/{}], train_loss:{:4f}\".format(i+1,epoch,iter+1,total_step,loss.item()/labels.shape[0]))\n",
    "    \n",
    "    Resnet34_new.eval()\n",
    "    test_total_loss = 0\n",
    "    test_total_correct = 0\n",
    "    test_total_num = 0\n",
    "    for iter,(images,labels) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = Resnet34_new(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        test_total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        test_total_loss += loss.item()\n",
    "        test_total_num += labels.shape[0]\n",
    "    print(\"Epoch [{}/{}], train_loss:{:.4f}, train_acc:{:.4f}%, test_loss:{:.4f}, test_acc:{:.4f}%\".format(\n",
    "        i+1, epoch, train_total_loss / train_total_num, train_total_correct / train_total_num * 100, test_total_loss / test_total_num, test_total_correct / test_total_num * 100\n",
    "    \n",
    "    ))\n",
    "    train_all_loss.append(np.round(train_total_loss / train_total_num,4))\n",
    "    test_all_loss.append(np.round(test_total_loss / test_total_num,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "504c5738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_total_correct: 0.1\n"
     ]
    }
   ],
   "source": [
    "total_correct = cal_predict_correct(Resnet34_new)\n",
    "print(\"test_total_correct: \"+ str(test_total_correct / 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc896105",
   "metadata": {},
   "source": [
    "## 2、timm微调\n",
    "- 安装：pip3 install timm\n",
    "\n",
    "### 2.1、查看预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "01035050",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "770"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "from torchinfo import summary\n",
    "avail_pretrained_models = timm.list_models(pretrained=True)\n",
    "len(avail_pretrained_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "039bddb4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adv_inception_v3',\n",
       " 'bat_resnext26ts',\n",
       " 'beit_base_patch16_224',\n",
       " 'beit_base_patch16_224_in22k',\n",
       " 'beit_base_patch16_384',\n",
       " 'beit_large_patch16_224',\n",
       " 'beit_large_patch16_224_in22k',\n",
       " 'beit_large_patch16_384',\n",
       " 'beit_large_patch16_512',\n",
       " 'beitv2_base_patch16_224',\n",
       " 'beitv2_base_patch16_224_in22k',\n",
       " 'beitv2_large_patch16_224',\n",
       " 'beitv2_large_patch16_224_in22k',\n",
       " 'botnet26t_256',\n",
       " 'cait_m36_384',\n",
       " 'cait_m48_448',\n",
       " 'cait_s24_224',\n",
       " 'cait_s24_384',\n",
       " 'cait_s36_384',\n",
       " 'cait_xs24_384',\n",
       " 'cait_xxs24_224',\n",
       " 'cait_xxs24_384',\n",
       " 'cait_xxs36_224',\n",
       " 'cait_xxs36_384',\n",
       " 'coat_lite_mini',\n",
       " 'coat_lite_small',\n",
       " 'coat_lite_tiny',\n",
       " 'coat_mini',\n",
       " 'coat_tiny',\n",
       " 'coatnet_0_rw_224',\n",
       " 'coatnet_1_rw_224',\n",
       " 'coatnet_bn_0_rw_224',\n",
       " 'coatnet_nano_rw_224',\n",
       " 'coatnet_rmlp_1_rw_224',\n",
       " 'coatnet_rmlp_2_rw_224',\n",
       " 'coatnet_rmlp_nano_rw_224',\n",
       " 'coatnext_nano_rw_224',\n",
       " 'convit_base',\n",
       " 'convit_small',\n",
       " 'convit_tiny',\n",
       " 'convmixer_768_32',\n",
       " 'convmixer_1024_20_ks9_p14',\n",
       " 'convmixer_1536_20',\n",
       " 'convnext_atto',\n",
       " 'convnext_atto_ols',\n",
       " 'convnext_base',\n",
       " 'convnext_base_384_in22ft1k',\n",
       " 'convnext_base_in22ft1k',\n",
       " 'convnext_base_in22k',\n",
       " 'convnext_femto',\n",
       " 'convnext_femto_ols',\n",
       " 'convnext_large',\n",
       " 'convnext_large_384_in22ft1k',\n",
       " 'convnext_large_in22ft1k',\n",
       " 'convnext_large_in22k',\n",
       " 'convnext_nano',\n",
       " 'convnext_nano_ols',\n",
       " 'convnext_pico',\n",
       " 'convnext_pico_ols',\n",
       " 'convnext_small',\n",
       " 'convnext_small_384_in22ft1k',\n",
       " 'convnext_small_in22ft1k',\n",
       " 'convnext_small_in22k',\n",
       " 'convnext_tiny',\n",
       " 'convnext_tiny_384_in22ft1k',\n",
       " 'convnext_tiny_hnf',\n",
       " 'convnext_tiny_in22ft1k',\n",
       " 'convnext_tiny_in22k',\n",
       " 'convnext_xlarge_384_in22ft1k',\n",
       " 'convnext_xlarge_in22ft1k',\n",
       " 'convnext_xlarge_in22k',\n",
       " 'crossvit_9_240',\n",
       " 'crossvit_9_dagger_240',\n",
       " 'crossvit_15_240',\n",
       " 'crossvit_15_dagger_240',\n",
       " 'crossvit_15_dagger_408',\n",
       " 'crossvit_18_240',\n",
       " 'crossvit_18_dagger_240',\n",
       " 'crossvit_18_dagger_408',\n",
       " 'crossvit_base_240',\n",
       " 'crossvit_small_240',\n",
       " 'crossvit_tiny_240',\n",
       " 'cs3darknet_focus_l',\n",
       " 'cs3darknet_focus_m',\n",
       " 'cs3darknet_l',\n",
       " 'cs3darknet_m',\n",
       " 'cs3darknet_x',\n",
       " 'cs3edgenet_x',\n",
       " 'cs3se_edgenet_x',\n",
       " 'cs3sedarknet_l',\n",
       " 'cs3sedarknet_x',\n",
       " 'cspdarknet53',\n",
       " 'cspresnet50',\n",
       " 'cspresnext50',\n",
       " 'darknet53',\n",
       " 'darknetaa53',\n",
       " 'deit3_base_patch16_224',\n",
       " 'deit3_base_patch16_224_in21ft1k',\n",
       " 'deit3_base_patch16_384',\n",
       " 'deit3_base_patch16_384_in21ft1k',\n",
       " 'deit3_huge_patch14_224',\n",
       " 'deit3_huge_patch14_224_in21ft1k',\n",
       " 'deit3_large_patch16_224',\n",
       " 'deit3_large_patch16_224_in21ft1k',\n",
       " 'deit3_large_patch16_384',\n",
       " 'deit3_large_patch16_384_in21ft1k',\n",
       " 'deit3_medium_patch16_224',\n",
       " 'deit3_medium_patch16_224_in21ft1k',\n",
       " 'deit3_small_patch16_224',\n",
       " 'deit3_small_patch16_224_in21ft1k',\n",
       " 'deit3_small_patch16_384',\n",
       " 'deit3_small_patch16_384_in21ft1k',\n",
       " 'deit_base_distilled_patch16_224',\n",
       " 'deit_base_distilled_patch16_384',\n",
       " 'deit_base_patch16_224',\n",
       " 'deit_base_patch16_384',\n",
       " 'deit_small_distilled_patch16_224',\n",
       " 'deit_small_patch16_224',\n",
       " 'deit_tiny_distilled_patch16_224',\n",
       " 'deit_tiny_patch16_224',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenetblur121d',\n",
       " 'dla34',\n",
       " 'dla46_c',\n",
       " 'dla46x_c',\n",
       " 'dla60',\n",
       " 'dla60_res2net',\n",
       " 'dla60_res2next',\n",
       " 'dla60x',\n",
       " 'dla60x_c',\n",
       " 'dla102',\n",
       " 'dla102x',\n",
       " 'dla102x2',\n",
       " 'dla169',\n",
       " 'dm_nfnet_f0',\n",
       " 'dm_nfnet_f1',\n",
       " 'dm_nfnet_f2',\n",
       " 'dm_nfnet_f3',\n",
       " 'dm_nfnet_f4',\n",
       " 'dm_nfnet_f5',\n",
       " 'dm_nfnet_f6',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn107',\n",
       " 'dpn131',\n",
       " 'eca_botnext26ts_256',\n",
       " 'eca_halonext26ts',\n",
       " 'eca_nfnet_l0',\n",
       " 'eca_nfnet_l1',\n",
       " 'eca_nfnet_l2',\n",
       " 'eca_resnet33ts',\n",
       " 'eca_resnext26ts',\n",
       " 'ecaresnet26t',\n",
       " 'ecaresnet50d',\n",
       " 'ecaresnet50d_pruned',\n",
       " 'ecaresnet50t',\n",
       " 'ecaresnet101d',\n",
       " 'ecaresnet101d_pruned',\n",
       " 'ecaresnet269d',\n",
       " 'ecaresnetlight',\n",
       " 'edgenext_base',\n",
       " 'edgenext_small',\n",
       " 'edgenext_small_rw',\n",
       " 'edgenext_x_small',\n",
       " 'edgenext_xx_small',\n",
       " 'efficientformer_l1',\n",
       " 'efficientformer_l3',\n",
       " 'efficientformer_l7',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_el_pruned',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_es_pruned',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnetv2_rw_m',\n",
       " 'efficientnetv2_rw_s',\n",
       " 'efficientnetv2_rw_t',\n",
       " 'ens_adv_inception_resnet_v2',\n",
       " 'ese_vovnet19b_dw',\n",
       " 'ese_vovnet39b',\n",
       " 'fbnetc_100',\n",
       " 'fbnetv3_b',\n",
       " 'fbnetv3_d',\n",
       " 'fbnetv3_g',\n",
       " 'gc_efficientnetv2_rw_t',\n",
       " 'gcresnet33ts',\n",
       " 'gcresnet50t',\n",
       " 'gcresnext26ts',\n",
       " 'gcresnext50ts',\n",
       " 'gcvit_base',\n",
       " 'gcvit_small',\n",
       " 'gcvit_tiny',\n",
       " 'gcvit_xtiny',\n",
       " 'gcvit_xxtiny',\n",
       " 'gernet_l',\n",
       " 'gernet_m',\n",
       " 'gernet_s',\n",
       " 'ghostnet_100',\n",
       " 'gluon_inception_v3',\n",
       " 'gluon_resnet18_v1b',\n",
       " 'gluon_resnet34_v1b',\n",
       " 'gluon_resnet50_v1b',\n",
       " 'gluon_resnet50_v1c',\n",
       " 'gluon_resnet50_v1d',\n",
       " 'gluon_resnet50_v1s',\n",
       " 'gluon_resnet101_v1b',\n",
       " 'gluon_resnet101_v1c',\n",
       " 'gluon_resnet101_v1d',\n",
       " 'gluon_resnet101_v1s',\n",
       " 'gluon_resnet152_v1b',\n",
       " 'gluon_resnet152_v1c',\n",
       " 'gluon_resnet152_v1d',\n",
       " 'gluon_resnet152_v1s',\n",
       " 'gluon_resnext50_32x4d',\n",
       " 'gluon_resnext101_32x4d',\n",
       " 'gluon_resnext101_64x4d',\n",
       " 'gluon_senet154',\n",
       " 'gluon_seresnext50_32x4d',\n",
       " 'gluon_seresnext101_32x4d',\n",
       " 'gluon_seresnext101_64x4d',\n",
       " 'gluon_xception65',\n",
       " 'gmixer_24_224',\n",
       " 'gmlp_s16_224',\n",
       " 'halo2botnet50ts_256',\n",
       " 'halonet26t',\n",
       " 'halonet50ts',\n",
       " 'haloregnetz_b',\n",
       " 'hardcorenas_a',\n",
       " 'hardcorenas_b',\n",
       " 'hardcorenas_c',\n",
       " 'hardcorenas_d',\n",
       " 'hardcorenas_e',\n",
       " 'hardcorenas_f',\n",
       " 'hrnet_w18',\n",
       " 'hrnet_w18_small',\n",
       " 'hrnet_w18_small_v2',\n",
       " 'hrnet_w30',\n",
       " 'hrnet_w32',\n",
       " 'hrnet_w40',\n",
       " 'hrnet_w44',\n",
       " 'hrnet_w48',\n",
       " 'hrnet_w64',\n",
       " 'ig_resnext101_32x8d',\n",
       " 'ig_resnext101_32x16d',\n",
       " 'ig_resnext101_32x32d',\n",
       " 'ig_resnext101_32x48d',\n",
       " 'inception_resnet_v2',\n",
       " 'inception_v3',\n",
       " 'inception_v4',\n",
       " 'jx_nest_base',\n",
       " 'jx_nest_small',\n",
       " 'jx_nest_tiny',\n",
       " 'lambda_resnet26rpt_256',\n",
       " 'lambda_resnet26t',\n",
       " 'lambda_resnet50ts',\n",
       " 'lamhalobotnet50ts_256',\n",
       " 'lcnet_050',\n",
       " 'lcnet_075',\n",
       " 'lcnet_100',\n",
       " 'legacy_senet154',\n",
       " 'legacy_seresnet18',\n",
       " 'legacy_seresnet34',\n",
       " 'legacy_seresnet50',\n",
       " 'legacy_seresnet101',\n",
       " 'legacy_seresnet152',\n",
       " 'legacy_seresnext26_32x4d',\n",
       " 'legacy_seresnext50_32x4d',\n",
       " 'legacy_seresnext101_32x4d',\n",
       " 'levit_128',\n",
       " 'levit_128s',\n",
       " 'levit_192',\n",
       " 'levit_256',\n",
       " 'levit_384',\n",
       " 'maxvit_nano_rw_256',\n",
       " 'maxvit_rmlp_nano_rw_256',\n",
       " 'maxvit_rmlp_pico_rw_256',\n",
       " 'maxvit_rmlp_small_rw_224',\n",
       " 'maxvit_rmlp_tiny_rw_256',\n",
       " 'maxvit_tiny_rw_224',\n",
       " 'maxxvit_rmlp_nano_rw_256',\n",
       " 'maxxvit_rmlp_small_rw_256',\n",
       " 'mixer_b16_224',\n",
       " 'mixer_b16_224_in21k',\n",
       " 'mixer_b16_224_miil',\n",
       " 'mixer_b16_224_miil_in21k',\n",
       " 'mixer_l16_224',\n",
       " 'mixer_l16_224_in21k',\n",
       " 'mixnet_l',\n",
       " 'mixnet_m',\n",
       " 'mixnet_s',\n",
       " 'mixnet_xl',\n",
       " 'mnasnet_100',\n",
       " 'mnasnet_small',\n",
       " 'mobilenetv2_050',\n",
       " 'mobilenetv2_100',\n",
       " 'mobilenetv2_110d',\n",
       " 'mobilenetv2_120d',\n",
       " 'mobilenetv2_140',\n",
       " 'mobilenetv3_large_100',\n",
       " 'mobilenetv3_large_100_miil',\n",
       " 'mobilenetv3_large_100_miil_in21k',\n",
       " 'mobilenetv3_rw',\n",
       " 'mobilenetv3_small_050',\n",
       " 'mobilenetv3_small_075',\n",
       " 'mobilenetv3_small_100',\n",
       " 'mobilevit_s',\n",
       " 'mobilevit_xs',\n",
       " 'mobilevit_xxs',\n",
       " 'mobilevitv2_050',\n",
       " 'mobilevitv2_075',\n",
       " 'mobilevitv2_100',\n",
       " 'mobilevitv2_125',\n",
       " 'mobilevitv2_150',\n",
       " 'mobilevitv2_150_384_in22ft1k',\n",
       " 'mobilevitv2_150_in22ft1k',\n",
       " 'mobilevitv2_175',\n",
       " 'mobilevitv2_175_384_in22ft1k',\n",
       " 'mobilevitv2_175_in22ft1k',\n",
       " 'mobilevitv2_200',\n",
       " 'mobilevitv2_200_384_in22ft1k',\n",
       " 'mobilevitv2_200_in22ft1k',\n",
       " 'mvitv2_base',\n",
       " 'mvitv2_large',\n",
       " 'mvitv2_small',\n",
       " 'mvitv2_tiny',\n",
       " 'nasnetalarge',\n",
       " 'nf_regnet_b1',\n",
       " 'nf_resnet50',\n",
       " 'nfnet_l0',\n",
       " 'pit_b_224',\n",
       " 'pit_b_distilled_224',\n",
       " 'pit_s_224',\n",
       " 'pit_s_distilled_224',\n",
       " 'pit_ti_224',\n",
       " 'pit_ti_distilled_224',\n",
       " 'pit_xs_224',\n",
       " 'pit_xs_distilled_224',\n",
       " 'pnasnet5large',\n",
       " 'poolformer_m36',\n",
       " 'poolformer_m48',\n",
       " 'poolformer_s12',\n",
       " 'poolformer_s24',\n",
       " 'poolformer_s36',\n",
       " 'pvt_v2_b0',\n",
       " 'pvt_v2_b1',\n",
       " 'pvt_v2_b2',\n",
       " 'pvt_v2_b2_li',\n",
       " 'pvt_v2_b3',\n",
       " 'pvt_v2_b4',\n",
       " 'pvt_v2_b5',\n",
       " 'regnetv_040',\n",
       " 'regnetv_064',\n",
       " 'regnetx_002',\n",
       " 'regnetx_004',\n",
       " 'regnetx_006',\n",
       " 'regnetx_008',\n",
       " 'regnetx_016',\n",
       " 'regnetx_032',\n",
       " 'regnetx_040',\n",
       " 'regnetx_064',\n",
       " 'regnetx_080',\n",
       " 'regnetx_120',\n",
       " 'regnetx_160',\n",
       " 'regnetx_320',\n",
       " 'regnety_002',\n",
       " 'regnety_004',\n",
       " 'regnety_006',\n",
       " 'regnety_008',\n",
       " 'regnety_016',\n",
       " 'regnety_032',\n",
       " 'regnety_040',\n",
       " 'regnety_064',\n",
       " 'regnety_080',\n",
       " 'regnety_120',\n",
       " 'regnety_160',\n",
       " 'regnety_320',\n",
       " 'regnetz_040',\n",
       " 'regnetz_040h',\n",
       " 'regnetz_b16',\n",
       " 'regnetz_c16',\n",
       " 'regnetz_c16_evos',\n",
       " 'regnetz_d8',\n",
       " 'regnetz_d8_evos',\n",
       " 'regnetz_d32',\n",
       " 'regnetz_e8',\n",
       " 'repvgg_a2',\n",
       " 'repvgg_b0',\n",
       " 'repvgg_b1',\n",
       " 'repvgg_b1g4',\n",
       " 'repvgg_b2',\n",
       " 'repvgg_b2g4',\n",
       " 'repvgg_b3',\n",
       " 'repvgg_b3g4',\n",
       " 'res2net50_14w_8s',\n",
       " 'res2net50_26w_4s',\n",
       " 'res2net50_26w_6s',\n",
       " 'res2net50_26w_8s',\n",
       " 'res2net50_48w_2s',\n",
       " 'res2net101_26w_4s',\n",
       " 'res2next50',\n",
       " 'resmlp_12_224',\n",
       " 'resmlp_12_224_dino',\n",
       " 'resmlp_12_distilled_224',\n",
       " 'resmlp_24_224',\n",
       " 'resmlp_24_224_dino',\n",
       " 'resmlp_24_distilled_224',\n",
       " 'resmlp_36_224',\n",
       " 'resmlp_36_distilled_224',\n",
       " 'resmlp_big_24_224',\n",
       " 'resmlp_big_24_224_in22ft1k',\n",
       " 'resmlp_big_24_distilled_224',\n",
       " 'resnest14d',\n",
       " 'resnest26d',\n",
       " 'resnest50d',\n",
       " 'resnest50d_1s4x24d',\n",
       " 'resnest50d_4s2x40d',\n",
       " 'resnest101e',\n",
       " 'resnest200e',\n",
       " 'resnest269e',\n",
       " 'resnet10t',\n",
       " 'resnet14t',\n",
       " 'resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet26t',\n",
       " 'resnet32ts',\n",
       " 'resnet33ts',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50_gn',\n",
       " 'resnet50d',\n",
       " 'resnet51q',\n",
       " 'resnet61q',\n",
       " 'resnet101',\n",
       " 'resnet101d',\n",
       " 'resnet152',\n",
       " 'resnet152d',\n",
       " 'resnet200d',\n",
       " 'resnetaa50',\n",
       " 'resnetblur50',\n",
       " 'resnetrs50',\n",
       " 'resnetrs101',\n",
       " 'resnetrs152',\n",
       " 'resnetrs200',\n",
       " 'resnetrs270',\n",
       " 'resnetrs350',\n",
       " 'resnetrs420',\n",
       " 'resnetv2_50',\n",
       " 'resnetv2_50d_evos',\n",
       " 'resnetv2_50d_gn',\n",
       " 'resnetv2_50x1_bit_distilled',\n",
       " 'resnetv2_50x1_bitm',\n",
       " 'resnetv2_50x1_bitm_in21k',\n",
       " 'resnetv2_50x3_bitm',\n",
       " 'resnetv2_50x3_bitm_in21k',\n",
       " 'resnetv2_101',\n",
       " 'resnetv2_101x1_bitm',\n",
       " 'resnetv2_101x1_bitm_in21k',\n",
       " 'resnetv2_101x3_bitm',\n",
       " 'resnetv2_101x3_bitm_in21k',\n",
       " 'resnetv2_152x2_bit_teacher',\n",
       " 'resnetv2_152x2_bit_teacher_384',\n",
       " 'resnetv2_152x2_bitm',\n",
       " 'resnetv2_152x2_bitm_in21k',\n",
       " 'resnetv2_152x4_bitm',\n",
       " 'resnetv2_152x4_bitm_in21k',\n",
       " 'resnext26ts',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext50d_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_64x4d',\n",
       " 'rexnet_100',\n",
       " 'rexnet_130',\n",
       " 'rexnet_150',\n",
       " 'rexnet_200',\n",
       " 'sebotnet33ts_256',\n",
       " 'sehalonet33ts',\n",
       " 'selecsls42b',\n",
       " 'selecsls60',\n",
       " 'selecsls60b',\n",
       " 'semnasnet_075',\n",
       " 'semnasnet_100',\n",
       " 'sequencer2d_l',\n",
       " 'sequencer2d_m',\n",
       " 'sequencer2d_s',\n",
       " 'seresnet33ts',\n",
       " 'seresnet50',\n",
       " 'seresnet152d',\n",
       " 'seresnext26d_32x4d',\n",
       " 'seresnext26t_32x4d',\n",
       " 'seresnext26ts',\n",
       " 'seresnext50_32x4d',\n",
       " 'seresnext101_32x8d',\n",
       " 'seresnext101d_32x8d',\n",
       " 'seresnextaa101d_32x8d',\n",
       " 'skresnet18',\n",
       " 'skresnet34',\n",
       " 'skresnext50_32x4d',\n",
       " 'spnasnet_100',\n",
       " 'ssl_resnet18',\n",
       " 'ssl_resnet50',\n",
       " 'ssl_resnext50_32x4d',\n",
       " 'ssl_resnext101_32x4d',\n",
       " 'ssl_resnext101_32x8d',\n",
       " 'ssl_resnext101_32x16d',\n",
       " 'swin_base_patch4_window7_224',\n",
       " 'swin_base_patch4_window7_224_in22k',\n",
       " 'swin_base_patch4_window12_384',\n",
       " 'swin_base_patch4_window12_384_in22k',\n",
       " 'swin_large_patch4_window7_224',\n",
       " 'swin_large_patch4_window7_224_in22k',\n",
       " 'swin_large_patch4_window12_384',\n",
       " 'swin_large_patch4_window12_384_in22k',\n",
       " 'swin_s3_base_224',\n",
       " 'swin_s3_small_224',\n",
       " 'swin_s3_tiny_224',\n",
       " 'swin_small_patch4_window7_224',\n",
       " 'swin_tiny_patch4_window7_224',\n",
       " 'swinv2_base_window8_256',\n",
       " 'swinv2_base_window12_192_22k',\n",
       " 'swinv2_base_window12to16_192to256_22kft1k',\n",
       " 'swinv2_base_window12to24_192to384_22kft1k',\n",
       " 'swinv2_base_window16_256',\n",
       " 'swinv2_cr_small_224',\n",
       " 'swinv2_cr_small_ns_224',\n",
       " 'swinv2_cr_tiny_ns_224',\n",
       " 'swinv2_large_window12_192_22k',\n",
       " 'swinv2_large_window12to16_192to256_22kft1k',\n",
       " 'swinv2_large_window12to24_192to384_22kft1k',\n",
       " 'swinv2_small_window8_256',\n",
       " 'swinv2_small_window16_256',\n",
       " 'swinv2_tiny_window8_256',\n",
       " 'swinv2_tiny_window16_256',\n",
       " 'swsl_resnet18',\n",
       " 'swsl_resnet50',\n",
       " 'swsl_resnext50_32x4d',\n",
       " 'swsl_resnext101_32x4d',\n",
       " 'swsl_resnext101_32x8d',\n",
       " 'swsl_resnext101_32x16d',\n",
       " 'tf_efficientnet_b0',\n",
       " 'tf_efficientnet_b0_ap',\n",
       " 'tf_efficientnet_b0_ns',\n",
       " 'tf_efficientnet_b1',\n",
       " 'tf_efficientnet_b1_ap',\n",
       " 'tf_efficientnet_b1_ns',\n",
       " 'tf_efficientnet_b2',\n",
       " 'tf_efficientnet_b2_ap',\n",
       " 'tf_efficientnet_b2_ns',\n",
       " 'tf_efficientnet_b3',\n",
       " 'tf_efficientnet_b3_ap',\n",
       " 'tf_efficientnet_b3_ns',\n",
       " 'tf_efficientnet_b4',\n",
       " 'tf_efficientnet_b4_ap',\n",
       " 'tf_efficientnet_b4_ns',\n",
       " 'tf_efficientnet_b5',\n",
       " 'tf_efficientnet_b5_ap',\n",
       " 'tf_efficientnet_b5_ns',\n",
       " 'tf_efficientnet_b6',\n",
       " 'tf_efficientnet_b6_ap',\n",
       " 'tf_efficientnet_b6_ns',\n",
       " 'tf_efficientnet_b7',\n",
       " 'tf_efficientnet_b7_ap',\n",
       " 'tf_efficientnet_b7_ns',\n",
       " 'tf_efficientnet_b8',\n",
       " 'tf_efficientnet_b8_ap',\n",
       " 'tf_efficientnet_cc_b0_4e',\n",
       " 'tf_efficientnet_cc_b0_8e',\n",
       " 'tf_efficientnet_cc_b1_8e',\n",
       " 'tf_efficientnet_el',\n",
       " 'tf_efficientnet_em',\n",
       " 'tf_efficientnet_es',\n",
       " 'tf_efficientnet_l2_ns',\n",
       " 'tf_efficientnet_l2_ns_475',\n",
       " 'tf_efficientnet_lite0',\n",
       " 'tf_efficientnet_lite1',\n",
       " 'tf_efficientnet_lite2',\n",
       " 'tf_efficientnet_lite3',\n",
       " 'tf_efficientnet_lite4',\n",
       " 'tf_efficientnetv2_b0',\n",
       " 'tf_efficientnetv2_b1',\n",
       " 'tf_efficientnetv2_b2',\n",
       " 'tf_efficientnetv2_b3',\n",
       " 'tf_efficientnetv2_l',\n",
       " 'tf_efficientnetv2_l_in21ft1k',\n",
       " 'tf_efficientnetv2_l_in21k',\n",
       " 'tf_efficientnetv2_m',\n",
       " 'tf_efficientnetv2_m_in21ft1k',\n",
       " 'tf_efficientnetv2_m_in21k',\n",
       " 'tf_efficientnetv2_s',\n",
       " 'tf_efficientnetv2_s_in21ft1k',\n",
       " 'tf_efficientnetv2_s_in21k',\n",
       " 'tf_efficientnetv2_xl_in21ft1k',\n",
       " 'tf_efficientnetv2_xl_in21k',\n",
       " 'tf_inception_v3',\n",
       " 'tf_mixnet_l',\n",
       " 'tf_mixnet_m',\n",
       " 'tf_mixnet_s',\n",
       " 'tf_mobilenetv3_large_075',\n",
       " 'tf_mobilenetv3_large_100',\n",
       " 'tf_mobilenetv3_large_minimal_100',\n",
       " 'tf_mobilenetv3_small_075',\n",
       " 'tf_mobilenetv3_small_100',\n",
       " 'tf_mobilenetv3_small_minimal_100',\n",
       " 'tinynet_a',\n",
       " 'tinynet_b',\n",
       " 'tinynet_c',\n",
       " 'tinynet_d',\n",
       " 'tinynet_e',\n",
       " 'tnt_s_patch16_224',\n",
       " 'tresnet_l',\n",
       " 'tresnet_l_448',\n",
       " 'tresnet_m',\n",
       " 'tresnet_m_448',\n",
       " 'tresnet_m_miil_in21k',\n",
       " 'tresnet_v2_l',\n",
       " 'tresnet_xl',\n",
       " 'tresnet_xl_448',\n",
       " 'tv_densenet121',\n",
       " 'tv_resnet34',\n",
       " 'tv_resnet50',\n",
       " 'tv_resnet101',\n",
       " 'tv_resnet152',\n",
       " 'tv_resnext50_32x4d',\n",
       " 'twins_pcpvt_base',\n",
       " 'twins_pcpvt_large',\n",
       " 'twins_pcpvt_small',\n",
       " 'twins_svt_base',\n",
       " 'twins_svt_large',\n",
       " 'twins_svt_small',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'visformer_small',\n",
       " 'vit_base_patch8_224',\n",
       " 'vit_base_patch8_224_dino',\n",
       " 'vit_base_patch8_224_in21k',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_dino',\n",
       " 'vit_base_patch16_224_in21k',\n",
       " 'vit_base_patch16_224_miil',\n",
       " 'vit_base_patch16_224_miil_in21k',\n",
       " 'vit_base_patch16_224_sam',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch16_rpn_224',\n",
       " 'vit_base_patch32_224',\n",
       " 'vit_base_patch32_224_clip_laion2b',\n",
       " 'vit_base_patch32_224_in21k',\n",
       " 'vit_base_patch32_224_sam',\n",
       " 'vit_base_patch32_384',\n",
       " 'vit_base_r50_s16_224_in21k',\n",
       " 'vit_base_r50_s16_384',\n",
       " 'vit_giant_patch14_224_clip_laion2b',\n",
       " 'vit_huge_patch14_224_clip_laion2b',\n",
       " 'vit_huge_patch14_224_in21k',\n",
       " 'vit_large_patch14_224_clip_laion2b',\n",
       " 'vit_large_patch16_224',\n",
       " 'vit_large_patch16_224_in21k',\n",
       " 'vit_large_patch16_384',\n",
       " 'vit_large_patch32_224_in21k',\n",
       " 'vit_large_patch32_384',\n",
       " 'vit_large_r50_s32_224',\n",
       " 'vit_large_r50_s32_224_in21k',\n",
       " 'vit_large_r50_s32_384',\n",
       " 'vit_relpos_base_patch16_224',\n",
       " 'vit_relpos_base_patch16_clsgap_224',\n",
       " 'vit_relpos_base_patch32_plus_rpn_256',\n",
       " 'vit_relpos_medium_patch16_224',\n",
       " 'vit_relpos_medium_patch16_cls_224',\n",
       " 'vit_relpos_medium_patch16_rpn_224',\n",
       " 'vit_relpos_small_patch16_224',\n",
       " 'vit_small_patch8_224_dino',\n",
       " 'vit_small_patch16_224',\n",
       " 'vit_small_patch16_224_dino',\n",
       " 'vit_small_patch16_224_in21k',\n",
       " 'vit_small_patch16_384',\n",
       " 'vit_small_patch32_224',\n",
       " 'vit_small_patch32_224_in21k',\n",
       " 'vit_small_patch32_384',\n",
       " 'vit_small_r26_s32_224',\n",
       " 'vit_small_r26_s32_224_in21k',\n",
       " 'vit_small_r26_s32_384',\n",
       " 'vit_srelpos_medium_patch16_224',\n",
       " 'vit_srelpos_small_patch16_224',\n",
       " 'vit_tiny_patch16_224',\n",
       " 'vit_tiny_patch16_224_in21k',\n",
       " 'vit_tiny_patch16_384',\n",
       " 'vit_tiny_r_s16_p8_224',\n",
       " 'vit_tiny_r_s16_p8_224_in21k',\n",
       " 'vit_tiny_r_s16_p8_384',\n",
       " 'volo_d1_224',\n",
       " 'volo_d1_384',\n",
       " 'volo_d2_224',\n",
       " 'volo_d2_384',\n",
       " 'volo_d3_224',\n",
       " 'volo_d3_448',\n",
       " 'volo_d4_224',\n",
       " 'volo_d4_448',\n",
       " 'volo_d5_224',\n",
       " 'volo_d5_448',\n",
       " 'volo_d5_512',\n",
       " 'wide_resnet50_2',\n",
       " 'wide_resnet101_2',\n",
       " 'xception',\n",
       " 'xception41',\n",
       " 'xception41p',\n",
       " 'xception65',\n",
       " 'xception65p',\n",
       " 'xception71',\n",
       " 'xcit_large_24_p8_224',\n",
       " 'xcit_large_24_p8_224_dist',\n",
       " 'xcit_large_24_p8_384_dist',\n",
       " 'xcit_large_24_p16_224',\n",
       " 'xcit_large_24_p16_224_dist',\n",
       " 'xcit_large_24_p16_384_dist',\n",
       " 'xcit_medium_24_p8_224',\n",
       " 'xcit_medium_24_p8_224_dist',\n",
       " 'xcit_medium_24_p8_384_dist',\n",
       " 'xcit_medium_24_p16_224',\n",
       " 'xcit_medium_24_p16_224_dist',\n",
       " 'xcit_medium_24_p16_384_dist',\n",
       " 'xcit_nano_12_p8_224',\n",
       " 'xcit_nano_12_p8_224_dist',\n",
       " 'xcit_nano_12_p8_384_dist',\n",
       " 'xcit_nano_12_p16_224',\n",
       " 'xcit_nano_12_p16_224_dist',\n",
       " 'xcit_nano_12_p16_384_dist',\n",
       " 'xcit_small_12_p8_224',\n",
       " 'xcit_small_12_p8_224_dist',\n",
       " 'xcit_small_12_p8_384_dist',\n",
       " 'xcit_small_12_p16_224',\n",
       " 'xcit_small_12_p16_224_dist',\n",
       " 'xcit_small_12_p16_384_dist',\n",
       " 'xcit_small_24_p8_224',\n",
       " 'xcit_small_24_p8_224_dist',\n",
       " 'xcit_small_24_p8_384_dist',\n",
       " 'xcit_small_24_p16_224',\n",
       " 'xcit_small_24_p16_224_dist',\n",
       " 'xcit_small_24_p16_384_dist',\n",
       " 'xcit_tiny_12_p8_224',\n",
       " 'xcit_tiny_12_p8_224_dist',\n",
       " 'xcit_tiny_12_p8_384_dist',\n",
       " 'xcit_tiny_12_p16_224',\n",
       " 'xcit_tiny_12_p16_224_dist',\n",
       " 'xcit_tiny_12_p16_384_dist',\n",
       " 'xcit_tiny_24_p8_224',\n",
       " 'xcit_tiny_24_p8_224_dist',\n",
       " 'xcit_tiny_24_p8_384_dist',\n",
       " 'xcit_tiny_24_p16_224',\n",
       " 'xcit_tiny_24_p16_224_dist',\n",
       " 'xcit_tiny_24_p16_384_dist']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型列表\n",
    "avail_pretrained_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f4c2d3",
   "metadata": {},
   "source": [
    "#### 2.1.1、查看模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5c6cb7a5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to C:\\Users\\xulele/.cache\\torch\\hub\\checkpoints\\resnet18-5c106cde.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'url': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
       " 'num_classes': 1000,\n",
       " 'input_size': (3, 224, 224),\n",
       " 'pool_size': (7, 7),\n",
       " 'crop_pct': 0.875,\n",
       " 'interpolation': 'bilinear',\n",
       " 'mean': (0.485, 0.456, 0.406),\n",
       " 'std': (0.229, 0.224, 0.225),\n",
       " 'first_conv': 'conv1',\n",
       " 'classifier': 'fc',\n",
       " 'architecture': 'resnet18'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model('resnet18',pretrained=True)\n",
    "model.default_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "79db96f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccc2bb4",
   "metadata": {},
   "source": [
    "### 2.2、修改预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "42b0bbb2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试模型\n",
    "x = torch.randn(1,3,224,224)\n",
    "output = model(x)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7559e9",
   "metadata": {},
   "source": [
    "### 2.2.1、查看某一层模型参数（以第一层卷积为例）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d51ae44",
   "metadata": {
    "collapsed": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[-1.0419e-02, -6.1356e-03, -1.8098e-03,  ...,  5.6615e-02,\n",
       "             1.7083e-02, -1.2694e-02],\n",
       "           [ 1.1083e-02,  9.5276e-03, -1.0993e-01,  ..., -2.7124e-01,\n",
       "            -1.2907e-01,  3.7424e-03],\n",
       "           [-6.9434e-03,  5.9089e-02,  2.9548e-01,  ...,  5.1972e-01,\n",
       "             2.5632e-01,  6.3573e-02],\n",
       "           ...,\n",
       "           [-2.7535e-02,  1.6045e-02,  7.2595e-02,  ..., -3.3285e-01,\n",
       "            -4.2058e-01, -2.5781e-01],\n",
       "           [ 3.0613e-02,  4.0960e-02,  6.2850e-02,  ...,  4.1384e-01,\n",
       "             3.9359e-01,  1.6606e-01],\n",
       "           [-1.3736e-02, -3.6746e-03, -2.4084e-02,  ..., -1.5070e-01,\n",
       "            -8.2230e-02, -5.7828e-03]],\n",
       " \n",
       "          [[-1.1397e-02, -2.6619e-02, -3.4641e-02,  ...,  3.2521e-02,\n",
       "             6.6221e-04, -2.5743e-02],\n",
       "           [ 4.5687e-02,  3.3603e-02, -1.0453e-01,  ..., -3.1253e-01,\n",
       "            -1.6051e-01, -1.2826e-03],\n",
       "           [-8.3730e-04,  9.8420e-02,  4.0210e-01,  ...,  7.0789e-01,\n",
       "             3.6887e-01,  1.2455e-01],\n",
       "           ...,\n",
       "           [-5.5926e-02, -5.2239e-03,  2.7081e-02,  ..., -4.6178e-01,\n",
       "            -5.7080e-01, -3.6552e-01],\n",
       "           [ 3.2860e-02,  5.5574e-02,  9.9670e-02,  ...,  5.4636e-01,\n",
       "             4.8276e-01,  1.9867e-01],\n",
       "           [ 5.3051e-03,  6.6938e-03, -1.7254e-02,  ..., -1.4822e-01,\n",
       "            -7.7248e-02,  7.2183e-04]],\n",
       " \n",
       "          [[-2.0315e-03, -9.1617e-03,  2.1209e-02,  ...,  8.9177e-02,\n",
       "             3.3655e-02, -2.0102e-02],\n",
       "           [ 1.5398e-02, -1.8648e-02, -1.2591e-01,  ..., -2.5342e-01,\n",
       "            -1.2980e-01, -2.7975e-02],\n",
       "           [ 9.8454e-03,  4.9047e-02,  2.1699e-01,  ...,  3.4872e-01,\n",
       "             1.0433e-01,  1.8413e-02],\n",
       "           ...,\n",
       "           [-2.8356e-02,  1.8404e-02,  9.8647e-02,  ..., -1.1740e-01,\n",
       "            -2.5760e-01, -1.5451e-01],\n",
       "           [ 2.0766e-02, -2.6286e-03, -3.7825e-02,  ...,  2.4141e-01,\n",
       "             2.4345e-01,  1.1796e-01],\n",
       "           [ 7.4684e-04,  7.7677e-04, -1.0050e-02,  ..., -1.4865e-01,\n",
       "            -1.1754e-01, -3.8350e-02]]],\n",
       " \n",
       " \n",
       "         [[[-4.4154e-03, -4.0645e-03,  3.1589e-03,  ..., -3.7026e-02,\n",
       "            -2.5158e-02, -4.7945e-02],\n",
       "           [ 5.1310e-02,  5.3402e-02,  8.0436e-02,  ...,  1.4480e-01,\n",
       "             1.4287e-01,  1.2312e-01],\n",
       "           [-7.3337e-03,  2.1755e-03,  3.7580e-02,  ...,  6.1517e-02,\n",
       "             8.0324e-02,  1.1715e-01],\n",
       "           ...,\n",
       "           [-2.6754e-02, -1.2297e-01, -1.3653e-01,  ..., -1.4068e-01,\n",
       "            -1.1155e-01, -4.9556e-02],\n",
       "           [ 2.3524e-02, -1.7288e-02, -1.1122e-02,  ..., -1.8826e-02,\n",
       "            -2.3320e-02, -2.9474e-02],\n",
       "           [ 2.8689e-02,  2.1659e-02,  4.7888e-02,  ...,  2.5498e-02,\n",
       "             3.5346e-02,  1.1280e-02]],\n",
       " \n",
       "          [[ 4.6919e-04,  1.2153e-02,  4.2035e-02,  ...,  4.6403e-02,\n",
       "             4.0423e-02, -1.4439e-02],\n",
       "           [ 4.3463e-02,  6.8779e-02,  1.3268e-01,  ...,  2.8606e-01,\n",
       "             2.6905e-01,  2.0935e-01],\n",
       "           [-5.7621e-02, -2.2642e-02,  3.0547e-02,  ...,  1.3763e-01,\n",
       "             1.6538e-01,  1.7946e-01],\n",
       "           ...,\n",
       "           [-1.0816e-01, -2.5227e-01, -2.9742e-01,  ..., -2.8503e-01,\n",
       "            -2.1493e-01, -1.0320e-01],\n",
       "           [ 4.0709e-02, -3.2771e-02, -6.3450e-02,  ..., -9.2360e-02,\n",
       "            -6.9876e-02, -4.9841e-02],\n",
       "           [ 8.2942e-02,  8.7580e-02,  1.0111e-01,  ...,  5.2714e-02,\n",
       "             6.0968e-02,  4.1198e-02]],\n",
       " \n",
       "          [[-1.6391e-02, -1.3870e-02,  5.2810e-03,  ...,  4.3698e-02,\n",
       "             2.2707e-02, -4.5983e-02],\n",
       "           [ 3.3202e-02,  4.2014e-02,  9.3500e-02,  ...,  2.6162e-01,\n",
       "             2.2970e-01,  1.6694e-01],\n",
       "           [-4.5987e-02, -1.6365e-02,  2.6811e-02,  ...,  1.4951e-01,\n",
       "             1.3216e-01,  1.3579e-01],\n",
       "           ...,\n",
       "           [-7.2129e-02, -1.8902e-01, -2.3389e-01,  ..., -1.9038e-01,\n",
       "            -1.5609e-01, -7.5974e-02],\n",
       "           [ 5.1161e-02, -2.5815e-02, -6.9357e-02,  ..., -5.8999e-02,\n",
       "            -6.1550e-02, -4.4555e-02],\n",
       "           [ 1.1174e-01,  7.8979e-02,  6.5849e-02,  ...,  3.1617e-02,\n",
       "             2.5221e-02,  7.4257e-03]]],\n",
       " \n",
       " \n",
       "         [[[-7.0826e-08, -6.4306e-08, -7.3806e-08,  ..., -9.8000e-08,\n",
       "            -1.0905e-07, -8.3421e-08],\n",
       "           [-6.1125e-09,  2.0613e-09, -8.0922e-09,  ..., -4.9840e-08,\n",
       "            -4.3836e-08, -3.0538e-09],\n",
       "           [ 7.1953e-08,  7.5616e-08,  5.9282e-08,  ..., -9.7509e-09,\n",
       "            -1.0951e-09,  4.2442e-08],\n",
       "           ...,\n",
       "           [ 9.5889e-08,  1.0039e-07,  7.9817e-08,  ..., -1.7491e-08,\n",
       "            -4.7666e-08, -1.3265e-08],\n",
       "           [ 1.2904e-07,  1.4762e-07,  1.7477e-07,  ...,  1.3233e-07,\n",
       "             1.0628e-07,  9.3316e-08],\n",
       "           [ 1.2558e-07,  1.3644e-07,  1.8431e-07,  ...,  2.1399e-07,\n",
       "             1.7710e-07,  1.7166e-07]],\n",
       " \n",
       "          [[-1.2690e-07, -9.6139e-08, -1.0372e-07,  ..., -1.1808e-07,\n",
       "            -1.3309e-07, -1.0820e-07],\n",
       "           [-5.7412e-08, -2.5055e-08, -3.0115e-08,  ..., -7.2922e-08,\n",
       "            -6.7022e-08, -2.2574e-08],\n",
       "           [ 2.1813e-08,  4.8608e-08,  3.1222e-08,  ..., -1.8694e-08,\n",
       "            -7.9591e-09,  3.9750e-08],\n",
       "           ...,\n",
       "           [ 5.6013e-08,  7.5526e-08,  4.4496e-08,  ..., -4.4128e-08,\n",
       "            -5.9930e-08, -1.8247e-08],\n",
       "           [ 7.7614e-08,  9.8348e-08,  1.0455e-07,  ...,  6.3272e-08,\n",
       "             4.1781e-08,  4.5901e-08],\n",
       "           [ 5.9834e-08,  7.1006e-08,  9.0437e-08,  ...,  1.1654e-07,\n",
       "             8.7550e-08,  9.8837e-08]],\n",
       " \n",
       "          [[-4.3810e-08,  1.3270e-08,  7.8275e-09,  ..., -5.8804e-09,\n",
       "            -2.6217e-08, -1.5649e-08],\n",
       "           [ 4.1700e-08,  1.0778e-07,  1.0946e-07,  ...,  7.6403e-08,\n",
       "             7.1450e-08,  9.7615e-08],\n",
       "           [ 1.0436e-07,  1.6586e-07,  1.5933e-07,  ...,  1.3517e-07,\n",
       "             1.3487e-07,  1.6449e-07],\n",
       "           ...,\n",
       "           [ 9.8763e-08,  1.5072e-07,  1.2547e-07,  ...,  6.8316e-08,\n",
       "             6.8382e-08,  1.1367e-07],\n",
       "           [ 9.1435e-08,  1.3576e-07,  1.3793e-07,  ...,  1.1678e-07,\n",
       "             1.1723e-07,  1.4394e-07],\n",
       "           [ 6.2183e-08,  8.8184e-08,  1.0456e-07,  ...,  1.3941e-07,\n",
       "             1.3333e-07,  1.5844e-07]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-6.1896e-02, -3.0206e-02,  1.9225e-02,  ...,  4.3665e-02,\n",
       "            -2.2114e-02, -4.2214e-02],\n",
       "           [-3.8061e-02,  6.0774e-03,  4.5797e-02,  ...,  9.6029e-02,\n",
       "             5.9254e-02,  2.9958e-02],\n",
       "           [-2.9672e-02,  2.7766e-03,  2.0457e-02,  ...,  5.9828e-02,\n",
       "             4.1422e-02,  2.3134e-02],\n",
       "           ...,\n",
       "           [ 1.1916e-02,  4.5701e-02,  4.4892e-02,  ...,  4.7419e-02,\n",
       "             2.2274e-02, -5.4993e-03],\n",
       "           [-3.2468e-02, -1.2210e-02,  2.2023e-02,  ...,  5.8061e-02,\n",
       "            -7.5033e-03, -5.9736e-02],\n",
       "           [-4.3314e-02, -2.8162e-02, -5.9126e-03,  ...,  8.8460e-02,\n",
       "             8.4406e-03, -5.0019e-02]],\n",
       " \n",
       "          [[-6.1292e-02, -1.4004e-02,  1.7229e-02,  ...,  1.8349e-02,\n",
       "            -3.2708e-02, -4.1060e-02],\n",
       "           [-3.1506e-02,  2.4460e-02,  4.5516e-02,  ...,  6.6806e-02,\n",
       "             4.6687e-02,  3.3248e-02],\n",
       "           [-3.2216e-02,  2.0718e-02,  2.3343e-02,  ...,  3.5265e-02,\n",
       "             3.6478e-02,  3.1291e-02],\n",
       "           ...,\n",
       "           [ 1.7739e-02,  6.1040e-02,  4.8247e-02,  ...,  3.7785e-02,\n",
       "             2.8894e-02,  1.3984e-02],\n",
       "           [-1.0890e-02,  2.2079e-02,  4.2737e-02,  ...,  6.0247e-02,\n",
       "             1.6197e-02, -1.2493e-02],\n",
       "           [-2.2284e-02,  1.3220e-02,  3.0897e-02,  ...,  1.0403e-01,\n",
       "             4.0119e-02, -5.3310e-03]],\n",
       " \n",
       "          [[-8.5322e-02, -4.2603e-02,  6.8145e-03,  ...,  3.0751e-02,\n",
       "            -3.4818e-02, -4.9945e-02],\n",
       "           [-2.9215e-02,  1.8165e-02,  5.1092e-02,  ...,  9.0200e-02,\n",
       "             5.3438e-02,  4.0169e-02],\n",
       "           [-3.9932e-02, -1.1100e-03,  9.6176e-03,  ...,  2.4114e-02,\n",
       "             2.6298e-02,  2.5489e-02],\n",
       "           ...,\n",
       "           [-3.1890e-03,  3.0454e-02,  1.6316e-02,  ...,  5.5054e-03,\n",
       "            -6.2689e-03, -8.4638e-03],\n",
       "           [-2.2995e-02, -2.8211e-03,  2.3203e-02,  ...,  3.5888e-02,\n",
       "            -1.4296e-02, -3.2419e-02],\n",
       "           [-9.8894e-03,  7.0542e-03,  1.0659e-02,  ...,  7.0495e-02,\n",
       "             1.2996e-02, -8.3417e-03]]],\n",
       " \n",
       " \n",
       "         [[[-7.8699e-03,  1.9911e-02,  3.4208e-02,  ...,  2.8694e-02,\n",
       "             1.2820e-02,  1.8142e-02],\n",
       "           [ 8.7942e-03, -3.2875e-02, -3.5713e-02,  ...,  7.2533e-02,\n",
       "             4.5889e-02,  5.2383e-02],\n",
       "           [-3.6122e-02, -1.1878e-01, -1.3767e-01,  ...,  3.3811e-02,\n",
       "             3.7806e-02,  2.6944e-02],\n",
       "           ...,\n",
       "           [ 1.7322e-02,  3.9589e-03, -8.2269e-03,  ...,  2.7543e-03,\n",
       "             1.8313e-02,  1.6057e-02],\n",
       "           [-9.5007e-04,  1.6428e-02,  1.7156e-02,  ...,  3.3672e-03,\n",
       "             2.2857e-02,  6.5783e-04],\n",
       "           [ 6.1727e-03,  2.7145e-02,  1.4340e-02,  ...,  7.5867e-03,\n",
       "             1.8770e-02,  1.5624e-02]],\n",
       " \n",
       "          [[-1.3423e-02, -5.0696e-04,  8.0959e-03,  ..., -6.0963e-03,\n",
       "             9.2341e-03,  1.5751e-02],\n",
       "           [-1.8343e-02, -6.7982e-02, -7.0685e-02,  ...,  2.9855e-02,\n",
       "             2.6264e-02,  2.3773e-02],\n",
       "           [-5.4359e-02, -1.4663e-01, -1.6211e-01,  ...,  1.1781e-02,\n",
       "             3.2477e-02,  1.1980e-02],\n",
       "           ...,\n",
       "           [ 8.3686e-04, -1.7564e-02, -1.9535e-02,  ..., -4.1382e-03,\n",
       "             2.4658e-02,  1.2893e-02],\n",
       "           [-6.3183e-04,  1.1788e-02,  2.4810e-02,  ...,  6.1105e-03,\n",
       "             3.9210e-02,  9.6696e-03],\n",
       "           [-7.1831e-03,  6.6918e-03,  5.2723e-03,  ..., -7.6077e-03,\n",
       "             2.7253e-02,  1.7735e-02]],\n",
       " \n",
       "          [[-2.3753e-04, -4.9343e-03,  2.2991e-03,  ..., -4.7958e-02,\n",
       "            -2.6154e-02, -2.3525e-02],\n",
       "           [-3.3053e-04, -5.1502e-02, -5.9977e-02,  ..., -1.7369e-02,\n",
       "            -2.3337e-02, -3.7312e-02],\n",
       "           [-2.2674e-02, -9.9412e-02, -1.1176e-01,  ..., -1.1725e-02,\n",
       "            -8.3744e-03, -4.0615e-02],\n",
       "           ...,\n",
       "           [ 1.1437e-02, -8.0313e-03, -1.4955e-03,  ..., -3.4133e-02,\n",
       "            -8.7267e-03, -2.3526e-02],\n",
       "           [ 2.9522e-03,  6.7770e-04,  1.9933e-02,  ..., -2.2002e-02,\n",
       "             1.4814e-02, -1.4487e-02],\n",
       "           [-1.9085e-02, -2.9430e-02, -2.3284e-02,  ..., -4.8587e-02,\n",
       "            -1.3049e-02, -2.4368e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.6296e-02,  7.1996e-03,  1.9100e-02,  ...,  1.9602e-02,\n",
       "             1.4870e-02, -1.7298e-02],\n",
       "           [-1.1061e-02,  8.5665e-02,  1.2667e-01,  ...,  1.3744e-02,\n",
       "            -5.5036e-05, -3.0162e-02],\n",
       "           [ 1.1322e-01,  1.8634e-01,  5.0658e-02,  ..., -1.7333e-01,\n",
       "            -7.2041e-02, -6.2474e-02],\n",
       "           ...,\n",
       "           [-5.3062e-02, -2.5781e-01, -2.6747e-01,  ...,  2.6781e-01,\n",
       "             1.4344e-01,  5.5145e-02],\n",
       "           [-2.1009e-02, -2.9969e-02,  1.0245e-01,  ...,  2.0843e-01,\n",
       "            -4.1518e-03, -3.8118e-02],\n",
       "           [-2.2155e-02,  1.2380e-02,  8.4302e-02,  ..., -4.4992e-02,\n",
       "            -1.4687e-01, -9.0890e-02]],\n",
       " \n",
       "          [[-5.3969e-03,  3.2799e-02,  1.5486e-02,  ..., -7.7451e-03,\n",
       "             3.0229e-03,  1.1216e-03],\n",
       "           [ 6.1723e-02,  1.4899e-01,  1.4645e-01,  ..., -2.8897e-02,\n",
       "            -2.0227e-02, -9.1878e-03],\n",
       "           [ 1.6146e-01,  2.0886e-01, -2.5589e-02,  ..., -2.7278e-01,\n",
       "            -1.0735e-01, -6.2971e-02],\n",
       "           ...,\n",
       "           [-1.3723e-01, -4.0863e-01, -3.8551e-01,  ...,  4.0846e-01,\n",
       "             2.6202e-01,  1.3491e-01],\n",
       "           [-5.9388e-02, -6.1187e-02,  1.4197e-01,  ...,  3.5780e-01,\n",
       "             9.0893e-02, -1.7392e-03],\n",
       "           [ 7.8613e-03,  5.8403e-02,  1.5339e-01,  ...,  4.7045e-02,\n",
       "            -1.0095e-01, -9.7920e-02]],\n",
       " \n",
       "          [[-5.6799e-03,  1.3425e-02, -2.6461e-02,  ...,  4.4881e-03,\n",
       "             2.0666e-03,  1.3902e-02],\n",
       "           [ 6.5943e-03,  4.5181e-02,  6.0260e-02,  ...,  1.4368e-02,\n",
       "            -5.0725e-03,  4.0505e-03],\n",
       "           [ 5.5257e-02,  1.2397e-01,  4.3193e-02,  ..., -1.4486e-01,\n",
       "            -7.4489e-02, -5.7533e-02],\n",
       "           ...,\n",
       "           [-3.1513e-02, -1.6334e-01, -1.5795e-01,  ...,  2.2904e-01,\n",
       "             1.2017e-01,  7.1998e-02],\n",
       "           [-1.0456e-02, -1.1248e-03,  8.4582e-02,  ...,  1.5748e-01,\n",
       "             2.2142e-02, -1.0083e-02],\n",
       "           [-4.8639e-03, -5.0065e-03,  3.6341e-02,  ..., -2.4361e-02,\n",
       "            -7.1195e-02, -6.6788e-02]]]], requires_grad=True)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dict(model.named_children())['conv1'].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9fa1f5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#微调\n",
    "#修改模型（将1000类改为10类输出）\n",
    "#改变输入通道数（比如我们传入的图片是单通道的，但是模型需要的是三通道图片） \n",
    "#我们可以通过添加in_chans=1来改变\n",
    "model = timm.create_model('resnet18',num_classes=10,pretrained=True,in_chans=1)\n",
    "x = torch.randn(1,1,224,224)\n",
    "output = model(x)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41886603",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#模型保存\n",
    "torch.save(model.state_dict(),'./checkpoint/timm_model.pth')\n",
    "model.load_state_dict(torch.load('./checkpoint/timm_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ec754c0e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "db1af780",
   "metadata": {},
   "source": [
    "## 3、半精度训练\n",
    "问题：\n",
    "- GPU的性能主要分为两部分：算力和显存。\n",
    "- 前者决定了显卡计算的速度，后者则决定了显卡可以同时放入多少数据用于计算\n",
    "- 在可以使用的显存数量一定的情况下，每次训练能够加载的数据更多（也就是batch size更大），则也可以提高训练效率\n",
    "\n",
    "定义：\n",
    "- PyTorch默认的浮点数存储方式用的是torch.float32，小数点后位数更多固然能保证数据的精确性\n",
    "- 但绝大多数场景其实并不需要这么精确，只保留一半的信息也不会影响结果，也就是使用torch.float16格式。由于数位减了一半，因此被称为“半精度”\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "显然半精度能够减少显存占用，使得显卡可以同时加载更多数据进行计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb5294f",
   "metadata": {},
   "source": [
    "### 3.1、半精度训练的设置\n",
    "- 1、引入 from torch.cuda.amp import autocast\n",
    "- 2、forward函数指定 autocast 装饰器\n",
    "- 3、训练过程： 只需在将数据输入模型及其之后的部分放入“with autocast():“\n",
    "- 4、半精度训练主要适用于数据本身的size比较大（比如说3D图像、视频等）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f54553a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# 引入\n",
    "\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "```python\n",
    "# forward指定装饰器\n",
    "@autocast()   \n",
    "def forward(self, x):\n",
    "    ...\n",
    "    return x\n",
    "```\n",
    "\n",
    "```python\n",
    "# 训练过程中：指定with autocast \n",
    " for x in train_loader:\n",
    "\tx = x.cuda()\n",
    "\twith autocast():\n",
    "      output = model(x)\n",
    "        ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de912d51",
   "metadata": {},
   "source": [
    "### 半精度训练案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c39de300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast\n",
    "# 半精度模型\n",
    "class DemoModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DemoModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    @autocast() \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "316468c2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [1/3125], train_loss:0.145123\n",
      "Epoch [1/2], Iter [2/3125], train_loss:0.144603\n",
      "Epoch [1/2], Iter [3/3125], train_loss:0.142649\n",
      "Epoch [1/2], Iter [4/3125], train_loss:0.144464\n",
      "Epoch [1/2], Iter [5/3125], train_loss:0.144249\n",
      "Epoch [1/2], Iter [6/3125], train_loss:0.144539\n",
      "Epoch [1/2], Iter [7/3125], train_loss:0.144195\n",
      "Epoch [1/2], Iter [8/3125], train_loss:0.143397\n",
      "Epoch [1/2], Iter [9/3125], train_loss:0.143726\n",
      "Epoch [1/2], Iter [10/3125], train_loss:0.144140\n",
      "Epoch [1/2], Iter [11/3125], train_loss:0.146184\n",
      "Epoch [1/2], Iter [12/3125], train_loss:0.145353\n",
      "Epoch [1/2], Iter [13/3125], train_loss:0.144314\n",
      "Epoch [1/2], Iter [14/3125], train_loss:0.142131\n",
      "Epoch [1/2], Iter [15/3125], train_loss:0.143993\n",
      "Epoch [1/2], Iter [16/3125], train_loss:0.143918\n",
      "Epoch [1/2], Iter [17/3125], train_loss:0.145396\n",
      "Epoch [1/2], Iter [18/3125], train_loss:0.144910\n",
      "Epoch [1/2], Iter [19/3125], train_loss:0.144746\n",
      "Epoch [1/2], Iter [20/3125], train_loss:0.142712\n",
      "Epoch [1/2], Iter [21/3125], train_loss:0.143974\n",
      "Epoch [1/2], Iter [22/3125], train_loss:0.143953\n",
      "Epoch [1/2], Iter [23/3125], train_loss:0.144154\n",
      "Epoch [1/2], Iter [24/3125], train_loss:0.144382\n",
      "Epoch [1/2], Iter [25/3125], train_loss:0.145523\n",
      "Epoch [1/2], Iter [26/3125], train_loss:0.143125\n",
      "Epoch [1/2], Iter [27/3125], train_loss:0.144682\n",
      "Epoch [1/2], Iter [28/3125], train_loss:0.143990\n",
      "Epoch [1/2], Iter [29/3125], train_loss:0.142709\n",
      "Epoch [1/2], Iter [30/3125], train_loss:0.143686\n",
      "Epoch [1/2], Iter [31/3125], train_loss:0.145638\n",
      "Epoch [1/2], Iter [32/3125], train_loss:0.143845\n",
      "Epoch [1/2], Iter [33/3125], train_loss:0.144406\n",
      "Epoch [1/2], Iter [34/3125], train_loss:0.142429\n",
      "Epoch [1/2], Iter [35/3125], train_loss:0.143678\n",
      "Epoch [1/2], Iter [36/3125], train_loss:0.144910\n",
      "Epoch [1/2], Iter [37/3125], train_loss:0.143973\n",
      "Epoch [1/2], Iter [38/3125], train_loss:0.144017\n",
      "Epoch [1/2], Iter [39/3125], train_loss:0.142608\n",
      "Epoch [1/2], Iter [40/3125], train_loss:0.143920\n",
      "Epoch [1/2], Iter [41/3125], train_loss:0.143526\n",
      "Epoch [1/2], Iter [42/3125], train_loss:0.144401\n",
      "Epoch [1/2], Iter [43/3125], train_loss:0.144161\n",
      "Epoch [1/2], Iter [44/3125], train_loss:0.144129\n",
      "Epoch [1/2], Iter [45/3125], train_loss:0.141828\n",
      "Epoch [1/2], Iter [46/3125], train_loss:0.144010\n",
      "Epoch [1/2], Iter [47/3125], train_loss:0.144050\n",
      "Epoch [1/2], Iter [48/3125], train_loss:0.144074\n",
      "Epoch [1/2], Iter [49/3125], train_loss:0.144133\n",
      "Epoch [1/2], Iter [50/3125], train_loss:0.144839\n",
      "Epoch [1/2], Iter [51/3125], train_loss:0.143798\n",
      "Epoch [1/2], Iter [52/3125], train_loss:0.142310\n",
      "Epoch [1/2], Iter [53/3125], train_loss:0.145090\n",
      "Epoch [1/2], Iter [54/3125], train_loss:0.142551\n",
      "Epoch [1/2], Iter [55/3125], train_loss:0.144017\n",
      "Epoch [1/2], Iter [56/3125], train_loss:0.144078\n",
      "Epoch [1/2], Iter [57/3125], train_loss:0.145832\n",
      "Epoch [1/2], Iter [58/3125], train_loss:0.144701\n",
      "Epoch [1/2], Iter [59/3125], train_loss:0.144726\n",
      "Epoch [1/2], Iter [60/3125], train_loss:0.143524\n",
      "Epoch [1/2], Iter [61/3125], train_loss:0.145250\n",
      "Epoch [1/2], Iter [62/3125], train_loss:0.145123\n",
      "Epoch [1/2], Iter [63/3125], train_loss:0.144435\n",
      "Epoch [1/2], Iter [64/3125], train_loss:0.143848\n",
      "Epoch [1/2], Iter [65/3125], train_loss:0.143405\n",
      "Epoch [1/2], Iter [66/3125], train_loss:0.143880\n",
      "Epoch [1/2], Iter [67/3125], train_loss:0.142896\n",
      "Epoch [1/2], Iter [68/3125], train_loss:0.144159\n",
      "Epoch [1/2], Iter [69/3125], train_loss:0.143277\n",
      "Epoch [1/2], Iter [70/3125], train_loss:0.142938\n",
      "Epoch [1/2], Iter [71/3125], train_loss:0.144635\n",
      "Epoch [1/2], Iter [72/3125], train_loss:0.143863\n",
      "Epoch [1/2], Iter [73/3125], train_loss:0.142993\n",
      "Epoch [1/2], Iter [74/3125], train_loss:0.142896\n",
      "Epoch [1/2], Iter [75/3125], train_loss:0.145138\n",
      "Epoch [1/2], Iter [76/3125], train_loss:0.144579\n",
      "Epoch [1/2], Iter [77/3125], train_loss:0.145725\n",
      "Epoch [1/2], Iter [78/3125], train_loss:0.144555\n",
      "Epoch [1/2], Iter [79/3125], train_loss:0.143831\n",
      "Epoch [1/2], Iter [80/3125], train_loss:0.145404\n",
      "Epoch [1/2], Iter [81/3125], train_loss:0.144425\n",
      "Epoch [1/2], Iter [82/3125], train_loss:0.143490\n",
      "Epoch [1/2], Iter [83/3125], train_loss:0.142418\n",
      "Epoch [1/2], Iter [84/3125], train_loss:0.144318\n",
      "Epoch [1/2], Iter [85/3125], train_loss:0.143453\n",
      "Epoch [1/2], Iter [86/3125], train_loss:0.143731\n",
      "Epoch [1/2], Iter [87/3125], train_loss:0.144668\n",
      "Epoch [1/2], Iter [88/3125], train_loss:0.144858\n",
      "Epoch [1/2], Iter [89/3125], train_loss:0.143293\n",
      "Epoch [1/2], Iter [90/3125], train_loss:0.143322\n",
      "Epoch [1/2], Iter [91/3125], train_loss:0.144684\n",
      "Epoch [1/2], Iter [92/3125], train_loss:0.143951\n",
      "Epoch [1/2], Iter [93/3125], train_loss:0.145094\n",
      "Epoch [1/2], Iter [94/3125], train_loss:0.143247\n",
      "Epoch [1/2], Iter [95/3125], train_loss:0.144266\n",
      "Epoch [1/2], Iter [96/3125], train_loss:0.142758\n",
      "Epoch [1/2], Iter [97/3125], train_loss:0.142844\n",
      "Epoch [1/2], Iter [98/3125], train_loss:0.144202\n",
      "Epoch [1/2], Iter [99/3125], train_loss:0.145142\n",
      "Epoch [1/2], Iter [100/3125], train_loss:0.144664\n",
      "Epoch [1/2], Iter [101/3125], train_loss:0.143905\n",
      "Epoch [1/2], Iter [102/3125], train_loss:0.144148\n",
      "Epoch [1/2], Iter [103/3125], train_loss:0.144533\n",
      "Epoch [1/2], Iter [104/3125], train_loss:0.142602\n",
      "Epoch [1/2], Iter [105/3125], train_loss:0.144229\n",
      "Epoch [1/2], Iter [106/3125], train_loss:0.145189\n",
      "Epoch [1/2], Iter [107/3125], train_loss:0.143734\n",
      "Epoch [1/2], Iter [108/3125], train_loss:0.144772\n",
      "Epoch [1/2], Iter [109/3125], train_loss:0.143265\n",
      "Epoch [1/2], Iter [110/3125], train_loss:0.145287\n",
      "Epoch [1/2], Iter [111/3125], train_loss:0.142609\n",
      "Epoch [1/2], Iter [112/3125], train_loss:0.143817\n",
      "Epoch [1/2], Iter [113/3125], train_loss:0.144015\n",
      "Epoch [1/2], Iter [114/3125], train_loss:0.144052\n",
      "Epoch [1/2], Iter [115/3125], train_loss:0.143653\n",
      "Epoch [1/2], Iter [116/3125], train_loss:0.142899\n",
      "Epoch [1/2], Iter [117/3125], train_loss:0.143484\n",
      "Epoch [1/2], Iter [118/3125], train_loss:0.143730\n",
      "Epoch [1/2], Iter [119/3125], train_loss:0.144217\n",
      "Epoch [1/2], Iter [120/3125], train_loss:0.144058\n",
      "Epoch [1/2], Iter [121/3125], train_loss:0.143485\n",
      "Epoch [1/2], Iter [122/3125], train_loss:0.143949\n",
      "Epoch [1/2], Iter [123/3125], train_loss:0.144037\n",
      "Epoch [1/2], Iter [124/3125], train_loss:0.143595\n",
      "Epoch [1/2], Iter [125/3125], train_loss:0.144441\n",
      "Epoch [1/2], Iter [126/3125], train_loss:0.142202\n",
      "Epoch [1/2], Iter [127/3125], train_loss:0.144581\n",
      "Epoch [1/2], Iter [128/3125], train_loss:0.143443\n",
      "Epoch [1/2], Iter [129/3125], train_loss:0.145869\n",
      "Epoch [1/2], Iter [130/3125], train_loss:0.143927\n",
      "Epoch [1/2], Iter [131/3125], train_loss:0.143736\n",
      "Epoch [1/2], Iter [132/3125], train_loss:0.144015\n",
      "Epoch [1/2], Iter [133/3125], train_loss:0.142674\n",
      "Epoch [1/2], Iter [134/3125], train_loss:0.144576\n",
      "Epoch [1/2], Iter [135/3125], train_loss:0.142641\n",
      "Epoch [1/2], Iter [136/3125], train_loss:0.144341\n",
      "Epoch [1/2], Iter [137/3125], train_loss:0.143068\n",
      "Epoch [1/2], Iter [138/3125], train_loss:0.144781\n",
      "Epoch [1/2], Iter [139/3125], train_loss:0.143179\n",
      "Epoch [1/2], Iter [140/3125], train_loss:0.143241\n",
      "Epoch [1/2], Iter [141/3125], train_loss:0.143996\n",
      "Epoch [1/2], Iter [142/3125], train_loss:0.144313\n",
      "Epoch [1/2], Iter [143/3125], train_loss:0.144490\n",
      "Epoch [1/2], Iter [144/3125], train_loss:0.143811\n",
      "Epoch [1/2], Iter [145/3125], train_loss:0.144611\n",
      "Epoch [1/2], Iter [146/3125], train_loss:0.143696\n",
      "Epoch [1/2], Iter [147/3125], train_loss:0.145448\n",
      "Epoch [1/2], Iter [148/3125], train_loss:0.145041\n",
      "Epoch [1/2], Iter [149/3125], train_loss:0.143520\n",
      "Epoch [1/2], Iter [150/3125], train_loss:0.143766\n",
      "Epoch [1/2], Iter [151/3125], train_loss:0.143931\n",
      "Epoch [1/2], Iter [152/3125], train_loss:0.143328\n",
      "Epoch [1/2], Iter [153/3125], train_loss:0.143918\n",
      "Epoch [1/2], Iter [154/3125], train_loss:0.143795\n",
      "Epoch [1/2], Iter [155/3125], train_loss:0.143427\n",
      "Epoch [1/2], Iter [156/3125], train_loss:0.143433\n",
      "Epoch [1/2], Iter [157/3125], train_loss:0.143669\n",
      "Epoch [1/2], Iter [158/3125], train_loss:0.143044\n",
      "Epoch [1/2], Iter [159/3125], train_loss:0.145075\n",
      "Epoch [1/2], Iter [160/3125], train_loss:0.144249\n",
      "Epoch [1/2], Iter [161/3125], train_loss:0.143763\n",
      "Epoch [1/2], Iter [162/3125], train_loss:0.143850\n",
      "Epoch [1/2], Iter [163/3125], train_loss:0.143536\n",
      "Epoch [1/2], Iter [164/3125], train_loss:0.144605\n",
      "Epoch [1/2], Iter [165/3125], train_loss:0.143409\n",
      "Epoch [1/2], Iter [166/3125], train_loss:0.143451\n",
      "Epoch [1/2], Iter [167/3125], train_loss:0.145272\n",
      "Epoch [1/2], Iter [168/3125], train_loss:0.144321\n",
      "Epoch [1/2], Iter [169/3125], train_loss:0.144229\n",
      "Epoch [1/2], Iter [170/3125], train_loss:0.141779\n",
      "Epoch [1/2], Iter [171/3125], train_loss:0.143077\n",
      "Epoch [1/2], Iter [172/3125], train_loss:0.144299\n",
      "Epoch [1/2], Iter [173/3125], train_loss:0.143962\n",
      "Epoch [1/2], Iter [174/3125], train_loss:0.145295\n",
      "Epoch [1/2], Iter [175/3125], train_loss:0.144075\n",
      "Epoch [1/2], Iter [176/3125], train_loss:0.143934\n",
      "Epoch [1/2], Iter [177/3125], train_loss:0.145711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [178/3125], train_loss:0.144303\n",
      "Epoch [1/2], Iter [179/3125], train_loss:0.144267\n",
      "Epoch [1/2], Iter [180/3125], train_loss:0.143710\n",
      "Epoch [1/2], Iter [181/3125], train_loss:0.144358\n",
      "Epoch [1/2], Iter [182/3125], train_loss:0.143774\n",
      "Epoch [1/2], Iter [183/3125], train_loss:0.145248\n",
      "Epoch [1/2], Iter [184/3125], train_loss:0.144374\n",
      "Epoch [1/2], Iter [185/3125], train_loss:0.145249\n",
      "Epoch [1/2], Iter [186/3125], train_loss:0.144803\n",
      "Epoch [1/2], Iter [187/3125], train_loss:0.143089\n",
      "Epoch [1/2], Iter [188/3125], train_loss:0.144409\n",
      "Epoch [1/2], Iter [189/3125], train_loss:0.142790\n",
      "Epoch [1/2], Iter [190/3125], train_loss:0.143664\n",
      "Epoch [1/2], Iter [191/3125], train_loss:0.144454\n",
      "Epoch [1/2], Iter [192/3125], train_loss:0.142591\n",
      "Epoch [1/2], Iter [193/3125], train_loss:0.144734\n",
      "Epoch [1/2], Iter [194/3125], train_loss:0.144165\n",
      "Epoch [1/2], Iter [195/3125], train_loss:0.145281\n",
      "Epoch [1/2], Iter [196/3125], train_loss:0.144067\n",
      "Epoch [1/2], Iter [197/3125], train_loss:0.142798\n",
      "Epoch [1/2], Iter [198/3125], train_loss:0.143304\n",
      "Epoch [1/2], Iter [199/3125], train_loss:0.144590\n",
      "Epoch [1/2], Iter [200/3125], train_loss:0.142651\n",
      "Epoch [1/2], Iter [201/3125], train_loss:0.143424\n",
      "Epoch [1/2], Iter [202/3125], train_loss:0.144029\n",
      "Epoch [1/2], Iter [203/3125], train_loss:0.144353\n",
      "Epoch [1/2], Iter [204/3125], train_loss:0.143733\n",
      "Epoch [1/2], Iter [205/3125], train_loss:0.144383\n",
      "Epoch [1/2], Iter [206/3125], train_loss:0.143550\n",
      "Epoch [1/2], Iter [207/3125], train_loss:0.144757\n",
      "Epoch [1/2], Iter [208/3125], train_loss:0.145007\n",
      "Epoch [1/2], Iter [209/3125], train_loss:0.143492\n",
      "Epoch [1/2], Iter [210/3125], train_loss:0.144105\n",
      "Epoch [1/2], Iter [211/3125], train_loss:0.143015\n",
      "Epoch [1/2], Iter [212/3125], train_loss:0.144304\n",
      "Epoch [1/2], Iter [213/3125], train_loss:0.143890\n",
      "Epoch [1/2], Iter [214/3125], train_loss:0.143652\n",
      "Epoch [1/2], Iter [215/3125], train_loss:0.144394\n",
      "Epoch [1/2], Iter [216/3125], train_loss:0.142498\n",
      "Epoch [1/2], Iter [217/3125], train_loss:0.145023\n",
      "Epoch [1/2], Iter [218/3125], train_loss:0.144854\n",
      "Epoch [1/2], Iter [219/3125], train_loss:0.143027\n",
      "Epoch [1/2], Iter [220/3125], train_loss:0.143117\n",
      "Epoch [1/2], Iter [221/3125], train_loss:0.144690\n",
      "Epoch [1/2], Iter [222/3125], train_loss:0.144028\n",
      "Epoch [1/2], Iter [223/3125], train_loss:0.144425\n",
      "Epoch [1/2], Iter [224/3125], train_loss:0.144978\n",
      "Epoch [1/2], Iter [225/3125], train_loss:0.143735\n",
      "Epoch [1/2], Iter [226/3125], train_loss:0.143588\n",
      "Epoch [1/2], Iter [227/3125], train_loss:0.145636\n",
      "Epoch [1/2], Iter [228/3125], train_loss:0.145386\n",
      "Epoch [1/2], Iter [229/3125], train_loss:0.144459\n",
      "Epoch [1/2], Iter [230/3125], train_loss:0.144033\n",
      "Epoch [1/2], Iter [231/3125], train_loss:0.144328\n",
      "Epoch [1/2], Iter [232/3125], train_loss:0.144164\n",
      "Epoch [1/2], Iter [233/3125], train_loss:0.143867\n",
      "Epoch [1/2], Iter [234/3125], train_loss:0.143866\n",
      "Epoch [1/2], Iter [235/3125], train_loss:0.144172\n",
      "Epoch [1/2], Iter [236/3125], train_loss:0.144344\n",
      "Epoch [1/2], Iter [237/3125], train_loss:0.143802\n",
      "Epoch [1/2], Iter [238/3125], train_loss:0.144098\n",
      "Epoch [1/2], Iter [239/3125], train_loss:0.144233\n",
      "Epoch [1/2], Iter [240/3125], train_loss:0.143733\n",
      "Epoch [1/2], Iter [241/3125], train_loss:0.142867\n",
      "Epoch [1/2], Iter [242/3125], train_loss:0.143252\n",
      "Epoch [1/2], Iter [243/3125], train_loss:0.143172\n",
      "Epoch [1/2], Iter [244/3125], train_loss:0.145077\n",
      "Epoch [1/2], Iter [245/3125], train_loss:0.144917\n",
      "Epoch [1/2], Iter [246/3125], train_loss:0.143621\n",
      "Epoch [1/2], Iter [247/3125], train_loss:0.145420\n",
      "Epoch [1/2], Iter [248/3125], train_loss:0.143262\n",
      "Epoch [1/2], Iter [249/3125], train_loss:0.143505\n",
      "Epoch [1/2], Iter [250/3125], train_loss:0.145192\n",
      "Epoch [1/2], Iter [251/3125], train_loss:0.144420\n",
      "Epoch [1/2], Iter [252/3125], train_loss:0.144301\n",
      "Epoch [1/2], Iter [253/3125], train_loss:0.144358\n",
      "Epoch [1/2], Iter [254/3125], train_loss:0.144582\n",
      "Epoch [1/2], Iter [255/3125], train_loss:0.142994\n",
      "Epoch [1/2], Iter [256/3125], train_loss:0.143743\n",
      "Epoch [1/2], Iter [257/3125], train_loss:0.143121\n",
      "Epoch [1/2], Iter [258/3125], train_loss:0.144393\n",
      "Epoch [1/2], Iter [259/3125], train_loss:0.143963\n",
      "Epoch [1/2], Iter [260/3125], train_loss:0.144898\n",
      "Epoch [1/2], Iter [261/3125], train_loss:0.144346\n",
      "Epoch [1/2], Iter [262/3125], train_loss:0.144585\n",
      "Epoch [1/2], Iter [263/3125], train_loss:0.144545\n",
      "Epoch [1/2], Iter [264/3125], train_loss:0.143658\n",
      "Epoch [1/2], Iter [265/3125], train_loss:0.144095\n",
      "Epoch [1/2], Iter [266/3125], train_loss:0.143290\n",
      "Epoch [1/2], Iter [267/3125], train_loss:0.144281\n",
      "Epoch [1/2], Iter [268/3125], train_loss:0.143689\n",
      "Epoch [1/2], Iter [269/3125], train_loss:0.143588\n",
      "Epoch [1/2], Iter [270/3125], train_loss:0.144217\n",
      "Epoch [1/2], Iter [271/3125], train_loss:0.144080\n",
      "Epoch [1/2], Iter [272/3125], train_loss:0.144606\n",
      "Epoch [1/2], Iter [273/3125], train_loss:0.143468\n",
      "Epoch [1/2], Iter [274/3125], train_loss:0.143654\n",
      "Epoch [1/2], Iter [275/3125], train_loss:0.143796\n",
      "Epoch [1/2], Iter [276/3125], train_loss:0.143784\n",
      "Epoch [1/2], Iter [277/3125], train_loss:0.144736\n",
      "Epoch [1/2], Iter [278/3125], train_loss:0.144746\n",
      "Epoch [1/2], Iter [279/3125], train_loss:0.144306\n",
      "Epoch [1/2], Iter [280/3125], train_loss:0.143289\n",
      "Epoch [1/2], Iter [281/3125], train_loss:0.143650\n",
      "Epoch [1/2], Iter [282/3125], train_loss:0.145434\n",
      "Epoch [1/2], Iter [283/3125], train_loss:0.144194\n",
      "Epoch [1/2], Iter [284/3125], train_loss:0.143631\n",
      "Epoch [1/2], Iter [285/3125], train_loss:0.143755\n",
      "Epoch [1/2], Iter [286/3125], train_loss:0.143541\n",
      "Epoch [1/2], Iter [287/3125], train_loss:0.144538\n",
      "Epoch [1/2], Iter [288/3125], train_loss:0.142920\n",
      "Epoch [1/2], Iter [289/3125], train_loss:0.146206\n",
      "Epoch [1/2], Iter [290/3125], train_loss:0.143666\n",
      "Epoch [1/2], Iter [291/3125], train_loss:0.143461\n",
      "Epoch [1/2], Iter [292/3125], train_loss:0.144256\n",
      "Epoch [1/2], Iter [293/3125], train_loss:0.143739\n",
      "Epoch [1/2], Iter [294/3125], train_loss:0.145513\n",
      "Epoch [1/2], Iter [295/3125], train_loss:0.144548\n",
      "Epoch [1/2], Iter [296/3125], train_loss:0.144947\n",
      "Epoch [1/2], Iter [297/3125], train_loss:0.144508\n",
      "Epoch [1/2], Iter [298/3125], train_loss:0.145361\n",
      "Epoch [1/2], Iter [299/3125], train_loss:0.143741\n",
      "Epoch [1/2], Iter [300/3125], train_loss:0.145236\n",
      "Epoch [1/2], Iter [301/3125], train_loss:0.142869\n",
      "Epoch [1/2], Iter [302/3125], train_loss:0.144584\n",
      "Epoch [1/2], Iter [303/3125], train_loss:0.143980\n",
      "Epoch [1/2], Iter [304/3125], train_loss:0.144357\n",
      "Epoch [1/2], Iter [305/3125], train_loss:0.143774\n",
      "Epoch [1/2], Iter [306/3125], train_loss:0.143550\n",
      "Epoch [1/2], Iter [307/3125], train_loss:0.145008\n",
      "Epoch [1/2], Iter [308/3125], train_loss:0.144083\n",
      "Epoch [1/2], Iter [309/3125], train_loss:0.143114\n",
      "Epoch [1/2], Iter [310/3125], train_loss:0.143013\n",
      "Epoch [1/2], Iter [311/3125], train_loss:0.144277\n",
      "Epoch [1/2], Iter [312/3125], train_loss:0.142777\n",
      "Epoch [1/2], Iter [313/3125], train_loss:0.143852\n",
      "Epoch [1/2], Iter [314/3125], train_loss:0.145015\n",
      "Epoch [1/2], Iter [315/3125], train_loss:0.143620\n",
      "Epoch [1/2], Iter [316/3125], train_loss:0.143359\n",
      "Epoch [1/2], Iter [317/3125], train_loss:0.144581\n",
      "Epoch [1/2], Iter [318/3125], train_loss:0.144784\n",
      "Epoch [1/2], Iter [319/3125], train_loss:0.144172\n",
      "Epoch [1/2], Iter [320/3125], train_loss:0.145035\n",
      "Epoch [1/2], Iter [321/3125], train_loss:0.144481\n",
      "Epoch [1/2], Iter [322/3125], train_loss:0.143538\n",
      "Epoch [1/2], Iter [323/3125], train_loss:0.143296\n",
      "Epoch [1/2], Iter [324/3125], train_loss:0.144243\n",
      "Epoch [1/2], Iter [325/3125], train_loss:0.143849\n",
      "Epoch [1/2], Iter [326/3125], train_loss:0.145094\n",
      "Epoch [1/2], Iter [327/3125], train_loss:0.144097\n",
      "Epoch [1/2], Iter [328/3125], train_loss:0.143257\n",
      "Epoch [1/2], Iter [329/3125], train_loss:0.142380\n",
      "Epoch [1/2], Iter [330/3125], train_loss:0.143339\n",
      "Epoch [1/2], Iter [331/3125], train_loss:0.144219\n",
      "Epoch [1/2], Iter [332/3125], train_loss:0.142517\n",
      "Epoch [1/2], Iter [333/3125], train_loss:0.142724\n",
      "Epoch [1/2], Iter [334/3125], train_loss:0.142649\n",
      "Epoch [1/2], Iter [335/3125], train_loss:0.144261\n",
      "Epoch [1/2], Iter [336/3125], train_loss:0.144854\n",
      "Epoch [1/2], Iter [337/3125], train_loss:0.143199\n",
      "Epoch [1/2], Iter [338/3125], train_loss:0.144743\n",
      "Epoch [1/2], Iter [339/3125], train_loss:0.144337\n",
      "Epoch [1/2], Iter [340/3125], train_loss:0.145490\n",
      "Epoch [1/2], Iter [341/3125], train_loss:0.142938\n",
      "Epoch [1/2], Iter [342/3125], train_loss:0.143423\n",
      "Epoch [1/2], Iter [343/3125], train_loss:0.144358\n",
      "Epoch [1/2], Iter [344/3125], train_loss:0.144531\n",
      "Epoch [1/2], Iter [345/3125], train_loss:0.143050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [346/3125], train_loss:0.144353\n",
      "Epoch [1/2], Iter [347/3125], train_loss:0.144403\n",
      "Epoch [1/2], Iter [348/3125], train_loss:0.141771\n",
      "Epoch [1/2], Iter [349/3125], train_loss:0.144969\n",
      "Epoch [1/2], Iter [350/3125], train_loss:0.143520\n",
      "Epoch [1/2], Iter [351/3125], train_loss:0.144363\n",
      "Epoch [1/2], Iter [352/3125], train_loss:0.143325\n",
      "Epoch [1/2], Iter [353/3125], train_loss:0.143918\n",
      "Epoch [1/2], Iter [354/3125], train_loss:0.145524\n",
      "Epoch [1/2], Iter [355/3125], train_loss:0.144857\n",
      "Epoch [1/2], Iter [356/3125], train_loss:0.143817\n",
      "Epoch [1/2], Iter [357/3125], train_loss:0.143084\n",
      "Epoch [1/2], Iter [358/3125], train_loss:0.145299\n",
      "Epoch [1/2], Iter [359/3125], train_loss:0.143585\n",
      "Epoch [1/2], Iter [360/3125], train_loss:0.142092\n",
      "Epoch [1/2], Iter [361/3125], train_loss:0.141837\n",
      "Epoch [1/2], Iter [362/3125], train_loss:0.143359\n",
      "Epoch [1/2], Iter [363/3125], train_loss:0.144293\n",
      "Epoch [1/2], Iter [364/3125], train_loss:0.145145\n",
      "Epoch [1/2], Iter [365/3125], train_loss:0.144505\n",
      "Epoch [1/2], Iter [366/3125], train_loss:0.143487\n",
      "Epoch [1/2], Iter [367/3125], train_loss:0.144058\n",
      "Epoch [1/2], Iter [368/3125], train_loss:0.145123\n",
      "Epoch [1/2], Iter [369/3125], train_loss:0.145615\n",
      "Epoch [1/2], Iter [370/3125], train_loss:0.142253\n",
      "Epoch [1/2], Iter [371/3125], train_loss:0.144285\n",
      "Epoch [1/2], Iter [372/3125], train_loss:0.143398\n",
      "Epoch [1/2], Iter [373/3125], train_loss:0.145253\n",
      "Epoch [1/2], Iter [374/3125], train_loss:0.145722\n",
      "Epoch [1/2], Iter [375/3125], train_loss:0.143899\n",
      "Epoch [1/2], Iter [376/3125], train_loss:0.146248\n",
      "Epoch [1/2], Iter [377/3125], train_loss:0.144375\n",
      "Epoch [1/2], Iter [378/3125], train_loss:0.144347\n",
      "Epoch [1/2], Iter [379/3125], train_loss:0.144282\n",
      "Epoch [1/2], Iter [380/3125], train_loss:0.145407\n",
      "Epoch [1/2], Iter [381/3125], train_loss:0.144719\n",
      "Epoch [1/2], Iter [382/3125], train_loss:0.143937\n",
      "Epoch [1/2], Iter [383/3125], train_loss:0.143794\n",
      "Epoch [1/2], Iter [384/3125], train_loss:0.143620\n",
      "Epoch [1/2], Iter [385/3125], train_loss:0.144129\n",
      "Epoch [1/2], Iter [386/3125], train_loss:0.142818\n",
      "Epoch [1/2], Iter [387/3125], train_loss:0.144101\n",
      "Epoch [1/2], Iter [388/3125], train_loss:0.143447\n",
      "Epoch [1/2], Iter [389/3125], train_loss:0.142684\n",
      "Epoch [1/2], Iter [390/3125], train_loss:0.144413\n",
      "Epoch [1/2], Iter [391/3125], train_loss:0.142835\n",
      "Epoch [1/2], Iter [392/3125], train_loss:0.143616\n",
      "Epoch [1/2], Iter [393/3125], train_loss:0.143371\n",
      "Epoch [1/2], Iter [394/3125], train_loss:0.143027\n",
      "Epoch [1/2], Iter [395/3125], train_loss:0.143053\n",
      "Epoch [1/2], Iter [396/3125], train_loss:0.145457\n",
      "Epoch [1/2], Iter [397/3125], train_loss:0.144000\n",
      "Epoch [1/2], Iter [398/3125], train_loss:0.143500\n",
      "Epoch [1/2], Iter [399/3125], train_loss:0.143394\n",
      "Epoch [1/2], Iter [400/3125], train_loss:0.144436\n",
      "Epoch [1/2], Iter [401/3125], train_loss:0.144239\n",
      "Epoch [1/2], Iter [402/3125], train_loss:0.143520\n",
      "Epoch [1/2], Iter [403/3125], train_loss:0.143963\n",
      "Epoch [1/2], Iter [404/3125], train_loss:0.144476\n",
      "Epoch [1/2], Iter [405/3125], train_loss:0.143889\n",
      "Epoch [1/2], Iter [406/3125], train_loss:0.144571\n",
      "Epoch [1/2], Iter [407/3125], train_loss:0.144867\n",
      "Epoch [1/2], Iter [408/3125], train_loss:0.142227\n",
      "Epoch [1/2], Iter [409/3125], train_loss:0.143253\n",
      "Epoch [1/2], Iter [410/3125], train_loss:0.143834\n",
      "Epoch [1/2], Iter [411/3125], train_loss:0.143335\n",
      "Epoch [1/2], Iter [412/3125], train_loss:0.143997\n",
      "Epoch [1/2], Iter [413/3125], train_loss:0.145516\n",
      "Epoch [1/2], Iter [414/3125], train_loss:0.143420\n",
      "Epoch [1/2], Iter [415/3125], train_loss:0.143635\n",
      "Epoch [1/2], Iter [416/3125], train_loss:0.143687\n",
      "Epoch [1/2], Iter [417/3125], train_loss:0.144087\n",
      "Epoch [1/2], Iter [418/3125], train_loss:0.144404\n",
      "Epoch [1/2], Iter [419/3125], train_loss:0.146390\n",
      "Epoch [1/2], Iter [420/3125], train_loss:0.142472\n",
      "Epoch [1/2], Iter [421/3125], train_loss:0.143509\n",
      "Epoch [1/2], Iter [422/3125], train_loss:0.144025\n",
      "Epoch [1/2], Iter [423/3125], train_loss:0.144064\n",
      "Epoch [1/2], Iter [424/3125], train_loss:0.143815\n",
      "Epoch [1/2], Iter [425/3125], train_loss:0.143667\n",
      "Epoch [1/2], Iter [426/3125], train_loss:0.143518\n",
      "Epoch [1/2], Iter [427/3125], train_loss:0.143103\n",
      "Epoch [1/2], Iter [428/3125], train_loss:0.144878\n",
      "Epoch [1/2], Iter [429/3125], train_loss:0.144331\n",
      "Epoch [1/2], Iter [430/3125], train_loss:0.144388\n",
      "Epoch [1/2], Iter [431/3125], train_loss:0.145167\n",
      "Epoch [1/2], Iter [432/3125], train_loss:0.144308\n",
      "Epoch [1/2], Iter [433/3125], train_loss:0.144407\n",
      "Epoch [1/2], Iter [434/3125], train_loss:0.144054\n",
      "Epoch [1/2], Iter [435/3125], train_loss:0.143954\n",
      "Epoch [1/2], Iter [436/3125], train_loss:0.143971\n",
      "Epoch [1/2], Iter [437/3125], train_loss:0.145001\n",
      "Epoch [1/2], Iter [438/3125], train_loss:0.144527\n",
      "Epoch [1/2], Iter [439/3125], train_loss:0.143126\n",
      "Epoch [1/2], Iter [440/3125], train_loss:0.144473\n",
      "Epoch [1/2], Iter [441/3125], train_loss:0.143902\n",
      "Epoch [1/2], Iter [442/3125], train_loss:0.143860\n",
      "Epoch [1/2], Iter [443/3125], train_loss:0.143253\n",
      "Epoch [1/2], Iter [444/3125], train_loss:0.143807\n",
      "Epoch [1/2], Iter [445/3125], train_loss:0.143428\n",
      "Epoch [1/2], Iter [446/3125], train_loss:0.144670\n",
      "Epoch [1/2], Iter [447/3125], train_loss:0.143730\n",
      "Epoch [1/2], Iter [448/3125], train_loss:0.142651\n",
      "Epoch [1/2], Iter [449/3125], train_loss:0.144801\n",
      "Epoch [1/2], Iter [450/3125], train_loss:0.145280\n",
      "Epoch [1/2], Iter [451/3125], train_loss:0.143771\n",
      "Epoch [1/2], Iter [452/3125], train_loss:0.144226\n",
      "Epoch [1/2], Iter [453/3125], train_loss:0.144436\n",
      "Epoch [1/2], Iter [454/3125], train_loss:0.145040\n",
      "Epoch [1/2], Iter [455/3125], train_loss:0.143348\n",
      "Epoch [1/2], Iter [456/3125], train_loss:0.144779\n",
      "Epoch [1/2], Iter [457/3125], train_loss:0.144902\n",
      "Epoch [1/2], Iter [458/3125], train_loss:0.143840\n",
      "Epoch [1/2], Iter [459/3125], train_loss:0.143529\n",
      "Epoch [1/2], Iter [460/3125], train_loss:0.143308\n",
      "Epoch [1/2], Iter [461/3125], train_loss:0.143579\n",
      "Epoch [1/2], Iter [462/3125], train_loss:0.143985\n",
      "Epoch [1/2], Iter [463/3125], train_loss:0.143581\n",
      "Epoch [1/2], Iter [464/3125], train_loss:0.144616\n",
      "Epoch [1/2], Iter [465/3125], train_loss:0.143626\n",
      "Epoch [1/2], Iter [466/3125], train_loss:0.145182\n",
      "Epoch [1/2], Iter [467/3125], train_loss:0.145341\n",
      "Epoch [1/2], Iter [468/3125], train_loss:0.145407\n",
      "Epoch [1/2], Iter [469/3125], train_loss:0.144565\n",
      "Epoch [1/2], Iter [470/3125], train_loss:0.145437\n",
      "Epoch [1/2], Iter [471/3125], train_loss:0.144272\n",
      "Epoch [1/2], Iter [472/3125], train_loss:0.144114\n",
      "Epoch [1/2], Iter [473/3125], train_loss:0.145105\n",
      "Epoch [1/2], Iter [474/3125], train_loss:0.142627\n",
      "Epoch [1/2], Iter [475/3125], train_loss:0.143691\n",
      "Epoch [1/2], Iter [476/3125], train_loss:0.143389\n",
      "Epoch [1/2], Iter [477/3125], train_loss:0.144314\n",
      "Epoch [1/2], Iter [478/3125], train_loss:0.142743\n",
      "Epoch [1/2], Iter [479/3125], train_loss:0.144533\n",
      "Epoch [1/2], Iter [480/3125], train_loss:0.144986\n",
      "Epoch [1/2], Iter [481/3125], train_loss:0.143027\n",
      "Epoch [1/2], Iter [482/3125], train_loss:0.142672\n",
      "Epoch [1/2], Iter [483/3125], train_loss:0.145390\n",
      "Epoch [1/2], Iter [484/3125], train_loss:0.142834\n",
      "Epoch [1/2], Iter [485/3125], train_loss:0.143004\n",
      "Epoch [1/2], Iter [486/3125], train_loss:0.144741\n",
      "Epoch [1/2], Iter [487/3125], train_loss:0.145017\n",
      "Epoch [1/2], Iter [488/3125], train_loss:0.145132\n",
      "Epoch [1/2], Iter [489/3125], train_loss:0.142878\n",
      "Epoch [1/2], Iter [490/3125], train_loss:0.144365\n",
      "Epoch [1/2], Iter [491/3125], train_loss:0.142794\n",
      "Epoch [1/2], Iter [492/3125], train_loss:0.143417\n",
      "Epoch [1/2], Iter [493/3125], train_loss:0.145014\n",
      "Epoch [1/2], Iter [494/3125], train_loss:0.145642\n",
      "Epoch [1/2], Iter [495/3125], train_loss:0.143548\n",
      "Epoch [1/2], Iter [496/3125], train_loss:0.144411\n",
      "Epoch [1/2], Iter [497/3125], train_loss:0.144709\n",
      "Epoch [1/2], Iter [498/3125], train_loss:0.143299\n",
      "Epoch [1/2], Iter [499/3125], train_loss:0.143982\n",
      "Epoch [1/2], Iter [500/3125], train_loss:0.143766\n",
      "Epoch [1/2], Iter [501/3125], train_loss:0.144128\n",
      "Epoch [1/2], Iter [502/3125], train_loss:0.143997\n",
      "Epoch [1/2], Iter [503/3125], train_loss:0.145093\n",
      "Epoch [1/2], Iter [504/3125], train_loss:0.143421\n",
      "Epoch [1/2], Iter [505/3125], train_loss:0.143287\n",
      "Epoch [1/2], Iter [506/3125], train_loss:0.143338\n",
      "Epoch [1/2], Iter [507/3125], train_loss:0.145972\n",
      "Epoch [1/2], Iter [508/3125], train_loss:0.144126\n",
      "Epoch [1/2], Iter [509/3125], train_loss:0.143406\n",
      "Epoch [1/2], Iter [510/3125], train_loss:0.145443\n",
      "Epoch [1/2], Iter [511/3125], train_loss:0.142967\n",
      "Epoch [1/2], Iter [512/3125], train_loss:0.143401\n",
      "Epoch [1/2], Iter [513/3125], train_loss:0.144955\n",
      "Epoch [1/2], Iter [514/3125], train_loss:0.143675\n",
      "Epoch [1/2], Iter [515/3125], train_loss:0.144120\n",
      "Epoch [1/2], Iter [516/3125], train_loss:0.143511\n",
      "Epoch [1/2], Iter [517/3125], train_loss:0.144836\n",
      "Epoch [1/2], Iter [518/3125], train_loss:0.144539\n",
      "Epoch [1/2], Iter [519/3125], train_loss:0.144501\n",
      "Epoch [1/2], Iter [520/3125], train_loss:0.143631\n",
      "Epoch [1/2], Iter [521/3125], train_loss:0.143037\n",
      "Epoch [1/2], Iter [522/3125], train_loss:0.144250\n",
      "Epoch [1/2], Iter [523/3125], train_loss:0.143453\n",
      "Epoch [1/2], Iter [524/3125], train_loss:0.144572\n",
      "Epoch [1/2], Iter [525/3125], train_loss:0.143910\n",
      "Epoch [1/2], Iter [526/3125], train_loss:0.144554\n",
      "Epoch [1/2], Iter [527/3125], train_loss:0.145569\n",
      "Epoch [1/2], Iter [528/3125], train_loss:0.143848\n",
      "Epoch [1/2], Iter [529/3125], train_loss:0.144029\n",
      "Epoch [1/2], Iter [530/3125], train_loss:0.143153\n",
      "Epoch [1/2], Iter [531/3125], train_loss:0.146261\n",
      "Epoch [1/2], Iter [532/3125], train_loss:0.144641\n",
      "Epoch [1/2], Iter [533/3125], train_loss:0.144261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [534/3125], train_loss:0.143914\n",
      "Epoch [1/2], Iter [535/3125], train_loss:0.143463\n",
      "Epoch [1/2], Iter [536/3125], train_loss:0.142805\n",
      "Epoch [1/2], Iter [537/3125], train_loss:0.143072\n",
      "Epoch [1/2], Iter [538/3125], train_loss:0.143652\n",
      "Epoch [1/2], Iter [539/3125], train_loss:0.143758\n",
      "Epoch [1/2], Iter [540/3125], train_loss:0.143843\n",
      "Epoch [1/2], Iter [541/3125], train_loss:0.144077\n",
      "Epoch [1/2], Iter [542/3125], train_loss:0.144083\n",
      "Epoch [1/2], Iter [543/3125], train_loss:0.144273\n",
      "Epoch [1/2], Iter [544/3125], train_loss:0.144592\n",
      "Epoch [1/2], Iter [545/3125], train_loss:0.141853\n",
      "Epoch [1/2], Iter [546/3125], train_loss:0.144067\n",
      "Epoch [1/2], Iter [547/3125], train_loss:0.142852\n",
      "Epoch [1/2], Iter [548/3125], train_loss:0.144938\n",
      "Epoch [1/2], Iter [549/3125], train_loss:0.144556\n",
      "Epoch [1/2], Iter [550/3125], train_loss:0.143375\n",
      "Epoch [1/2], Iter [551/3125], train_loss:0.144623\n",
      "Epoch [1/2], Iter [552/3125], train_loss:0.144261\n",
      "Epoch [1/2], Iter [553/3125], train_loss:0.145460\n",
      "Epoch [1/2], Iter [554/3125], train_loss:0.145549\n",
      "Epoch [1/2], Iter [555/3125], train_loss:0.142661\n",
      "Epoch [1/2], Iter [556/3125], train_loss:0.144651\n",
      "Epoch [1/2], Iter [557/3125], train_loss:0.145358\n",
      "Epoch [1/2], Iter [558/3125], train_loss:0.143328\n",
      "Epoch [1/2], Iter [559/3125], train_loss:0.144935\n",
      "Epoch [1/2], Iter [560/3125], train_loss:0.144370\n",
      "Epoch [1/2], Iter [561/3125], train_loss:0.143458\n",
      "Epoch [1/2], Iter [562/3125], train_loss:0.143746\n",
      "Epoch [1/2], Iter [563/3125], train_loss:0.143155\n",
      "Epoch [1/2], Iter [564/3125], train_loss:0.143798\n",
      "Epoch [1/2], Iter [565/3125], train_loss:0.143719\n",
      "Epoch [1/2], Iter [566/3125], train_loss:0.143512\n",
      "Epoch [1/2], Iter [567/3125], train_loss:0.143226\n",
      "Epoch [1/2], Iter [568/3125], train_loss:0.145802\n",
      "Epoch [1/2], Iter [569/3125], train_loss:0.143464\n",
      "Epoch [1/2], Iter [570/3125], train_loss:0.144498\n",
      "Epoch [1/2], Iter [571/3125], train_loss:0.143215\n",
      "Epoch [1/2], Iter [572/3125], train_loss:0.144424\n",
      "Epoch [1/2], Iter [573/3125], train_loss:0.143748\n",
      "Epoch [1/2], Iter [574/3125], train_loss:0.143817\n",
      "Epoch [1/2], Iter [575/3125], train_loss:0.142056\n",
      "Epoch [1/2], Iter [576/3125], train_loss:0.144498\n",
      "Epoch [1/2], Iter [577/3125], train_loss:0.143991\n",
      "Epoch [1/2], Iter [578/3125], train_loss:0.144485\n",
      "Epoch [1/2], Iter [579/3125], train_loss:0.144256\n",
      "Epoch [1/2], Iter [580/3125], train_loss:0.143135\n",
      "Epoch [1/2], Iter [581/3125], train_loss:0.144680\n",
      "Epoch [1/2], Iter [582/3125], train_loss:0.143940\n",
      "Epoch [1/2], Iter [583/3125], train_loss:0.144204\n",
      "Epoch [1/2], Iter [584/3125], train_loss:0.144393\n",
      "Epoch [1/2], Iter [585/3125], train_loss:0.143562\n",
      "Epoch [1/2], Iter [586/3125], train_loss:0.143764\n",
      "Epoch [1/2], Iter [587/3125], train_loss:0.144878\n",
      "Epoch [1/2], Iter [588/3125], train_loss:0.144329\n",
      "Epoch [1/2], Iter [589/3125], train_loss:0.142709\n",
      "Epoch [1/2], Iter [590/3125], train_loss:0.143638\n",
      "Epoch [1/2], Iter [591/3125], train_loss:0.144334\n",
      "Epoch [1/2], Iter [592/3125], train_loss:0.143794\n",
      "Epoch [1/2], Iter [593/3125], train_loss:0.144586\n",
      "Epoch [1/2], Iter [594/3125], train_loss:0.143812\n",
      "Epoch [1/2], Iter [595/3125], train_loss:0.142139\n",
      "Epoch [1/2], Iter [596/3125], train_loss:0.144121\n",
      "Epoch [1/2], Iter [597/3125], train_loss:0.144172\n",
      "Epoch [1/2], Iter [598/3125], train_loss:0.144158\n",
      "Epoch [1/2], Iter [599/3125], train_loss:0.143962\n",
      "Epoch [1/2], Iter [600/3125], train_loss:0.145314\n",
      "Epoch [1/2], Iter [601/3125], train_loss:0.143765\n",
      "Epoch [1/2], Iter [602/3125], train_loss:0.143635\n",
      "Epoch [1/2], Iter [603/3125], train_loss:0.143340\n",
      "Epoch [1/2], Iter [604/3125], train_loss:0.142513\n",
      "Epoch [1/2], Iter [605/3125], train_loss:0.146240\n",
      "Epoch [1/2], Iter [606/3125], train_loss:0.144107\n",
      "Epoch [1/2], Iter [607/3125], train_loss:0.144100\n",
      "Epoch [1/2], Iter [608/3125], train_loss:0.144805\n",
      "Epoch [1/2], Iter [609/3125], train_loss:0.143522\n",
      "Epoch [1/2], Iter [610/3125], train_loss:0.142234\n",
      "Epoch [1/2], Iter [611/3125], train_loss:0.143688\n",
      "Epoch [1/2], Iter [612/3125], train_loss:0.142907\n",
      "Epoch [1/2], Iter [613/3125], train_loss:0.143964\n",
      "Epoch [1/2], Iter [614/3125], train_loss:0.142476\n",
      "Epoch [1/2], Iter [615/3125], train_loss:0.143179\n",
      "Epoch [1/2], Iter [616/3125], train_loss:0.145140\n",
      "Epoch [1/2], Iter [617/3125], train_loss:0.143173\n",
      "Epoch [1/2], Iter [618/3125], train_loss:0.142801\n",
      "Epoch [1/2], Iter [619/3125], train_loss:0.143232\n",
      "Epoch [1/2], Iter [620/3125], train_loss:0.143472\n",
      "Epoch [1/2], Iter [621/3125], train_loss:0.143404\n",
      "Epoch [1/2], Iter [622/3125], train_loss:0.144472\n",
      "Epoch [1/2], Iter [623/3125], train_loss:0.144566\n",
      "Epoch [1/2], Iter [624/3125], train_loss:0.143505\n",
      "Epoch [1/2], Iter [625/3125], train_loss:0.143312\n",
      "Epoch [1/2], Iter [626/3125], train_loss:0.143009\n",
      "Epoch [1/2], Iter [627/3125], train_loss:0.143868\n",
      "Epoch [1/2], Iter [628/3125], train_loss:0.143613\n",
      "Epoch [1/2], Iter [629/3125], train_loss:0.144232\n",
      "Epoch [1/2], Iter [630/3125], train_loss:0.143456\n",
      "Epoch [1/2], Iter [631/3125], train_loss:0.144803\n",
      "Epoch [1/2], Iter [632/3125], train_loss:0.144093\n",
      "Epoch [1/2], Iter [633/3125], train_loss:0.144596\n",
      "Epoch [1/2], Iter [634/3125], train_loss:0.143623\n",
      "Epoch [1/2], Iter [635/3125], train_loss:0.143952\n",
      "Epoch [1/2], Iter [636/3125], train_loss:0.146236\n",
      "Epoch [1/2], Iter [637/3125], train_loss:0.145225\n",
      "Epoch [1/2], Iter [638/3125], train_loss:0.142943\n",
      "Epoch [1/2], Iter [639/3125], train_loss:0.143302\n",
      "Epoch [1/2], Iter [640/3125], train_loss:0.143856\n",
      "Epoch [1/2], Iter [641/3125], train_loss:0.143435\n",
      "Epoch [1/2], Iter [642/3125], train_loss:0.143328\n",
      "Epoch [1/2], Iter [643/3125], train_loss:0.144207\n",
      "Epoch [1/2], Iter [644/3125], train_loss:0.144519\n",
      "Epoch [1/2], Iter [645/3125], train_loss:0.144429\n",
      "Epoch [1/2], Iter [646/3125], train_loss:0.142894\n",
      "Epoch [1/2], Iter [647/3125], train_loss:0.144359\n",
      "Epoch [1/2], Iter [648/3125], train_loss:0.142946\n",
      "Epoch [1/2], Iter [649/3125], train_loss:0.144440\n",
      "Epoch [1/2], Iter [650/3125], train_loss:0.142416\n",
      "Epoch [1/2], Iter [651/3125], train_loss:0.142866\n",
      "Epoch [1/2], Iter [652/3125], train_loss:0.142275\n",
      "Epoch [1/2], Iter [653/3125], train_loss:0.143811\n",
      "Epoch [1/2], Iter [654/3125], train_loss:0.146101\n",
      "Epoch [1/2], Iter [655/3125], train_loss:0.145134\n",
      "Epoch [1/2], Iter [656/3125], train_loss:0.142879\n",
      "Epoch [1/2], Iter [657/3125], train_loss:0.144963\n",
      "Epoch [1/2], Iter [658/3125], train_loss:0.144496\n",
      "Epoch [1/2], Iter [659/3125], train_loss:0.144722\n",
      "Epoch [1/2], Iter [660/3125], train_loss:0.143617\n",
      "Epoch [1/2], Iter [661/3125], train_loss:0.145444\n",
      "Epoch [1/2], Iter [662/3125], train_loss:0.143885\n",
      "Epoch [1/2], Iter [663/3125], train_loss:0.143424\n",
      "Epoch [1/2], Iter [664/3125], train_loss:0.144555\n",
      "Epoch [1/2], Iter [665/3125], train_loss:0.144288\n",
      "Epoch [1/2], Iter [666/3125], train_loss:0.143300\n",
      "Epoch [1/2], Iter [667/3125], train_loss:0.143907\n",
      "Epoch [1/2], Iter [668/3125], train_loss:0.143708\n",
      "Epoch [1/2], Iter [669/3125], train_loss:0.144051\n",
      "Epoch [1/2], Iter [670/3125], train_loss:0.143056\n",
      "Epoch [1/2], Iter [671/3125], train_loss:0.142238\n",
      "Epoch [1/2], Iter [672/3125], train_loss:0.145287\n",
      "Epoch [1/2], Iter [673/3125], train_loss:0.144106\n",
      "Epoch [1/2], Iter [674/3125], train_loss:0.144390\n",
      "Epoch [1/2], Iter [675/3125], train_loss:0.142949\n",
      "Epoch [1/2], Iter [676/3125], train_loss:0.143753\n",
      "Epoch [1/2], Iter [677/3125], train_loss:0.144853\n",
      "Epoch [1/2], Iter [678/3125], train_loss:0.145274\n",
      "Epoch [1/2], Iter [679/3125], train_loss:0.143530\n",
      "Epoch [1/2], Iter [680/3125], train_loss:0.145179\n",
      "Epoch [1/2], Iter [681/3125], train_loss:0.143009\n",
      "Epoch [1/2], Iter [682/3125], train_loss:0.143400\n",
      "Epoch [1/2], Iter [683/3125], train_loss:0.142664\n",
      "Epoch [1/2], Iter [684/3125], train_loss:0.143656\n",
      "Epoch [1/2], Iter [685/3125], train_loss:0.144791\n",
      "Epoch [1/2], Iter [686/3125], train_loss:0.144038\n",
      "Epoch [1/2], Iter [687/3125], train_loss:0.142632\n",
      "Epoch [1/2], Iter [688/3125], train_loss:0.144372\n",
      "Epoch [1/2], Iter [689/3125], train_loss:0.144485\n",
      "Epoch [1/2], Iter [690/3125], train_loss:0.144070\n",
      "Epoch [1/2], Iter [691/3125], train_loss:0.143109\n",
      "Epoch [1/2], Iter [692/3125], train_loss:0.143991\n",
      "Epoch [1/2], Iter [693/3125], train_loss:0.144297\n",
      "Epoch [1/2], Iter [694/3125], train_loss:0.143844\n",
      "Epoch [1/2], Iter [695/3125], train_loss:0.144082\n",
      "Epoch [1/2], Iter [696/3125], train_loss:0.143913\n",
      "Epoch [1/2], Iter [697/3125], train_loss:0.144982\n",
      "Epoch [1/2], Iter [698/3125], train_loss:0.144366\n",
      "Epoch [1/2], Iter [699/3125], train_loss:0.143428\n",
      "Epoch [1/2], Iter [700/3125], train_loss:0.144262\n",
      "Epoch [1/2], Iter [701/3125], train_loss:0.144296\n",
      "Epoch [1/2], Iter [702/3125], train_loss:0.145537\n",
      "Epoch [1/2], Iter [703/3125], train_loss:0.143572\n",
      "Epoch [1/2], Iter [704/3125], train_loss:0.144391\n",
      "Epoch [1/2], Iter [705/3125], train_loss:0.143530\n",
      "Epoch [1/2], Iter [706/3125], train_loss:0.143831\n",
      "Epoch [1/2], Iter [707/3125], train_loss:0.145907\n",
      "Epoch [1/2], Iter [708/3125], train_loss:0.144082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [709/3125], train_loss:0.144517\n",
      "Epoch [1/2], Iter [710/3125], train_loss:0.144125\n",
      "Epoch [1/2], Iter [711/3125], train_loss:0.142756\n",
      "Epoch [1/2], Iter [712/3125], train_loss:0.144819\n",
      "Epoch [1/2], Iter [713/3125], train_loss:0.144305\n",
      "Epoch [1/2], Iter [714/3125], train_loss:0.144245\n",
      "Epoch [1/2], Iter [715/3125], train_loss:0.145034\n",
      "Epoch [1/2], Iter [716/3125], train_loss:0.144910\n",
      "Epoch [1/2], Iter [717/3125], train_loss:0.144443\n",
      "Epoch [1/2], Iter [718/3125], train_loss:0.143508\n",
      "Epoch [1/2], Iter [719/3125], train_loss:0.142979\n",
      "Epoch [1/2], Iter [720/3125], train_loss:0.145010\n",
      "Epoch [1/2], Iter [721/3125], train_loss:0.144247\n",
      "Epoch [1/2], Iter [722/3125], train_loss:0.145295\n",
      "Epoch [1/2], Iter [723/3125], train_loss:0.143537\n",
      "Epoch [1/2], Iter [724/3125], train_loss:0.143099\n",
      "Epoch [1/2], Iter [725/3125], train_loss:0.142971\n",
      "Epoch [1/2], Iter [726/3125], train_loss:0.143939\n",
      "Epoch [1/2], Iter [727/3125], train_loss:0.142080\n",
      "Epoch [1/2], Iter [728/3125], train_loss:0.143390\n",
      "Epoch [1/2], Iter [729/3125], train_loss:0.143017\n",
      "Epoch [1/2], Iter [730/3125], train_loss:0.144828\n",
      "Epoch [1/2], Iter [731/3125], train_loss:0.141674\n",
      "Epoch [1/2], Iter [732/3125], train_loss:0.144393\n",
      "Epoch [1/2], Iter [733/3125], train_loss:0.144675\n",
      "Epoch [1/2], Iter [734/3125], train_loss:0.144739\n",
      "Epoch [1/2], Iter [735/3125], train_loss:0.144022\n",
      "Epoch [1/2], Iter [736/3125], train_loss:0.143676\n",
      "Epoch [1/2], Iter [737/3125], train_loss:0.144291\n",
      "Epoch [1/2], Iter [738/3125], train_loss:0.143679\n",
      "Epoch [1/2], Iter [739/3125], train_loss:0.144432\n",
      "Epoch [1/2], Iter [740/3125], train_loss:0.145463\n",
      "Epoch [1/2], Iter [741/3125], train_loss:0.141786\n",
      "Epoch [1/2], Iter [742/3125], train_loss:0.144856\n",
      "Epoch [1/2], Iter [743/3125], train_loss:0.144376\n",
      "Epoch [1/2], Iter [744/3125], train_loss:0.145511\n",
      "Epoch [1/2], Iter [745/3125], train_loss:0.144057\n",
      "Epoch [1/2], Iter [746/3125], train_loss:0.144055\n",
      "Epoch [1/2], Iter [747/3125], train_loss:0.144694\n",
      "Epoch [1/2], Iter [748/3125], train_loss:0.144230\n",
      "Epoch [1/2], Iter [749/3125], train_loss:0.143100\n",
      "Epoch [1/2], Iter [750/3125], train_loss:0.144233\n",
      "Epoch [1/2], Iter [751/3125], train_loss:0.144460\n",
      "Epoch [1/2], Iter [752/3125], train_loss:0.143298\n",
      "Epoch [1/2], Iter [753/3125], train_loss:0.144294\n",
      "Epoch [1/2], Iter [754/3125], train_loss:0.145636\n",
      "Epoch [1/2], Iter [755/3125], train_loss:0.143514\n",
      "Epoch [1/2], Iter [756/3125], train_loss:0.144042\n",
      "Epoch [1/2], Iter [757/3125], train_loss:0.142611\n",
      "Epoch [1/2], Iter [758/3125], train_loss:0.142230\n",
      "Epoch [1/2], Iter [759/3125], train_loss:0.142767\n",
      "Epoch [1/2], Iter [760/3125], train_loss:0.144865\n",
      "Epoch [1/2], Iter [761/3125], train_loss:0.144861\n",
      "Epoch [1/2], Iter [762/3125], train_loss:0.145156\n",
      "Epoch [1/2], Iter [763/3125], train_loss:0.141092\n",
      "Epoch [1/2], Iter [764/3125], train_loss:0.144120\n",
      "Epoch [1/2], Iter [765/3125], train_loss:0.144146\n",
      "Epoch [1/2], Iter [766/3125], train_loss:0.144493\n",
      "Epoch [1/2], Iter [767/3125], train_loss:0.144667\n",
      "Epoch [1/2], Iter [768/3125], train_loss:0.145016\n",
      "Epoch [1/2], Iter [769/3125], train_loss:0.144880\n",
      "Epoch [1/2], Iter [770/3125], train_loss:0.144406\n",
      "Epoch [1/2], Iter [771/3125], train_loss:0.144283\n",
      "Epoch [1/2], Iter [772/3125], train_loss:0.142924\n",
      "Epoch [1/2], Iter [773/3125], train_loss:0.143295\n",
      "Epoch [1/2], Iter [774/3125], train_loss:0.143065\n",
      "Epoch [1/2], Iter [775/3125], train_loss:0.144664\n",
      "Epoch [1/2], Iter [776/3125], train_loss:0.144868\n",
      "Epoch [1/2], Iter [777/3125], train_loss:0.143101\n",
      "Epoch [1/2], Iter [778/3125], train_loss:0.143961\n",
      "Epoch [1/2], Iter [779/3125], train_loss:0.143863\n",
      "Epoch [1/2], Iter [780/3125], train_loss:0.141788\n",
      "Epoch [1/2], Iter [781/3125], train_loss:0.143562\n",
      "Epoch [1/2], Iter [782/3125], train_loss:0.142616\n",
      "Epoch [1/2], Iter [783/3125], train_loss:0.144452\n",
      "Epoch [1/2], Iter [784/3125], train_loss:0.144012\n",
      "Epoch [1/2], Iter [785/3125], train_loss:0.144890\n",
      "Epoch [1/2], Iter [786/3125], train_loss:0.144834\n",
      "Epoch [1/2], Iter [787/3125], train_loss:0.143290\n",
      "Epoch [1/2], Iter [788/3125], train_loss:0.142728\n",
      "Epoch [1/2], Iter [789/3125], train_loss:0.144109\n",
      "Epoch [1/2], Iter [790/3125], train_loss:0.144229\n",
      "Epoch [1/2], Iter [791/3125], train_loss:0.144136\n",
      "Epoch [1/2], Iter [792/3125], train_loss:0.143800\n",
      "Epoch [1/2], Iter [793/3125], train_loss:0.143069\n",
      "Epoch [1/2], Iter [794/3125], train_loss:0.143036\n",
      "Epoch [1/2], Iter [795/3125], train_loss:0.143386\n",
      "Epoch [1/2], Iter [796/3125], train_loss:0.143862\n",
      "Epoch [1/2], Iter [797/3125], train_loss:0.144221\n",
      "Epoch [1/2], Iter [798/3125], train_loss:0.143124\n",
      "Epoch [1/2], Iter [799/3125], train_loss:0.144542\n",
      "Epoch [1/2], Iter [800/3125], train_loss:0.145882\n",
      "Epoch [1/2], Iter [801/3125], train_loss:0.142879\n",
      "Epoch [1/2], Iter [802/3125], train_loss:0.144651\n",
      "Epoch [1/2], Iter [803/3125], train_loss:0.143374\n",
      "Epoch [1/2], Iter [804/3125], train_loss:0.144009\n",
      "Epoch [1/2], Iter [805/3125], train_loss:0.143993\n",
      "Epoch [1/2], Iter [806/3125], train_loss:0.144328\n",
      "Epoch [1/2], Iter [807/3125], train_loss:0.144310\n",
      "Epoch [1/2], Iter [808/3125], train_loss:0.143364\n",
      "Epoch [1/2], Iter [809/3125], train_loss:0.144338\n",
      "Epoch [1/2], Iter [810/3125], train_loss:0.142575\n",
      "Epoch [1/2], Iter [811/3125], train_loss:0.144168\n",
      "Epoch [1/2], Iter [812/3125], train_loss:0.143331\n",
      "Epoch [1/2], Iter [813/3125], train_loss:0.143919\n",
      "Epoch [1/2], Iter [814/3125], train_loss:0.144880\n",
      "Epoch [1/2], Iter [815/3125], train_loss:0.143826\n",
      "Epoch [1/2], Iter [816/3125], train_loss:0.145079\n",
      "Epoch [1/2], Iter [817/3125], train_loss:0.144667\n",
      "Epoch [1/2], Iter [818/3125], train_loss:0.143197\n",
      "Epoch [1/2], Iter [819/3125], train_loss:0.142962\n",
      "Epoch [1/2], Iter [820/3125], train_loss:0.143481\n",
      "Epoch [1/2], Iter [821/3125], train_loss:0.143661\n",
      "Epoch [1/2], Iter [822/3125], train_loss:0.145470\n",
      "Epoch [1/2], Iter [823/3125], train_loss:0.144405\n",
      "Epoch [1/2], Iter [824/3125], train_loss:0.144823\n",
      "Epoch [1/2], Iter [825/3125], train_loss:0.144049\n",
      "Epoch [1/2], Iter [826/3125], train_loss:0.144759\n",
      "Epoch [1/2], Iter [827/3125], train_loss:0.144745\n",
      "Epoch [1/2], Iter [828/3125], train_loss:0.143838\n",
      "Epoch [1/2], Iter [829/3125], train_loss:0.145012\n",
      "Epoch [1/2], Iter [830/3125], train_loss:0.144643\n",
      "Epoch [1/2], Iter [831/3125], train_loss:0.143551\n",
      "Epoch [1/2], Iter [832/3125], train_loss:0.142510\n",
      "Epoch [1/2], Iter [833/3125], train_loss:0.144326\n",
      "Epoch [1/2], Iter [834/3125], train_loss:0.144485\n",
      "Epoch [1/2], Iter [835/3125], train_loss:0.146017\n",
      "Epoch [1/2], Iter [836/3125], train_loss:0.144557\n",
      "Epoch [1/2], Iter [837/3125], train_loss:0.144408\n",
      "Epoch [1/2], Iter [838/3125], train_loss:0.144435\n",
      "Epoch [1/2], Iter [839/3125], train_loss:0.144190\n",
      "Epoch [1/2], Iter [840/3125], train_loss:0.144117\n",
      "Epoch [1/2], Iter [841/3125], train_loss:0.144301\n",
      "Epoch [1/2], Iter [842/3125], train_loss:0.143852\n",
      "Epoch [1/2], Iter [843/3125], train_loss:0.145326\n",
      "Epoch [1/2], Iter [844/3125], train_loss:0.145223\n",
      "Epoch [1/2], Iter [845/3125], train_loss:0.144541\n",
      "Epoch [1/2], Iter [846/3125], train_loss:0.144927\n",
      "Epoch [1/2], Iter [847/3125], train_loss:0.144471\n",
      "Epoch [1/2], Iter [848/3125], train_loss:0.144535\n",
      "Epoch [1/2], Iter [849/3125], train_loss:0.144045\n",
      "Epoch [1/2], Iter [850/3125], train_loss:0.144050\n",
      "Epoch [1/2], Iter [851/3125], train_loss:0.143971\n",
      "Epoch [1/2], Iter [852/3125], train_loss:0.145103\n",
      "Epoch [1/2], Iter [853/3125], train_loss:0.143199\n",
      "Epoch [1/2], Iter [854/3125], train_loss:0.144075\n",
      "Epoch [1/2], Iter [855/3125], train_loss:0.142770\n",
      "Epoch [1/2], Iter [856/3125], train_loss:0.145694\n",
      "Epoch [1/2], Iter [857/3125], train_loss:0.144558\n",
      "Epoch [1/2], Iter [858/3125], train_loss:0.144959\n",
      "Epoch [1/2], Iter [859/3125], train_loss:0.145050\n",
      "Epoch [1/2], Iter [860/3125], train_loss:0.145766\n",
      "Epoch [1/2], Iter [861/3125], train_loss:0.143231\n",
      "Epoch [1/2], Iter [862/3125], train_loss:0.142879\n",
      "Epoch [1/2], Iter [863/3125], train_loss:0.143542\n",
      "Epoch [1/2], Iter [864/3125], train_loss:0.144657\n",
      "Epoch [1/2], Iter [865/3125], train_loss:0.142816\n",
      "Epoch [1/2], Iter [866/3125], train_loss:0.144978\n",
      "Epoch [1/2], Iter [867/3125], train_loss:0.143179\n",
      "Epoch [1/2], Iter [868/3125], train_loss:0.142703\n",
      "Epoch [1/2], Iter [869/3125], train_loss:0.144574\n",
      "Epoch [1/2], Iter [870/3125], train_loss:0.145315\n",
      "Epoch [1/2], Iter [871/3125], train_loss:0.143001\n",
      "Epoch [1/2], Iter [872/3125], train_loss:0.144145\n",
      "Epoch [1/2], Iter [873/3125], train_loss:0.144332\n",
      "Epoch [1/2], Iter [874/3125], train_loss:0.143187\n",
      "Epoch [1/2], Iter [875/3125], train_loss:0.143591\n",
      "Epoch [1/2], Iter [876/3125], train_loss:0.144817\n",
      "Epoch [1/2], Iter [877/3125], train_loss:0.145252\n",
      "Epoch [1/2], Iter [878/3125], train_loss:0.144458\n",
      "Epoch [1/2], Iter [879/3125], train_loss:0.143162\n",
      "Epoch [1/2], Iter [880/3125], train_loss:0.145033\n",
      "Epoch [1/2], Iter [881/3125], train_loss:0.143855\n",
      "Epoch [1/2], Iter [882/3125], train_loss:0.143100\n",
      "Epoch [1/2], Iter [883/3125], train_loss:0.144713\n",
      "Epoch [1/2], Iter [884/3125], train_loss:0.144274\n",
      "Epoch [1/2], Iter [885/3125], train_loss:0.143928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [886/3125], train_loss:0.143566\n",
      "Epoch [1/2], Iter [887/3125], train_loss:0.143165\n",
      "Epoch [1/2], Iter [888/3125], train_loss:0.143400\n",
      "Epoch [1/2], Iter [889/3125], train_loss:0.143615\n",
      "Epoch [1/2], Iter [890/3125], train_loss:0.143618\n",
      "Epoch [1/2], Iter [891/3125], train_loss:0.143219\n",
      "Epoch [1/2], Iter [892/3125], train_loss:0.144987\n",
      "Epoch [1/2], Iter [893/3125], train_loss:0.143366\n",
      "Epoch [1/2], Iter [894/3125], train_loss:0.142526\n",
      "Epoch [1/2], Iter [895/3125], train_loss:0.142739\n",
      "Epoch [1/2], Iter [896/3125], train_loss:0.143722\n",
      "Epoch [1/2], Iter [897/3125], train_loss:0.143818\n",
      "Epoch [1/2], Iter [898/3125], train_loss:0.144769\n",
      "Epoch [1/2], Iter [899/3125], train_loss:0.143408\n",
      "Epoch [1/2], Iter [900/3125], train_loss:0.144746\n",
      "Epoch [1/2], Iter [901/3125], train_loss:0.143799\n",
      "Epoch [1/2], Iter [902/3125], train_loss:0.144751\n",
      "Epoch [1/2], Iter [903/3125], train_loss:0.142593\n",
      "Epoch [1/2], Iter [904/3125], train_loss:0.142894\n",
      "Epoch [1/2], Iter [905/3125], train_loss:0.144096\n",
      "Epoch [1/2], Iter [906/3125], train_loss:0.143322\n",
      "Epoch [1/2], Iter [907/3125], train_loss:0.144021\n",
      "Epoch [1/2], Iter [908/3125], train_loss:0.143847\n",
      "Epoch [1/2], Iter [909/3125], train_loss:0.143546\n",
      "Epoch [1/2], Iter [910/3125], train_loss:0.144423\n",
      "Epoch [1/2], Iter [911/3125], train_loss:0.144387\n",
      "Epoch [1/2], Iter [912/3125], train_loss:0.144107\n",
      "Epoch [1/2], Iter [913/3125], train_loss:0.144542\n",
      "Epoch [1/2], Iter [914/3125], train_loss:0.145981\n",
      "Epoch [1/2], Iter [915/3125], train_loss:0.144660\n",
      "Epoch [1/2], Iter [916/3125], train_loss:0.144173\n",
      "Epoch [1/2], Iter [917/3125], train_loss:0.143897\n",
      "Epoch [1/2], Iter [918/3125], train_loss:0.143801\n",
      "Epoch [1/2], Iter [919/3125], train_loss:0.143501\n",
      "Epoch [1/2], Iter [920/3125], train_loss:0.143868\n",
      "Epoch [1/2], Iter [921/3125], train_loss:0.144244\n",
      "Epoch [1/2], Iter [922/3125], train_loss:0.144996\n",
      "Epoch [1/2], Iter [923/3125], train_loss:0.142746\n",
      "Epoch [1/2], Iter [924/3125], train_loss:0.144495\n",
      "Epoch [1/2], Iter [925/3125], train_loss:0.142692\n",
      "Epoch [1/2], Iter [926/3125], train_loss:0.143209\n",
      "Epoch [1/2], Iter [927/3125], train_loss:0.144940\n",
      "Epoch [1/2], Iter [928/3125], train_loss:0.143623\n",
      "Epoch [1/2], Iter [929/3125], train_loss:0.144906\n",
      "Epoch [1/2], Iter [930/3125], train_loss:0.144742\n",
      "Epoch [1/2], Iter [931/3125], train_loss:0.145324\n",
      "Epoch [1/2], Iter [932/3125], train_loss:0.142604\n",
      "Epoch [1/2], Iter [933/3125], train_loss:0.143736\n",
      "Epoch [1/2], Iter [934/3125], train_loss:0.144436\n",
      "Epoch [1/2], Iter [935/3125], train_loss:0.143367\n",
      "Epoch [1/2], Iter [936/3125], train_loss:0.144962\n",
      "Epoch [1/2], Iter [937/3125], train_loss:0.144509\n",
      "Epoch [1/2], Iter [938/3125], train_loss:0.144007\n",
      "Epoch [1/2], Iter [939/3125], train_loss:0.143408\n",
      "Epoch [1/2], Iter [940/3125], train_loss:0.145328\n",
      "Epoch [1/2], Iter [941/3125], train_loss:0.144996\n",
      "Epoch [1/2], Iter [942/3125], train_loss:0.143947\n",
      "Epoch [1/2], Iter [943/3125], train_loss:0.145150\n",
      "Epoch [1/2], Iter [944/3125], train_loss:0.143001\n",
      "Epoch [1/2], Iter [945/3125], train_loss:0.142703\n",
      "Epoch [1/2], Iter [946/3125], train_loss:0.145818\n",
      "Epoch [1/2], Iter [947/3125], train_loss:0.144039\n",
      "Epoch [1/2], Iter [948/3125], train_loss:0.144735\n",
      "Epoch [1/2], Iter [949/3125], train_loss:0.145423\n",
      "Epoch [1/2], Iter [950/3125], train_loss:0.142681\n",
      "Epoch [1/2], Iter [951/3125], train_loss:0.145469\n",
      "Epoch [1/2], Iter [952/3125], train_loss:0.145243\n",
      "Epoch [1/2], Iter [953/3125], train_loss:0.144807\n",
      "Epoch [1/2], Iter [954/3125], train_loss:0.144986\n",
      "Epoch [1/2], Iter [955/3125], train_loss:0.143384\n",
      "Epoch [1/2], Iter [956/3125], train_loss:0.144726\n",
      "Epoch [1/2], Iter [957/3125], train_loss:0.144320\n",
      "Epoch [1/2], Iter [958/3125], train_loss:0.144024\n",
      "Epoch [1/2], Iter [959/3125], train_loss:0.143662\n",
      "Epoch [1/2], Iter [960/3125], train_loss:0.144442\n",
      "Epoch [1/2], Iter [961/3125], train_loss:0.144619\n",
      "Epoch [1/2], Iter [962/3125], train_loss:0.144207\n",
      "Epoch [1/2], Iter [963/3125], train_loss:0.142285\n",
      "Epoch [1/2], Iter [964/3125], train_loss:0.143683\n",
      "Epoch [1/2], Iter [965/3125], train_loss:0.142136\n",
      "Epoch [1/2], Iter [966/3125], train_loss:0.142434\n",
      "Epoch [1/2], Iter [967/3125], train_loss:0.143202\n",
      "Epoch [1/2], Iter [968/3125], train_loss:0.143654\n",
      "Epoch [1/2], Iter [969/3125], train_loss:0.144401\n",
      "Epoch [1/2], Iter [970/3125], train_loss:0.144031\n",
      "Epoch [1/2], Iter [971/3125], train_loss:0.144607\n",
      "Epoch [1/2], Iter [972/3125], train_loss:0.144821\n",
      "Epoch [1/2], Iter [973/3125], train_loss:0.144040\n",
      "Epoch [1/2], Iter [974/3125], train_loss:0.146443\n",
      "Epoch [1/2], Iter [975/3125], train_loss:0.144624\n",
      "Epoch [1/2], Iter [976/3125], train_loss:0.143920\n",
      "Epoch [1/2], Iter [977/3125], train_loss:0.144279\n",
      "Epoch [1/2], Iter [978/3125], train_loss:0.144408\n",
      "Epoch [1/2], Iter [979/3125], train_loss:0.144372\n",
      "Epoch [1/2], Iter [980/3125], train_loss:0.143867\n",
      "Epoch [1/2], Iter [981/3125], train_loss:0.143983\n",
      "Epoch [1/2], Iter [982/3125], train_loss:0.145519\n",
      "Epoch [1/2], Iter [983/3125], train_loss:0.143356\n",
      "Epoch [1/2], Iter [984/3125], train_loss:0.143429\n",
      "Epoch [1/2], Iter [985/3125], train_loss:0.142922\n",
      "Epoch [1/2], Iter [986/3125], train_loss:0.142831\n",
      "Epoch [1/2], Iter [987/3125], train_loss:0.142859\n",
      "Epoch [1/2], Iter [988/3125], train_loss:0.144326\n",
      "Epoch [1/2], Iter [989/3125], train_loss:0.142945\n",
      "Epoch [1/2], Iter [990/3125], train_loss:0.143577\n",
      "Epoch [1/2], Iter [991/3125], train_loss:0.144257\n",
      "Epoch [1/2], Iter [992/3125], train_loss:0.144022\n",
      "Epoch [1/2], Iter [993/3125], train_loss:0.142969\n",
      "Epoch [1/2], Iter [994/3125], train_loss:0.144304\n",
      "Epoch [1/2], Iter [995/3125], train_loss:0.143026\n",
      "Epoch [1/2], Iter [996/3125], train_loss:0.144812\n",
      "Epoch [1/2], Iter [997/3125], train_loss:0.142847\n",
      "Epoch [1/2], Iter [998/3125], train_loss:0.144831\n",
      "Epoch [1/2], Iter [999/3125], train_loss:0.143902\n",
      "Epoch [1/2], Iter [1000/3125], train_loss:0.143035\n",
      "Epoch [1/2], Iter [1001/3125], train_loss:0.142501\n",
      "Epoch [1/2], Iter [1002/3125], train_loss:0.144055\n",
      "Epoch [1/2], Iter [1003/3125], train_loss:0.144942\n",
      "Epoch [1/2], Iter [1004/3125], train_loss:0.145144\n",
      "Epoch [1/2], Iter [1005/3125], train_loss:0.143524\n",
      "Epoch [1/2], Iter [1006/3125], train_loss:0.143070\n",
      "Epoch [1/2], Iter [1007/3125], train_loss:0.143048\n",
      "Epoch [1/2], Iter [1008/3125], train_loss:0.143437\n",
      "Epoch [1/2], Iter [1009/3125], train_loss:0.144896\n",
      "Epoch [1/2], Iter [1010/3125], train_loss:0.143797\n",
      "Epoch [1/2], Iter [1011/3125], train_loss:0.143489\n",
      "Epoch [1/2], Iter [1012/3125], train_loss:0.143489\n",
      "Epoch [1/2], Iter [1013/3125], train_loss:0.143481\n",
      "Epoch [1/2], Iter [1014/3125], train_loss:0.141987\n",
      "Epoch [1/2], Iter [1015/3125], train_loss:0.143838\n",
      "Epoch [1/2], Iter [1016/3125], train_loss:0.143489\n",
      "Epoch [1/2], Iter [1017/3125], train_loss:0.144265\n",
      "Epoch [1/2], Iter [1018/3125], train_loss:0.143530\n",
      "Epoch [1/2], Iter [1019/3125], train_loss:0.142641\n",
      "Epoch [1/2], Iter [1020/3125], train_loss:0.144614\n",
      "Epoch [1/2], Iter [1021/3125], train_loss:0.142927\n",
      "Epoch [1/2], Iter [1022/3125], train_loss:0.143368\n",
      "Epoch [1/2], Iter [1023/3125], train_loss:0.145399\n",
      "Epoch [1/2], Iter [1024/3125], train_loss:0.144169\n",
      "Epoch [1/2], Iter [1025/3125], train_loss:0.145340\n",
      "Epoch [1/2], Iter [1026/3125], train_loss:0.141860\n",
      "Epoch [1/2], Iter [1027/3125], train_loss:0.145077\n",
      "Epoch [1/2], Iter [1028/3125], train_loss:0.144657\n",
      "Epoch [1/2], Iter [1029/3125], train_loss:0.142878\n",
      "Epoch [1/2], Iter [1030/3125], train_loss:0.143432\n",
      "Epoch [1/2], Iter [1031/3125], train_loss:0.143728\n",
      "Epoch [1/2], Iter [1032/3125], train_loss:0.144249\n",
      "Epoch [1/2], Iter [1033/3125], train_loss:0.144848\n",
      "Epoch [1/2], Iter [1034/3125], train_loss:0.142585\n",
      "Epoch [1/2], Iter [1035/3125], train_loss:0.143590\n",
      "Epoch [1/2], Iter [1036/3125], train_loss:0.144087\n",
      "Epoch [1/2], Iter [1037/3125], train_loss:0.142931\n",
      "Epoch [1/2], Iter [1038/3125], train_loss:0.143689\n",
      "Epoch [1/2], Iter [1039/3125], train_loss:0.143733\n",
      "Epoch [1/2], Iter [1040/3125], train_loss:0.144356\n",
      "Epoch [1/2], Iter [1041/3125], train_loss:0.143714\n",
      "Epoch [1/2], Iter [1042/3125], train_loss:0.144558\n",
      "Epoch [1/2], Iter [1043/3125], train_loss:0.142513\n",
      "Epoch [1/2], Iter [1044/3125], train_loss:0.143408\n",
      "Epoch [1/2], Iter [1045/3125], train_loss:0.144309\n",
      "Epoch [1/2], Iter [1046/3125], train_loss:0.144565\n",
      "Epoch [1/2], Iter [1047/3125], train_loss:0.143208\n",
      "Epoch [1/2], Iter [1048/3125], train_loss:0.143875\n",
      "Epoch [1/2], Iter [1049/3125], train_loss:0.144027\n",
      "Epoch [1/2], Iter [1050/3125], train_loss:0.144544\n",
      "Epoch [1/2], Iter [1051/3125], train_loss:0.142449\n",
      "Epoch [1/2], Iter [1052/3125], train_loss:0.144162\n",
      "Epoch [1/2], Iter [1053/3125], train_loss:0.143356\n",
      "Epoch [1/2], Iter [1054/3125], train_loss:0.145124\n",
      "Epoch [1/2], Iter [1055/3125], train_loss:0.144010\n",
      "Epoch [1/2], Iter [1056/3125], train_loss:0.143395\n",
      "Epoch [1/2], Iter [1057/3125], train_loss:0.144466\n",
      "Epoch [1/2], Iter [1058/3125], train_loss:0.144741\n",
      "Epoch [1/2], Iter [1059/3125], train_loss:0.143132\n",
      "Epoch [1/2], Iter [1060/3125], train_loss:0.145447\n",
      "Epoch [1/2], Iter [1061/3125], train_loss:0.143716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [1062/3125], train_loss:0.142604\n",
      "Epoch [1/2], Iter [1063/3125], train_loss:0.143565\n",
      "Epoch [1/2], Iter [1064/3125], train_loss:0.143565\n",
      "Epoch [1/2], Iter [1065/3125], train_loss:0.143837\n",
      "Epoch [1/2], Iter [1066/3125], train_loss:0.142543\n",
      "Epoch [1/2], Iter [1067/3125], train_loss:0.142937\n",
      "Epoch [1/2], Iter [1068/3125], train_loss:0.142791\n",
      "Epoch [1/2], Iter [1069/3125], train_loss:0.144512\n",
      "Epoch [1/2], Iter [1070/3125], train_loss:0.143378\n",
      "Epoch [1/2], Iter [1071/3125], train_loss:0.144531\n",
      "Epoch [1/2], Iter [1072/3125], train_loss:0.144421\n",
      "Epoch [1/2], Iter [1073/3125], train_loss:0.143944\n",
      "Epoch [1/2], Iter [1074/3125], train_loss:0.143188\n",
      "Epoch [1/2], Iter [1075/3125], train_loss:0.144417\n",
      "Epoch [1/2], Iter [1076/3125], train_loss:0.143870\n",
      "Epoch [1/2], Iter [1077/3125], train_loss:0.144572\n",
      "Epoch [1/2], Iter [1078/3125], train_loss:0.142294\n",
      "Epoch [1/2], Iter [1079/3125], train_loss:0.144546\n",
      "Epoch [1/2], Iter [1080/3125], train_loss:0.142623\n",
      "Epoch [1/2], Iter [1081/3125], train_loss:0.143858\n",
      "Epoch [1/2], Iter [1082/3125], train_loss:0.144140\n",
      "Epoch [1/2], Iter [1083/3125], train_loss:0.142672\n",
      "Epoch [1/2], Iter [1084/3125], train_loss:0.144146\n",
      "Epoch [1/2], Iter [1085/3125], train_loss:0.145197\n",
      "Epoch [1/2], Iter [1086/3125], train_loss:0.144224\n",
      "Epoch [1/2], Iter [1087/3125], train_loss:0.144073\n",
      "Epoch [1/2], Iter [1088/3125], train_loss:0.143439\n",
      "Epoch [1/2], Iter [1089/3125], train_loss:0.143335\n",
      "Epoch [1/2], Iter [1090/3125], train_loss:0.144464\n",
      "Epoch [1/2], Iter [1091/3125], train_loss:0.145930\n",
      "Epoch [1/2], Iter [1092/3125], train_loss:0.142244\n",
      "Epoch [1/2], Iter [1093/3125], train_loss:0.145985\n",
      "Epoch [1/2], Iter [1094/3125], train_loss:0.144570\n",
      "Epoch [1/2], Iter [1095/3125], train_loss:0.142874\n",
      "Epoch [1/2], Iter [1096/3125], train_loss:0.144027\n",
      "Epoch [1/2], Iter [1097/3125], train_loss:0.143402\n",
      "Epoch [1/2], Iter [1098/3125], train_loss:0.143679\n",
      "Epoch [1/2], Iter [1099/3125], train_loss:0.142630\n",
      "Epoch [1/2], Iter [1100/3125], train_loss:0.143624\n",
      "Epoch [1/2], Iter [1101/3125], train_loss:0.142811\n",
      "Epoch [1/2], Iter [1102/3125], train_loss:0.145283\n",
      "Epoch [1/2], Iter [1103/3125], train_loss:0.145129\n",
      "Epoch [1/2], Iter [1104/3125], train_loss:0.144672\n",
      "Epoch [1/2], Iter [1105/3125], train_loss:0.143073\n",
      "Epoch [1/2], Iter [1106/3125], train_loss:0.142793\n",
      "Epoch [1/2], Iter [1107/3125], train_loss:0.144736\n",
      "Epoch [1/2], Iter [1108/3125], train_loss:0.144047\n",
      "Epoch [1/2], Iter [1109/3125], train_loss:0.144945\n",
      "Epoch [1/2], Iter [1110/3125], train_loss:0.143988\n",
      "Epoch [1/2], Iter [1111/3125], train_loss:0.144144\n",
      "Epoch [1/2], Iter [1112/3125], train_loss:0.143366\n",
      "Epoch [1/2], Iter [1113/3125], train_loss:0.143512\n",
      "Epoch [1/2], Iter [1114/3125], train_loss:0.145660\n",
      "Epoch [1/2], Iter [1115/3125], train_loss:0.143379\n",
      "Epoch [1/2], Iter [1116/3125], train_loss:0.142742\n",
      "Epoch [1/2], Iter [1117/3125], train_loss:0.144158\n",
      "Epoch [1/2], Iter [1118/3125], train_loss:0.144839\n",
      "Epoch [1/2], Iter [1119/3125], train_loss:0.143861\n",
      "Epoch [1/2], Iter [1120/3125], train_loss:0.144716\n",
      "Epoch [1/2], Iter [1121/3125], train_loss:0.143849\n",
      "Epoch [1/2], Iter [1122/3125], train_loss:0.142786\n",
      "Epoch [1/2], Iter [1123/3125], train_loss:0.143727\n",
      "Epoch [1/2], Iter [1124/3125], train_loss:0.143954\n",
      "Epoch [1/2], Iter [1125/3125], train_loss:0.145652\n",
      "Epoch [1/2], Iter [1126/3125], train_loss:0.143079\n",
      "Epoch [1/2], Iter [1127/3125], train_loss:0.142661\n",
      "Epoch [1/2], Iter [1128/3125], train_loss:0.143753\n",
      "Epoch [1/2], Iter [1129/3125], train_loss:0.144290\n",
      "Epoch [1/2], Iter [1130/3125], train_loss:0.143757\n",
      "Epoch [1/2], Iter [1131/3125], train_loss:0.143792\n",
      "Epoch [1/2], Iter [1132/3125], train_loss:0.143488\n",
      "Epoch [1/2], Iter [1133/3125], train_loss:0.143432\n",
      "Epoch [1/2], Iter [1134/3125], train_loss:0.143810\n",
      "Epoch [1/2], Iter [1135/3125], train_loss:0.143507\n",
      "Epoch [1/2], Iter [1136/3125], train_loss:0.144128\n",
      "Epoch [1/2], Iter [1137/3125], train_loss:0.143380\n",
      "Epoch [1/2], Iter [1138/3125], train_loss:0.144398\n",
      "Epoch [1/2], Iter [1139/3125], train_loss:0.144353\n",
      "Epoch [1/2], Iter [1140/3125], train_loss:0.144007\n",
      "Epoch [1/2], Iter [1141/3125], train_loss:0.143084\n",
      "Epoch [1/2], Iter [1142/3125], train_loss:0.142731\n",
      "Epoch [1/2], Iter [1143/3125], train_loss:0.144646\n",
      "Epoch [1/2], Iter [1144/3125], train_loss:0.143792\n",
      "Epoch [1/2], Iter [1145/3125], train_loss:0.144606\n",
      "Epoch [1/2], Iter [1146/3125], train_loss:0.142224\n",
      "Epoch [1/2], Iter [1147/3125], train_loss:0.143089\n",
      "Epoch [1/2], Iter [1148/3125], train_loss:0.142889\n",
      "Epoch [1/2], Iter [1149/3125], train_loss:0.143806\n",
      "Epoch [1/2], Iter [1150/3125], train_loss:0.142722\n",
      "Epoch [1/2], Iter [1151/3125], train_loss:0.144462\n",
      "Epoch [1/2], Iter [1152/3125], train_loss:0.143506\n",
      "Epoch [1/2], Iter [1153/3125], train_loss:0.144690\n",
      "Epoch [1/2], Iter [1154/3125], train_loss:0.143665\n",
      "Epoch [1/2], Iter [1155/3125], train_loss:0.143218\n",
      "Epoch [1/2], Iter [1156/3125], train_loss:0.142782\n",
      "Epoch [1/2], Iter [1157/3125], train_loss:0.141784\n",
      "Epoch [1/2], Iter [1158/3125], train_loss:0.143317\n",
      "Epoch [1/2], Iter [1159/3125], train_loss:0.143717\n",
      "Epoch [1/2], Iter [1160/3125], train_loss:0.144434\n",
      "Epoch [1/2], Iter [1161/3125], train_loss:0.144071\n",
      "Epoch [1/2], Iter [1162/3125], train_loss:0.143871\n",
      "Epoch [1/2], Iter [1163/3125], train_loss:0.144744\n",
      "Epoch [1/2], Iter [1164/3125], train_loss:0.143682\n",
      "Epoch [1/2], Iter [1165/3125], train_loss:0.142420\n",
      "Epoch [1/2], Iter [1166/3125], train_loss:0.142082\n",
      "Epoch [1/2], Iter [1167/3125], train_loss:0.145153\n",
      "Epoch [1/2], Iter [1168/3125], train_loss:0.144739\n",
      "Epoch [1/2], Iter [1169/3125], train_loss:0.142693\n",
      "Epoch [1/2], Iter [1170/3125], train_loss:0.143770\n",
      "Epoch [1/2], Iter [1171/3125], train_loss:0.143208\n",
      "Epoch [1/2], Iter [1172/3125], train_loss:0.144313\n",
      "Epoch [1/2], Iter [1173/3125], train_loss:0.142762\n",
      "Epoch [1/2], Iter [1174/3125], train_loss:0.144290\n",
      "Epoch [1/2], Iter [1175/3125], train_loss:0.143541\n",
      "Epoch [1/2], Iter [1176/3125], train_loss:0.144000\n",
      "Epoch [1/2], Iter [1177/3125], train_loss:0.144154\n",
      "Epoch [1/2], Iter [1178/3125], train_loss:0.144404\n",
      "Epoch [1/2], Iter [1179/3125], train_loss:0.144591\n",
      "Epoch [1/2], Iter [1180/3125], train_loss:0.144576\n",
      "Epoch [1/2], Iter [1181/3125], train_loss:0.144695\n",
      "Epoch [1/2], Iter [1182/3125], train_loss:0.144840\n",
      "Epoch [1/2], Iter [1183/3125], train_loss:0.143233\n",
      "Epoch [1/2], Iter [1184/3125], train_loss:0.143061\n",
      "Epoch [1/2], Iter [1185/3125], train_loss:0.142585\n",
      "Epoch [1/2], Iter [1186/3125], train_loss:0.145937\n",
      "Epoch [1/2], Iter [1187/3125], train_loss:0.145079\n",
      "Epoch [1/2], Iter [1188/3125], train_loss:0.143871\n",
      "Epoch [1/2], Iter [1189/3125], train_loss:0.144338\n",
      "Epoch [1/2], Iter [1190/3125], train_loss:0.144071\n",
      "Epoch [1/2], Iter [1191/3125], train_loss:0.144483\n",
      "Epoch [1/2], Iter [1192/3125], train_loss:0.145517\n",
      "Epoch [1/2], Iter [1193/3125], train_loss:0.143843\n",
      "Epoch [1/2], Iter [1194/3125], train_loss:0.144009\n",
      "Epoch [1/2], Iter [1195/3125], train_loss:0.144907\n",
      "Epoch [1/2], Iter [1196/3125], train_loss:0.144613\n",
      "Epoch [1/2], Iter [1197/3125], train_loss:0.143344\n",
      "Epoch [1/2], Iter [1198/3125], train_loss:0.144792\n",
      "Epoch [1/2], Iter [1199/3125], train_loss:0.143254\n",
      "Epoch [1/2], Iter [1200/3125], train_loss:0.142829\n",
      "Epoch [1/2], Iter [1201/3125], train_loss:0.144294\n",
      "Epoch [1/2], Iter [1202/3125], train_loss:0.144920\n",
      "Epoch [1/2], Iter [1203/3125], train_loss:0.143797\n",
      "Epoch [1/2], Iter [1204/3125], train_loss:0.144018\n",
      "Epoch [1/2], Iter [1205/3125], train_loss:0.143314\n",
      "Epoch [1/2], Iter [1206/3125], train_loss:0.143697\n",
      "Epoch [1/2], Iter [1207/3125], train_loss:0.144010\n",
      "Epoch [1/2], Iter [1208/3125], train_loss:0.143692\n",
      "Epoch [1/2], Iter [1209/3125], train_loss:0.145847\n",
      "Epoch [1/2], Iter [1210/3125], train_loss:0.144026\n",
      "Epoch [1/2], Iter [1211/3125], train_loss:0.142782\n",
      "Epoch [1/2], Iter [1212/3125], train_loss:0.143377\n",
      "Epoch [1/2], Iter [1213/3125], train_loss:0.142919\n",
      "Epoch [1/2], Iter [1214/3125], train_loss:0.144661\n",
      "Epoch [1/2], Iter [1215/3125], train_loss:0.143675\n",
      "Epoch [1/2], Iter [1216/3125], train_loss:0.144225\n",
      "Epoch [1/2], Iter [1217/3125], train_loss:0.143807\n",
      "Epoch [1/2], Iter [1218/3125], train_loss:0.145227\n",
      "Epoch [1/2], Iter [1219/3125], train_loss:0.141703\n",
      "Epoch [1/2], Iter [1220/3125], train_loss:0.142003\n",
      "Epoch [1/2], Iter [1221/3125], train_loss:0.144182\n",
      "Epoch [1/2], Iter [1222/3125], train_loss:0.143391\n",
      "Epoch [1/2], Iter [1223/3125], train_loss:0.143987\n",
      "Epoch [1/2], Iter [1224/3125], train_loss:0.144349\n",
      "Epoch [1/2], Iter [1225/3125], train_loss:0.144064\n",
      "Epoch [1/2], Iter [1226/3125], train_loss:0.144743\n",
      "Epoch [1/2], Iter [1227/3125], train_loss:0.145096\n",
      "Epoch [1/2], Iter [1228/3125], train_loss:0.145484\n",
      "Epoch [1/2], Iter [1229/3125], train_loss:0.144941\n",
      "Epoch [1/2], Iter [1230/3125], train_loss:0.143383\n",
      "Epoch [1/2], Iter [1231/3125], train_loss:0.143401\n",
      "Epoch [1/2], Iter [1232/3125], train_loss:0.142533\n",
      "Epoch [1/2], Iter [1233/3125], train_loss:0.145146\n",
      "Epoch [1/2], Iter [1234/3125], train_loss:0.144903\n",
      "Epoch [1/2], Iter [1235/3125], train_loss:0.143258\n",
      "Epoch [1/2], Iter [1236/3125], train_loss:0.145479\n",
      "Epoch [1/2], Iter [1237/3125], train_loss:0.143150\n",
      "Epoch [1/2], Iter [1238/3125], train_loss:0.142888\n",
      "Epoch [1/2], Iter [1239/3125], train_loss:0.144639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [1240/3125], train_loss:0.144127\n",
      "Epoch [1/2], Iter [1241/3125], train_loss:0.144186\n",
      "Epoch [1/2], Iter [1242/3125], train_loss:0.143595\n",
      "Epoch [1/2], Iter [1243/3125], train_loss:0.144265\n",
      "Epoch [1/2], Iter [1244/3125], train_loss:0.144759\n",
      "Epoch [1/2], Iter [1245/3125], train_loss:0.143969\n",
      "Epoch [1/2], Iter [1246/3125], train_loss:0.144552\n",
      "Epoch [1/2], Iter [1247/3125], train_loss:0.143295\n",
      "Epoch [1/2], Iter [1248/3125], train_loss:0.144535\n",
      "Epoch [1/2], Iter [1249/3125], train_loss:0.143148\n",
      "Epoch [1/2], Iter [1250/3125], train_loss:0.143761\n",
      "Epoch [1/2], Iter [1251/3125], train_loss:0.141894\n",
      "Epoch [1/2], Iter [1252/3125], train_loss:0.143703\n",
      "Epoch [1/2], Iter [1253/3125], train_loss:0.143913\n",
      "Epoch [1/2], Iter [1254/3125], train_loss:0.143690\n",
      "Epoch [1/2], Iter [1255/3125], train_loss:0.145600\n",
      "Epoch [1/2], Iter [1256/3125], train_loss:0.145439\n",
      "Epoch [1/2], Iter [1257/3125], train_loss:0.145078\n",
      "Epoch [1/2], Iter [1258/3125], train_loss:0.143724\n",
      "Epoch [1/2], Iter [1259/3125], train_loss:0.144935\n",
      "Epoch [1/2], Iter [1260/3125], train_loss:0.144190\n",
      "Epoch [1/2], Iter [1261/3125], train_loss:0.142778\n",
      "Epoch [1/2], Iter [1262/3125], train_loss:0.144209\n",
      "Epoch [1/2], Iter [1263/3125], train_loss:0.144646\n",
      "Epoch [1/2], Iter [1264/3125], train_loss:0.144531\n",
      "Epoch [1/2], Iter [1265/3125], train_loss:0.143747\n",
      "Epoch [1/2], Iter [1266/3125], train_loss:0.145259\n",
      "Epoch [1/2], Iter [1267/3125], train_loss:0.143310\n",
      "Epoch [1/2], Iter [1268/3125], train_loss:0.142863\n",
      "Epoch [1/2], Iter [1269/3125], train_loss:0.145236\n",
      "Epoch [1/2], Iter [1270/3125], train_loss:0.144506\n",
      "Epoch [1/2], Iter [1271/3125], train_loss:0.143809\n",
      "Epoch [1/2], Iter [1272/3125], train_loss:0.144283\n",
      "Epoch [1/2], Iter [1273/3125], train_loss:0.143109\n",
      "Epoch [1/2], Iter [1274/3125], train_loss:0.143813\n",
      "Epoch [1/2], Iter [1275/3125], train_loss:0.144097\n",
      "Epoch [1/2], Iter [1276/3125], train_loss:0.145577\n",
      "Epoch [1/2], Iter [1277/3125], train_loss:0.143906\n",
      "Epoch [1/2], Iter [1278/3125], train_loss:0.145472\n",
      "Epoch [1/2], Iter [1279/3125], train_loss:0.144800\n",
      "Epoch [1/2], Iter [1280/3125], train_loss:0.145203\n",
      "Epoch [1/2], Iter [1281/3125], train_loss:0.143986\n",
      "Epoch [1/2], Iter [1282/3125], train_loss:0.143712\n",
      "Epoch [1/2], Iter [1283/3125], train_loss:0.143111\n",
      "Epoch [1/2], Iter [1284/3125], train_loss:0.143690\n",
      "Epoch [1/2], Iter [1285/3125], train_loss:0.143583\n",
      "Epoch [1/2], Iter [1286/3125], train_loss:0.144027\n",
      "Epoch [1/2], Iter [1287/3125], train_loss:0.144322\n",
      "Epoch [1/2], Iter [1288/3125], train_loss:0.143440\n",
      "Epoch [1/2], Iter [1289/3125], train_loss:0.143536\n",
      "Epoch [1/2], Iter [1290/3125], train_loss:0.143414\n",
      "Epoch [1/2], Iter [1291/3125], train_loss:0.142751\n",
      "Epoch [1/2], Iter [1292/3125], train_loss:0.142032\n",
      "Epoch [1/2], Iter [1293/3125], train_loss:0.143846\n",
      "Epoch [1/2], Iter [1294/3125], train_loss:0.142911\n",
      "Epoch [1/2], Iter [1295/3125], train_loss:0.143722\n",
      "Epoch [1/2], Iter [1296/3125], train_loss:0.144263\n",
      "Epoch [1/2], Iter [1297/3125], train_loss:0.144517\n",
      "Epoch [1/2], Iter [1298/3125], train_loss:0.144930\n",
      "Epoch [1/2], Iter [1299/3125], train_loss:0.143242\n",
      "Epoch [1/2], Iter [1300/3125], train_loss:0.144576\n",
      "Epoch [1/2], Iter [1301/3125], train_loss:0.143995\n",
      "Epoch [1/2], Iter [1302/3125], train_loss:0.144442\n",
      "Epoch [1/2], Iter [1303/3125], train_loss:0.145045\n",
      "Epoch [1/2], Iter [1304/3125], train_loss:0.143620\n",
      "Epoch [1/2], Iter [1305/3125], train_loss:0.144006\n",
      "Epoch [1/2], Iter [1306/3125], train_loss:0.144872\n",
      "Epoch [1/2], Iter [1307/3125], train_loss:0.145171\n",
      "Epoch [1/2], Iter [1308/3125], train_loss:0.144149\n",
      "Epoch [1/2], Iter [1309/3125], train_loss:0.143820\n",
      "Epoch [1/2], Iter [1310/3125], train_loss:0.144387\n",
      "Epoch [1/2], Iter [1311/3125], train_loss:0.143076\n",
      "Epoch [1/2], Iter [1312/3125], train_loss:0.144074\n",
      "Epoch [1/2], Iter [1313/3125], train_loss:0.145157\n",
      "Epoch [1/2], Iter [1314/3125], train_loss:0.143986\n",
      "Epoch [1/2], Iter [1315/3125], train_loss:0.144041\n",
      "Epoch [1/2], Iter [1316/3125], train_loss:0.143370\n",
      "Epoch [1/2], Iter [1317/3125], train_loss:0.143759\n",
      "Epoch [1/2], Iter [1318/3125], train_loss:0.145010\n",
      "Epoch [1/2], Iter [1319/3125], train_loss:0.144025\n",
      "Epoch [1/2], Iter [1320/3125], train_loss:0.142796\n",
      "Epoch [1/2], Iter [1321/3125], train_loss:0.142900\n",
      "Epoch [1/2], Iter [1322/3125], train_loss:0.143843\n",
      "Epoch [1/2], Iter [1323/3125], train_loss:0.143512\n",
      "Epoch [1/2], Iter [1324/3125], train_loss:0.144023\n",
      "Epoch [1/2], Iter [1325/3125], train_loss:0.143564\n",
      "Epoch [1/2], Iter [1326/3125], train_loss:0.143606\n",
      "Epoch [1/2], Iter [1327/3125], train_loss:0.144877\n",
      "Epoch [1/2], Iter [1328/3125], train_loss:0.143468\n",
      "Epoch [1/2], Iter [1329/3125], train_loss:0.142944\n",
      "Epoch [1/2], Iter [1330/3125], train_loss:0.143234\n",
      "Epoch [1/2], Iter [1331/3125], train_loss:0.142924\n",
      "Epoch [1/2], Iter [1332/3125], train_loss:0.144265\n",
      "Epoch [1/2], Iter [1333/3125], train_loss:0.144685\n",
      "Epoch [1/2], Iter [1334/3125], train_loss:0.144212\n",
      "Epoch [1/2], Iter [1335/3125], train_loss:0.142779\n",
      "Epoch [1/2], Iter [1336/3125], train_loss:0.143155\n",
      "Epoch [1/2], Iter [1337/3125], train_loss:0.144395\n",
      "Epoch [1/2], Iter [1338/3125], train_loss:0.144293\n",
      "Epoch [1/2], Iter [1339/3125], train_loss:0.144487\n",
      "Epoch [1/2], Iter [1340/3125], train_loss:0.145144\n",
      "Epoch [1/2], Iter [1341/3125], train_loss:0.143509\n",
      "Epoch [1/2], Iter [1342/3125], train_loss:0.144032\n",
      "Epoch [1/2], Iter [1343/3125], train_loss:0.144902\n",
      "Epoch [1/2], Iter [1344/3125], train_loss:0.143830\n",
      "Epoch [1/2], Iter [1345/3125], train_loss:0.143956\n",
      "Epoch [1/2], Iter [1346/3125], train_loss:0.144809\n",
      "Epoch [1/2], Iter [1347/3125], train_loss:0.144274\n",
      "Epoch [1/2], Iter [1348/3125], train_loss:0.144758\n",
      "Epoch [1/2], Iter [1349/3125], train_loss:0.143904\n",
      "Epoch [1/2], Iter [1350/3125], train_loss:0.144597\n",
      "Epoch [1/2], Iter [1351/3125], train_loss:0.143619\n",
      "Epoch [1/2], Iter [1352/3125], train_loss:0.144504\n",
      "Epoch [1/2], Iter [1353/3125], train_loss:0.143509\n",
      "Epoch [1/2], Iter [1354/3125], train_loss:0.144600\n",
      "Epoch [1/2], Iter [1355/3125], train_loss:0.143271\n",
      "Epoch [1/2], Iter [1356/3125], train_loss:0.144745\n",
      "Epoch [1/2], Iter [1357/3125], train_loss:0.143209\n",
      "Epoch [1/2], Iter [1358/3125], train_loss:0.143980\n",
      "Epoch [1/2], Iter [1359/3125], train_loss:0.143962\n",
      "Epoch [1/2], Iter [1360/3125], train_loss:0.144664\n",
      "Epoch [1/2], Iter [1361/3125], train_loss:0.143978\n",
      "Epoch [1/2], Iter [1362/3125], train_loss:0.144903\n",
      "Epoch [1/2], Iter [1363/3125], train_loss:0.143973\n",
      "Epoch [1/2], Iter [1364/3125], train_loss:0.144969\n",
      "Epoch [1/2], Iter [1365/3125], train_loss:0.142606\n",
      "Epoch [1/2], Iter [1366/3125], train_loss:0.143619\n",
      "Epoch [1/2], Iter [1367/3125], train_loss:0.142560\n",
      "Epoch [1/2], Iter [1368/3125], train_loss:0.145752\n",
      "Epoch [1/2], Iter [1369/3125], train_loss:0.144747\n",
      "Epoch [1/2], Iter [1370/3125], train_loss:0.142676\n",
      "Epoch [1/2], Iter [1371/3125], train_loss:0.143302\n",
      "Epoch [1/2], Iter [1372/3125], train_loss:0.144508\n",
      "Epoch [1/2], Iter [1373/3125], train_loss:0.144152\n",
      "Epoch [1/2], Iter [1374/3125], train_loss:0.144278\n",
      "Epoch [1/2], Iter [1375/3125], train_loss:0.143611\n",
      "Epoch [1/2], Iter [1376/3125], train_loss:0.144194\n",
      "Epoch [1/2], Iter [1377/3125], train_loss:0.144695\n",
      "Epoch [1/2], Iter [1378/3125], train_loss:0.145062\n",
      "Epoch [1/2], Iter [1379/3125], train_loss:0.143310\n",
      "Epoch [1/2], Iter [1380/3125], train_loss:0.144133\n",
      "Epoch [1/2], Iter [1381/3125], train_loss:0.144340\n",
      "Epoch [1/2], Iter [1382/3125], train_loss:0.144811\n",
      "Epoch [1/2], Iter [1383/3125], train_loss:0.144024\n",
      "Epoch [1/2], Iter [1384/3125], train_loss:0.143119\n",
      "Epoch [1/2], Iter [1385/3125], train_loss:0.143819\n",
      "Epoch [1/2], Iter [1386/3125], train_loss:0.145499\n",
      "Epoch [1/2], Iter [1387/3125], train_loss:0.143974\n",
      "Epoch [1/2], Iter [1388/3125], train_loss:0.144645\n",
      "Epoch [1/2], Iter [1389/3125], train_loss:0.143071\n",
      "Epoch [1/2], Iter [1390/3125], train_loss:0.143727\n",
      "Epoch [1/2], Iter [1391/3125], train_loss:0.143947\n",
      "Epoch [1/2], Iter [1392/3125], train_loss:0.141969\n",
      "Epoch [1/2], Iter [1393/3125], train_loss:0.142379\n",
      "Epoch [1/2], Iter [1394/3125], train_loss:0.144611\n",
      "Epoch [1/2], Iter [1395/3125], train_loss:0.143174\n",
      "Epoch [1/2], Iter [1396/3125], train_loss:0.143541\n",
      "Epoch [1/2], Iter [1397/3125], train_loss:0.143647\n",
      "Epoch [1/2], Iter [1398/3125], train_loss:0.143026\n",
      "Epoch [1/2], Iter [1399/3125], train_loss:0.142671\n",
      "Epoch [1/2], Iter [1400/3125], train_loss:0.144512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [1401/3125], train_loss:0.143844\n",
      "Epoch [1/2], Iter [1402/3125], train_loss:0.143268\n",
      "Epoch [1/2], Iter [1403/3125], train_loss:0.145617\n",
      "Epoch [1/2], Iter [1404/3125], train_loss:0.144770\n",
      "Epoch [1/2], Iter [1405/3125], train_loss:0.144653\n",
      "Epoch [1/2], Iter [1406/3125], train_loss:0.144107\n",
      "Epoch [1/2], Iter [1407/3125], train_loss:0.144448\n",
      "Epoch [1/2], Iter [1408/3125], train_loss:0.142808\n",
      "Epoch [1/2], Iter [1409/3125], train_loss:0.143818\n",
      "Epoch [1/2], Iter [1410/3125], train_loss:0.145061\n",
      "Epoch [1/2], Iter [1411/3125], train_loss:0.142640\n",
      "Epoch [1/2], Iter [1412/3125], train_loss:0.143431\n",
      "Epoch [1/2], Iter [1413/3125], train_loss:0.144524\n",
      "Epoch [1/2], Iter [1414/3125], train_loss:0.144385\n",
      "Epoch [1/2], Iter [1415/3125], train_loss:0.142809\n",
      "Epoch [1/2], Iter [1416/3125], train_loss:0.144587\n",
      "Epoch [1/2], Iter [1417/3125], train_loss:0.144608\n",
      "Epoch [1/2], Iter [1418/3125], train_loss:0.144227\n",
      "Epoch [1/2], Iter [1419/3125], train_loss:0.143087\n",
      "Epoch [1/2], Iter [1420/3125], train_loss:0.144255\n",
      "Epoch [1/2], Iter [1421/3125], train_loss:0.144273\n",
      "Epoch [1/2], Iter [1422/3125], train_loss:0.143694\n",
      "Epoch [1/2], Iter [1423/3125], train_loss:0.143774\n",
      "Epoch [1/2], Iter [1424/3125], train_loss:0.143493\n",
      "Epoch [1/2], Iter [1425/3125], train_loss:0.144277\n",
      "Epoch [1/2], Iter [1426/3125], train_loss:0.144898\n",
      "Epoch [1/2], Iter [1427/3125], train_loss:0.143688\n",
      "Epoch [1/2], Iter [1428/3125], train_loss:0.142489\n",
      "Epoch [1/2], Iter [1429/3125], train_loss:0.143051\n",
      "Epoch [1/2], Iter [1430/3125], train_loss:0.144574\n",
      "Epoch [1/2], Iter [1431/3125], train_loss:0.141841\n",
      "Epoch [1/2], Iter [1432/3125], train_loss:0.144702\n",
      "Epoch [1/2], Iter [1433/3125], train_loss:0.144381\n",
      "Epoch [1/2], Iter [1434/3125], train_loss:0.143726\n",
      "Epoch [1/2], Iter [1435/3125], train_loss:0.144256\n",
      "Epoch [1/2], Iter [1436/3125], train_loss:0.144734\n",
      "Epoch [1/2], Iter [1437/3125], train_loss:0.142888\n",
      "Epoch [1/2], Iter [1438/3125], train_loss:0.144111\n",
      "Epoch [1/2], Iter [1439/3125], train_loss:0.144813\n",
      "Epoch [1/2], Iter [1440/3125], train_loss:0.144660\n",
      "Epoch [1/2], Iter [1441/3125], train_loss:0.143067\n",
      "Epoch [1/2], Iter [1442/3125], train_loss:0.143339\n",
      "Epoch [1/2], Iter [1443/3125], train_loss:0.143419\n",
      "Epoch [1/2], Iter [1444/3125], train_loss:0.144826\n",
      "Epoch [1/2], Iter [1445/3125], train_loss:0.145181\n",
      "Epoch [1/2], Iter [1446/3125], train_loss:0.144175\n",
      "Epoch [1/2], Iter [1447/3125], train_loss:0.142661\n",
      "Epoch [1/2], Iter [1448/3125], train_loss:0.144011\n",
      "Epoch [1/2], Iter [1449/3125], train_loss:0.143424\n",
      "Epoch [1/2], Iter [1450/3125], train_loss:0.144263\n",
      "Epoch [1/2], Iter [1451/3125], train_loss:0.144463\n",
      "Epoch [1/2], Iter [1452/3125], train_loss:0.143401\n",
      "Epoch [1/2], Iter [1453/3125], train_loss:0.145640\n",
      "Epoch [1/2], Iter [1454/3125], train_loss:0.144537\n",
      "Epoch [1/2], Iter [1455/3125], train_loss:0.144848\n",
      "Epoch [1/2], Iter [1456/3125], train_loss:0.144618\n",
      "Epoch [1/2], Iter [1457/3125], train_loss:0.144926\n",
      "Epoch [1/2], Iter [1458/3125], train_loss:0.143920\n",
      "Epoch [1/2], Iter [1459/3125], train_loss:0.144162\n",
      "Epoch [1/2], Iter [1460/3125], train_loss:0.145565\n",
      "Epoch [1/2], Iter [1461/3125], train_loss:0.143279\n",
      "Epoch [1/2], Iter [1462/3125], train_loss:0.142301\n",
      "Epoch [1/2], Iter [1463/3125], train_loss:0.143592\n",
      "Epoch [1/2], Iter [1464/3125], train_loss:0.144595\n",
      "Epoch [1/2], Iter [1465/3125], train_loss:0.143212\n",
      "Epoch [1/2], Iter [1466/3125], train_loss:0.144872\n",
      "Epoch [1/2], Iter [1467/3125], train_loss:0.143911\n",
      "Epoch [1/2], Iter [1468/3125], train_loss:0.143112\n",
      "Epoch [1/2], Iter [1469/3125], train_loss:0.145289\n",
      "Epoch [1/2], Iter [1470/3125], train_loss:0.142893\n",
      "Epoch [1/2], Iter [1471/3125], train_loss:0.144046\n",
      "Epoch [1/2], Iter [1472/3125], train_loss:0.144292\n",
      "Epoch [1/2], Iter [1473/3125], train_loss:0.142930\n",
      "Epoch [1/2], Iter [1474/3125], train_loss:0.144414\n",
      "Epoch [1/2], Iter [1475/3125], train_loss:0.144056\n",
      "Epoch [1/2], Iter [1476/3125], train_loss:0.143933\n",
      "Epoch [1/2], Iter [1477/3125], train_loss:0.143824\n",
      "Epoch [1/2], Iter [1478/3125], train_loss:0.143157\n",
      "Epoch [1/2], Iter [1479/3125], train_loss:0.143391\n",
      "Epoch [1/2], Iter [1480/3125], train_loss:0.142837\n",
      "Epoch [1/2], Iter [1481/3125], train_loss:0.145383\n",
      "Epoch [1/2], Iter [1482/3125], train_loss:0.144199\n",
      "Epoch [1/2], Iter [1483/3125], train_loss:0.145276\n",
      "Epoch [1/2], Iter [1484/3125], train_loss:0.143950\n",
      "Epoch [1/2], Iter [1485/3125], train_loss:0.143961\n",
      "Epoch [1/2], Iter [1486/3125], train_loss:0.144233\n",
      "Epoch [1/2], Iter [1487/3125], train_loss:0.144896\n",
      "Epoch [1/2], Iter [1488/3125], train_loss:0.143502\n",
      "Epoch [1/2], Iter [1489/3125], train_loss:0.143028\n",
      "Epoch [1/2], Iter [1490/3125], train_loss:0.143507\n",
      "Epoch [1/2], Iter [1491/3125], train_loss:0.143828\n",
      "Epoch [1/2], Iter [1492/3125], train_loss:0.144373\n",
      "Epoch [1/2], Iter [1493/3125], train_loss:0.143112\n",
      "Epoch [1/2], Iter [1494/3125], train_loss:0.144043\n",
      "Epoch [1/2], Iter [1495/3125], train_loss:0.144760\n",
      "Epoch [1/2], Iter [1496/3125], train_loss:0.143414\n",
      "Epoch [1/2], Iter [1497/3125], train_loss:0.143909\n",
      "Epoch [1/2], Iter [1498/3125], train_loss:0.143093\n",
      "Epoch [1/2], Iter [1499/3125], train_loss:0.144999\n",
      "Epoch [1/2], Iter [1500/3125], train_loss:0.143330\n",
      "Epoch [1/2], Iter [1501/3125], train_loss:0.143255\n",
      "Epoch [1/2], Iter [1502/3125], train_loss:0.143210\n",
      "Epoch [1/2], Iter [1503/3125], train_loss:0.144210\n",
      "Epoch [1/2], Iter [1504/3125], train_loss:0.143363\n",
      "Epoch [1/2], Iter [1505/3125], train_loss:0.143868\n",
      "Epoch [1/2], Iter [1506/3125], train_loss:0.142670\n",
      "Epoch [1/2], Iter [1507/3125], train_loss:0.143760\n",
      "Epoch [1/2], Iter [1508/3125], train_loss:0.144949\n",
      "Epoch [1/2], Iter [1509/3125], train_loss:0.145224\n",
      "Epoch [1/2], Iter [1510/3125], train_loss:0.143596\n",
      "Epoch [1/2], Iter [1511/3125], train_loss:0.141924\n",
      "Epoch [1/2], Iter [1512/3125], train_loss:0.144739\n",
      "Epoch [1/2], Iter [1513/3125], train_loss:0.143032\n",
      "Epoch [1/2], Iter [1514/3125], train_loss:0.144325\n",
      "Epoch [1/2], Iter [1515/3125], train_loss:0.143442\n",
      "Epoch [1/2], Iter [1516/3125], train_loss:0.143245\n",
      "Epoch [1/2], Iter [1517/3125], train_loss:0.144857\n",
      "Epoch [1/2], Iter [1518/3125], train_loss:0.143352\n",
      "Epoch [1/2], Iter [1519/3125], train_loss:0.143484\n",
      "Epoch [1/2], Iter [1520/3125], train_loss:0.143989\n",
      "Epoch [1/2], Iter [1521/3125], train_loss:0.142731\n",
      "Epoch [1/2], Iter [1522/3125], train_loss:0.143922\n",
      "Epoch [1/2], Iter [1523/3125], train_loss:0.144923\n",
      "Epoch [1/2], Iter [1524/3125], train_loss:0.143298\n",
      "Epoch [1/2], Iter [1525/3125], train_loss:0.144058\n",
      "Epoch [1/2], Iter [1526/3125], train_loss:0.144019\n",
      "Epoch [1/2], Iter [1527/3125], train_loss:0.144400\n",
      "Epoch [1/2], Iter [1528/3125], train_loss:0.143191\n",
      "Epoch [1/2], Iter [1529/3125], train_loss:0.144393\n",
      "Epoch [1/2], Iter [1530/3125], train_loss:0.143587\n",
      "Epoch [1/2], Iter [1531/3125], train_loss:0.144607\n",
      "Epoch [1/2], Iter [1532/3125], train_loss:0.143895\n",
      "Epoch [1/2], Iter [1533/3125], train_loss:0.143900\n",
      "Epoch [1/2], Iter [1534/3125], train_loss:0.144580\n",
      "Epoch [1/2], Iter [1535/3125], train_loss:0.145561\n",
      "Epoch [1/2], Iter [1536/3125], train_loss:0.143732\n",
      "Epoch [1/2], Iter [1537/3125], train_loss:0.144494\n",
      "Epoch [1/2], Iter [1538/3125], train_loss:0.144140\n",
      "Epoch [1/2], Iter [1539/3125], train_loss:0.143858\n",
      "Epoch [1/2], Iter [1540/3125], train_loss:0.144920\n",
      "Epoch [1/2], Iter [1541/3125], train_loss:0.145761\n",
      "Epoch [1/2], Iter [1542/3125], train_loss:0.144742\n",
      "Epoch [1/2], Iter [1543/3125], train_loss:0.143744\n",
      "Epoch [1/2], Iter [1544/3125], train_loss:0.143401\n",
      "Epoch [1/2], Iter [1545/3125], train_loss:0.144513\n",
      "Epoch [1/2], Iter [1546/3125], train_loss:0.144207\n",
      "Epoch [1/2], Iter [1547/3125], train_loss:0.144399\n",
      "Epoch [1/2], Iter [1548/3125], train_loss:0.145030\n",
      "Epoch [1/2], Iter [1549/3125], train_loss:0.143089\n",
      "Epoch [1/2], Iter [1550/3125], train_loss:0.143098\n",
      "Epoch [1/2], Iter [1551/3125], train_loss:0.144308\n",
      "Epoch [1/2], Iter [1552/3125], train_loss:0.145008\n",
      "Epoch [1/2], Iter [1553/3125], train_loss:0.143576\n",
      "Epoch [1/2], Iter [1554/3125], train_loss:0.143904\n",
      "Epoch [1/2], Iter [1555/3125], train_loss:0.144215\n",
      "Epoch [1/2], Iter [1556/3125], train_loss:0.143975\n",
      "Epoch [1/2], Iter [1557/3125], train_loss:0.144424\n",
      "Epoch [1/2], Iter [1558/3125], train_loss:0.142579\n",
      "Epoch [1/2], Iter [1559/3125], train_loss:0.144243\n",
      "Epoch [1/2], Iter [1560/3125], train_loss:0.144639\n",
      "Epoch [1/2], Iter [1561/3125], train_loss:0.143873\n",
      "Epoch [1/2], Iter [1562/3125], train_loss:0.143539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [1563/3125], train_loss:0.143983\n",
      "Epoch [1/2], Iter [1564/3125], train_loss:0.142121\n",
      "Epoch [1/2], Iter [1565/3125], train_loss:0.143437\n",
      "Epoch [1/2], Iter [1566/3125], train_loss:0.145382\n",
      "Epoch [1/2], Iter [1567/3125], train_loss:0.143641\n",
      "Epoch [1/2], Iter [1568/3125], train_loss:0.145593\n",
      "Epoch [1/2], Iter [1569/3125], train_loss:0.143672\n",
      "Epoch [1/2], Iter [1570/3125], train_loss:0.144536\n",
      "Epoch [1/2], Iter [1571/3125], train_loss:0.145059\n",
      "Epoch [1/2], Iter [1572/3125], train_loss:0.142913\n",
      "Epoch [1/2], Iter [1573/3125], train_loss:0.143935\n",
      "Epoch [1/2], Iter [1574/3125], train_loss:0.142209\n",
      "Epoch [1/2], Iter [1575/3125], train_loss:0.144704\n",
      "Epoch [1/2], Iter [1576/3125], train_loss:0.145256\n",
      "Epoch [1/2], Iter [1577/3125], train_loss:0.144652\n",
      "Epoch [1/2], Iter [1578/3125], train_loss:0.142689\n",
      "Epoch [1/2], Iter [1579/3125], train_loss:0.144541\n",
      "Epoch [1/2], Iter [1580/3125], train_loss:0.144296\n",
      "Epoch [1/2], Iter [1581/3125], train_loss:0.145190\n",
      "Epoch [1/2], Iter [1582/3125], train_loss:0.143835\n",
      "Epoch [1/2], Iter [1583/3125], train_loss:0.143299\n",
      "Epoch [1/2], Iter [1584/3125], train_loss:0.145315\n",
      "Epoch [1/2], Iter [1585/3125], train_loss:0.143692\n",
      "Epoch [1/2], Iter [1586/3125], train_loss:0.144402\n",
      "Epoch [1/2], Iter [1587/3125], train_loss:0.144213\n",
      "Epoch [1/2], Iter [1588/3125], train_loss:0.143919\n",
      "Epoch [1/2], Iter [1589/3125], train_loss:0.143627\n",
      "Epoch [1/2], Iter [1590/3125], train_loss:0.144478\n",
      "Epoch [1/2], Iter [1591/3125], train_loss:0.142383\n",
      "Epoch [1/2], Iter [1592/3125], train_loss:0.144484\n",
      "Epoch [1/2], Iter [1593/3125], train_loss:0.143803\n",
      "Epoch [1/2], Iter [1594/3125], train_loss:0.142854\n",
      "Epoch [1/2], Iter [1595/3125], train_loss:0.143686\n",
      "Epoch [1/2], Iter [1596/3125], train_loss:0.145100\n",
      "Epoch [1/2], Iter [1597/3125], train_loss:0.144201\n",
      "Epoch [1/2], Iter [1598/3125], train_loss:0.143878\n",
      "Epoch [1/2], Iter [1599/3125], train_loss:0.144793\n",
      "Epoch [1/2], Iter [1600/3125], train_loss:0.144630\n",
      "Epoch [1/2], Iter [1601/3125], train_loss:0.143905\n",
      "Epoch [1/2], Iter [1602/3125], train_loss:0.146380\n",
      "Epoch [1/2], Iter [1603/3125], train_loss:0.142715\n",
      "Epoch [1/2], Iter [1604/3125], train_loss:0.143370\n",
      "Epoch [1/2], Iter [1605/3125], train_loss:0.144884\n",
      "Epoch [1/2], Iter [1606/3125], train_loss:0.144241\n",
      "Epoch [1/2], Iter [1607/3125], train_loss:0.144396\n",
      "Epoch [1/2], Iter [1608/3125], train_loss:0.144478\n",
      "Epoch [1/2], Iter [1609/3125], train_loss:0.144405\n",
      "Epoch [1/2], Iter [1610/3125], train_loss:0.142891\n",
      "Epoch [1/2], Iter [1611/3125], train_loss:0.143310\n",
      "Epoch [1/2], Iter [1612/3125], train_loss:0.144047\n",
      "Epoch [1/2], Iter [1613/3125], train_loss:0.143219\n",
      "Epoch [1/2], Iter [1614/3125], train_loss:0.145607\n",
      "Epoch [1/2], Iter [1615/3125], train_loss:0.144126\n",
      "Epoch [1/2], Iter [1616/3125], train_loss:0.143735\n",
      "Epoch [1/2], Iter [1617/3125], train_loss:0.143634\n",
      "Epoch [1/2], Iter [1618/3125], train_loss:0.144251\n",
      "Epoch [1/2], Iter [1619/3125], train_loss:0.143406\n",
      "Epoch [1/2], Iter [1620/3125], train_loss:0.144669\n",
      "Epoch [1/2], Iter [1621/3125], train_loss:0.143538\n",
      "Epoch [1/2], Iter [1622/3125], train_loss:0.142804\n",
      "Epoch [1/2], Iter [1623/3125], train_loss:0.144560\n",
      "Epoch [1/2], Iter [1624/3125], train_loss:0.143509\n",
      "Epoch [1/2], Iter [1625/3125], train_loss:0.145114\n",
      "Epoch [1/2], Iter [1626/3125], train_loss:0.143554\n",
      "Epoch [1/2], Iter [1627/3125], train_loss:0.144287\n",
      "Epoch [1/2], Iter [1628/3125], train_loss:0.144687\n",
      "Epoch [1/2], Iter [1629/3125], train_loss:0.143417\n",
      "Epoch [1/2], Iter [1630/3125], train_loss:0.143966\n",
      "Epoch [1/2], Iter [1631/3125], train_loss:0.143308\n",
      "Epoch [1/2], Iter [1632/3125], train_loss:0.145927\n",
      "Epoch [1/2], Iter [1633/3125], train_loss:0.143724\n",
      "Epoch [1/2], Iter [1634/3125], train_loss:0.144148\n",
      "Epoch [1/2], Iter [1635/3125], train_loss:0.144750\n",
      "Epoch [1/2], Iter [1636/3125], train_loss:0.144902\n",
      "Epoch [1/2], Iter [1637/3125], train_loss:0.144163\n",
      "Epoch [1/2], Iter [1638/3125], train_loss:0.144523\n",
      "Epoch [1/2], Iter [1639/3125], train_loss:0.144145\n",
      "Epoch [1/2], Iter [1640/3125], train_loss:0.144504\n",
      "Epoch [1/2], Iter [1641/3125], train_loss:0.144214\n",
      "Epoch [1/2], Iter [1642/3125], train_loss:0.143147\n",
      "Epoch [1/2], Iter [1643/3125], train_loss:0.144990\n",
      "Epoch [1/2], Iter [1644/3125], train_loss:0.143900\n",
      "Epoch [1/2], Iter [1645/3125], train_loss:0.143417\n",
      "Epoch [1/2], Iter [1646/3125], train_loss:0.145712\n",
      "Epoch [1/2], Iter [1647/3125], train_loss:0.144449\n",
      "Epoch [1/2], Iter [1648/3125], train_loss:0.143031\n",
      "Epoch [1/2], Iter [1649/3125], train_loss:0.144523\n",
      "Epoch [1/2], Iter [1650/3125], train_loss:0.145374\n",
      "Epoch [1/2], Iter [1651/3125], train_loss:0.143135\n",
      "Epoch [1/2], Iter [1652/3125], train_loss:0.141949\n",
      "Epoch [1/2], Iter [1653/3125], train_loss:0.144668\n",
      "Epoch [1/2], Iter [1654/3125], train_loss:0.143488\n",
      "Epoch [1/2], Iter [1655/3125], train_loss:0.142736\n",
      "Epoch [1/2], Iter [1656/3125], train_loss:0.144752\n",
      "Epoch [1/2], Iter [1657/3125], train_loss:0.144907\n",
      "Epoch [1/2], Iter [1658/3125], train_loss:0.144509\n",
      "Epoch [1/2], Iter [1659/3125], train_loss:0.146503\n",
      "Epoch [1/2], Iter [1660/3125], train_loss:0.144591\n",
      "Epoch [1/2], Iter [1661/3125], train_loss:0.144229\n",
      "Epoch [1/2], Iter [1662/3125], train_loss:0.144941\n",
      "Epoch [1/2], Iter [1663/3125], train_loss:0.144367\n",
      "Epoch [1/2], Iter [1664/3125], train_loss:0.142308\n",
      "Epoch [1/2], Iter [1665/3125], train_loss:0.143756\n",
      "Epoch [1/2], Iter [1666/3125], train_loss:0.144205\n",
      "Epoch [1/2], Iter [1667/3125], train_loss:0.143374\n",
      "Epoch [1/2], Iter [1668/3125], train_loss:0.143733\n",
      "Epoch [1/2], Iter [1669/3125], train_loss:0.143915\n",
      "Epoch [1/2], Iter [1670/3125], train_loss:0.144340\n",
      "Epoch [1/2], Iter [1671/3125], train_loss:0.144462\n",
      "Epoch [1/2], Iter [1672/3125], train_loss:0.144202\n",
      "Epoch [1/2], Iter [1673/3125], train_loss:0.145061\n",
      "Epoch [1/2], Iter [1674/3125], train_loss:0.143934\n",
      "Epoch [1/2], Iter [1675/3125], train_loss:0.142873\n",
      "Epoch [1/2], Iter [1676/3125], train_loss:0.143028\n",
      "Epoch [1/2], Iter [1677/3125], train_loss:0.145003\n",
      "Epoch [1/2], Iter [1678/3125], train_loss:0.143931\n",
      "Epoch [1/2], Iter [1679/3125], train_loss:0.144499\n",
      "Epoch [1/2], Iter [1680/3125], train_loss:0.143871\n",
      "Epoch [1/2], Iter [1681/3125], train_loss:0.143687\n",
      "Epoch [1/2], Iter [1682/3125], train_loss:0.143672\n",
      "Epoch [1/2], Iter [1683/3125], train_loss:0.144955\n",
      "Epoch [1/2], Iter [1684/3125], train_loss:0.144404\n",
      "Epoch [1/2], Iter [1685/3125], train_loss:0.145612\n",
      "Epoch [1/2], Iter [1686/3125], train_loss:0.143598\n",
      "Epoch [1/2], Iter [1687/3125], train_loss:0.145592\n",
      "Epoch [1/2], Iter [1688/3125], train_loss:0.145377\n",
      "Epoch [1/2], Iter [1689/3125], train_loss:0.145545\n",
      "Epoch [1/2], Iter [1690/3125], train_loss:0.144387\n",
      "Epoch [1/2], Iter [1691/3125], train_loss:0.142930\n",
      "Epoch [1/2], Iter [1692/3125], train_loss:0.143986\n",
      "Epoch [1/2], Iter [1693/3125], train_loss:0.142636\n",
      "Epoch [1/2], Iter [1694/3125], train_loss:0.144208\n",
      "Epoch [1/2], Iter [1695/3125], train_loss:0.143869\n",
      "Epoch [1/2], Iter [1696/3125], train_loss:0.143839\n",
      "Epoch [1/2], Iter [1697/3125], train_loss:0.145106\n",
      "Epoch [1/2], Iter [1698/3125], train_loss:0.144089\n",
      "Epoch [1/2], Iter [1699/3125], train_loss:0.144522\n",
      "Epoch [1/2], Iter [1700/3125], train_loss:0.143149\n",
      "Epoch [1/2], Iter [1701/3125], train_loss:0.143842\n",
      "Epoch [1/2], Iter [1702/3125], train_loss:0.143724\n",
      "Epoch [1/2], Iter [1703/3125], train_loss:0.142962\n",
      "Epoch [1/2], Iter [1704/3125], train_loss:0.144339\n",
      "Epoch [1/2], Iter [1705/3125], train_loss:0.142535\n",
      "Epoch [1/2], Iter [1706/3125], train_loss:0.143831\n",
      "Epoch [1/2], Iter [1707/3125], train_loss:0.144982\n",
      "Epoch [1/2], Iter [1708/3125], train_loss:0.144410\n",
      "Epoch [1/2], Iter [1709/3125], train_loss:0.143086\n",
      "Epoch [1/2], Iter [1710/3125], train_loss:0.145149\n",
      "Epoch [1/2], Iter [1711/3125], train_loss:0.144501\n",
      "Epoch [1/2], Iter [1712/3125], train_loss:0.144873\n",
      "Epoch [1/2], Iter [1713/3125], train_loss:0.142660\n",
      "Epoch [1/2], Iter [1714/3125], train_loss:0.143667\n",
      "Epoch [1/2], Iter [1715/3125], train_loss:0.144257\n",
      "Epoch [1/2], Iter [1716/3125], train_loss:0.143462\n",
      "Epoch [1/2], Iter [1717/3125], train_loss:0.142835\n",
      "Epoch [1/2], Iter [1718/3125], train_loss:0.144268\n",
      "Epoch [1/2], Iter [1719/3125], train_loss:0.143391\n",
      "Epoch [1/2], Iter [1720/3125], train_loss:0.143947\n",
      "Epoch [1/2], Iter [1721/3125], train_loss:0.145645\n",
      "Epoch [1/2], Iter [1722/3125], train_loss:0.144343\n",
      "Epoch [1/2], Iter [1723/3125], train_loss:0.143907\n",
      "Epoch [1/2], Iter [1724/3125], train_loss:0.143687\n",
      "Epoch [1/2], Iter [1725/3125], train_loss:0.143317\n",
      "Epoch [1/2], Iter [1726/3125], train_loss:0.144270\n",
      "Epoch [1/2], Iter [1727/3125], train_loss:0.144121\n",
      "Epoch [1/2], Iter [1728/3125], train_loss:0.143719\n",
      "Epoch [1/2], Iter [1729/3125], train_loss:0.145175\n",
      "Epoch [1/2], Iter [1730/3125], train_loss:0.144512\n",
      "Epoch [1/2], Iter [1731/3125], train_loss:0.143618\n",
      "Epoch [1/2], Iter [1732/3125], train_loss:0.142991\n",
      "Epoch [1/2], Iter [1733/3125], train_loss:0.143719\n",
      "Epoch [1/2], Iter [1734/3125], train_loss:0.145468\n",
      "Epoch [1/2], Iter [1735/3125], train_loss:0.145390\n",
      "Epoch [1/2], Iter [1736/3125], train_loss:0.144036\n",
      "Epoch [1/2], Iter [1737/3125], train_loss:0.143311\n",
      "Epoch [1/2], Iter [1738/3125], train_loss:0.144505\n",
      "Epoch [1/2], Iter [1739/3125], train_loss:0.142971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [1740/3125], train_loss:0.143961\n",
      "Epoch [1/2], Iter [1741/3125], train_loss:0.143450\n",
      "Epoch [1/2], Iter [1742/3125], train_loss:0.143193\n",
      "Epoch [1/2], Iter [1743/3125], train_loss:0.143672\n",
      "Epoch [1/2], Iter [1744/3125], train_loss:0.143723\n",
      "Epoch [1/2], Iter [1745/3125], train_loss:0.146398\n",
      "Epoch [1/2], Iter [1746/3125], train_loss:0.144666\n",
      "Epoch [1/2], Iter [1747/3125], train_loss:0.144321\n",
      "Epoch [1/2], Iter [1748/3125], train_loss:0.143597\n",
      "Epoch [1/2], Iter [1749/3125], train_loss:0.143754\n",
      "Epoch [1/2], Iter [1750/3125], train_loss:0.144281\n",
      "Epoch [1/2], Iter [1751/3125], train_loss:0.146180\n",
      "Epoch [1/2], Iter [1752/3125], train_loss:0.143114\n",
      "Epoch [1/2], Iter [1753/3125], train_loss:0.142879\n",
      "Epoch [1/2], Iter [1754/3125], train_loss:0.143066\n",
      "Epoch [1/2], Iter [1755/3125], train_loss:0.144403\n",
      "Epoch [1/2], Iter [1756/3125], train_loss:0.143491\n",
      "Epoch [1/2], Iter [1757/3125], train_loss:0.144278\n",
      "Epoch [1/2], Iter [1758/3125], train_loss:0.144270\n",
      "Epoch [1/2], Iter [1759/3125], train_loss:0.143957\n",
      "Epoch [1/2], Iter [1760/3125], train_loss:0.143205\n",
      "Epoch [1/2], Iter [1761/3125], train_loss:0.143218\n",
      "Epoch [1/2], Iter [1762/3125], train_loss:0.142952\n",
      "Epoch [1/2], Iter [1763/3125], train_loss:0.145104\n",
      "Epoch [1/2], Iter [1764/3125], train_loss:0.143757\n",
      "Epoch [1/2], Iter [1765/3125], train_loss:0.144911\n",
      "Epoch [1/2], Iter [1766/3125], train_loss:0.144462\n",
      "Epoch [1/2], Iter [1767/3125], train_loss:0.144721\n",
      "Epoch [1/2], Iter [1768/3125], train_loss:0.143558\n",
      "Epoch [1/2], Iter [1769/3125], train_loss:0.144334\n",
      "Epoch [1/2], Iter [1770/3125], train_loss:0.142316\n",
      "Epoch [1/2], Iter [1771/3125], train_loss:0.144608\n",
      "Epoch [1/2], Iter [1772/3125], train_loss:0.144683\n",
      "Epoch [1/2], Iter [1773/3125], train_loss:0.143894\n",
      "Epoch [1/2], Iter [1774/3125], train_loss:0.144060\n",
      "Epoch [1/2], Iter [1775/3125], train_loss:0.144900\n",
      "Epoch [1/2], Iter [1776/3125], train_loss:0.143838\n",
      "Epoch [1/2], Iter [1777/3125], train_loss:0.145486\n",
      "Epoch [1/2], Iter [1778/3125], train_loss:0.145247\n",
      "Epoch [1/2], Iter [1779/3125], train_loss:0.144054\n",
      "Epoch [1/2], Iter [1780/3125], train_loss:0.143585\n",
      "Epoch [1/2], Iter [1781/3125], train_loss:0.143429\n",
      "Epoch [1/2], Iter [1782/3125], train_loss:0.143316\n",
      "Epoch [1/2], Iter [1783/3125], train_loss:0.144306\n",
      "Epoch [1/2], Iter [1784/3125], train_loss:0.144655\n",
      "Epoch [1/2], Iter [1785/3125], train_loss:0.143516\n",
      "Epoch [1/2], Iter [1786/3125], train_loss:0.142640\n",
      "Epoch [1/2], Iter [1787/3125], train_loss:0.145844\n",
      "Epoch [1/2], Iter [1788/3125], train_loss:0.144021\n",
      "Epoch [1/2], Iter [1789/3125], train_loss:0.143496\n",
      "Epoch [1/2], Iter [1790/3125], train_loss:0.143275\n",
      "Epoch [1/2], Iter [1791/3125], train_loss:0.143903\n",
      "Epoch [1/2], Iter [1792/3125], train_loss:0.143064\n",
      "Epoch [1/2], Iter [1793/3125], train_loss:0.144225\n",
      "Epoch [1/2], Iter [1794/3125], train_loss:0.143919\n",
      "Epoch [1/2], Iter [1795/3125], train_loss:0.144071\n",
      "Epoch [1/2], Iter [1796/3125], train_loss:0.144981\n",
      "Epoch [1/2], Iter [1797/3125], train_loss:0.142998\n",
      "Epoch [1/2], Iter [1798/3125], train_loss:0.143241\n",
      "Epoch [1/2], Iter [1799/3125], train_loss:0.143523\n",
      "Epoch [1/2], Iter [1800/3125], train_loss:0.145304\n",
      "Epoch [1/2], Iter [1801/3125], train_loss:0.144967\n",
      "Epoch [1/2], Iter [1802/3125], train_loss:0.144663\n",
      "Epoch [1/2], Iter [1803/3125], train_loss:0.145420\n",
      "Epoch [1/2], Iter [1804/3125], train_loss:0.143650\n",
      "Epoch [1/2], Iter [1805/3125], train_loss:0.142107\n",
      "Epoch [1/2], Iter [1806/3125], train_loss:0.142258\n",
      "Epoch [1/2], Iter [1807/3125], train_loss:0.142522\n",
      "Epoch [1/2], Iter [1808/3125], train_loss:0.144335\n",
      "Epoch [1/2], Iter [1809/3125], train_loss:0.142603\n",
      "Epoch [1/2], Iter [1810/3125], train_loss:0.144420\n",
      "Epoch [1/2], Iter [1811/3125], train_loss:0.144124\n",
      "Epoch [1/2], Iter [1812/3125], train_loss:0.144895\n",
      "Epoch [1/2], Iter [1813/3125], train_loss:0.143795\n",
      "Epoch [1/2], Iter [1814/3125], train_loss:0.144077\n",
      "Epoch [1/2], Iter [1815/3125], train_loss:0.144744\n",
      "Epoch [1/2], Iter [1816/3125], train_loss:0.143097\n",
      "Epoch [1/2], Iter [1817/3125], train_loss:0.145164\n",
      "Epoch [1/2], Iter [1818/3125], train_loss:0.144247\n",
      "Epoch [1/2], Iter [1819/3125], train_loss:0.143800\n",
      "Epoch [1/2], Iter [1820/3125], train_loss:0.144988\n",
      "Epoch [1/2], Iter [1821/3125], train_loss:0.142167\n",
      "Epoch [1/2], Iter [1822/3125], train_loss:0.145032\n",
      "Epoch [1/2], Iter [1823/3125], train_loss:0.143713\n",
      "Epoch [1/2], Iter [1824/3125], train_loss:0.143918\n",
      "Epoch [1/2], Iter [1825/3125], train_loss:0.144823\n",
      "Epoch [1/2], Iter [1826/3125], train_loss:0.144213\n",
      "Epoch [1/2], Iter [1827/3125], train_loss:0.143396\n",
      "Epoch [1/2], Iter [1828/3125], train_loss:0.142888\n",
      "Epoch [1/2], Iter [1829/3125], train_loss:0.143617\n",
      "Epoch [1/2], Iter [1830/3125], train_loss:0.143901\n",
      "Epoch [1/2], Iter [1831/3125], train_loss:0.145604\n",
      "Epoch [1/2], Iter [1832/3125], train_loss:0.145392\n",
      "Epoch [1/2], Iter [1833/3125], train_loss:0.144043\n",
      "Epoch [1/2], Iter [1834/3125], train_loss:0.145657\n",
      "Epoch [1/2], Iter [1835/3125], train_loss:0.144148\n",
      "Epoch [1/2], Iter [1836/3125], train_loss:0.144796\n",
      "Epoch [1/2], Iter [1837/3125], train_loss:0.144393\n",
      "Epoch [1/2], Iter [1838/3125], train_loss:0.144530\n",
      "Epoch [1/2], Iter [1839/3125], train_loss:0.144889\n",
      "Epoch [1/2], Iter [1840/3125], train_loss:0.144490\n",
      "Epoch [1/2], Iter [1841/3125], train_loss:0.144570\n",
      "Epoch [1/2], Iter [1842/3125], train_loss:0.144785\n",
      "Epoch [1/2], Iter [1843/3125], train_loss:0.144944\n",
      "Epoch [1/2], Iter [1844/3125], train_loss:0.143712\n",
      "Epoch [1/2], Iter [1845/3125], train_loss:0.143416\n",
      "Epoch [1/2], Iter [1846/3125], train_loss:0.143166\n",
      "Epoch [1/2], Iter [1847/3125], train_loss:0.144074\n",
      "Epoch [1/2], Iter [1848/3125], train_loss:0.144159\n",
      "Epoch [1/2], Iter [1849/3125], train_loss:0.143234\n",
      "Epoch [1/2], Iter [1850/3125], train_loss:0.144309\n",
      "Epoch [1/2], Iter [1851/3125], train_loss:0.144442\n",
      "Epoch [1/2], Iter [1852/3125], train_loss:0.145250\n",
      "Epoch [1/2], Iter [1853/3125], train_loss:0.144717\n",
      "Epoch [1/2], Iter [1854/3125], train_loss:0.142888\n",
      "Epoch [1/2], Iter [1855/3125], train_loss:0.144458\n",
      "Epoch [1/2], Iter [1856/3125], train_loss:0.143648\n",
      "Epoch [1/2], Iter [1857/3125], train_loss:0.144172\n",
      "Epoch [1/2], Iter [1858/3125], train_loss:0.145148\n",
      "Epoch [1/2], Iter [1859/3125], train_loss:0.143895\n",
      "Epoch [1/2], Iter [1860/3125], train_loss:0.143952\n",
      "Epoch [1/2], Iter [1861/3125], train_loss:0.144192\n",
      "Epoch [1/2], Iter [1862/3125], train_loss:0.143637\n",
      "Epoch [1/2], Iter [1863/3125], train_loss:0.142922\n",
      "Epoch [1/2], Iter [1864/3125], train_loss:0.143255\n",
      "Epoch [1/2], Iter [1865/3125], train_loss:0.145422\n",
      "Epoch [1/2], Iter [1866/3125], train_loss:0.142994\n",
      "Epoch [1/2], Iter [1867/3125], train_loss:0.142385\n",
      "Epoch [1/2], Iter [1868/3125], train_loss:0.145667\n",
      "Epoch [1/2], Iter [1869/3125], train_loss:0.144111\n",
      "Epoch [1/2], Iter [1870/3125], train_loss:0.143457\n",
      "Epoch [1/2], Iter [1871/3125], train_loss:0.142491\n",
      "Epoch [1/2], Iter [1872/3125], train_loss:0.144468\n",
      "Epoch [1/2], Iter [1873/3125], train_loss:0.144142\n",
      "Epoch [1/2], Iter [1874/3125], train_loss:0.143026\n",
      "Epoch [1/2], Iter [1875/3125], train_loss:0.143473\n",
      "Epoch [1/2], Iter [1876/3125], train_loss:0.144129\n",
      "Epoch [1/2], Iter [1877/3125], train_loss:0.144572\n",
      "Epoch [1/2], Iter [1878/3125], train_loss:0.144055\n",
      "Epoch [1/2], Iter [1879/3125], train_loss:0.144766\n",
      "Epoch [1/2], Iter [1880/3125], train_loss:0.144818\n",
      "Epoch [1/2], Iter [1881/3125], train_loss:0.142428\n",
      "Epoch [1/2], Iter [1882/3125], train_loss:0.144489\n",
      "Epoch [1/2], Iter [1883/3125], train_loss:0.143872\n",
      "Epoch [1/2], Iter [1884/3125], train_loss:0.143600\n",
      "Epoch [1/2], Iter [1885/3125], train_loss:0.145288\n",
      "Epoch [1/2], Iter [1886/3125], train_loss:0.142142\n",
      "Epoch [1/2], Iter [1887/3125], train_loss:0.142804\n",
      "Epoch [1/2], Iter [1888/3125], train_loss:0.142663\n",
      "Epoch [1/2], Iter [1889/3125], train_loss:0.144270\n",
      "Epoch [1/2], Iter [1890/3125], train_loss:0.144009\n",
      "Epoch [1/2], Iter [1891/3125], train_loss:0.143184\n",
      "Epoch [1/2], Iter [1892/3125], train_loss:0.144836\n",
      "Epoch [1/2], Iter [1893/3125], train_loss:0.143683\n",
      "Epoch [1/2], Iter [1894/3125], train_loss:0.143749\n",
      "Epoch [1/2], Iter [1895/3125], train_loss:0.143939\n",
      "Epoch [1/2], Iter [1896/3125], train_loss:0.143604\n",
      "Epoch [1/2], Iter [1897/3125], train_loss:0.142507\n",
      "Epoch [1/2], Iter [1898/3125], train_loss:0.142748\n",
      "Epoch [1/2], Iter [1899/3125], train_loss:0.144132\n",
      "Epoch [1/2], Iter [1900/3125], train_loss:0.144773\n",
      "Epoch [1/2], Iter [1901/3125], train_loss:0.144476\n",
      "Epoch [1/2], Iter [1902/3125], train_loss:0.142749\n",
      "Epoch [1/2], Iter [1903/3125], train_loss:0.143630\n",
      "Epoch [1/2], Iter [1904/3125], train_loss:0.143455\n",
      "Epoch [1/2], Iter [1905/3125], train_loss:0.147118\n",
      "Epoch [1/2], Iter [1906/3125], train_loss:0.144174\n",
      "Epoch [1/2], Iter [1907/3125], train_loss:0.143823\n",
      "Epoch [1/2], Iter [1908/3125], train_loss:0.143214\n",
      "Epoch [1/2], Iter [1909/3125], train_loss:0.143631\n",
      "Epoch [1/2], Iter [1910/3125], train_loss:0.144682\n",
      "Epoch [1/2], Iter [1911/3125], train_loss:0.144731\n",
      "Epoch [1/2], Iter [1912/3125], train_loss:0.143479\n",
      "Epoch [1/2], Iter [1913/3125], train_loss:0.143555\n",
      "Epoch [1/2], Iter [1914/3125], train_loss:0.142280\n",
      "Epoch [1/2], Iter [1915/3125], train_loss:0.143875\n",
      "Epoch [1/2], Iter [1916/3125], train_loss:0.144546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [1917/3125], train_loss:0.144401\n",
      "Epoch [1/2], Iter [1918/3125], train_loss:0.143320\n",
      "Epoch [1/2], Iter [1919/3125], train_loss:0.145524\n",
      "Epoch [1/2], Iter [1920/3125], train_loss:0.144696\n",
      "Epoch [1/2], Iter [1921/3125], train_loss:0.143110\n",
      "Epoch [1/2], Iter [1922/3125], train_loss:0.144066\n",
      "Epoch [1/2], Iter [1923/3125], train_loss:0.143514\n",
      "Epoch [1/2], Iter [1924/3125], train_loss:0.142873\n",
      "Epoch [1/2], Iter [1925/3125], train_loss:0.143869\n",
      "Epoch [1/2], Iter [1926/3125], train_loss:0.144686\n",
      "Epoch [1/2], Iter [1927/3125], train_loss:0.144182\n",
      "Epoch [1/2], Iter [1928/3125], train_loss:0.144357\n",
      "Epoch [1/2], Iter [1929/3125], train_loss:0.143219\n",
      "Epoch [1/2], Iter [1930/3125], train_loss:0.144602\n",
      "Epoch [1/2], Iter [1931/3125], train_loss:0.143951\n",
      "Epoch [1/2], Iter [1932/3125], train_loss:0.143895\n",
      "Epoch [1/2], Iter [1933/3125], train_loss:0.145482\n",
      "Epoch [1/2], Iter [1934/3125], train_loss:0.142999\n",
      "Epoch [1/2], Iter [1935/3125], train_loss:0.143940\n",
      "Epoch [1/2], Iter [1936/3125], train_loss:0.144836\n",
      "Epoch [1/2], Iter [1937/3125], train_loss:0.143661\n",
      "Epoch [1/2], Iter [1938/3125], train_loss:0.143904\n",
      "Epoch [1/2], Iter [1939/3125], train_loss:0.144028\n",
      "Epoch [1/2], Iter [1940/3125], train_loss:0.143942\n",
      "Epoch [1/2], Iter [1941/3125], train_loss:0.143444\n",
      "Epoch [1/2], Iter [1942/3125], train_loss:0.144959\n",
      "Epoch [1/2], Iter [1943/3125], train_loss:0.143376\n",
      "Epoch [1/2], Iter [1944/3125], train_loss:0.143824\n",
      "Epoch [1/2], Iter [1945/3125], train_loss:0.142069\n",
      "Epoch [1/2], Iter [1946/3125], train_loss:0.144337\n",
      "Epoch [1/2], Iter [1947/3125], train_loss:0.144609\n",
      "Epoch [1/2], Iter [1948/3125], train_loss:0.143830\n",
      "Epoch [1/2], Iter [1949/3125], train_loss:0.144141\n",
      "Epoch [1/2], Iter [1950/3125], train_loss:0.144754\n",
      "Epoch [1/2], Iter [1951/3125], train_loss:0.143703\n",
      "Epoch [1/2], Iter [1952/3125], train_loss:0.144445\n",
      "Epoch [1/2], Iter [1953/3125], train_loss:0.144146\n",
      "Epoch [1/2], Iter [1954/3125], train_loss:0.141797\n",
      "Epoch [1/2], Iter [1955/3125], train_loss:0.144548\n",
      "Epoch [1/2], Iter [1956/3125], train_loss:0.143901\n",
      "Epoch [1/2], Iter [1957/3125], train_loss:0.142273\n",
      "Epoch [1/2], Iter [1958/3125], train_loss:0.143835\n",
      "Epoch [1/2], Iter [1959/3125], train_loss:0.144207\n",
      "Epoch [1/2], Iter [1960/3125], train_loss:0.143892\n",
      "Epoch [1/2], Iter [1961/3125], train_loss:0.144197\n",
      "Epoch [1/2], Iter [1962/3125], train_loss:0.141497\n",
      "Epoch [1/2], Iter [1963/3125], train_loss:0.142953\n",
      "Epoch [1/2], Iter [1964/3125], train_loss:0.144178\n",
      "Epoch [1/2], Iter [1965/3125], train_loss:0.144313\n",
      "Epoch [1/2], Iter [1966/3125], train_loss:0.145376\n",
      "Epoch [1/2], Iter [1967/3125], train_loss:0.143611\n",
      "Epoch [1/2], Iter [1968/3125], train_loss:0.143802\n",
      "Epoch [1/2], Iter [1969/3125], train_loss:0.144811\n",
      "Epoch [1/2], Iter [1970/3125], train_loss:0.143097\n",
      "Epoch [1/2], Iter [1971/3125], train_loss:0.143925\n",
      "Epoch [1/2], Iter [1972/3125], train_loss:0.144482\n",
      "Epoch [1/2], Iter [1973/3125], train_loss:0.144370\n",
      "Epoch [1/2], Iter [1974/3125], train_loss:0.143504\n",
      "Epoch [1/2], Iter [1975/3125], train_loss:0.144400\n",
      "Epoch [1/2], Iter [1976/3125], train_loss:0.144813\n",
      "Epoch [1/2], Iter [1977/3125], train_loss:0.144880\n",
      "Epoch [1/2], Iter [1978/3125], train_loss:0.143977\n",
      "Epoch [1/2], Iter [1979/3125], train_loss:0.143225\n",
      "Epoch [1/2], Iter [1980/3125], train_loss:0.145141\n",
      "Epoch [1/2], Iter [1981/3125], train_loss:0.143131\n",
      "Epoch [1/2], Iter [1982/3125], train_loss:0.141774\n",
      "Epoch [1/2], Iter [1983/3125], train_loss:0.143336\n",
      "Epoch [1/2], Iter [1984/3125], train_loss:0.145433\n",
      "Epoch [1/2], Iter [1985/3125], train_loss:0.144116\n",
      "Epoch [1/2], Iter [1986/3125], train_loss:0.144679\n",
      "Epoch [1/2], Iter [1987/3125], train_loss:0.143334\n",
      "Epoch [1/2], Iter [1988/3125], train_loss:0.145647\n",
      "Epoch [1/2], Iter [1989/3125], train_loss:0.144525\n",
      "Epoch [1/2], Iter [1990/3125], train_loss:0.143522\n",
      "Epoch [1/2], Iter [1991/3125], train_loss:0.143266\n",
      "Epoch [1/2], Iter [1992/3125], train_loss:0.143736\n",
      "Epoch [1/2], Iter [1993/3125], train_loss:0.144377\n",
      "Epoch [1/2], Iter [1994/3125], train_loss:0.144130\n",
      "Epoch [1/2], Iter [1995/3125], train_loss:0.144317\n",
      "Epoch [1/2], Iter [1996/3125], train_loss:0.144777\n",
      "Epoch [1/2], Iter [1997/3125], train_loss:0.142641\n",
      "Epoch [1/2], Iter [1998/3125], train_loss:0.145139\n",
      "Epoch [1/2], Iter [1999/3125], train_loss:0.145204\n",
      "Epoch [1/2], Iter [2000/3125], train_loss:0.145253\n",
      "Epoch [1/2], Iter [2001/3125], train_loss:0.145249\n",
      "Epoch [1/2], Iter [2002/3125], train_loss:0.143328\n",
      "Epoch [1/2], Iter [2003/3125], train_loss:0.143616\n",
      "Epoch [1/2], Iter [2004/3125], train_loss:0.144935\n",
      "Epoch [1/2], Iter [2005/3125], train_loss:0.142160\n",
      "Epoch [1/2], Iter [2006/3125], train_loss:0.145853\n",
      "Epoch [1/2], Iter [2007/3125], train_loss:0.144242\n",
      "Epoch [1/2], Iter [2008/3125], train_loss:0.144427\n",
      "Epoch [1/2], Iter [2009/3125], train_loss:0.145689\n",
      "Epoch [1/2], Iter [2010/3125], train_loss:0.144990\n",
      "Epoch [1/2], Iter [2011/3125], train_loss:0.144498\n",
      "Epoch [1/2], Iter [2012/3125], train_loss:0.144087\n",
      "Epoch [1/2], Iter [2013/3125], train_loss:0.144506\n",
      "Epoch [1/2], Iter [2014/3125], train_loss:0.144841\n",
      "Epoch [1/2], Iter [2015/3125], train_loss:0.143995\n",
      "Epoch [1/2], Iter [2016/3125], train_loss:0.143052\n",
      "Epoch [1/2], Iter [2017/3125], train_loss:0.143192\n",
      "Epoch [1/2], Iter [2018/3125], train_loss:0.143088\n",
      "Epoch [1/2], Iter [2019/3125], train_loss:0.143936\n",
      "Epoch [1/2], Iter [2020/3125], train_loss:0.146363\n",
      "Epoch [1/2], Iter [2021/3125], train_loss:0.144188\n",
      "Epoch [1/2], Iter [2022/3125], train_loss:0.143204\n",
      "Epoch [1/2], Iter [2023/3125], train_loss:0.145260\n",
      "Epoch [1/2], Iter [2024/3125], train_loss:0.143073\n",
      "Epoch [1/2], Iter [2025/3125], train_loss:0.143619\n",
      "Epoch [1/2], Iter [2026/3125], train_loss:0.144336\n",
      "Epoch [1/2], Iter [2027/3125], train_loss:0.143401\n",
      "Epoch [1/2], Iter [2028/3125], train_loss:0.144269\n",
      "Epoch [1/2], Iter [2029/3125], train_loss:0.144545\n",
      "Epoch [1/2], Iter [2030/3125], train_loss:0.143189\n",
      "Epoch [1/2], Iter [2031/3125], train_loss:0.146014\n",
      "Epoch [1/2], Iter [2032/3125], train_loss:0.144205\n",
      "Epoch [1/2], Iter [2033/3125], train_loss:0.142616\n",
      "Epoch [1/2], Iter [2034/3125], train_loss:0.142729\n",
      "Epoch [1/2], Iter [2035/3125], train_loss:0.143769\n",
      "Epoch [1/2], Iter [2036/3125], train_loss:0.145133\n",
      "Epoch [1/2], Iter [2037/3125], train_loss:0.144505\n",
      "Epoch [1/2], Iter [2038/3125], train_loss:0.143161\n",
      "Epoch [1/2], Iter [2039/3125], train_loss:0.142306\n",
      "Epoch [1/2], Iter [2040/3125], train_loss:0.145199\n",
      "Epoch [1/2], Iter [2041/3125], train_loss:0.143407\n",
      "Epoch [1/2], Iter [2042/3125], train_loss:0.144937\n",
      "Epoch [1/2], Iter [2043/3125], train_loss:0.143101\n",
      "Epoch [1/2], Iter [2044/3125], train_loss:0.144253\n",
      "Epoch [1/2], Iter [2045/3125], train_loss:0.144320\n",
      "Epoch [1/2], Iter [2046/3125], train_loss:0.143201\n",
      "Epoch [1/2], Iter [2047/3125], train_loss:0.142781\n",
      "Epoch [1/2], Iter [2048/3125], train_loss:0.146027\n",
      "Epoch [1/2], Iter [2049/3125], train_loss:0.143090\n",
      "Epoch [1/2], Iter [2050/3125], train_loss:0.143553\n",
      "Epoch [1/2], Iter [2051/3125], train_loss:0.143628\n",
      "Epoch [1/2], Iter [2052/3125], train_loss:0.142730\n",
      "Epoch [1/2], Iter [2053/3125], train_loss:0.143109\n",
      "Epoch [1/2], Iter [2054/3125], train_loss:0.143169\n",
      "Epoch [1/2], Iter [2055/3125], train_loss:0.144001\n",
      "Epoch [1/2], Iter [2056/3125], train_loss:0.143950\n",
      "Epoch [1/2], Iter [2057/3125], train_loss:0.143693\n",
      "Epoch [1/2], Iter [2058/3125], train_loss:0.144899\n",
      "Epoch [1/2], Iter [2059/3125], train_loss:0.145009\n",
      "Epoch [1/2], Iter [2060/3125], train_loss:0.145116\n",
      "Epoch [1/2], Iter [2061/3125], train_loss:0.143748\n",
      "Epoch [1/2], Iter [2062/3125], train_loss:0.143548\n",
      "Epoch [1/2], Iter [2063/3125], train_loss:0.144752\n",
      "Epoch [1/2], Iter [2064/3125], train_loss:0.144083\n",
      "Epoch [1/2], Iter [2065/3125], train_loss:0.144187\n",
      "Epoch [1/2], Iter [2066/3125], train_loss:0.144315\n",
      "Epoch [1/2], Iter [2067/3125], train_loss:0.143896\n",
      "Epoch [1/2], Iter [2068/3125], train_loss:0.144939\n",
      "Epoch [1/2], Iter [2069/3125], train_loss:0.144600\n",
      "Epoch [1/2], Iter [2070/3125], train_loss:0.142044\n",
      "Epoch [1/2], Iter [2071/3125], train_loss:0.144449\n",
      "Epoch [1/2], Iter [2072/3125], train_loss:0.143944\n",
      "Epoch [1/2], Iter [2073/3125], train_loss:0.143838\n",
      "Epoch [1/2], Iter [2074/3125], train_loss:0.144990\n",
      "Epoch [1/2], Iter [2075/3125], train_loss:0.143290\n",
      "Epoch [1/2], Iter [2076/3125], train_loss:0.143533\n",
      "Epoch [1/2], Iter [2077/3125], train_loss:0.143454\n",
      "Epoch [1/2], Iter [2078/3125], train_loss:0.144920\n",
      "Epoch [1/2], Iter [2079/3125], train_loss:0.143934\n",
      "Epoch [1/2], Iter [2080/3125], train_loss:0.143993\n",
      "Epoch [1/2], Iter [2081/3125], train_loss:0.144664\n",
      "Epoch [1/2], Iter [2082/3125], train_loss:0.144552\n",
      "Epoch [1/2], Iter [2083/3125], train_loss:0.144288\n",
      "Epoch [1/2], Iter [2084/3125], train_loss:0.143241\n",
      "Epoch [1/2], Iter [2085/3125], train_loss:0.144031\n",
      "Epoch [1/2], Iter [2086/3125], train_loss:0.143766\n",
      "Epoch [1/2], Iter [2087/3125], train_loss:0.144532\n",
      "Epoch [1/2], Iter [2088/3125], train_loss:0.142622\n",
      "Epoch [1/2], Iter [2089/3125], train_loss:0.144388\n",
      "Epoch [1/2], Iter [2090/3125], train_loss:0.144237\n",
      "Epoch [1/2], Iter [2091/3125], train_loss:0.144933\n",
      "Epoch [1/2], Iter [2092/3125], train_loss:0.144060\n",
      "Epoch [1/2], Iter [2093/3125], train_loss:0.144134\n",
      "Epoch [1/2], Iter [2094/3125], train_loss:0.143728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [2095/3125], train_loss:0.145574\n",
      "Epoch [1/2], Iter [2096/3125], train_loss:0.144049\n",
      "Epoch [1/2], Iter [2097/3125], train_loss:0.144942\n",
      "Epoch [1/2], Iter [2098/3125], train_loss:0.144347\n",
      "Epoch [1/2], Iter [2099/3125], train_loss:0.143462\n",
      "Epoch [1/2], Iter [2100/3125], train_loss:0.141226\n",
      "Epoch [1/2], Iter [2101/3125], train_loss:0.144108\n",
      "Epoch [1/2], Iter [2102/3125], train_loss:0.143105\n",
      "Epoch [1/2], Iter [2103/3125], train_loss:0.144368\n",
      "Epoch [1/2], Iter [2104/3125], train_loss:0.144280\n",
      "Epoch [1/2], Iter [2105/3125], train_loss:0.143625\n",
      "Epoch [1/2], Iter [2106/3125], train_loss:0.143109\n",
      "Epoch [1/2], Iter [2107/3125], train_loss:0.144015\n",
      "Epoch [1/2], Iter [2108/3125], train_loss:0.144688\n",
      "Epoch [1/2], Iter [2109/3125], train_loss:0.143459\n",
      "Epoch [1/2], Iter [2110/3125], train_loss:0.145338\n",
      "Epoch [1/2], Iter [2111/3125], train_loss:0.144176\n",
      "Epoch [1/2], Iter [2112/3125], train_loss:0.143381\n",
      "Epoch [1/2], Iter [2113/3125], train_loss:0.143703\n",
      "Epoch [1/2], Iter [2114/3125], train_loss:0.141904\n",
      "Epoch [1/2], Iter [2115/3125], train_loss:0.144001\n",
      "Epoch [1/2], Iter [2116/3125], train_loss:0.143615\n",
      "Epoch [1/2], Iter [2117/3125], train_loss:0.145624\n",
      "Epoch [1/2], Iter [2118/3125], train_loss:0.143867\n",
      "Epoch [1/2], Iter [2119/3125], train_loss:0.143888\n",
      "Epoch [1/2], Iter [2120/3125], train_loss:0.143008\n",
      "Epoch [1/2], Iter [2121/3125], train_loss:0.143810\n",
      "Epoch [1/2], Iter [2122/3125], train_loss:0.144019\n",
      "Epoch [1/2], Iter [2123/3125], train_loss:0.144528\n",
      "Epoch [1/2], Iter [2124/3125], train_loss:0.143166\n",
      "Epoch [1/2], Iter [2125/3125], train_loss:0.143557\n",
      "Epoch [1/2], Iter [2126/3125], train_loss:0.143077\n",
      "Epoch [1/2], Iter [2127/3125], train_loss:0.144243\n",
      "Epoch [1/2], Iter [2128/3125], train_loss:0.143354\n",
      "Epoch [1/2], Iter [2129/3125], train_loss:0.144990\n",
      "Epoch [1/2], Iter [2130/3125], train_loss:0.144673\n",
      "Epoch [1/2], Iter [2131/3125], train_loss:0.143464\n",
      "Epoch [1/2], Iter [2132/3125], train_loss:0.144039\n",
      "Epoch [1/2], Iter [2133/3125], train_loss:0.143941\n",
      "Epoch [1/2], Iter [2134/3125], train_loss:0.145473\n",
      "Epoch [1/2], Iter [2135/3125], train_loss:0.145653\n",
      "Epoch [1/2], Iter [2136/3125], train_loss:0.143884\n",
      "Epoch [1/2], Iter [2137/3125], train_loss:0.143330\n",
      "Epoch [1/2], Iter [2138/3125], train_loss:0.144973\n",
      "Epoch [1/2], Iter [2139/3125], train_loss:0.145184\n",
      "Epoch [1/2], Iter [2140/3125], train_loss:0.143872\n",
      "Epoch [1/2], Iter [2141/3125], train_loss:0.143557\n",
      "Epoch [1/2], Iter [2142/3125], train_loss:0.144445\n",
      "Epoch [1/2], Iter [2143/3125], train_loss:0.145904\n",
      "Epoch [1/2], Iter [2144/3125], train_loss:0.143827\n",
      "Epoch [1/2], Iter [2145/3125], train_loss:0.142945\n",
      "Epoch [1/2], Iter [2146/3125], train_loss:0.144723\n",
      "Epoch [1/2], Iter [2147/3125], train_loss:0.143907\n",
      "Epoch [1/2], Iter [2148/3125], train_loss:0.142551\n",
      "Epoch [1/2], Iter [2149/3125], train_loss:0.143482\n",
      "Epoch [1/2], Iter [2150/3125], train_loss:0.144027\n",
      "Epoch [1/2], Iter [2151/3125], train_loss:0.143018\n",
      "Epoch [1/2], Iter [2152/3125], train_loss:0.145315\n",
      "Epoch [1/2], Iter [2153/3125], train_loss:0.143092\n",
      "Epoch [1/2], Iter [2154/3125], train_loss:0.143914\n",
      "Epoch [1/2], Iter [2155/3125], train_loss:0.143807\n",
      "Epoch [1/2], Iter [2156/3125], train_loss:0.144009\n",
      "Epoch [1/2], Iter [2157/3125], train_loss:0.144386\n",
      "Epoch [1/2], Iter [2158/3125], train_loss:0.143329\n",
      "Epoch [1/2], Iter [2159/3125], train_loss:0.143002\n",
      "Epoch [1/2], Iter [2160/3125], train_loss:0.145045\n",
      "Epoch [1/2], Iter [2161/3125], train_loss:0.143934\n",
      "Epoch [1/2], Iter [2162/3125], train_loss:0.144914\n",
      "Epoch [1/2], Iter [2163/3125], train_loss:0.143710\n",
      "Epoch [1/2], Iter [2164/3125], train_loss:0.143627\n",
      "Epoch [1/2], Iter [2165/3125], train_loss:0.144123\n",
      "Epoch [1/2], Iter [2166/3125], train_loss:0.144108\n",
      "Epoch [1/2], Iter [2167/3125], train_loss:0.142318\n",
      "Epoch [1/2], Iter [2168/3125], train_loss:0.143572\n",
      "Epoch [1/2], Iter [2169/3125], train_loss:0.143071\n",
      "Epoch [1/2], Iter [2170/3125], train_loss:0.144883\n",
      "Epoch [1/2], Iter [2171/3125], train_loss:0.142710\n",
      "Epoch [1/2], Iter [2172/3125], train_loss:0.144646\n",
      "Epoch [1/2], Iter [2173/3125], train_loss:0.143657\n",
      "Epoch [1/2], Iter [2174/3125], train_loss:0.144882\n",
      "Epoch [1/2], Iter [2175/3125], train_loss:0.144273\n",
      "Epoch [1/2], Iter [2176/3125], train_loss:0.143131\n",
      "Epoch [1/2], Iter [2177/3125], train_loss:0.144058\n",
      "Epoch [1/2], Iter [2178/3125], train_loss:0.144864\n",
      "Epoch [1/2], Iter [2179/3125], train_loss:0.145556\n",
      "Epoch [1/2], Iter [2180/3125], train_loss:0.143360\n",
      "Epoch [1/2], Iter [2181/3125], train_loss:0.145560\n",
      "Epoch [1/2], Iter [2182/3125], train_loss:0.144492\n",
      "Epoch [1/2], Iter [2183/3125], train_loss:0.143027\n",
      "Epoch [1/2], Iter [2184/3125], train_loss:0.143743\n",
      "Epoch [1/2], Iter [2185/3125], train_loss:0.143424\n",
      "Epoch [1/2], Iter [2186/3125], train_loss:0.144801\n",
      "Epoch [1/2], Iter [2187/3125], train_loss:0.144731\n",
      "Epoch [1/2], Iter [2188/3125], train_loss:0.143224\n",
      "Epoch [1/2], Iter [2189/3125], train_loss:0.143551\n",
      "Epoch [1/2], Iter [2190/3125], train_loss:0.144095\n",
      "Epoch [1/2], Iter [2191/3125], train_loss:0.144204\n",
      "Epoch [1/2], Iter [2192/3125], train_loss:0.145444\n",
      "Epoch [1/2], Iter [2193/3125], train_loss:0.144721\n",
      "Epoch [1/2], Iter [2194/3125], train_loss:0.144286\n",
      "Epoch [1/2], Iter [2195/3125], train_loss:0.145719\n",
      "Epoch [1/2], Iter [2196/3125], train_loss:0.144884\n",
      "Epoch [1/2], Iter [2197/3125], train_loss:0.143799\n",
      "Epoch [1/2], Iter [2198/3125], train_loss:0.144087\n",
      "Epoch [1/2], Iter [2199/3125], train_loss:0.143117\n",
      "Epoch [1/2], Iter [2200/3125], train_loss:0.143535\n",
      "Epoch [1/2], Iter [2201/3125], train_loss:0.143823\n",
      "Epoch [1/2], Iter [2202/3125], train_loss:0.144697\n",
      "Epoch [1/2], Iter [2203/3125], train_loss:0.143535\n",
      "Epoch [1/2], Iter [2204/3125], train_loss:0.144420\n",
      "Epoch [1/2], Iter [2205/3125], train_loss:0.143898\n",
      "Epoch [1/2], Iter [2206/3125], train_loss:0.143503\n",
      "Epoch [1/2], Iter [2207/3125], train_loss:0.144051\n",
      "Epoch [1/2], Iter [2208/3125], train_loss:0.144082\n",
      "Epoch [1/2], Iter [2209/3125], train_loss:0.144420\n",
      "Epoch [1/2], Iter [2210/3125], train_loss:0.144177\n",
      "Epoch [1/2], Iter [2211/3125], train_loss:0.145044\n",
      "Epoch [1/2], Iter [2212/3125], train_loss:0.143716\n",
      "Epoch [1/2], Iter [2213/3125], train_loss:0.144038\n",
      "Epoch [1/2], Iter [2214/3125], train_loss:0.143661\n",
      "Epoch [1/2], Iter [2215/3125], train_loss:0.143431\n",
      "Epoch [1/2], Iter [2216/3125], train_loss:0.144381\n",
      "Epoch [1/2], Iter [2217/3125], train_loss:0.144944\n",
      "Epoch [1/2], Iter [2218/3125], train_loss:0.144345\n",
      "Epoch [1/2], Iter [2219/3125], train_loss:0.144387\n",
      "Epoch [1/2], Iter [2220/3125], train_loss:0.144369\n",
      "Epoch [1/2], Iter [2221/3125], train_loss:0.145072\n",
      "Epoch [1/2], Iter [2222/3125], train_loss:0.143889\n",
      "Epoch [1/2], Iter [2223/3125], train_loss:0.143811\n",
      "Epoch [1/2], Iter [2224/3125], train_loss:0.143874\n",
      "Epoch [1/2], Iter [2225/3125], train_loss:0.145251\n",
      "Epoch [1/2], Iter [2226/3125], train_loss:0.142463\n",
      "Epoch [1/2], Iter [2227/3125], train_loss:0.144900\n",
      "Epoch [1/2], Iter [2228/3125], train_loss:0.144921\n",
      "Epoch [1/2], Iter [2229/3125], train_loss:0.144071\n",
      "Epoch [1/2], Iter [2230/3125], train_loss:0.143362\n",
      "Epoch [1/2], Iter [2231/3125], train_loss:0.144389\n",
      "Epoch [1/2], Iter [2232/3125], train_loss:0.144043\n",
      "Epoch [1/2], Iter [2233/3125], train_loss:0.143944\n",
      "Epoch [1/2], Iter [2234/3125], train_loss:0.143074\n",
      "Epoch [1/2], Iter [2235/3125], train_loss:0.143517\n",
      "Epoch [1/2], Iter [2236/3125], train_loss:0.144878\n",
      "Epoch [1/2], Iter [2237/3125], train_loss:0.143533\n",
      "Epoch [1/2], Iter [2238/3125], train_loss:0.143122\n",
      "Epoch [1/2], Iter [2239/3125], train_loss:0.144094\n",
      "Epoch [1/2], Iter [2240/3125], train_loss:0.143049\n",
      "Epoch [1/2], Iter [2241/3125], train_loss:0.145415\n",
      "Epoch [1/2], Iter [2242/3125], train_loss:0.145115\n",
      "Epoch [1/2], Iter [2243/3125], train_loss:0.143321\n",
      "Epoch [1/2], Iter [2244/3125], train_loss:0.144017\n",
      "Epoch [1/2], Iter [2245/3125], train_loss:0.144730\n",
      "Epoch [1/2], Iter [2246/3125], train_loss:0.143561\n",
      "Epoch [1/2], Iter [2247/3125], train_loss:0.142791\n",
      "Epoch [1/2], Iter [2248/3125], train_loss:0.143886\n",
      "Epoch [1/2], Iter [2249/3125], train_loss:0.142681\n",
      "Epoch [1/2], Iter [2250/3125], train_loss:0.142595\n",
      "Epoch [1/2], Iter [2251/3125], train_loss:0.143162\n",
      "Epoch [1/2], Iter [2252/3125], train_loss:0.143978\n",
      "Epoch [1/2], Iter [2253/3125], train_loss:0.144705\n",
      "Epoch [1/2], Iter [2254/3125], train_loss:0.144939\n",
      "Epoch [1/2], Iter [2255/3125], train_loss:0.143519\n",
      "Epoch [1/2], Iter [2256/3125], train_loss:0.143603\n",
      "Epoch [1/2], Iter [2257/3125], train_loss:0.143429\n",
      "Epoch [1/2], Iter [2258/3125], train_loss:0.144076\n",
      "Epoch [1/2], Iter [2259/3125], train_loss:0.144765\n",
      "Epoch [1/2], Iter [2260/3125], train_loss:0.144532\n",
      "Epoch [1/2], Iter [2261/3125], train_loss:0.142069\n",
      "Epoch [1/2], Iter [2262/3125], train_loss:0.142688\n",
      "Epoch [1/2], Iter [2263/3125], train_loss:0.144190\n",
      "Epoch [1/2], Iter [2264/3125], train_loss:0.143708\n",
      "Epoch [1/2], Iter [2265/3125], train_loss:0.144758\n",
      "Epoch [1/2], Iter [2266/3125], train_loss:0.142190\n",
      "Epoch [1/2], Iter [2267/3125], train_loss:0.144142\n",
      "Epoch [1/2], Iter [2268/3125], train_loss:0.144004\n",
      "Epoch [1/2], Iter [2269/3125], train_loss:0.143661\n",
      "Epoch [1/2], Iter [2270/3125], train_loss:0.144255\n",
      "Epoch [1/2], Iter [2271/3125], train_loss:0.143930\n",
      "Epoch [1/2], Iter [2272/3125], train_loss:0.144234\n",
      "Epoch [1/2], Iter [2273/3125], train_loss:0.143378\n",
      "Epoch [1/2], Iter [2274/3125], train_loss:0.143714\n",
      "Epoch [1/2], Iter [2275/3125], train_loss:0.143738\n",
      "Epoch [1/2], Iter [2276/3125], train_loss:0.142990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [2277/3125], train_loss:0.144048\n",
      "Epoch [1/2], Iter [2278/3125], train_loss:0.143889\n",
      "Epoch [1/2], Iter [2279/3125], train_loss:0.144102\n",
      "Epoch [1/2], Iter [2280/3125], train_loss:0.144539\n",
      "Epoch [1/2], Iter [2281/3125], train_loss:0.143488\n",
      "Epoch [1/2], Iter [2282/3125], train_loss:0.143994\n",
      "Epoch [1/2], Iter [2283/3125], train_loss:0.144321\n",
      "Epoch [1/2], Iter [2284/3125], train_loss:0.142902\n",
      "Epoch [1/2], Iter [2285/3125], train_loss:0.144954\n",
      "Epoch [1/2], Iter [2286/3125], train_loss:0.144875\n",
      "Epoch [1/2], Iter [2287/3125], train_loss:0.144440\n",
      "Epoch [1/2], Iter [2288/3125], train_loss:0.143496\n",
      "Epoch [1/2], Iter [2289/3125], train_loss:0.144408\n",
      "Epoch [1/2], Iter [2290/3125], train_loss:0.143076\n",
      "Epoch [1/2], Iter [2291/3125], train_loss:0.144952\n",
      "Epoch [1/2], Iter [2292/3125], train_loss:0.142678\n",
      "Epoch [1/2], Iter [2293/3125], train_loss:0.144356\n",
      "Epoch [1/2], Iter [2294/3125], train_loss:0.144050\n",
      "Epoch [1/2], Iter [2295/3125], train_loss:0.142533\n",
      "Epoch [1/2], Iter [2296/3125], train_loss:0.143230\n",
      "Epoch [1/2], Iter [2297/3125], train_loss:0.144639\n",
      "Epoch [1/2], Iter [2298/3125], train_loss:0.143166\n",
      "Epoch [1/2], Iter [2299/3125], train_loss:0.145608\n",
      "Epoch [1/2], Iter [2300/3125], train_loss:0.145098\n",
      "Epoch [1/2], Iter [2301/3125], train_loss:0.144811\n",
      "Epoch [1/2], Iter [2302/3125], train_loss:0.144184\n",
      "Epoch [1/2], Iter [2303/3125], train_loss:0.145288\n",
      "Epoch [1/2], Iter [2304/3125], train_loss:0.144275\n",
      "Epoch [1/2], Iter [2305/3125], train_loss:0.144990\n",
      "Epoch [1/2], Iter [2306/3125], train_loss:0.144581\n",
      "Epoch [1/2], Iter [2307/3125], train_loss:0.143692\n",
      "Epoch [1/2], Iter [2308/3125], train_loss:0.144809\n",
      "Epoch [1/2], Iter [2309/3125], train_loss:0.143322\n",
      "Epoch [1/2], Iter [2310/3125], train_loss:0.144191\n",
      "Epoch [1/2], Iter [2311/3125], train_loss:0.144327\n",
      "Epoch [1/2], Iter [2312/3125], train_loss:0.143179\n",
      "Epoch [1/2], Iter [2313/3125], train_loss:0.144924\n",
      "Epoch [1/2], Iter [2314/3125], train_loss:0.143707\n",
      "Epoch [1/2], Iter [2315/3125], train_loss:0.145278\n",
      "Epoch [1/2], Iter [2316/3125], train_loss:0.143161\n",
      "Epoch [1/2], Iter [2317/3125], train_loss:0.144609\n",
      "Epoch [1/2], Iter [2318/3125], train_loss:0.143496\n",
      "Epoch [1/2], Iter [2319/3125], train_loss:0.143841\n",
      "Epoch [1/2], Iter [2320/3125], train_loss:0.144440\n",
      "Epoch [1/2], Iter [2321/3125], train_loss:0.144370\n",
      "Epoch [1/2], Iter [2322/3125], train_loss:0.145025\n",
      "Epoch [1/2], Iter [2323/3125], train_loss:0.143291\n",
      "Epoch [1/2], Iter [2324/3125], train_loss:0.143961\n",
      "Epoch [1/2], Iter [2325/3125], train_loss:0.143610\n",
      "Epoch [1/2], Iter [2326/3125], train_loss:0.143694\n",
      "Epoch [1/2], Iter [2327/3125], train_loss:0.143313\n",
      "Epoch [1/2], Iter [2328/3125], train_loss:0.144374\n",
      "Epoch [1/2], Iter [2329/3125], train_loss:0.144280\n",
      "Epoch [1/2], Iter [2330/3125], train_loss:0.144154\n",
      "Epoch [1/2], Iter [2331/3125], train_loss:0.144915\n",
      "Epoch [1/2], Iter [2332/3125], train_loss:0.142967\n",
      "Epoch [1/2], Iter [2333/3125], train_loss:0.143280\n",
      "Epoch [1/2], Iter [2334/3125], train_loss:0.144521\n",
      "Epoch [1/2], Iter [2335/3125], train_loss:0.143451\n",
      "Epoch [1/2], Iter [2336/3125], train_loss:0.143608\n",
      "Epoch [1/2], Iter [2337/3125], train_loss:0.144127\n",
      "Epoch [1/2], Iter [2338/3125], train_loss:0.143634\n",
      "Epoch [1/2], Iter [2339/3125], train_loss:0.141629\n",
      "Epoch [1/2], Iter [2340/3125], train_loss:0.144362\n",
      "Epoch [1/2], Iter [2341/3125], train_loss:0.143183\n",
      "Epoch [1/2], Iter [2342/3125], train_loss:0.143263\n",
      "Epoch [1/2], Iter [2343/3125], train_loss:0.142989\n",
      "Epoch [1/2], Iter [2344/3125], train_loss:0.142953\n",
      "Epoch [1/2], Iter [2345/3125], train_loss:0.144877\n",
      "Epoch [1/2], Iter [2346/3125], train_loss:0.143761\n",
      "Epoch [1/2], Iter [2347/3125], train_loss:0.146244\n",
      "Epoch [1/2], Iter [2348/3125], train_loss:0.144309\n",
      "Epoch [1/2], Iter [2349/3125], train_loss:0.143447\n",
      "Epoch [1/2], Iter [2350/3125], train_loss:0.144973\n",
      "Epoch [1/2], Iter [2351/3125], train_loss:0.143875\n",
      "Epoch [1/2], Iter [2352/3125], train_loss:0.144019\n",
      "Epoch [1/2], Iter [2353/3125], train_loss:0.140748\n",
      "Epoch [1/2], Iter [2354/3125], train_loss:0.143934\n",
      "Epoch [1/2], Iter [2355/3125], train_loss:0.144645\n",
      "Epoch [1/2], Iter [2356/3125], train_loss:0.143047\n",
      "Epoch [1/2], Iter [2357/3125], train_loss:0.144035\n",
      "Epoch [1/2], Iter [2358/3125], train_loss:0.144938\n",
      "Epoch [1/2], Iter [2359/3125], train_loss:0.144950\n",
      "Epoch [1/2], Iter [2360/3125], train_loss:0.143997\n",
      "Epoch [1/2], Iter [2361/3125], train_loss:0.143716\n",
      "Epoch [1/2], Iter [2362/3125], train_loss:0.143349\n",
      "Epoch [1/2], Iter [2363/3125], train_loss:0.143016\n",
      "Epoch [1/2], Iter [2364/3125], train_loss:0.143721\n",
      "Epoch [1/2], Iter [2365/3125], train_loss:0.143850\n",
      "Epoch [1/2], Iter [2366/3125], train_loss:0.143392\n",
      "Epoch [1/2], Iter [2367/3125], train_loss:0.143968\n",
      "Epoch [1/2], Iter [2368/3125], train_loss:0.144254\n",
      "Epoch [1/2], Iter [2369/3125], train_loss:0.143653\n",
      "Epoch [1/2], Iter [2370/3125], train_loss:0.143340\n",
      "Epoch [1/2], Iter [2371/3125], train_loss:0.143871\n",
      "Epoch [1/2], Iter [2372/3125], train_loss:0.144727\n",
      "Epoch [1/2], Iter [2373/3125], train_loss:0.144019\n",
      "Epoch [1/2], Iter [2374/3125], train_loss:0.143955\n",
      "Epoch [1/2], Iter [2375/3125], train_loss:0.144419\n",
      "Epoch [1/2], Iter [2376/3125], train_loss:0.144486\n",
      "Epoch [1/2], Iter [2377/3125], train_loss:0.144529\n",
      "Epoch [1/2], Iter [2378/3125], train_loss:0.146293\n",
      "Epoch [1/2], Iter [2379/3125], train_loss:0.145414\n",
      "Epoch [1/2], Iter [2380/3125], train_loss:0.143599\n",
      "Epoch [1/2], Iter [2381/3125], train_loss:0.144303\n",
      "Epoch [1/2], Iter [2382/3125], train_loss:0.143505\n",
      "Epoch [1/2], Iter [2383/3125], train_loss:0.143116\n",
      "Epoch [1/2], Iter [2384/3125], train_loss:0.143324\n",
      "Epoch [1/2], Iter [2385/3125], train_loss:0.145273\n",
      "Epoch [1/2], Iter [2386/3125], train_loss:0.143546\n",
      "Epoch [1/2], Iter [2387/3125], train_loss:0.144141\n",
      "Epoch [1/2], Iter [2388/3125], train_loss:0.144829\n",
      "Epoch [1/2], Iter [2389/3125], train_loss:0.144073\n",
      "Epoch [1/2], Iter [2390/3125], train_loss:0.145034\n",
      "Epoch [1/2], Iter [2391/3125], train_loss:0.143858\n",
      "Epoch [1/2], Iter [2392/3125], train_loss:0.143326\n",
      "Epoch [1/2], Iter [2393/3125], train_loss:0.143274\n",
      "Epoch [1/2], Iter [2394/3125], train_loss:0.144860\n",
      "Epoch [1/2], Iter [2395/3125], train_loss:0.144227\n",
      "Epoch [1/2], Iter [2396/3125], train_loss:0.145502\n",
      "Epoch [1/2], Iter [2397/3125], train_loss:0.142806\n",
      "Epoch [1/2], Iter [2398/3125], train_loss:0.145099\n",
      "Epoch [1/2], Iter [2399/3125], train_loss:0.142546\n",
      "Epoch [1/2], Iter [2400/3125], train_loss:0.144381\n",
      "Epoch [1/2], Iter [2401/3125], train_loss:0.142384\n",
      "Epoch [1/2], Iter [2402/3125], train_loss:0.145082\n",
      "Epoch [1/2], Iter [2403/3125], train_loss:0.144099\n",
      "Epoch [1/2], Iter [2404/3125], train_loss:0.144985\n",
      "Epoch [1/2], Iter [2405/3125], train_loss:0.143662\n",
      "Epoch [1/2], Iter [2406/3125], train_loss:0.144324\n",
      "Epoch [1/2], Iter [2407/3125], train_loss:0.143729\n",
      "Epoch [1/2], Iter [2408/3125], train_loss:0.142938\n",
      "Epoch [1/2], Iter [2409/3125], train_loss:0.143199\n",
      "Epoch [1/2], Iter [2410/3125], train_loss:0.145130\n",
      "Epoch [1/2], Iter [2411/3125], train_loss:0.144141\n",
      "Epoch [1/2], Iter [2412/3125], train_loss:0.143037\n",
      "Epoch [1/2], Iter [2413/3125], train_loss:0.144798\n",
      "Epoch [1/2], Iter [2414/3125], train_loss:0.144236\n",
      "Epoch [1/2], Iter [2415/3125], train_loss:0.145150\n",
      "Epoch [1/2], Iter [2416/3125], train_loss:0.144623\n",
      "Epoch [1/2], Iter [2417/3125], train_loss:0.144002\n",
      "Epoch [1/2], Iter [2418/3125], train_loss:0.143724\n",
      "Epoch [1/2], Iter [2419/3125], train_loss:0.145653\n",
      "Epoch [1/2], Iter [2420/3125], train_loss:0.142286\n",
      "Epoch [1/2], Iter [2421/3125], train_loss:0.143354\n",
      "Epoch [1/2], Iter [2422/3125], train_loss:0.144390\n",
      "Epoch [1/2], Iter [2423/3125], train_loss:0.143103\n",
      "Epoch [1/2], Iter [2424/3125], train_loss:0.142037\n",
      "Epoch [1/2], Iter [2425/3125], train_loss:0.144933\n",
      "Epoch [1/2], Iter [2426/3125], train_loss:0.144710\n",
      "Epoch [1/2], Iter [2427/3125], train_loss:0.144726\n",
      "Epoch [1/2], Iter [2428/3125], train_loss:0.145224\n",
      "Epoch [1/2], Iter [2429/3125], train_loss:0.143259\n",
      "Epoch [1/2], Iter [2430/3125], train_loss:0.143748\n",
      "Epoch [1/2], Iter [2431/3125], train_loss:0.144943\n",
      "Epoch [1/2], Iter [2432/3125], train_loss:0.144319\n",
      "Epoch [1/2], Iter [2433/3125], train_loss:0.145117\n",
      "Epoch [1/2], Iter [2434/3125], train_loss:0.143591\n",
      "Epoch [1/2], Iter [2435/3125], train_loss:0.142980\n",
      "Epoch [1/2], Iter [2436/3125], train_loss:0.143981\n",
      "Epoch [1/2], Iter [2437/3125], train_loss:0.142656\n",
      "Epoch [1/2], Iter [2438/3125], train_loss:0.144071\n",
      "Epoch [1/2], Iter [2439/3125], train_loss:0.143726\n",
      "Epoch [1/2], Iter [2440/3125], train_loss:0.144970\n",
      "Epoch [1/2], Iter [2441/3125], train_loss:0.142693\n",
      "Epoch [1/2], Iter [2442/3125], train_loss:0.145041\n",
      "Epoch [1/2], Iter [2443/3125], train_loss:0.145284\n",
      "Epoch [1/2], Iter [2444/3125], train_loss:0.145855\n",
      "Epoch [1/2], Iter [2445/3125], train_loss:0.143079\n",
      "Epoch [1/2], Iter [2446/3125], train_loss:0.144320\n",
      "Epoch [1/2], Iter [2447/3125], train_loss:0.142643\n",
      "Epoch [1/2], Iter [2448/3125], train_loss:0.143914\n",
      "Epoch [1/2], Iter [2449/3125], train_loss:0.144535\n",
      "Epoch [1/2], Iter [2450/3125], train_loss:0.143694\n",
      "Epoch [1/2], Iter [2451/3125], train_loss:0.145006\n",
      "Epoch [1/2], Iter [2452/3125], train_loss:0.144824\n",
      "Epoch [1/2], Iter [2453/3125], train_loss:0.143869\n",
      "Epoch [1/2], Iter [2454/3125], train_loss:0.143230\n",
      "Epoch [1/2], Iter [2455/3125], train_loss:0.144635\n",
      "Epoch [1/2], Iter [2456/3125], train_loss:0.143948\n",
      "Epoch [1/2], Iter [2457/3125], train_loss:0.144872\n",
      "Epoch [1/2], Iter [2458/3125], train_loss:0.145113\n",
      "Epoch [1/2], Iter [2459/3125], train_loss:0.143338\n",
      "Epoch [1/2], Iter [2460/3125], train_loss:0.142899\n",
      "Epoch [1/2], Iter [2461/3125], train_loss:0.144589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [2462/3125], train_loss:0.142491\n",
      "Epoch [1/2], Iter [2463/3125], train_loss:0.144053\n",
      "Epoch [1/2], Iter [2464/3125], train_loss:0.144557\n",
      "Epoch [1/2], Iter [2465/3125], train_loss:0.143731\n",
      "Epoch [1/2], Iter [2466/3125], train_loss:0.145374\n",
      "Epoch [1/2], Iter [2467/3125], train_loss:0.143314\n",
      "Epoch [1/2], Iter [2468/3125], train_loss:0.143493\n",
      "Epoch [1/2], Iter [2469/3125], train_loss:0.143275\n",
      "Epoch [1/2], Iter [2470/3125], train_loss:0.144532\n",
      "Epoch [1/2], Iter [2471/3125], train_loss:0.144118\n",
      "Epoch [1/2], Iter [2472/3125], train_loss:0.145079\n",
      "Epoch [1/2], Iter [2473/3125], train_loss:0.144283\n",
      "Epoch [1/2], Iter [2474/3125], train_loss:0.144988\n",
      "Epoch [1/2], Iter [2475/3125], train_loss:0.144109\n",
      "Epoch [1/2], Iter [2476/3125], train_loss:0.145141\n",
      "Epoch [1/2], Iter [2477/3125], train_loss:0.143784\n",
      "Epoch [1/2], Iter [2478/3125], train_loss:0.144066\n",
      "Epoch [1/2], Iter [2479/3125], train_loss:0.144671\n",
      "Epoch [1/2], Iter [2480/3125], train_loss:0.144818\n",
      "Epoch [1/2], Iter [2481/3125], train_loss:0.144162\n",
      "Epoch [1/2], Iter [2482/3125], train_loss:0.143942\n",
      "Epoch [1/2], Iter [2483/3125], train_loss:0.143597\n",
      "Epoch [1/2], Iter [2484/3125], train_loss:0.143157\n",
      "Epoch [1/2], Iter [2485/3125], train_loss:0.142916\n",
      "Epoch [1/2], Iter [2486/3125], train_loss:0.145141\n",
      "Epoch [1/2], Iter [2487/3125], train_loss:0.143734\n",
      "Epoch [1/2], Iter [2488/3125], train_loss:0.144621\n",
      "Epoch [1/2], Iter [2489/3125], train_loss:0.144617\n",
      "Epoch [1/2], Iter [2490/3125], train_loss:0.145527\n",
      "Epoch [1/2], Iter [2491/3125], train_loss:0.143515\n",
      "Epoch [1/2], Iter [2492/3125], train_loss:0.144993\n",
      "Epoch [1/2], Iter [2493/3125], train_loss:0.145467\n",
      "Epoch [1/2], Iter [2494/3125], train_loss:0.144240\n",
      "Epoch [1/2], Iter [2495/3125], train_loss:0.143797\n",
      "Epoch [1/2], Iter [2496/3125], train_loss:0.143400\n",
      "Epoch [1/2], Iter [2497/3125], train_loss:0.144260\n",
      "Epoch [1/2], Iter [2498/3125], train_loss:0.142376\n",
      "Epoch [1/2], Iter [2499/3125], train_loss:0.145519\n",
      "Epoch [1/2], Iter [2500/3125], train_loss:0.145188\n",
      "Epoch [1/2], Iter [2501/3125], train_loss:0.144733\n",
      "Epoch [1/2], Iter [2502/3125], train_loss:0.142881\n",
      "Epoch [1/2], Iter [2503/3125], train_loss:0.144183\n",
      "Epoch [1/2], Iter [2504/3125], train_loss:0.143008\n",
      "Epoch [1/2], Iter [2505/3125], train_loss:0.143152\n",
      "Epoch [1/2], Iter [2506/3125], train_loss:0.143825\n",
      "Epoch [1/2], Iter [2507/3125], train_loss:0.143825\n",
      "Epoch [1/2], Iter [2508/3125], train_loss:0.145245\n",
      "Epoch [1/2], Iter [2509/3125], train_loss:0.144121\n",
      "Epoch [1/2], Iter [2510/3125], train_loss:0.143826\n",
      "Epoch [1/2], Iter [2511/3125], train_loss:0.143717\n",
      "Epoch [1/2], Iter [2512/3125], train_loss:0.144065\n",
      "Epoch [1/2], Iter [2513/3125], train_loss:0.143843\n",
      "Epoch [1/2], Iter [2514/3125], train_loss:0.145297\n",
      "Epoch [1/2], Iter [2515/3125], train_loss:0.145124\n",
      "Epoch [1/2], Iter [2516/3125], train_loss:0.145023\n",
      "Epoch [1/2], Iter [2517/3125], train_loss:0.143207\n",
      "Epoch [1/2], Iter [2518/3125], train_loss:0.143580\n",
      "Epoch [1/2], Iter [2519/3125], train_loss:0.143954\n",
      "Epoch [1/2], Iter [2520/3125], train_loss:0.143079\n",
      "Epoch [1/2], Iter [2521/3125], train_loss:0.143076\n",
      "Epoch [1/2], Iter [2522/3125], train_loss:0.143126\n",
      "Epoch [1/2], Iter [2523/3125], train_loss:0.144433\n",
      "Epoch [1/2], Iter [2524/3125], train_loss:0.143181\n",
      "Epoch [1/2], Iter [2525/3125], train_loss:0.144458\n",
      "Epoch [1/2], Iter [2526/3125], train_loss:0.144030\n",
      "Epoch [1/2], Iter [2527/3125], train_loss:0.144800\n",
      "Epoch [1/2], Iter [2528/3125], train_loss:0.142041\n",
      "Epoch [1/2], Iter [2529/3125], train_loss:0.143760\n",
      "Epoch [1/2], Iter [2530/3125], train_loss:0.143568\n",
      "Epoch [1/2], Iter [2531/3125], train_loss:0.145264\n",
      "Epoch [1/2], Iter [2532/3125], train_loss:0.145827\n",
      "Epoch [1/2], Iter [2533/3125], train_loss:0.145150\n",
      "Epoch [1/2], Iter [2534/3125], train_loss:0.144797\n",
      "Epoch [1/2], Iter [2535/3125], train_loss:0.143932\n",
      "Epoch [1/2], Iter [2536/3125], train_loss:0.142884\n",
      "Epoch [1/2], Iter [2537/3125], train_loss:0.142844\n",
      "Epoch [1/2], Iter [2538/3125], train_loss:0.144324\n",
      "Epoch [1/2], Iter [2539/3125], train_loss:0.143854\n",
      "Epoch [1/2], Iter [2540/3125], train_loss:0.142186\n",
      "Epoch [1/2], Iter [2541/3125], train_loss:0.146024\n",
      "Epoch [1/2], Iter [2542/3125], train_loss:0.144605\n",
      "Epoch [1/2], Iter [2543/3125], train_loss:0.143695\n",
      "Epoch [1/2], Iter [2544/3125], train_loss:0.144473\n",
      "Epoch [1/2], Iter [2545/3125], train_loss:0.144448\n",
      "Epoch [1/2], Iter [2546/3125], train_loss:0.144621\n",
      "Epoch [1/2], Iter [2547/3125], train_loss:0.142773\n",
      "Epoch [1/2], Iter [2548/3125], train_loss:0.144560\n",
      "Epoch [1/2], Iter [2549/3125], train_loss:0.144487\n",
      "Epoch [1/2], Iter [2550/3125], train_loss:0.143807\n",
      "Epoch [1/2], Iter [2551/3125], train_loss:0.145153\n",
      "Epoch [1/2], Iter [2552/3125], train_loss:0.144498\n",
      "Epoch [1/2], Iter [2553/3125], train_loss:0.143301\n",
      "Epoch [1/2], Iter [2554/3125], train_loss:0.144541\n",
      "Epoch [1/2], Iter [2555/3125], train_loss:0.142759\n",
      "Epoch [1/2], Iter [2556/3125], train_loss:0.143984\n",
      "Epoch [1/2], Iter [2557/3125], train_loss:0.143889\n",
      "Epoch [1/2], Iter [2558/3125], train_loss:0.145499\n",
      "Epoch [1/2], Iter [2559/3125], train_loss:0.144940\n",
      "Epoch [1/2], Iter [2560/3125], train_loss:0.145003\n",
      "Epoch [1/2], Iter [2561/3125], train_loss:0.144612\n",
      "Epoch [1/2], Iter [2562/3125], train_loss:0.141287\n",
      "Epoch [1/2], Iter [2563/3125], train_loss:0.144000\n",
      "Epoch [1/2], Iter [2564/3125], train_loss:0.144281\n",
      "Epoch [1/2], Iter [2565/3125], train_loss:0.144241\n",
      "Epoch [1/2], Iter [2566/3125], train_loss:0.144301\n",
      "Epoch [1/2], Iter [2567/3125], train_loss:0.145439\n",
      "Epoch [1/2], Iter [2568/3125], train_loss:0.143179\n",
      "Epoch [1/2], Iter [2569/3125], train_loss:0.143535\n",
      "Epoch [1/2], Iter [2570/3125], train_loss:0.143813\n",
      "Epoch [1/2], Iter [2571/3125], train_loss:0.145037\n",
      "Epoch [1/2], Iter [2572/3125], train_loss:0.143332\n",
      "Epoch [1/2], Iter [2573/3125], train_loss:0.145411\n",
      "Epoch [1/2], Iter [2574/3125], train_loss:0.143693\n",
      "Epoch [1/2], Iter [2575/3125], train_loss:0.145153\n",
      "Epoch [1/2], Iter [2576/3125], train_loss:0.143743\n",
      "Epoch [1/2], Iter [2577/3125], train_loss:0.143534\n",
      "Epoch [1/2], Iter [2578/3125], train_loss:0.144721\n",
      "Epoch [1/2], Iter [2579/3125], train_loss:0.144196\n",
      "Epoch [1/2], Iter [2580/3125], train_loss:0.143212\n",
      "Epoch [1/2], Iter [2581/3125], train_loss:0.145165\n",
      "Epoch [1/2], Iter [2582/3125], train_loss:0.144479\n",
      "Epoch [1/2], Iter [2583/3125], train_loss:0.143899\n",
      "Epoch [1/2], Iter [2584/3125], train_loss:0.143580\n",
      "Epoch [1/2], Iter [2585/3125], train_loss:0.143252\n",
      "Epoch [1/2], Iter [2586/3125], train_loss:0.144280\n",
      "Epoch [1/2], Iter [2587/3125], train_loss:0.144734\n",
      "Epoch [1/2], Iter [2588/3125], train_loss:0.145305\n",
      "Epoch [1/2], Iter [2589/3125], train_loss:0.144644\n",
      "Epoch [1/2], Iter [2590/3125], train_loss:0.143346\n",
      "Epoch [1/2], Iter [2591/3125], train_loss:0.144233\n",
      "Epoch [1/2], Iter [2592/3125], train_loss:0.144199\n",
      "Epoch [1/2], Iter [2593/3125], train_loss:0.142558\n",
      "Epoch [1/2], Iter [2594/3125], train_loss:0.144444\n",
      "Epoch [1/2], Iter [2595/3125], train_loss:0.143016\n",
      "Epoch [1/2], Iter [2596/3125], train_loss:0.142637\n",
      "Epoch [1/2], Iter [2597/3125], train_loss:0.143674\n",
      "Epoch [1/2], Iter [2598/3125], train_loss:0.143961\n",
      "Epoch [1/2], Iter [2599/3125], train_loss:0.143420\n",
      "Epoch [1/2], Iter [2600/3125], train_loss:0.144020\n",
      "Epoch [1/2], Iter [2601/3125], train_loss:0.143387\n",
      "Epoch [1/2], Iter [2602/3125], train_loss:0.143102\n",
      "Epoch [1/2], Iter [2603/3125], train_loss:0.145012\n",
      "Epoch [1/2], Iter [2604/3125], train_loss:0.142931\n",
      "Epoch [1/2], Iter [2605/3125], train_loss:0.145360\n",
      "Epoch [1/2], Iter [2606/3125], train_loss:0.144374\n",
      "Epoch [1/2], Iter [2607/3125], train_loss:0.144062\n",
      "Epoch [1/2], Iter [2608/3125], train_loss:0.145222\n",
      "Epoch [1/2], Iter [2609/3125], train_loss:0.143260\n",
      "Epoch [1/2], Iter [2610/3125], train_loss:0.145147\n",
      "Epoch [1/2], Iter [2611/3125], train_loss:0.144385\n",
      "Epoch [1/2], Iter [2612/3125], train_loss:0.144451\n",
      "Epoch [1/2], Iter [2613/3125], train_loss:0.144041\n",
      "Epoch [1/2], Iter [2614/3125], train_loss:0.141998\n",
      "Epoch [1/2], Iter [2615/3125], train_loss:0.144151\n",
      "Epoch [1/2], Iter [2616/3125], train_loss:0.144319\n",
      "Epoch [1/2], Iter [2617/3125], train_loss:0.143153\n",
      "Epoch [1/2], Iter [2618/3125], train_loss:0.143051\n",
      "Epoch [1/2], Iter [2619/3125], train_loss:0.144841\n",
      "Epoch [1/2], Iter [2620/3125], train_loss:0.144379\n",
      "Epoch [1/2], Iter [2621/3125], train_loss:0.143038\n",
      "Epoch [1/2], Iter [2622/3125], train_loss:0.144823\n",
      "Epoch [1/2], Iter [2623/3125], train_loss:0.142981\n",
      "Epoch [1/2], Iter [2624/3125], train_loss:0.144094\n",
      "Epoch [1/2], Iter [2625/3125], train_loss:0.143033\n",
      "Epoch [1/2], Iter [2626/3125], train_loss:0.143880\n",
      "Epoch [1/2], Iter [2627/3125], train_loss:0.144373\n",
      "Epoch [1/2], Iter [2628/3125], train_loss:0.143264\n",
      "Epoch [1/2], Iter [2629/3125], train_loss:0.143299\n",
      "Epoch [1/2], Iter [2630/3125], train_loss:0.145359\n",
      "Epoch [1/2], Iter [2631/3125], train_loss:0.142462\n",
      "Epoch [1/2], Iter [2632/3125], train_loss:0.145752\n",
      "Epoch [1/2], Iter [2633/3125], train_loss:0.143645\n",
      "Epoch [1/2], Iter [2634/3125], train_loss:0.143894\n",
      "Epoch [1/2], Iter [2635/3125], train_loss:0.143829\n",
      "Epoch [1/2], Iter [2636/3125], train_loss:0.143754\n",
      "Epoch [1/2], Iter [2637/3125], train_loss:0.145181\n",
      "Epoch [1/2], Iter [2638/3125], train_loss:0.144930\n",
      "Epoch [1/2], Iter [2639/3125], train_loss:0.143176\n",
      "Epoch [1/2], Iter [2640/3125], train_loss:0.145244\n",
      "Epoch [1/2], Iter [2641/3125], train_loss:0.142942\n",
      "Epoch [1/2], Iter [2642/3125], train_loss:0.143332\n",
      "Epoch [1/2], Iter [2643/3125], train_loss:0.143973\n",
      "Epoch [1/2], Iter [2644/3125], train_loss:0.144993\n",
      "Epoch [1/2], Iter [2645/3125], train_loss:0.145408\n",
      "Epoch [1/2], Iter [2646/3125], train_loss:0.143460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [2647/3125], train_loss:0.144602\n",
      "Epoch [1/2], Iter [2648/3125], train_loss:0.143527\n",
      "Epoch [1/2], Iter [2649/3125], train_loss:0.142852\n",
      "Epoch [1/2], Iter [2650/3125], train_loss:0.145023\n",
      "Epoch [1/2], Iter [2651/3125], train_loss:0.141899\n",
      "Epoch [1/2], Iter [2652/3125], train_loss:0.145086\n",
      "Epoch [1/2], Iter [2653/3125], train_loss:0.143586\n",
      "Epoch [1/2], Iter [2654/3125], train_loss:0.145163\n",
      "Epoch [1/2], Iter [2655/3125], train_loss:0.144321\n",
      "Epoch [1/2], Iter [2656/3125], train_loss:0.143783\n",
      "Epoch [1/2], Iter [2657/3125], train_loss:0.145278\n",
      "Epoch [1/2], Iter [2658/3125], train_loss:0.144103\n",
      "Epoch [1/2], Iter [2659/3125], train_loss:0.142452\n",
      "Epoch [1/2], Iter [2660/3125], train_loss:0.142492\n",
      "Epoch [1/2], Iter [2661/3125], train_loss:0.144963\n",
      "Epoch [1/2], Iter [2662/3125], train_loss:0.143000\n",
      "Epoch [1/2], Iter [2663/3125], train_loss:0.144481\n",
      "Epoch [1/2], Iter [2664/3125], train_loss:0.144055\n",
      "Epoch [1/2], Iter [2665/3125], train_loss:0.144353\n",
      "Epoch [1/2], Iter [2666/3125], train_loss:0.144462\n",
      "Epoch [1/2], Iter [2667/3125], train_loss:0.144795\n",
      "Epoch [1/2], Iter [2668/3125], train_loss:0.144522\n",
      "Epoch [1/2], Iter [2669/3125], train_loss:0.143384\n",
      "Epoch [1/2], Iter [2670/3125], train_loss:0.143284\n",
      "Epoch [1/2], Iter [2671/3125], train_loss:0.145301\n",
      "Epoch [1/2], Iter [2672/3125], train_loss:0.145105\n",
      "Epoch [1/2], Iter [2673/3125], train_loss:0.143342\n",
      "Epoch [1/2], Iter [2674/3125], train_loss:0.144253\n",
      "Epoch [1/2], Iter [2675/3125], train_loss:0.143540\n",
      "Epoch [1/2], Iter [2676/3125], train_loss:0.144391\n",
      "Epoch [1/2], Iter [2677/3125], train_loss:0.144209\n",
      "Epoch [1/2], Iter [2678/3125], train_loss:0.142666\n",
      "Epoch [1/2], Iter [2679/3125], train_loss:0.144612\n",
      "Epoch [1/2], Iter [2680/3125], train_loss:0.144355\n",
      "Epoch [1/2], Iter [2681/3125], train_loss:0.144500\n",
      "Epoch [1/2], Iter [2682/3125], train_loss:0.143680\n",
      "Epoch [1/2], Iter [2683/3125], train_loss:0.144374\n",
      "Epoch [1/2], Iter [2684/3125], train_loss:0.143668\n",
      "Epoch [1/2], Iter [2685/3125], train_loss:0.143975\n",
      "Epoch [1/2], Iter [2686/3125], train_loss:0.143527\n",
      "Epoch [1/2], Iter [2687/3125], train_loss:0.144899\n",
      "Epoch [1/2], Iter [2688/3125], train_loss:0.144865\n",
      "Epoch [1/2], Iter [2689/3125], train_loss:0.143730\n",
      "Epoch [1/2], Iter [2690/3125], train_loss:0.143718\n",
      "Epoch [1/2], Iter [2691/3125], train_loss:0.144435\n",
      "Epoch [1/2], Iter [2692/3125], train_loss:0.143295\n",
      "Epoch [1/2], Iter [2693/3125], train_loss:0.143201\n",
      "Epoch [1/2], Iter [2694/3125], train_loss:0.144394\n",
      "Epoch [1/2], Iter [2695/3125], train_loss:0.145039\n",
      "Epoch [1/2], Iter [2696/3125], train_loss:0.143614\n",
      "Epoch [1/2], Iter [2697/3125], train_loss:0.144040\n",
      "Epoch [1/2], Iter [2698/3125], train_loss:0.144248\n",
      "Epoch [1/2], Iter [2699/3125], train_loss:0.144459\n",
      "Epoch [1/2], Iter [2700/3125], train_loss:0.144469\n",
      "Epoch [1/2], Iter [2701/3125], train_loss:0.144855\n",
      "Epoch [1/2], Iter [2702/3125], train_loss:0.142848\n",
      "Epoch [1/2], Iter [2703/3125], train_loss:0.143708\n",
      "Epoch [1/2], Iter [2704/3125], train_loss:0.143438\n",
      "Epoch [1/2], Iter [2705/3125], train_loss:0.144289\n",
      "Epoch [1/2], Iter [2706/3125], train_loss:0.145531\n",
      "Epoch [1/2], Iter [2707/3125], train_loss:0.144607\n",
      "Epoch [1/2], Iter [2708/3125], train_loss:0.144879\n",
      "Epoch [1/2], Iter [2709/3125], train_loss:0.144015\n",
      "Epoch [1/2], Iter [2710/3125], train_loss:0.143639\n",
      "Epoch [1/2], Iter [2711/3125], train_loss:0.143680\n",
      "Epoch [1/2], Iter [2712/3125], train_loss:0.146035\n",
      "Epoch [1/2], Iter [2713/3125], train_loss:0.143453\n",
      "Epoch [1/2], Iter [2714/3125], train_loss:0.142938\n",
      "Epoch [1/2], Iter [2715/3125], train_loss:0.144998\n",
      "Epoch [1/2], Iter [2716/3125], train_loss:0.143836\n",
      "Epoch [1/2], Iter [2717/3125], train_loss:0.144034\n",
      "Epoch [1/2], Iter [2718/3125], train_loss:0.143783\n",
      "Epoch [1/2], Iter [2719/3125], train_loss:0.142578\n",
      "Epoch [1/2], Iter [2720/3125], train_loss:0.143307\n",
      "Epoch [1/2], Iter [2721/3125], train_loss:0.144291\n",
      "Epoch [1/2], Iter [2722/3125], train_loss:0.144125\n",
      "Epoch [1/2], Iter [2723/3125], train_loss:0.144053\n",
      "Epoch [1/2], Iter [2724/3125], train_loss:0.143692\n",
      "Epoch [1/2], Iter [2725/3125], train_loss:0.144037\n",
      "Epoch [1/2], Iter [2726/3125], train_loss:0.143527\n",
      "Epoch [1/2], Iter [2727/3125], train_loss:0.143582\n",
      "Epoch [1/2], Iter [2728/3125], train_loss:0.144093\n",
      "Epoch [1/2], Iter [2729/3125], train_loss:0.144264\n",
      "Epoch [1/2], Iter [2730/3125], train_loss:0.143351\n",
      "Epoch [1/2], Iter [2731/3125], train_loss:0.142999\n",
      "Epoch [1/2], Iter [2732/3125], train_loss:0.143406\n",
      "Epoch [1/2], Iter [2733/3125], train_loss:0.143150\n",
      "Epoch [1/2], Iter [2734/3125], train_loss:0.143672\n",
      "Epoch [1/2], Iter [2735/3125], train_loss:0.145864\n",
      "Epoch [1/2], Iter [2736/3125], train_loss:0.144517\n",
      "Epoch [1/2], Iter [2737/3125], train_loss:0.142088\n",
      "Epoch [1/2], Iter [2738/3125], train_loss:0.144039\n",
      "Epoch [1/2], Iter [2739/3125], train_loss:0.143960\n",
      "Epoch [1/2], Iter [2740/3125], train_loss:0.143465\n",
      "Epoch [1/2], Iter [2741/3125], train_loss:0.143721\n",
      "Epoch [1/2], Iter [2742/3125], train_loss:0.144047\n",
      "Epoch [1/2], Iter [2743/3125], train_loss:0.144331\n",
      "Epoch [1/2], Iter [2744/3125], train_loss:0.144121\n",
      "Epoch [1/2], Iter [2745/3125], train_loss:0.142374\n",
      "Epoch [1/2], Iter [2746/3125], train_loss:0.144039\n",
      "Epoch [1/2], Iter [2747/3125], train_loss:0.144534\n",
      "Epoch [1/2], Iter [2748/3125], train_loss:0.143411\n",
      "Epoch [1/2], Iter [2749/3125], train_loss:0.145637\n",
      "Epoch [1/2], Iter [2750/3125], train_loss:0.142799\n",
      "Epoch [1/2], Iter [2751/3125], train_loss:0.144757\n",
      "Epoch [1/2], Iter [2752/3125], train_loss:0.144644\n",
      "Epoch [1/2], Iter [2753/3125], train_loss:0.144329\n",
      "Epoch [1/2], Iter [2754/3125], train_loss:0.145511\n",
      "Epoch [1/2], Iter [2755/3125], train_loss:0.143338\n",
      "Epoch [1/2], Iter [2756/3125], train_loss:0.144487\n",
      "Epoch [1/2], Iter [2757/3125], train_loss:0.144542\n",
      "Epoch [1/2], Iter [2758/3125], train_loss:0.143581\n",
      "Epoch [1/2], Iter [2759/3125], train_loss:0.144048\n",
      "Epoch [1/2], Iter [2760/3125], train_loss:0.144220\n",
      "Epoch [1/2], Iter [2761/3125], train_loss:0.143682\n",
      "Epoch [1/2], Iter [2762/3125], train_loss:0.143837\n",
      "Epoch [1/2], Iter [2763/3125], train_loss:0.142797\n",
      "Epoch [1/2], Iter [2764/3125], train_loss:0.142386\n",
      "Epoch [1/2], Iter [2765/3125], train_loss:0.145083\n",
      "Epoch [1/2], Iter [2766/3125], train_loss:0.144636\n",
      "Epoch [1/2], Iter [2767/3125], train_loss:0.144195\n",
      "Epoch [1/2], Iter [2768/3125], train_loss:0.144106\n",
      "Epoch [1/2], Iter [2769/3125], train_loss:0.144387\n",
      "Epoch [1/2], Iter [2770/3125], train_loss:0.144569\n",
      "Epoch [1/2], Iter [2771/3125], train_loss:0.142780\n",
      "Epoch [1/2], Iter [2772/3125], train_loss:0.144147\n",
      "Epoch [1/2], Iter [2773/3125], train_loss:0.144585\n",
      "Epoch [1/2], Iter [2774/3125], train_loss:0.144061\n",
      "Epoch [1/2], Iter [2775/3125], train_loss:0.144508\n",
      "Epoch [1/2], Iter [2776/3125], train_loss:0.143799\n",
      "Epoch [1/2], Iter [2777/3125], train_loss:0.143191\n",
      "Epoch [1/2], Iter [2778/3125], train_loss:0.143721\n",
      "Epoch [1/2], Iter [2779/3125], train_loss:0.143564\n",
      "Epoch [1/2], Iter [2780/3125], train_loss:0.144263\n",
      "Epoch [1/2], Iter [2781/3125], train_loss:0.142544\n",
      "Epoch [1/2], Iter [2782/3125], train_loss:0.143540\n",
      "Epoch [1/2], Iter [2783/3125], train_loss:0.142845\n",
      "Epoch [1/2], Iter [2784/3125], train_loss:0.144043\n",
      "Epoch [1/2], Iter [2785/3125], train_loss:0.143034\n",
      "Epoch [1/2], Iter [2786/3125], train_loss:0.143068\n",
      "Epoch [1/2], Iter [2787/3125], train_loss:0.143712\n",
      "Epoch [1/2], Iter [2788/3125], train_loss:0.144065\n",
      "Epoch [1/2], Iter [2789/3125], train_loss:0.143193\n",
      "Epoch [1/2], Iter [2790/3125], train_loss:0.143056\n",
      "Epoch [1/2], Iter [2791/3125], train_loss:0.143775\n",
      "Epoch [1/2], Iter [2792/3125], train_loss:0.143515\n",
      "Epoch [1/2], Iter [2793/3125], train_loss:0.144277\n",
      "Epoch [1/2], Iter [2794/3125], train_loss:0.143442\n",
      "Epoch [1/2], Iter [2795/3125], train_loss:0.143413\n",
      "Epoch [1/2], Iter [2796/3125], train_loss:0.144412\n",
      "Epoch [1/2], Iter [2797/3125], train_loss:0.143297\n",
      "Epoch [1/2], Iter [2798/3125], train_loss:0.142332\n",
      "Epoch [1/2], Iter [2799/3125], train_loss:0.142307\n",
      "Epoch [1/2], Iter [2800/3125], train_loss:0.143421\n",
      "Epoch [1/2], Iter [2801/3125], train_loss:0.143156\n",
      "Epoch [1/2], Iter [2802/3125], train_loss:0.144746\n",
      "Epoch [1/2], Iter [2803/3125], train_loss:0.143261\n",
      "Epoch [1/2], Iter [2804/3125], train_loss:0.144069\n",
      "Epoch [1/2], Iter [2805/3125], train_loss:0.143945\n",
      "Epoch [1/2], Iter [2806/3125], train_loss:0.143808\n",
      "Epoch [1/2], Iter [2807/3125], train_loss:0.143974\n",
      "Epoch [1/2], Iter [2808/3125], train_loss:0.143842\n",
      "Epoch [1/2], Iter [2809/3125], train_loss:0.143151\n",
      "Epoch [1/2], Iter [2810/3125], train_loss:0.142411\n",
      "Epoch [1/2], Iter [2811/3125], train_loss:0.145234\n",
      "Epoch [1/2], Iter [2812/3125], train_loss:0.142729\n",
      "Epoch [1/2], Iter [2813/3125], train_loss:0.143405\n",
      "Epoch [1/2], Iter [2814/3125], train_loss:0.144475\n",
      "Epoch [1/2], Iter [2815/3125], train_loss:0.143860\n",
      "Epoch [1/2], Iter [2816/3125], train_loss:0.142988\n",
      "Epoch [1/2], Iter [2817/3125], train_loss:0.144185\n",
      "Epoch [1/2], Iter [2818/3125], train_loss:0.143213\n",
      "Epoch [1/2], Iter [2819/3125], train_loss:0.143689\n",
      "Epoch [1/2], Iter [2820/3125], train_loss:0.144903\n",
      "Epoch [1/2], Iter [2821/3125], train_loss:0.142944\n",
      "Epoch [1/2], Iter [2822/3125], train_loss:0.144967\n",
      "Epoch [1/2], Iter [2823/3125], train_loss:0.143297\n",
      "Epoch [1/2], Iter [2824/3125], train_loss:0.143572\n",
      "Epoch [1/2], Iter [2825/3125], train_loss:0.144294\n",
      "Epoch [1/2], Iter [2826/3125], train_loss:0.143459\n",
      "Epoch [1/2], Iter [2827/3125], train_loss:0.141584\n",
      "Epoch [1/2], Iter [2828/3125], train_loss:0.143452\n",
      "Epoch [1/2], Iter [2829/3125], train_loss:0.143711\n",
      "Epoch [1/2], Iter [2830/3125], train_loss:0.142716\n",
      "Epoch [1/2], Iter [2831/3125], train_loss:0.143866\n",
      "Epoch [1/2], Iter [2832/3125], train_loss:0.145111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [2833/3125], train_loss:0.145325\n",
      "Epoch [1/2], Iter [2834/3125], train_loss:0.143195\n",
      "Epoch [1/2], Iter [2835/3125], train_loss:0.143386\n",
      "Epoch [1/2], Iter [2836/3125], train_loss:0.143796\n",
      "Epoch [1/2], Iter [2837/3125], train_loss:0.143619\n",
      "Epoch [1/2], Iter [2838/3125], train_loss:0.143824\n",
      "Epoch [1/2], Iter [2839/3125], train_loss:0.145041\n",
      "Epoch [1/2], Iter [2840/3125], train_loss:0.144156\n",
      "Epoch [1/2], Iter [2841/3125], train_loss:0.144186\n",
      "Epoch [1/2], Iter [2842/3125], train_loss:0.142785\n",
      "Epoch [1/2], Iter [2843/3125], train_loss:0.144664\n",
      "Epoch [1/2], Iter [2844/3125], train_loss:0.143627\n",
      "Epoch [1/2], Iter [2845/3125], train_loss:0.143006\n",
      "Epoch [1/2], Iter [2846/3125], train_loss:0.144436\n",
      "Epoch [1/2], Iter [2847/3125], train_loss:0.144083\n",
      "Epoch [1/2], Iter [2848/3125], train_loss:0.144224\n",
      "Epoch [1/2], Iter [2849/3125], train_loss:0.143347\n",
      "Epoch [1/2], Iter [2850/3125], train_loss:0.143182\n",
      "Epoch [1/2], Iter [2851/3125], train_loss:0.143745\n",
      "Epoch [1/2], Iter [2852/3125], train_loss:0.143832\n",
      "Epoch [1/2], Iter [2853/3125], train_loss:0.144091\n",
      "Epoch [1/2], Iter [2854/3125], train_loss:0.143609\n",
      "Epoch [1/2], Iter [2855/3125], train_loss:0.145200\n",
      "Epoch [1/2], Iter [2856/3125], train_loss:0.143487\n",
      "Epoch [1/2], Iter [2857/3125], train_loss:0.144616\n",
      "Epoch [1/2], Iter [2858/3125], train_loss:0.144021\n",
      "Epoch [1/2], Iter [2859/3125], train_loss:0.144821\n",
      "Epoch [1/2], Iter [2860/3125], train_loss:0.144089\n",
      "Epoch [1/2], Iter [2861/3125], train_loss:0.145350\n",
      "Epoch [1/2], Iter [2862/3125], train_loss:0.143757\n",
      "Epoch [1/2], Iter [2863/3125], train_loss:0.143720\n",
      "Epoch [1/2], Iter [2864/3125], train_loss:0.144411\n",
      "Epoch [1/2], Iter [2865/3125], train_loss:0.145012\n",
      "Epoch [1/2], Iter [2866/3125], train_loss:0.143823\n",
      "Epoch [1/2], Iter [2867/3125], train_loss:0.143428\n",
      "Epoch [1/2], Iter [2868/3125], train_loss:0.144533\n",
      "Epoch [1/2], Iter [2869/3125], train_loss:0.142758\n",
      "Epoch [1/2], Iter [2870/3125], train_loss:0.144033\n",
      "Epoch [1/2], Iter [2871/3125], train_loss:0.144377\n",
      "Epoch [1/2], Iter [2872/3125], train_loss:0.144336\n",
      "Epoch [1/2], Iter [2873/3125], train_loss:0.143576\n",
      "Epoch [1/2], Iter [2874/3125], train_loss:0.144024\n",
      "Epoch [1/2], Iter [2875/3125], train_loss:0.142841\n",
      "Epoch [1/2], Iter [2876/3125], train_loss:0.143970\n",
      "Epoch [1/2], Iter [2877/3125], train_loss:0.144089\n",
      "Epoch [1/2], Iter [2878/3125], train_loss:0.142749\n",
      "Epoch [1/2], Iter [2879/3125], train_loss:0.144485\n",
      "Epoch [1/2], Iter [2880/3125], train_loss:0.144909\n",
      "Epoch [1/2], Iter [2881/3125], train_loss:0.143526\n",
      "Epoch [1/2], Iter [2882/3125], train_loss:0.144731\n",
      "Epoch [1/2], Iter [2883/3125], train_loss:0.144131\n",
      "Epoch [1/2], Iter [2884/3125], train_loss:0.143102\n",
      "Epoch [1/2], Iter [2885/3125], train_loss:0.143350\n",
      "Epoch [1/2], Iter [2886/3125], train_loss:0.144716\n",
      "Epoch [1/2], Iter [2887/3125], train_loss:0.144042\n",
      "Epoch [1/2], Iter [2888/3125], train_loss:0.144286\n",
      "Epoch [1/2], Iter [2889/3125], train_loss:0.143671\n",
      "Epoch [1/2], Iter [2890/3125], train_loss:0.143187\n",
      "Epoch [1/2], Iter [2891/3125], train_loss:0.143558\n",
      "Epoch [1/2], Iter [2892/3125], train_loss:0.145344\n",
      "Epoch [1/2], Iter [2893/3125], train_loss:0.142492\n",
      "Epoch [1/2], Iter [2894/3125], train_loss:0.145172\n",
      "Epoch [1/2], Iter [2895/3125], train_loss:0.144849\n",
      "Epoch [1/2], Iter [2896/3125], train_loss:0.143549\n",
      "Epoch [1/2], Iter [2897/3125], train_loss:0.145048\n",
      "Epoch [1/2], Iter [2898/3125], train_loss:0.145281\n",
      "Epoch [1/2], Iter [2899/3125], train_loss:0.144295\n",
      "Epoch [1/2], Iter [2900/3125], train_loss:0.143799\n",
      "Epoch [1/2], Iter [2901/3125], train_loss:0.143290\n",
      "Epoch [1/2], Iter [2902/3125], train_loss:0.145011\n",
      "Epoch [1/2], Iter [2903/3125], train_loss:0.143401\n",
      "Epoch [1/2], Iter [2904/3125], train_loss:0.144886\n",
      "Epoch [1/2], Iter [2905/3125], train_loss:0.143926\n",
      "Epoch [1/2], Iter [2906/3125], train_loss:0.144103\n",
      "Epoch [1/2], Iter [2907/3125], train_loss:0.143026\n",
      "Epoch [1/2], Iter [2908/3125], train_loss:0.142866\n",
      "Epoch [1/2], Iter [2909/3125], train_loss:0.143589\n",
      "Epoch [1/2], Iter [2910/3125], train_loss:0.145885\n",
      "Epoch [1/2], Iter [2911/3125], train_loss:0.145185\n",
      "Epoch [1/2], Iter [2912/3125], train_loss:0.144891\n",
      "Epoch [1/2], Iter [2913/3125], train_loss:0.144358\n",
      "Epoch [1/2], Iter [2914/3125], train_loss:0.143849\n",
      "Epoch [1/2], Iter [2915/3125], train_loss:0.145244\n",
      "Epoch [1/2], Iter [2916/3125], train_loss:0.143645\n",
      "Epoch [1/2], Iter [2917/3125], train_loss:0.143661\n",
      "Epoch [1/2], Iter [2918/3125], train_loss:0.143980\n",
      "Epoch [1/2], Iter [2919/3125], train_loss:0.144143\n",
      "Epoch [1/2], Iter [2920/3125], train_loss:0.143175\n",
      "Epoch [1/2], Iter [2921/3125], train_loss:0.143935\n",
      "Epoch [1/2], Iter [2922/3125], train_loss:0.143679\n",
      "Epoch [1/2], Iter [2923/3125], train_loss:0.142542\n",
      "Epoch [1/2], Iter [2924/3125], train_loss:0.143302\n",
      "Epoch [1/2], Iter [2925/3125], train_loss:0.143786\n",
      "Epoch [1/2], Iter [2926/3125], train_loss:0.143882\n",
      "Epoch [1/2], Iter [2927/3125], train_loss:0.143613\n",
      "Epoch [1/2], Iter [2928/3125], train_loss:0.142819\n",
      "Epoch [1/2], Iter [2929/3125], train_loss:0.144098\n",
      "Epoch [1/2], Iter [2930/3125], train_loss:0.143859\n",
      "Epoch [1/2], Iter [2931/3125], train_loss:0.145435\n",
      "Epoch [1/2], Iter [2932/3125], train_loss:0.144354\n",
      "Epoch [1/2], Iter [2933/3125], train_loss:0.143570\n",
      "Epoch [1/2], Iter [2934/3125], train_loss:0.143808\n",
      "Epoch [1/2], Iter [2935/3125], train_loss:0.143949\n",
      "Epoch [1/2], Iter [2936/3125], train_loss:0.144544\n",
      "Epoch [1/2], Iter [2937/3125], train_loss:0.145801\n",
      "Epoch [1/2], Iter [2938/3125], train_loss:0.144612\n",
      "Epoch [1/2], Iter [2939/3125], train_loss:0.142687\n",
      "Epoch [1/2], Iter [2940/3125], train_loss:0.146081\n",
      "Epoch [1/2], Iter [2941/3125], train_loss:0.144532\n",
      "Epoch [1/2], Iter [2942/3125], train_loss:0.143510\n",
      "Epoch [1/2], Iter [2943/3125], train_loss:0.144032\n",
      "Epoch [1/2], Iter [2944/3125], train_loss:0.142758\n",
      "Epoch [1/2], Iter [2945/3125], train_loss:0.142960\n",
      "Epoch [1/2], Iter [2946/3125], train_loss:0.145162\n",
      "Epoch [1/2], Iter [2947/3125], train_loss:0.143250\n",
      "Epoch [1/2], Iter [2948/3125], train_loss:0.143844\n",
      "Epoch [1/2], Iter [2949/3125], train_loss:0.143420\n",
      "Epoch [1/2], Iter [2950/3125], train_loss:0.144616\n",
      "Epoch [1/2], Iter [2951/3125], train_loss:0.144217\n",
      "Epoch [1/2], Iter [2952/3125], train_loss:0.143640\n",
      "Epoch [1/2], Iter [2953/3125], train_loss:0.144096\n",
      "Epoch [1/2], Iter [2954/3125], train_loss:0.144934\n",
      "Epoch [1/2], Iter [2955/3125], train_loss:0.145093\n",
      "Epoch [1/2], Iter [2956/3125], train_loss:0.142941\n",
      "Epoch [1/2], Iter [2957/3125], train_loss:0.144921\n",
      "Epoch [1/2], Iter [2958/3125], train_loss:0.142875\n",
      "Epoch [1/2], Iter [2959/3125], train_loss:0.144501\n",
      "Epoch [1/2], Iter [2960/3125], train_loss:0.144654\n",
      "Epoch [1/2], Iter [2961/3125], train_loss:0.142742\n",
      "Epoch [1/2], Iter [2962/3125], train_loss:0.144516\n",
      "Epoch [1/2], Iter [2963/3125], train_loss:0.144737\n",
      "Epoch [1/2], Iter [2964/3125], train_loss:0.143827\n",
      "Epoch [1/2], Iter [2965/3125], train_loss:0.144435\n",
      "Epoch [1/2], Iter [2966/3125], train_loss:0.142405\n",
      "Epoch [1/2], Iter [2967/3125], train_loss:0.145107\n",
      "Epoch [1/2], Iter [2968/3125], train_loss:0.142905\n",
      "Epoch [1/2], Iter [2969/3125], train_loss:0.142845\n",
      "Epoch [1/2], Iter [2970/3125], train_loss:0.144338\n",
      "Epoch [1/2], Iter [2971/3125], train_loss:0.143084\n",
      "Epoch [1/2], Iter [2972/3125], train_loss:0.144816\n",
      "Epoch [1/2], Iter [2973/3125], train_loss:0.144393\n",
      "Epoch [1/2], Iter [2974/3125], train_loss:0.141828\n",
      "Epoch [1/2], Iter [2975/3125], train_loss:0.143851\n",
      "Epoch [1/2], Iter [2976/3125], train_loss:0.144412\n",
      "Epoch [1/2], Iter [2977/3125], train_loss:0.143124\n",
      "Epoch [1/2], Iter [2978/3125], train_loss:0.143889\n",
      "Epoch [1/2], Iter [2979/3125], train_loss:0.145339\n",
      "Epoch [1/2], Iter [2980/3125], train_loss:0.144110\n",
      "Epoch [1/2], Iter [2981/3125], train_loss:0.144331\n",
      "Epoch [1/2], Iter [2982/3125], train_loss:0.143590\n",
      "Epoch [1/2], Iter [2983/3125], train_loss:0.144199\n",
      "Epoch [1/2], Iter [2984/3125], train_loss:0.143941\n",
      "Epoch [1/2], Iter [2985/3125], train_loss:0.143494\n",
      "Epoch [1/2], Iter [2986/3125], train_loss:0.143484\n",
      "Epoch [1/2], Iter [2987/3125], train_loss:0.144830\n",
      "Epoch [1/2], Iter [2988/3125], train_loss:0.145222\n",
      "Epoch [1/2], Iter [2989/3125], train_loss:0.143857\n",
      "Epoch [1/2], Iter [2990/3125], train_loss:0.144278\n",
      "Epoch [1/2], Iter [2991/3125], train_loss:0.141994\n",
      "Epoch [1/2], Iter [2992/3125], train_loss:0.142483\n",
      "Epoch [1/2], Iter [2993/3125], train_loss:0.144888\n",
      "Epoch [1/2], Iter [2994/3125], train_loss:0.143551\n",
      "Epoch [1/2], Iter [2995/3125], train_loss:0.144858\n",
      "Epoch [1/2], Iter [2996/3125], train_loss:0.143017\n",
      "Epoch [1/2], Iter [2997/3125], train_loss:0.144040\n",
      "Epoch [1/2], Iter [2998/3125], train_loss:0.143057\n",
      "Epoch [1/2], Iter [2999/3125], train_loss:0.144295\n",
      "Epoch [1/2], Iter [3000/3125], train_loss:0.142110\n",
      "Epoch [1/2], Iter [3001/3125], train_loss:0.143673\n",
      "Epoch [1/2], Iter [3002/3125], train_loss:0.143132\n",
      "Epoch [1/2], Iter [3003/3125], train_loss:0.144501\n",
      "Epoch [1/2], Iter [3004/3125], train_loss:0.143692\n",
      "Epoch [1/2], Iter [3005/3125], train_loss:0.144279\n",
      "Epoch [1/2], Iter [3006/3125], train_loss:0.143340\n",
      "Epoch [1/2], Iter [3007/3125], train_loss:0.144387\n",
      "Epoch [1/2], Iter [3008/3125], train_loss:0.142805\n",
      "Epoch [1/2], Iter [3009/3125], train_loss:0.144092\n",
      "Epoch [1/2], Iter [3010/3125], train_loss:0.144092\n",
      "Epoch [1/2], Iter [3011/3125], train_loss:0.144225\n",
      "Epoch [1/2], Iter [3012/3125], train_loss:0.145456\n",
      "Epoch [1/2], Iter [3013/3125], train_loss:0.143298\n",
      "Epoch [1/2], Iter [3014/3125], train_loss:0.141541\n",
      "Epoch [1/2], Iter [3015/3125], train_loss:0.143129\n",
      "Epoch [1/2], Iter [3016/3125], train_loss:0.144669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [3017/3125], train_loss:0.143761\n",
      "Epoch [1/2], Iter [3018/3125], train_loss:0.143270\n",
      "Epoch [1/2], Iter [3019/3125], train_loss:0.144641\n",
      "Epoch [1/2], Iter [3020/3125], train_loss:0.143964\n",
      "Epoch [1/2], Iter [3021/3125], train_loss:0.145061\n",
      "Epoch [1/2], Iter [3022/3125], train_loss:0.142531\n",
      "Epoch [1/2], Iter [3023/3125], train_loss:0.143364\n",
      "Epoch [1/2], Iter [3024/3125], train_loss:0.144739\n",
      "Epoch [1/2], Iter [3025/3125], train_loss:0.143609\n",
      "Epoch [1/2], Iter [3026/3125], train_loss:0.143417\n",
      "Epoch [1/2], Iter [3027/3125], train_loss:0.144802\n",
      "Epoch [1/2], Iter [3028/3125], train_loss:0.143367\n",
      "Epoch [1/2], Iter [3029/3125], train_loss:0.144781\n",
      "Epoch [1/2], Iter [3030/3125], train_loss:0.144847\n",
      "Epoch [1/2], Iter [3031/3125], train_loss:0.143750\n",
      "Epoch [1/2], Iter [3032/3125], train_loss:0.143195\n",
      "Epoch [1/2], Iter [3033/3125], train_loss:0.143907\n",
      "Epoch [1/2], Iter [3034/3125], train_loss:0.144760\n",
      "Epoch [1/2], Iter [3035/3125], train_loss:0.143240\n",
      "Epoch [1/2], Iter [3036/3125], train_loss:0.144400\n",
      "Epoch [1/2], Iter [3037/3125], train_loss:0.142924\n",
      "Epoch [1/2], Iter [3038/3125], train_loss:0.144481\n",
      "Epoch [1/2], Iter [3039/3125], train_loss:0.144326\n",
      "Epoch [1/2], Iter [3040/3125], train_loss:0.143687\n",
      "Epoch [1/2], Iter [3041/3125], train_loss:0.143568\n",
      "Epoch [1/2], Iter [3042/3125], train_loss:0.143472\n",
      "Epoch [1/2], Iter [3043/3125], train_loss:0.142846\n",
      "Epoch [1/2], Iter [3044/3125], train_loss:0.142785\n",
      "Epoch [1/2], Iter [3045/3125], train_loss:0.142347\n",
      "Epoch [1/2], Iter [3046/3125], train_loss:0.145740\n",
      "Epoch [1/2], Iter [3047/3125], train_loss:0.145637\n",
      "Epoch [1/2], Iter [3048/3125], train_loss:0.144783\n",
      "Epoch [1/2], Iter [3049/3125], train_loss:0.143835\n",
      "Epoch [1/2], Iter [3050/3125], train_loss:0.144688\n",
      "Epoch [1/2], Iter [3051/3125], train_loss:0.143384\n",
      "Epoch [1/2], Iter [3052/3125], train_loss:0.144539\n",
      "Epoch [1/2], Iter [3053/3125], train_loss:0.143730\n",
      "Epoch [1/2], Iter [3054/3125], train_loss:0.143646\n",
      "Epoch [1/2], Iter [3055/3125], train_loss:0.143745\n",
      "Epoch [1/2], Iter [3056/3125], train_loss:0.143447\n",
      "Epoch [1/2], Iter [3057/3125], train_loss:0.143730\n",
      "Epoch [1/2], Iter [3058/3125], train_loss:0.143631\n",
      "Epoch [1/2], Iter [3059/3125], train_loss:0.144199\n",
      "Epoch [1/2], Iter [3060/3125], train_loss:0.142161\n",
      "Epoch [1/2], Iter [3061/3125], train_loss:0.142919\n",
      "Epoch [1/2], Iter [3062/3125], train_loss:0.144105\n",
      "Epoch [1/2], Iter [3063/3125], train_loss:0.142719\n",
      "Epoch [1/2], Iter [3064/3125], train_loss:0.143312\n",
      "Epoch [1/2], Iter [3065/3125], train_loss:0.144363\n",
      "Epoch [1/2], Iter [3066/3125], train_loss:0.142937\n",
      "Epoch [1/2], Iter [3067/3125], train_loss:0.144822\n",
      "Epoch [1/2], Iter [3068/3125], train_loss:0.143649\n",
      "Epoch [1/2], Iter [3069/3125], train_loss:0.142922\n",
      "Epoch [1/2], Iter [3070/3125], train_loss:0.145058\n",
      "Epoch [1/2], Iter [3071/3125], train_loss:0.144336\n",
      "Epoch [1/2], Iter [3072/3125], train_loss:0.143142\n",
      "Epoch [1/2], Iter [3073/3125], train_loss:0.143526\n",
      "Epoch [1/2], Iter [3074/3125], train_loss:0.143643\n",
      "Epoch [1/2], Iter [3075/3125], train_loss:0.145336\n",
      "Epoch [1/2], Iter [3076/3125], train_loss:0.143497\n",
      "Epoch [1/2], Iter [3077/3125], train_loss:0.143373\n",
      "Epoch [1/2], Iter [3078/3125], train_loss:0.144764\n",
      "Epoch [1/2], Iter [3079/3125], train_loss:0.145904\n",
      "Epoch [1/2], Iter [3080/3125], train_loss:0.142959\n",
      "Epoch [1/2], Iter [3081/3125], train_loss:0.143540\n",
      "Epoch [1/2], Iter [3082/3125], train_loss:0.143014\n",
      "Epoch [1/2], Iter [3083/3125], train_loss:0.144031\n",
      "Epoch [1/2], Iter [3084/3125], train_loss:0.143054\n",
      "Epoch [1/2], Iter [3085/3125], train_loss:0.142663\n",
      "Epoch [1/2], Iter [3086/3125], train_loss:0.143869\n",
      "Epoch [1/2], Iter [3087/3125], train_loss:0.143996\n",
      "Epoch [1/2], Iter [3088/3125], train_loss:0.142680\n",
      "Epoch [1/2], Iter [3089/3125], train_loss:0.144275\n",
      "Epoch [1/2], Iter [3090/3125], train_loss:0.145224\n",
      "Epoch [1/2], Iter [3091/3125], train_loss:0.142489\n",
      "Epoch [1/2], Iter [3092/3125], train_loss:0.143619\n",
      "Epoch [1/2], Iter [3093/3125], train_loss:0.142152\n",
      "Epoch [1/2], Iter [3094/3125], train_loss:0.142857\n",
      "Epoch [1/2], Iter [3095/3125], train_loss:0.143261\n",
      "Epoch [1/2], Iter [3096/3125], train_loss:0.144491\n",
      "Epoch [1/2], Iter [3097/3125], train_loss:0.145542\n",
      "Epoch [1/2], Iter [3098/3125], train_loss:0.144013\n",
      "Epoch [1/2], Iter [3099/3125], train_loss:0.143228\n",
      "Epoch [1/2], Iter [3100/3125], train_loss:0.143346\n",
      "Epoch [1/2], Iter [3101/3125], train_loss:0.144719\n",
      "Epoch [1/2], Iter [3102/3125], train_loss:0.143600\n",
      "Epoch [1/2], Iter [3103/3125], train_loss:0.143245\n",
      "Epoch [1/2], Iter [3104/3125], train_loss:0.144345\n",
      "Epoch [1/2], Iter [3105/3125], train_loss:0.144411\n",
      "Epoch [1/2], Iter [3106/3125], train_loss:0.145854\n",
      "Epoch [1/2], Iter [3107/3125], train_loss:0.143273\n",
      "Epoch [1/2], Iter [3108/3125], train_loss:0.143581\n",
      "Epoch [1/2], Iter [3109/3125], train_loss:0.142511\n",
      "Epoch [1/2], Iter [3110/3125], train_loss:0.143806\n",
      "Epoch [1/2], Iter [3111/3125], train_loss:0.144418\n",
      "Epoch [1/2], Iter [3112/3125], train_loss:0.145893\n",
      "Epoch [1/2], Iter [3113/3125], train_loss:0.144416\n",
      "Epoch [1/2], Iter [3114/3125], train_loss:0.142889\n",
      "Epoch [1/2], Iter [3115/3125], train_loss:0.145470\n",
      "Epoch [1/2], Iter [3116/3125], train_loss:0.145032\n",
      "Epoch [1/2], Iter [3117/3125], train_loss:0.143771\n",
      "Epoch [1/2], Iter [3118/3125], train_loss:0.143344\n",
      "Epoch [1/2], Iter [3119/3125], train_loss:0.144119\n",
      "Epoch [1/2], Iter [3120/3125], train_loss:0.142540\n",
      "Epoch [1/2], Iter [3121/3125], train_loss:0.144717\n",
      "Epoch [1/2], Iter [3122/3125], train_loss:0.143962\n",
      "Epoch [1/2], Iter [3123/3125], train_loss:0.144726\n",
      "Epoch [1/2], Iter [3124/3125], train_loss:0.143790\n",
      "Epoch [1/2], Iter [3125/3125], train_loss:0.145640\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1449, test_acc:0.0000%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1445, test_acc:3.1250%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1442, test_acc:4.1667%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1447, test_acc:3.1250%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1445, test_acc:7.5000%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1444, test_acc:8.3333%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1444, test_acc:7.1429%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1443, test_acc:8.5938%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1442, test_acc:9.7222%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.6250%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2273%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.4167%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.0962%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.8214%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1442, test_acc:9.1667%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.3750%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.5588%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.0278%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.2105%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.0625%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:8.9286%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.0909%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.5109%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.3750%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.5000%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3365%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4167%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2679%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.5603%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.2083%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.8790%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9609%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6591%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.5588%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6429%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8958%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6284%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7039%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7756%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6875%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.6037%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.3750%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.3023%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.6591%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.5833%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.6467%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.8404%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1562%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2041%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1250%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.0490%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.9760%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4953%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.4167%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.4545%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.2679%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.1974%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.0216%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.2754%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.1042%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.0410%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.0806%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.9206%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.7656%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.8077%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.9432%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.7948%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.7426%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.7826%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.8214%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.8592%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0694%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.9315%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.8818%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.8333%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.7862%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.6591%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.6154%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.8101%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.8438%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.7222%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.7561%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7892%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7470%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8529%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8837%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8420%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8722%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7612%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6528%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6841%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6467%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6774%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8404%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9342%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8958%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9227%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8852%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9116%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8750%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8391%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8039%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7694%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7356%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7619%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7288%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6963%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6644%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.5757%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7159%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8536%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7656%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7898%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7039%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6739%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6983%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7756%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7458%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7164%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6875%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7624%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7336%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8577%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7782%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7500%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7222%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6457%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6680%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.5930%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8077%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8760%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9432%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0094%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0280%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0000%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0643%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0365%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0543%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1619%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1786%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1507%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1673%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1399%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1562%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2155%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2740%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2466%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3463%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3188%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2917%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2649%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2796%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2533%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2679%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2823%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2564%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2309%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3244%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3774%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4297%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4814%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4552%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4678%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4421%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4924%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4292%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4042%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4539%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5399%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4779%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5263%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6105%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5853%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5963%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5357%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5824%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5932%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6039%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6145%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5556%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5318%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5426%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5874%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5978%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5743%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.5175%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5949%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6051%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5489%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5921%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5366%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5143%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5246%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5026%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4808%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4273%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4695%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4798%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4585%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4688%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4167%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3960%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3448%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3554%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3049%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2852%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2657%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3365%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3469%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3274%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3377%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3479%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3580%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3680%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3488%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3877%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3975%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4358%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4167%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4261%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4921%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5011%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4540%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4353%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5000%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4812%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4626%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4441%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4803%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4891%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5249%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5065%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5687%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6303%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6117%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6197%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6540%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6355%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6433%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6250%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6328%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6147%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6224%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5789%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6122%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6199%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6022%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5847%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5924%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6500%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6823%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6399%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6472%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6053%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.6127%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.5713%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.6031%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.5862%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5936%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6010%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6082%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.5677%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5751%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5824%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5896%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5733%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5571%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5410%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5716%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5556%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5397%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5009%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5082%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4927%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4773%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4620%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4919%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5216%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5511%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5134%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5205%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4832%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4682%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4974%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5044%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5114%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4747%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4601%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4455%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4310%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4811%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4452%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4096%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4167%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4025%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4307%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4167%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4027%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4097%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.3750%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.3821%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3477%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3548%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3413%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3279%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3350%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3420%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3084%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2751%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2823%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2693%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2364%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2236%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2508%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2381%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2255%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2129%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2005%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1881%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1758%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1830%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1514%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1780%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1852%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1731%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1610%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1491%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1562%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1634%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1894%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1586%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1280%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1164%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1048%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0933%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1004%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0890%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1146%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1217%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0919%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0990%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0694%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0765%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0654%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0543%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0614%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0684%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0395%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0287%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0357%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0071%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9787%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9681%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9753%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9648%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9895%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0140%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0384%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0453%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0521%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0589%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0656%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0723%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0618%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0685%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0581%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0647%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0543%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0271%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0169%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9899%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9798%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9698%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9432%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9333%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9235%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9138%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9372%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9274%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9507%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9738%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9967%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0033%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9935%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9838%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9903%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9968%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9710%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9775%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9840%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0064%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0287%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0350%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0095%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0000%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0063%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9969%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0345%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0094%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0000%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9906%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9969%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9721%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9938%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9846%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9754%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9662%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0031%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0092%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0152%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0061%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9970%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0333%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0091%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0151%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0060%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9970%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0030%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0239%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0744%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0653%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0711%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0621%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0973%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0735%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0499%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0410%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0321%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0233%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0000%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0203%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0405%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0462%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0662%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0431%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0344%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0257%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0171%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0370%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0142%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0340%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0537%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0451%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0648%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0983%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0757%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0531%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0307%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0362%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0417%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0333%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0525%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0442%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0496%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0412%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0329%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0246%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0437%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0354%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0408%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0597%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0379%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0297%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0081%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0269%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0054%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0241%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0027%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0080%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0266%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0318%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0106%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0423%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0211%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0395%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0446%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0498%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0418%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0861%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1172%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0962%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0882%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0932%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0852%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0773%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1080%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0873%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0794%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0971%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1148%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1324%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1245%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1166%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1215%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1263%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1310%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1861%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1657%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1578%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1625%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1672%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1718%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1640%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1687%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1485%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1655%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1578%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1378%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1302%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1103%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1027%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0830%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0755%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0681%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0607%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0654%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0580%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0507%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0313%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0361%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0168%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9976%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0024%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0072%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0000%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0048%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0213%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0142%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0307%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0354%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0400%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0329%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0141%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0070%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0000%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9930%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9977%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9791%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9722%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9653%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9931%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9862%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9908%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9724%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0115%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0275%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0320%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0365%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0296%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0114%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0045%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0091%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0249%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0406%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0225%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0045%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0090%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0022%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9843%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9888%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9933%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0089%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0022%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0066%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0442%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0486%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0529%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0572%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0725%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0658%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0701%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0634%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0676%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0719%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0652%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0586%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0520%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0454%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0389%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0323%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0151%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0086%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0129%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0064%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0107%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0043%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9979%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9915%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9958%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0106%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0042%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0084%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0232%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0168%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0000%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0042%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0084%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9916%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9958%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9792%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9730%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9772%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9917%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9752%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9690%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9835%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9773%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9609%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9651%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9693%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9734%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9980%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0020%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9857%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0102%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0041%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9980%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0020%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0061%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0101%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9940%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9779%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0020%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0060%\n",
      "Epoch [1/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0000%\n",
      "Epoch [2/2], Iter [1/3125], train_loss:0.144268\n",
      "Epoch [2/2], Iter [2/3125], train_loss:0.143500\n",
      "Epoch [2/2], Iter [3/3125], train_loss:0.144605\n",
      "Epoch [2/2], Iter [4/3125], train_loss:0.143070\n",
      "Epoch [2/2], Iter [5/3125], train_loss:0.144434\n",
      "Epoch [2/2], Iter [6/3125], train_loss:0.143728\n",
      "Epoch [2/2], Iter [7/3125], train_loss:0.143243\n",
      "Epoch [2/2], Iter [8/3125], train_loss:0.142683\n",
      "Epoch [2/2], Iter [9/3125], train_loss:0.143534\n",
      "Epoch [2/2], Iter [10/3125], train_loss:0.142066\n",
      "Epoch [2/2], Iter [11/3125], train_loss:0.145110\n",
      "Epoch [2/2], Iter [12/3125], train_loss:0.145814\n",
      "Epoch [2/2], Iter [13/3125], train_loss:0.142881\n",
      "Epoch [2/2], Iter [14/3125], train_loss:0.144166\n",
      "Epoch [2/2], Iter [15/3125], train_loss:0.143608\n",
      "Epoch [2/2], Iter [16/3125], train_loss:0.142145\n",
      "Epoch [2/2], Iter [17/3125], train_loss:0.144981\n",
      "Epoch [2/2], Iter [18/3125], train_loss:0.143870\n",
      "Epoch [2/2], Iter [19/3125], train_loss:0.145051\n",
      "Epoch [2/2], Iter [20/3125], train_loss:0.141847\n",
      "Epoch [2/2], Iter [21/3125], train_loss:0.144584\n",
      "Epoch [2/2], Iter [22/3125], train_loss:0.142819\n",
      "Epoch [2/2], Iter [23/3125], train_loss:0.145160\n",
      "Epoch [2/2], Iter [24/3125], train_loss:0.142071\n",
      "Epoch [2/2], Iter [25/3125], train_loss:0.144794\n",
      "Epoch [2/2], Iter [26/3125], train_loss:0.144199\n",
      "Epoch [2/2], Iter [27/3125], train_loss:0.143838\n",
      "Epoch [2/2], Iter [28/3125], train_loss:0.144351\n",
      "Epoch [2/2], Iter [29/3125], train_loss:0.144244\n",
      "Epoch [2/2], Iter [30/3125], train_loss:0.142630\n",
      "Epoch [2/2], Iter [31/3125], train_loss:0.144561\n",
      "Epoch [2/2], Iter [32/3125], train_loss:0.141716\n",
      "Epoch [2/2], Iter [33/3125], train_loss:0.143817\n",
      "Epoch [2/2], Iter [34/3125], train_loss:0.144596\n",
      "Epoch [2/2], Iter [35/3125], train_loss:0.144637\n",
      "Epoch [2/2], Iter [36/3125], train_loss:0.146210\n",
      "Epoch [2/2], Iter [37/3125], train_loss:0.142942\n",
      "Epoch [2/2], Iter [38/3125], train_loss:0.145166\n",
      "Epoch [2/2], Iter [39/3125], train_loss:0.144306\n",
      "Epoch [2/2], Iter [40/3125], train_loss:0.145146\n",
      "Epoch [2/2], Iter [41/3125], train_loss:0.144300\n",
      "Epoch [2/2], Iter [42/3125], train_loss:0.144018\n",
      "Epoch [2/2], Iter [43/3125], train_loss:0.145074\n",
      "Epoch [2/2], Iter [44/3125], train_loss:0.142860\n",
      "Epoch [2/2], Iter [45/3125], train_loss:0.142390\n",
      "Epoch [2/2], Iter [46/3125], train_loss:0.144545\n",
      "Epoch [2/2], Iter [47/3125], train_loss:0.143916\n",
      "Epoch [2/2], Iter [48/3125], train_loss:0.144254\n",
      "Epoch [2/2], Iter [49/3125], train_loss:0.144419\n",
      "Epoch [2/2], Iter [50/3125], train_loss:0.143273\n",
      "Epoch [2/2], Iter [51/3125], train_loss:0.142697\n",
      "Epoch [2/2], Iter [52/3125], train_loss:0.143353\n",
      "Epoch [2/2], Iter [53/3125], train_loss:0.143020\n",
      "Epoch [2/2], Iter [54/3125], train_loss:0.142609\n",
      "Epoch [2/2], Iter [55/3125], train_loss:0.143881\n",
      "Epoch [2/2], Iter [56/3125], train_loss:0.142483\n",
      "Epoch [2/2], Iter [57/3125], train_loss:0.143953\n",
      "Epoch [2/2], Iter [58/3125], train_loss:0.142978\n",
      "Epoch [2/2], Iter [59/3125], train_loss:0.143670\n",
      "Epoch [2/2], Iter [60/3125], train_loss:0.143550\n",
      "Epoch [2/2], Iter [61/3125], train_loss:0.143603\n",
      "Epoch [2/2], Iter [62/3125], train_loss:0.142879\n",
      "Epoch [2/2], Iter [63/3125], train_loss:0.143138\n",
      "Epoch [2/2], Iter [64/3125], train_loss:0.143869\n",
      "Epoch [2/2], Iter [65/3125], train_loss:0.142942\n",
      "Epoch [2/2], Iter [66/3125], train_loss:0.144211\n",
      "Epoch [2/2], Iter [67/3125], train_loss:0.144672\n",
      "Epoch [2/2], Iter [68/3125], train_loss:0.144040\n",
      "Epoch [2/2], Iter [69/3125], train_loss:0.144384\n",
      "Epoch [2/2], Iter [70/3125], train_loss:0.144021\n",
      "Epoch [2/2], Iter [71/3125], train_loss:0.144191\n",
      "Epoch [2/2], Iter [72/3125], train_loss:0.145301\n",
      "Epoch [2/2], Iter [73/3125], train_loss:0.143475\n",
      "Epoch [2/2], Iter [74/3125], train_loss:0.144630\n",
      "Epoch [2/2], Iter [75/3125], train_loss:0.144629\n",
      "Epoch [2/2], Iter [76/3125], train_loss:0.142185\n",
      "Epoch [2/2], Iter [77/3125], train_loss:0.144421\n",
      "Epoch [2/2], Iter [78/3125], train_loss:0.142702\n",
      "Epoch [2/2], Iter [79/3125], train_loss:0.143542\n",
      "Epoch [2/2], Iter [80/3125], train_loss:0.144081\n",
      "Epoch [2/2], Iter [81/3125], train_loss:0.143140\n",
      "Epoch [2/2], Iter [82/3125], train_loss:0.145369\n",
      "Epoch [2/2], Iter [83/3125], train_loss:0.144859\n",
      "Epoch [2/2], Iter [84/3125], train_loss:0.142666\n",
      "Epoch [2/2], Iter [85/3125], train_loss:0.142852\n",
      "Epoch [2/2], Iter [86/3125], train_loss:0.144905\n",
      "Epoch [2/2], Iter [87/3125], train_loss:0.143560\n",
      "Epoch [2/2], Iter [88/3125], train_loss:0.145596\n",
      "Epoch [2/2], Iter [89/3125], train_loss:0.143254\n",
      "Epoch [2/2], Iter [90/3125], train_loss:0.143824\n",
      "Epoch [2/2], Iter [91/3125], train_loss:0.145501\n",
      "Epoch [2/2], Iter [92/3125], train_loss:0.144748\n",
      "Epoch [2/2], Iter [93/3125], train_loss:0.142990\n",
      "Epoch [2/2], Iter [94/3125], train_loss:0.144406\n",
      "Epoch [2/2], Iter [95/3125], train_loss:0.143347\n",
      "Epoch [2/2], Iter [96/3125], train_loss:0.144963\n",
      "Epoch [2/2], Iter [97/3125], train_loss:0.143672\n",
      "Epoch [2/2], Iter [98/3125], train_loss:0.144179\n",
      "Epoch [2/2], Iter [99/3125], train_loss:0.142958\n",
      "Epoch [2/2], Iter [100/3125], train_loss:0.143864\n",
      "Epoch [2/2], Iter [101/3125], train_loss:0.143219\n",
      "Epoch [2/2], Iter [102/3125], train_loss:0.144069\n",
      "Epoch [2/2], Iter [103/3125], train_loss:0.144251\n",
      "Epoch [2/2], Iter [104/3125], train_loss:0.145745\n",
      "Epoch [2/2], Iter [105/3125], train_loss:0.143878\n",
      "Epoch [2/2], Iter [106/3125], train_loss:0.143100\n",
      "Epoch [2/2], Iter [107/3125], train_loss:0.144689\n",
      "Epoch [2/2], Iter [108/3125], train_loss:0.143296\n",
      "Epoch [2/2], Iter [109/3125], train_loss:0.146527\n",
      "Epoch [2/2], Iter [110/3125], train_loss:0.143875\n",
      "Epoch [2/2], Iter [111/3125], train_loss:0.144145\n",
      "Epoch [2/2], Iter [112/3125], train_loss:0.145002\n",
      "Epoch [2/2], Iter [113/3125], train_loss:0.143468\n",
      "Epoch [2/2], Iter [114/3125], train_loss:0.144130\n",
      "Epoch [2/2], Iter [115/3125], train_loss:0.144296\n",
      "Epoch [2/2], Iter [116/3125], train_loss:0.144547\n",
      "Epoch [2/2], Iter [117/3125], train_loss:0.144971\n",
      "Epoch [2/2], Iter [118/3125], train_loss:0.144391\n",
      "Epoch [2/2], Iter [119/3125], train_loss:0.143303\n",
      "Epoch [2/2], Iter [120/3125], train_loss:0.143313\n",
      "Epoch [2/2], Iter [121/3125], train_loss:0.144219\n",
      "Epoch [2/2], Iter [122/3125], train_loss:0.144419\n",
      "Epoch [2/2], Iter [123/3125], train_loss:0.143722\n",
      "Epoch [2/2], Iter [124/3125], train_loss:0.145215\n",
      "Epoch [2/2], Iter [125/3125], train_loss:0.143225\n",
      "Epoch [2/2], Iter [126/3125], train_loss:0.144113\n",
      "Epoch [2/2], Iter [127/3125], train_loss:0.144636\n",
      "Epoch [2/2], Iter [128/3125], train_loss:0.143141\n",
      "Epoch [2/2], Iter [129/3125], train_loss:0.143671\n",
      "Epoch [2/2], Iter [130/3125], train_loss:0.143032\n",
      "Epoch [2/2], Iter [131/3125], train_loss:0.143921\n",
      "Epoch [2/2], Iter [132/3125], train_loss:0.143659\n",
      "Epoch [2/2], Iter [133/3125], train_loss:0.144998\n",
      "Epoch [2/2], Iter [134/3125], train_loss:0.142432\n",
      "Epoch [2/2], Iter [135/3125], train_loss:0.142786\n",
      "Epoch [2/2], Iter [136/3125], train_loss:0.143008\n",
      "Epoch [2/2], Iter [137/3125], train_loss:0.143018\n",
      "Epoch [2/2], Iter [138/3125], train_loss:0.145603\n",
      "Epoch [2/2], Iter [139/3125], train_loss:0.142744\n",
      "Epoch [2/2], Iter [140/3125], train_loss:0.143853\n",
      "Epoch [2/2], Iter [141/3125], train_loss:0.143857\n",
      "Epoch [2/2], Iter [142/3125], train_loss:0.143891\n",
      "Epoch [2/2], Iter [143/3125], train_loss:0.143983\n",
      "Epoch [2/2], Iter [144/3125], train_loss:0.143657\n",
      "Epoch [2/2], Iter [145/3125], train_loss:0.142375\n",
      "Epoch [2/2], Iter [146/3125], train_loss:0.143401\n",
      "Epoch [2/2], Iter [147/3125], train_loss:0.143738\n",
      "Epoch [2/2], Iter [148/3125], train_loss:0.144868\n",
      "Epoch [2/2], Iter [149/3125], train_loss:0.143473\n",
      "Epoch [2/2], Iter [150/3125], train_loss:0.143474\n",
      "Epoch [2/2], Iter [151/3125], train_loss:0.144017\n",
      "Epoch [2/2], Iter [152/3125], train_loss:0.144098\n",
      "Epoch [2/2], Iter [153/3125], train_loss:0.145007\n",
      "Epoch [2/2], Iter [154/3125], train_loss:0.143983\n",
      "Epoch [2/2], Iter [155/3125], train_loss:0.145258\n",
      "Epoch [2/2], Iter [156/3125], train_loss:0.144916\n",
      "Epoch [2/2], Iter [157/3125], train_loss:0.144741\n",
      "Epoch [2/2], Iter [158/3125], train_loss:0.145688\n",
      "Epoch [2/2], Iter [159/3125], train_loss:0.143160\n",
      "Epoch [2/2], Iter [160/3125], train_loss:0.144816\n",
      "Epoch [2/2], Iter [161/3125], train_loss:0.144294\n",
      "Epoch [2/2], Iter [162/3125], train_loss:0.144146\n",
      "Epoch [2/2], Iter [163/3125], train_loss:0.144022\n",
      "Epoch [2/2], Iter [164/3125], train_loss:0.144466\n",
      "Epoch [2/2], Iter [165/3125], train_loss:0.144939\n",
      "Epoch [2/2], Iter [166/3125], train_loss:0.142486\n",
      "Epoch [2/2], Iter [167/3125], train_loss:0.142472\n",
      "Epoch [2/2], Iter [168/3125], train_loss:0.144909\n",
      "Epoch [2/2], Iter [169/3125], train_loss:0.143202\n",
      "Epoch [2/2], Iter [170/3125], train_loss:0.144350\n",
      "Epoch [2/2], Iter [171/3125], train_loss:0.145309\n",
      "Epoch [2/2], Iter [172/3125], train_loss:0.143527\n",
      "Epoch [2/2], Iter [173/3125], train_loss:0.144442\n",
      "Epoch [2/2], Iter [174/3125], train_loss:0.143970\n",
      "Epoch [2/2], Iter [175/3125], train_loss:0.144188\n",
      "Epoch [2/2], Iter [176/3125], train_loss:0.143632\n",
      "Epoch [2/2], Iter [177/3125], train_loss:0.144272\n",
      "Epoch [2/2], Iter [178/3125], train_loss:0.145248\n",
      "Epoch [2/2], Iter [179/3125], train_loss:0.143908\n",
      "Epoch [2/2], Iter [180/3125], train_loss:0.143464\n",
      "Epoch [2/2], Iter [181/3125], train_loss:0.143227\n",
      "Epoch [2/2], Iter [182/3125], train_loss:0.143022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [183/3125], train_loss:0.144852\n",
      "Epoch [2/2], Iter [184/3125], train_loss:0.145115\n",
      "Epoch [2/2], Iter [185/3125], train_loss:0.144001\n",
      "Epoch [2/2], Iter [186/3125], train_loss:0.143442\n",
      "Epoch [2/2], Iter [187/3125], train_loss:0.144112\n",
      "Epoch [2/2], Iter [188/3125], train_loss:0.144492\n",
      "Epoch [2/2], Iter [189/3125], train_loss:0.143379\n",
      "Epoch [2/2], Iter [190/3125], train_loss:0.144725\n",
      "Epoch [2/2], Iter [191/3125], train_loss:0.143464\n",
      "Epoch [2/2], Iter [192/3125], train_loss:0.143090\n",
      "Epoch [2/2], Iter [193/3125], train_loss:0.142695\n",
      "Epoch [2/2], Iter [194/3125], train_loss:0.145640\n",
      "Epoch [2/2], Iter [195/3125], train_loss:0.145253\n",
      "Epoch [2/2], Iter [196/3125], train_loss:0.144886\n",
      "Epoch [2/2], Iter [197/3125], train_loss:0.143255\n",
      "Epoch [2/2], Iter [198/3125], train_loss:0.144008\n",
      "Epoch [2/2], Iter [199/3125], train_loss:0.142820\n",
      "Epoch [2/2], Iter [200/3125], train_loss:0.145200\n",
      "Epoch [2/2], Iter [201/3125], train_loss:0.143884\n",
      "Epoch [2/2], Iter [202/3125], train_loss:0.143713\n",
      "Epoch [2/2], Iter [203/3125], train_loss:0.143864\n",
      "Epoch [2/2], Iter [204/3125], train_loss:0.143284\n",
      "Epoch [2/2], Iter [205/3125], train_loss:0.145279\n",
      "Epoch [2/2], Iter [206/3125], train_loss:0.142954\n",
      "Epoch [2/2], Iter [207/3125], train_loss:0.143024\n",
      "Epoch [2/2], Iter [208/3125], train_loss:0.142036\n",
      "Epoch [2/2], Iter [209/3125], train_loss:0.143585\n",
      "Epoch [2/2], Iter [210/3125], train_loss:0.143180\n",
      "Epoch [2/2], Iter [211/3125], train_loss:0.143474\n",
      "Epoch [2/2], Iter [212/3125], train_loss:0.143796\n",
      "Epoch [2/2], Iter [213/3125], train_loss:0.144539\n",
      "Epoch [2/2], Iter [214/3125], train_loss:0.142824\n",
      "Epoch [2/2], Iter [215/3125], train_loss:0.144564\n",
      "Epoch [2/2], Iter [216/3125], train_loss:0.143568\n",
      "Epoch [2/2], Iter [217/3125], train_loss:0.145288\n",
      "Epoch [2/2], Iter [218/3125], train_loss:0.143670\n",
      "Epoch [2/2], Iter [219/3125], train_loss:0.143026\n",
      "Epoch [2/2], Iter [220/3125], train_loss:0.144960\n",
      "Epoch [2/2], Iter [221/3125], train_loss:0.144191\n",
      "Epoch [2/2], Iter [222/3125], train_loss:0.143464\n",
      "Epoch [2/2], Iter [223/3125], train_loss:0.143559\n",
      "Epoch [2/2], Iter [224/3125], train_loss:0.143727\n",
      "Epoch [2/2], Iter [225/3125], train_loss:0.145130\n",
      "Epoch [2/2], Iter [226/3125], train_loss:0.143894\n",
      "Epoch [2/2], Iter [227/3125], train_loss:0.143516\n",
      "Epoch [2/2], Iter [228/3125], train_loss:0.144441\n",
      "Epoch [2/2], Iter [229/3125], train_loss:0.143796\n",
      "Epoch [2/2], Iter [230/3125], train_loss:0.143915\n",
      "Epoch [2/2], Iter [231/3125], train_loss:0.142574\n",
      "Epoch [2/2], Iter [232/3125], train_loss:0.145225\n",
      "Epoch [2/2], Iter [233/3125], train_loss:0.142120\n",
      "Epoch [2/2], Iter [234/3125], train_loss:0.144312\n",
      "Epoch [2/2], Iter [235/3125], train_loss:0.144874\n",
      "Epoch [2/2], Iter [236/3125], train_loss:0.143233\n",
      "Epoch [2/2], Iter [237/3125], train_loss:0.143480\n",
      "Epoch [2/2], Iter [238/3125], train_loss:0.143033\n",
      "Epoch [2/2], Iter [239/3125], train_loss:0.143849\n",
      "Epoch [2/2], Iter [240/3125], train_loss:0.143733\n",
      "Epoch [2/2], Iter [241/3125], train_loss:0.143410\n",
      "Epoch [2/2], Iter [242/3125], train_loss:0.144236\n",
      "Epoch [2/2], Iter [243/3125], train_loss:0.142951\n",
      "Epoch [2/2], Iter [244/3125], train_loss:0.144863\n",
      "Epoch [2/2], Iter [245/3125], train_loss:0.144075\n",
      "Epoch [2/2], Iter [246/3125], train_loss:0.143951\n",
      "Epoch [2/2], Iter [247/3125], train_loss:0.143621\n",
      "Epoch [2/2], Iter [248/3125], train_loss:0.143890\n",
      "Epoch [2/2], Iter [249/3125], train_loss:0.142151\n",
      "Epoch [2/2], Iter [250/3125], train_loss:0.144330\n",
      "Epoch [2/2], Iter [251/3125], train_loss:0.142807\n",
      "Epoch [2/2], Iter [252/3125], train_loss:0.142787\n",
      "Epoch [2/2], Iter [253/3125], train_loss:0.144353\n",
      "Epoch [2/2], Iter [254/3125], train_loss:0.144273\n",
      "Epoch [2/2], Iter [255/3125], train_loss:0.144459\n",
      "Epoch [2/2], Iter [256/3125], train_loss:0.143137\n",
      "Epoch [2/2], Iter [257/3125], train_loss:0.145259\n",
      "Epoch [2/2], Iter [258/3125], train_loss:0.142577\n",
      "Epoch [2/2], Iter [259/3125], train_loss:0.143752\n",
      "Epoch [2/2], Iter [260/3125], train_loss:0.142201\n",
      "Epoch [2/2], Iter [261/3125], train_loss:0.144095\n",
      "Epoch [2/2], Iter [262/3125], train_loss:0.144311\n",
      "Epoch [2/2], Iter [263/3125], train_loss:0.143138\n",
      "Epoch [2/2], Iter [264/3125], train_loss:0.144339\n",
      "Epoch [2/2], Iter [265/3125], train_loss:0.143781\n",
      "Epoch [2/2], Iter [266/3125], train_loss:0.144610\n",
      "Epoch [2/2], Iter [267/3125], train_loss:0.142708\n",
      "Epoch [2/2], Iter [268/3125], train_loss:0.145199\n",
      "Epoch [2/2], Iter [269/3125], train_loss:0.143141\n",
      "Epoch [2/2], Iter [270/3125], train_loss:0.143839\n",
      "Epoch [2/2], Iter [271/3125], train_loss:0.141941\n",
      "Epoch [2/2], Iter [272/3125], train_loss:0.143314\n",
      "Epoch [2/2], Iter [273/3125], train_loss:0.144635\n",
      "Epoch [2/2], Iter [274/3125], train_loss:0.144025\n",
      "Epoch [2/2], Iter [275/3125], train_loss:0.144072\n",
      "Epoch [2/2], Iter [276/3125], train_loss:0.143273\n",
      "Epoch [2/2], Iter [277/3125], train_loss:0.144481\n",
      "Epoch [2/2], Iter [278/3125], train_loss:0.144893\n",
      "Epoch [2/2], Iter [279/3125], train_loss:0.142821\n",
      "Epoch [2/2], Iter [280/3125], train_loss:0.142402\n",
      "Epoch [2/2], Iter [281/3125], train_loss:0.144427\n",
      "Epoch [2/2], Iter [282/3125], train_loss:0.144417\n",
      "Epoch [2/2], Iter [283/3125], train_loss:0.143549\n",
      "Epoch [2/2], Iter [284/3125], train_loss:0.142309\n",
      "Epoch [2/2], Iter [285/3125], train_loss:0.143604\n",
      "Epoch [2/2], Iter [286/3125], train_loss:0.144810\n",
      "Epoch [2/2], Iter [287/3125], train_loss:0.142320\n",
      "Epoch [2/2], Iter [288/3125], train_loss:0.144910\n",
      "Epoch [2/2], Iter [289/3125], train_loss:0.143477\n",
      "Epoch [2/2], Iter [290/3125], train_loss:0.144538\n",
      "Epoch [2/2], Iter [291/3125], train_loss:0.144257\n",
      "Epoch [2/2], Iter [292/3125], train_loss:0.143619\n",
      "Epoch [2/2], Iter [293/3125], train_loss:0.143501\n",
      "Epoch [2/2], Iter [294/3125], train_loss:0.142260\n",
      "Epoch [2/2], Iter [295/3125], train_loss:0.145454\n",
      "Epoch [2/2], Iter [296/3125], train_loss:0.143288\n",
      "Epoch [2/2], Iter [297/3125], train_loss:0.143932\n",
      "Epoch [2/2], Iter [298/3125], train_loss:0.143805\n",
      "Epoch [2/2], Iter [299/3125], train_loss:0.142082\n",
      "Epoch [2/2], Iter [300/3125], train_loss:0.143302\n",
      "Epoch [2/2], Iter [301/3125], train_loss:0.144434\n",
      "Epoch [2/2], Iter [302/3125], train_loss:0.145391\n",
      "Epoch [2/2], Iter [303/3125], train_loss:0.144358\n",
      "Epoch [2/2], Iter [304/3125], train_loss:0.143887\n",
      "Epoch [2/2], Iter [305/3125], train_loss:0.145081\n",
      "Epoch [2/2], Iter [306/3125], train_loss:0.143411\n",
      "Epoch [2/2], Iter [307/3125], train_loss:0.143706\n",
      "Epoch [2/2], Iter [308/3125], train_loss:0.143396\n",
      "Epoch [2/2], Iter [309/3125], train_loss:0.143130\n",
      "Epoch [2/2], Iter [310/3125], train_loss:0.144064\n",
      "Epoch [2/2], Iter [311/3125], train_loss:0.143662\n",
      "Epoch [2/2], Iter [312/3125], train_loss:0.144075\n",
      "Epoch [2/2], Iter [313/3125], train_loss:0.144715\n",
      "Epoch [2/2], Iter [314/3125], train_loss:0.144325\n",
      "Epoch [2/2], Iter [315/3125], train_loss:0.144565\n",
      "Epoch [2/2], Iter [316/3125], train_loss:0.144189\n",
      "Epoch [2/2], Iter [317/3125], train_loss:0.144811\n",
      "Epoch [2/2], Iter [318/3125], train_loss:0.145500\n",
      "Epoch [2/2], Iter [319/3125], train_loss:0.145231\n",
      "Epoch [2/2], Iter [320/3125], train_loss:0.144175\n",
      "Epoch [2/2], Iter [321/3125], train_loss:0.144487\n",
      "Epoch [2/2], Iter [322/3125], train_loss:0.144449\n",
      "Epoch [2/2], Iter [323/3125], train_loss:0.145278\n",
      "Epoch [2/2], Iter [324/3125], train_loss:0.144194\n",
      "Epoch [2/2], Iter [325/3125], train_loss:0.144747\n",
      "Epoch [2/2], Iter [326/3125], train_loss:0.142718\n",
      "Epoch [2/2], Iter [327/3125], train_loss:0.144318\n",
      "Epoch [2/2], Iter [328/3125], train_loss:0.143219\n",
      "Epoch [2/2], Iter [329/3125], train_loss:0.144582\n",
      "Epoch [2/2], Iter [330/3125], train_loss:0.145044\n",
      "Epoch [2/2], Iter [331/3125], train_loss:0.145682\n",
      "Epoch [2/2], Iter [332/3125], train_loss:0.143602\n",
      "Epoch [2/2], Iter [333/3125], train_loss:0.144465\n",
      "Epoch [2/2], Iter [334/3125], train_loss:0.142727\n",
      "Epoch [2/2], Iter [335/3125], train_loss:0.142297\n",
      "Epoch [2/2], Iter [336/3125], train_loss:0.143792\n",
      "Epoch [2/2], Iter [337/3125], train_loss:0.145993\n",
      "Epoch [2/2], Iter [338/3125], train_loss:0.142780\n",
      "Epoch [2/2], Iter [339/3125], train_loss:0.145076\n",
      "Epoch [2/2], Iter [340/3125], train_loss:0.144562\n",
      "Epoch [2/2], Iter [341/3125], train_loss:0.143021\n",
      "Epoch [2/2], Iter [342/3125], train_loss:0.144210\n",
      "Epoch [2/2], Iter [343/3125], train_loss:0.143132\n",
      "Epoch [2/2], Iter [344/3125], train_loss:0.145560\n",
      "Epoch [2/2], Iter [345/3125], train_loss:0.144371\n",
      "Epoch [2/2], Iter [346/3125], train_loss:0.145245\n",
      "Epoch [2/2], Iter [347/3125], train_loss:0.145928\n",
      "Epoch [2/2], Iter [348/3125], train_loss:0.145378\n",
      "Epoch [2/2], Iter [349/3125], train_loss:0.144603\n",
      "Epoch [2/2], Iter [350/3125], train_loss:0.144679\n",
      "Epoch [2/2], Iter [351/3125], train_loss:0.144851\n",
      "Epoch [2/2], Iter [352/3125], train_loss:0.142814\n",
      "Epoch [2/2], Iter [353/3125], train_loss:0.144662\n",
      "Epoch [2/2], Iter [354/3125], train_loss:0.144872\n",
      "Epoch [2/2], Iter [355/3125], train_loss:0.144589\n",
      "Epoch [2/2], Iter [356/3125], train_loss:0.144009\n",
      "Epoch [2/2], Iter [357/3125], train_loss:0.143911\n",
      "Epoch [2/2], Iter [358/3125], train_loss:0.144027\n",
      "Epoch [2/2], Iter [359/3125], train_loss:0.143956\n",
      "Epoch [2/2], Iter [360/3125], train_loss:0.144739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [361/3125], train_loss:0.144698\n",
      "Epoch [2/2], Iter [362/3125], train_loss:0.142400\n",
      "Epoch [2/2], Iter [363/3125], train_loss:0.143792\n",
      "Epoch [2/2], Iter [364/3125], train_loss:0.144898\n",
      "Epoch [2/2], Iter [365/3125], train_loss:0.142545\n",
      "Epoch [2/2], Iter [366/3125], train_loss:0.144898\n",
      "Epoch [2/2], Iter [367/3125], train_loss:0.144106\n",
      "Epoch [2/2], Iter [368/3125], train_loss:0.145724\n",
      "Epoch [2/2], Iter [369/3125], train_loss:0.143750\n",
      "Epoch [2/2], Iter [370/3125], train_loss:0.143088\n",
      "Epoch [2/2], Iter [371/3125], train_loss:0.144603\n",
      "Epoch [2/2], Iter [372/3125], train_loss:0.144719\n",
      "Epoch [2/2], Iter [373/3125], train_loss:0.144378\n",
      "Epoch [2/2], Iter [374/3125], train_loss:0.145297\n",
      "Epoch [2/2], Iter [375/3125], train_loss:0.143653\n",
      "Epoch [2/2], Iter [376/3125], train_loss:0.142078\n",
      "Epoch [2/2], Iter [377/3125], train_loss:0.142474\n",
      "Epoch [2/2], Iter [378/3125], train_loss:0.145086\n",
      "Epoch [2/2], Iter [379/3125], train_loss:0.143891\n",
      "Epoch [2/2], Iter [380/3125], train_loss:0.143823\n",
      "Epoch [2/2], Iter [381/3125], train_loss:0.144088\n",
      "Epoch [2/2], Iter [382/3125], train_loss:0.143956\n",
      "Epoch [2/2], Iter [383/3125], train_loss:0.142206\n",
      "Epoch [2/2], Iter [384/3125], train_loss:0.144640\n",
      "Epoch [2/2], Iter [385/3125], train_loss:0.145805\n",
      "Epoch [2/2], Iter [386/3125], train_loss:0.144146\n",
      "Epoch [2/2], Iter [387/3125], train_loss:0.143026\n",
      "Epoch [2/2], Iter [388/3125], train_loss:0.143700\n",
      "Epoch [2/2], Iter [389/3125], train_loss:0.144830\n",
      "Epoch [2/2], Iter [390/3125], train_loss:0.143541\n",
      "Epoch [2/2], Iter [391/3125], train_loss:0.142554\n",
      "Epoch [2/2], Iter [392/3125], train_loss:0.143876\n",
      "Epoch [2/2], Iter [393/3125], train_loss:0.142520\n",
      "Epoch [2/2], Iter [394/3125], train_loss:0.143323\n",
      "Epoch [2/2], Iter [395/3125], train_loss:0.144632\n",
      "Epoch [2/2], Iter [396/3125], train_loss:0.144859\n",
      "Epoch [2/2], Iter [397/3125], train_loss:0.144010\n",
      "Epoch [2/2], Iter [398/3125], train_loss:0.144377\n",
      "Epoch [2/2], Iter [399/3125], train_loss:0.144556\n",
      "Epoch [2/2], Iter [400/3125], train_loss:0.143829\n",
      "Epoch [2/2], Iter [401/3125], train_loss:0.144363\n",
      "Epoch [2/2], Iter [402/3125], train_loss:0.143538\n",
      "Epoch [2/2], Iter [403/3125], train_loss:0.143440\n",
      "Epoch [2/2], Iter [404/3125], train_loss:0.143380\n",
      "Epoch [2/2], Iter [405/3125], train_loss:0.144227\n",
      "Epoch [2/2], Iter [406/3125], train_loss:0.144674\n",
      "Epoch [2/2], Iter [407/3125], train_loss:0.145460\n",
      "Epoch [2/2], Iter [408/3125], train_loss:0.144243\n",
      "Epoch [2/2], Iter [409/3125], train_loss:0.144797\n",
      "Epoch [2/2], Iter [410/3125], train_loss:0.145117\n",
      "Epoch [2/2], Iter [411/3125], train_loss:0.143816\n",
      "Epoch [2/2], Iter [412/3125], train_loss:0.143811\n",
      "Epoch [2/2], Iter [413/3125], train_loss:0.144264\n",
      "Epoch [2/2], Iter [414/3125], train_loss:0.143723\n",
      "Epoch [2/2], Iter [415/3125], train_loss:0.145243\n",
      "Epoch [2/2], Iter [416/3125], train_loss:0.142878\n",
      "Epoch [2/2], Iter [417/3125], train_loss:0.146035\n",
      "Epoch [2/2], Iter [418/3125], train_loss:0.143082\n",
      "Epoch [2/2], Iter [419/3125], train_loss:0.143425\n",
      "Epoch [2/2], Iter [420/3125], train_loss:0.142807\n",
      "Epoch [2/2], Iter [421/3125], train_loss:0.143905\n",
      "Epoch [2/2], Iter [422/3125], train_loss:0.145305\n",
      "Epoch [2/2], Iter [423/3125], train_loss:0.144057\n",
      "Epoch [2/2], Iter [424/3125], train_loss:0.145078\n",
      "Epoch [2/2], Iter [425/3125], train_loss:0.144703\n",
      "Epoch [2/2], Iter [426/3125], train_loss:0.142684\n",
      "Epoch [2/2], Iter [427/3125], train_loss:0.144592\n",
      "Epoch [2/2], Iter [428/3125], train_loss:0.144342\n",
      "Epoch [2/2], Iter [429/3125], train_loss:0.144688\n",
      "Epoch [2/2], Iter [430/3125], train_loss:0.144044\n",
      "Epoch [2/2], Iter [431/3125], train_loss:0.144550\n",
      "Epoch [2/2], Iter [432/3125], train_loss:0.144203\n",
      "Epoch [2/2], Iter [433/3125], train_loss:0.144179\n",
      "Epoch [2/2], Iter [434/3125], train_loss:0.144389\n",
      "Epoch [2/2], Iter [435/3125], train_loss:0.143690\n",
      "Epoch [2/2], Iter [436/3125], train_loss:0.144132\n",
      "Epoch [2/2], Iter [437/3125], train_loss:0.144583\n",
      "Epoch [2/2], Iter [438/3125], train_loss:0.142764\n",
      "Epoch [2/2], Iter [439/3125], train_loss:0.143820\n",
      "Epoch [2/2], Iter [440/3125], train_loss:0.143642\n",
      "Epoch [2/2], Iter [441/3125], train_loss:0.145496\n",
      "Epoch [2/2], Iter [442/3125], train_loss:0.143225\n",
      "Epoch [2/2], Iter [443/3125], train_loss:0.144147\n",
      "Epoch [2/2], Iter [444/3125], train_loss:0.145569\n",
      "Epoch [2/2], Iter [445/3125], train_loss:0.145312\n",
      "Epoch [2/2], Iter [446/3125], train_loss:0.145300\n",
      "Epoch [2/2], Iter [447/3125], train_loss:0.143758\n",
      "Epoch [2/2], Iter [448/3125], train_loss:0.144017\n",
      "Epoch [2/2], Iter [449/3125], train_loss:0.145424\n",
      "Epoch [2/2], Iter [450/3125], train_loss:0.145280\n",
      "Epoch [2/2], Iter [451/3125], train_loss:0.145162\n",
      "Epoch [2/2], Iter [452/3125], train_loss:0.142999\n",
      "Epoch [2/2], Iter [453/3125], train_loss:0.142479\n",
      "Epoch [2/2], Iter [454/3125], train_loss:0.144192\n",
      "Epoch [2/2], Iter [455/3125], train_loss:0.145021\n",
      "Epoch [2/2], Iter [456/3125], train_loss:0.144502\n",
      "Epoch [2/2], Iter [457/3125], train_loss:0.142553\n",
      "Epoch [2/2], Iter [458/3125], train_loss:0.145130\n",
      "Epoch [2/2], Iter [459/3125], train_loss:0.145586\n",
      "Epoch [2/2], Iter [460/3125], train_loss:0.143893\n",
      "Epoch [2/2], Iter [461/3125], train_loss:0.144420\n",
      "Epoch [2/2], Iter [462/3125], train_loss:0.145116\n",
      "Epoch [2/2], Iter [463/3125], train_loss:0.144972\n",
      "Epoch [2/2], Iter [464/3125], train_loss:0.143428\n",
      "Epoch [2/2], Iter [465/3125], train_loss:0.143782\n",
      "Epoch [2/2], Iter [466/3125], train_loss:0.143861\n",
      "Epoch [2/2], Iter [467/3125], train_loss:0.143978\n",
      "Epoch [2/2], Iter [468/3125], train_loss:0.143566\n",
      "Epoch [2/2], Iter [469/3125], train_loss:0.144346\n",
      "Epoch [2/2], Iter [470/3125], train_loss:0.144769\n",
      "Epoch [2/2], Iter [471/3125], train_loss:0.145166\n",
      "Epoch [2/2], Iter [472/3125], train_loss:0.143442\n",
      "Epoch [2/2], Iter [473/3125], train_loss:0.144183\n",
      "Epoch [2/2], Iter [474/3125], train_loss:0.144809\n",
      "Epoch [2/2], Iter [475/3125], train_loss:0.144536\n",
      "Epoch [2/2], Iter [476/3125], train_loss:0.144461\n",
      "Epoch [2/2], Iter [477/3125], train_loss:0.143630\n",
      "Epoch [2/2], Iter [478/3125], train_loss:0.143180\n",
      "Epoch [2/2], Iter [479/3125], train_loss:0.143834\n",
      "Epoch [2/2], Iter [480/3125], train_loss:0.145168\n",
      "Epoch [2/2], Iter [481/3125], train_loss:0.143957\n",
      "Epoch [2/2], Iter [482/3125], train_loss:0.144389\n",
      "Epoch [2/2], Iter [483/3125], train_loss:0.145370\n",
      "Epoch [2/2], Iter [484/3125], train_loss:0.144037\n",
      "Epoch [2/2], Iter [485/3125], train_loss:0.143125\n",
      "Epoch [2/2], Iter [486/3125], train_loss:0.145519\n",
      "Epoch [2/2], Iter [487/3125], train_loss:0.143918\n",
      "Epoch [2/2], Iter [488/3125], train_loss:0.143833\n",
      "Epoch [2/2], Iter [489/3125], train_loss:0.144650\n",
      "Epoch [2/2], Iter [490/3125], train_loss:0.143934\n",
      "Epoch [2/2], Iter [491/3125], train_loss:0.144018\n",
      "Epoch [2/2], Iter [492/3125], train_loss:0.143004\n",
      "Epoch [2/2], Iter [493/3125], train_loss:0.143630\n",
      "Epoch [2/2], Iter [494/3125], train_loss:0.144441\n",
      "Epoch [2/2], Iter [495/3125], train_loss:0.144880\n",
      "Epoch [2/2], Iter [496/3125], train_loss:0.143989\n",
      "Epoch [2/2], Iter [497/3125], train_loss:0.144092\n",
      "Epoch [2/2], Iter [498/3125], train_loss:0.143856\n",
      "Epoch [2/2], Iter [499/3125], train_loss:0.145663\n",
      "Epoch [2/2], Iter [500/3125], train_loss:0.143648\n",
      "Epoch [2/2], Iter [501/3125], train_loss:0.143502\n",
      "Epoch [2/2], Iter [502/3125], train_loss:0.146002\n",
      "Epoch [2/2], Iter [503/3125], train_loss:0.143400\n",
      "Epoch [2/2], Iter [504/3125], train_loss:0.145866\n",
      "Epoch [2/2], Iter [505/3125], train_loss:0.144080\n",
      "Epoch [2/2], Iter [506/3125], train_loss:0.146366\n",
      "Epoch [2/2], Iter [507/3125], train_loss:0.144557\n",
      "Epoch [2/2], Iter [508/3125], train_loss:0.145143\n",
      "Epoch [2/2], Iter [509/3125], train_loss:0.145309\n",
      "Epoch [2/2], Iter [510/3125], train_loss:0.144341\n",
      "Epoch [2/2], Iter [511/3125], train_loss:0.144699\n",
      "Epoch [2/2], Iter [512/3125], train_loss:0.143308\n",
      "Epoch [2/2], Iter [513/3125], train_loss:0.144971\n",
      "Epoch [2/2], Iter [514/3125], train_loss:0.145187\n",
      "Epoch [2/2], Iter [515/3125], train_loss:0.145811\n",
      "Epoch [2/2], Iter [516/3125], train_loss:0.144357\n",
      "Epoch [2/2], Iter [517/3125], train_loss:0.144941\n",
      "Epoch [2/2], Iter [518/3125], train_loss:0.143373\n",
      "Epoch [2/2], Iter [519/3125], train_loss:0.143147\n",
      "Epoch [2/2], Iter [520/3125], train_loss:0.143249\n",
      "Epoch [2/2], Iter [521/3125], train_loss:0.145531\n",
      "Epoch [2/2], Iter [522/3125], train_loss:0.145191\n",
      "Epoch [2/2], Iter [523/3125], train_loss:0.143940\n",
      "Epoch [2/2], Iter [524/3125], train_loss:0.143853\n",
      "Epoch [2/2], Iter [525/3125], train_loss:0.143975\n",
      "Epoch [2/2], Iter [526/3125], train_loss:0.144216\n",
      "Epoch [2/2], Iter [527/3125], train_loss:0.142740\n",
      "Epoch [2/2], Iter [528/3125], train_loss:0.141665\n",
      "Epoch [2/2], Iter [529/3125], train_loss:0.143609\n",
      "Epoch [2/2], Iter [530/3125], train_loss:0.144790\n",
      "Epoch [2/2], Iter [531/3125], train_loss:0.143697\n",
      "Epoch [2/2], Iter [532/3125], train_loss:0.144065\n",
      "Epoch [2/2], Iter [533/3125], train_loss:0.143329\n",
      "Epoch [2/2], Iter [534/3125], train_loss:0.144259\n",
      "Epoch [2/2], Iter [535/3125], train_loss:0.144807\n",
      "Epoch [2/2], Iter [536/3125], train_loss:0.145296\n",
      "Epoch [2/2], Iter [537/3125], train_loss:0.144553\n",
      "Epoch [2/2], Iter [538/3125], train_loss:0.144454\n",
      "Epoch [2/2], Iter [539/3125], train_loss:0.144069\n",
      "Epoch [2/2], Iter [540/3125], train_loss:0.143724\n",
      "Epoch [2/2], Iter [541/3125], train_loss:0.144940\n",
      "Epoch [2/2], Iter [542/3125], train_loss:0.143775\n",
      "Epoch [2/2], Iter [543/3125], train_loss:0.143568\n",
      "Epoch [2/2], Iter [544/3125], train_loss:0.145049\n",
      "Epoch [2/2], Iter [545/3125], train_loss:0.143940\n",
      "Epoch [2/2], Iter [546/3125], train_loss:0.144242\n",
      "Epoch [2/2], Iter [547/3125], train_loss:0.143721\n",
      "Epoch [2/2], Iter [548/3125], train_loss:0.143631\n",
      "Epoch [2/2], Iter [549/3125], train_loss:0.143989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [550/3125], train_loss:0.144407\n",
      "Epoch [2/2], Iter [551/3125], train_loss:0.143035\n",
      "Epoch [2/2], Iter [552/3125], train_loss:0.144164\n",
      "Epoch [2/2], Iter [553/3125], train_loss:0.144285\n",
      "Epoch [2/2], Iter [554/3125], train_loss:0.144310\n",
      "Epoch [2/2], Iter [555/3125], train_loss:0.144027\n",
      "Epoch [2/2], Iter [556/3125], train_loss:0.145306\n",
      "Epoch [2/2], Iter [557/3125], train_loss:0.143419\n",
      "Epoch [2/2], Iter [558/3125], train_loss:0.143495\n",
      "Epoch [2/2], Iter [559/3125], train_loss:0.144807\n",
      "Epoch [2/2], Iter [560/3125], train_loss:0.143957\n",
      "Epoch [2/2], Iter [561/3125], train_loss:0.143188\n",
      "Epoch [2/2], Iter [562/3125], train_loss:0.144172\n",
      "Epoch [2/2], Iter [563/3125], train_loss:0.144180\n",
      "Epoch [2/2], Iter [564/3125], train_loss:0.143870\n",
      "Epoch [2/2], Iter [565/3125], train_loss:0.142312\n",
      "Epoch [2/2], Iter [566/3125], train_loss:0.144081\n",
      "Epoch [2/2], Iter [567/3125], train_loss:0.143015\n",
      "Epoch [2/2], Iter [568/3125], train_loss:0.144368\n",
      "Epoch [2/2], Iter [569/3125], train_loss:0.144287\n",
      "Epoch [2/2], Iter [570/3125], train_loss:0.143932\n",
      "Epoch [2/2], Iter [571/3125], train_loss:0.142007\n",
      "Epoch [2/2], Iter [572/3125], train_loss:0.143727\n",
      "Epoch [2/2], Iter [573/3125], train_loss:0.145466\n",
      "Epoch [2/2], Iter [574/3125], train_loss:0.144018\n",
      "Epoch [2/2], Iter [575/3125], train_loss:0.143469\n",
      "Epoch [2/2], Iter [576/3125], train_loss:0.143204\n",
      "Epoch [2/2], Iter [577/3125], train_loss:0.143540\n",
      "Epoch [2/2], Iter [578/3125], train_loss:0.143789\n",
      "Epoch [2/2], Iter [579/3125], train_loss:0.142742\n",
      "Epoch [2/2], Iter [580/3125], train_loss:0.144082\n",
      "Epoch [2/2], Iter [581/3125], train_loss:0.144377\n",
      "Epoch [2/2], Iter [582/3125], train_loss:0.143948\n",
      "Epoch [2/2], Iter [583/3125], train_loss:0.143691\n",
      "Epoch [2/2], Iter [584/3125], train_loss:0.143932\n",
      "Epoch [2/2], Iter [585/3125], train_loss:0.143775\n",
      "Epoch [2/2], Iter [586/3125], train_loss:0.144418\n",
      "Epoch [2/2], Iter [587/3125], train_loss:0.143812\n",
      "Epoch [2/2], Iter [588/3125], train_loss:0.142890\n",
      "Epoch [2/2], Iter [589/3125], train_loss:0.143395\n",
      "Epoch [2/2], Iter [590/3125], train_loss:0.142874\n",
      "Epoch [2/2], Iter [591/3125], train_loss:0.142782\n",
      "Epoch [2/2], Iter [592/3125], train_loss:0.143652\n",
      "Epoch [2/2], Iter [593/3125], train_loss:0.144702\n",
      "Epoch [2/2], Iter [594/3125], train_loss:0.144081\n",
      "Epoch [2/2], Iter [595/3125], train_loss:0.143470\n",
      "Epoch [2/2], Iter [596/3125], train_loss:0.143730\n",
      "Epoch [2/2], Iter [597/3125], train_loss:0.143776\n",
      "Epoch [2/2], Iter [598/3125], train_loss:0.142999\n",
      "Epoch [2/2], Iter [599/3125], train_loss:0.143793\n",
      "Epoch [2/2], Iter [600/3125], train_loss:0.143406\n",
      "Epoch [2/2], Iter [601/3125], train_loss:0.142634\n",
      "Epoch [2/2], Iter [602/3125], train_loss:0.143054\n",
      "Epoch [2/2], Iter [603/3125], train_loss:0.143375\n",
      "Epoch [2/2], Iter [604/3125], train_loss:0.144502\n",
      "Epoch [2/2], Iter [605/3125], train_loss:0.142857\n",
      "Epoch [2/2], Iter [606/3125], train_loss:0.143722\n",
      "Epoch [2/2], Iter [607/3125], train_loss:0.143275\n",
      "Epoch [2/2], Iter [608/3125], train_loss:0.143322\n",
      "Epoch [2/2], Iter [609/3125], train_loss:0.142407\n",
      "Epoch [2/2], Iter [610/3125], train_loss:0.143971\n",
      "Epoch [2/2], Iter [611/3125], train_loss:0.142344\n",
      "Epoch [2/2], Iter [612/3125], train_loss:0.142984\n",
      "Epoch [2/2], Iter [613/3125], train_loss:0.144371\n",
      "Epoch [2/2], Iter [614/3125], train_loss:0.145318\n",
      "Epoch [2/2], Iter [615/3125], train_loss:0.144015\n",
      "Epoch [2/2], Iter [616/3125], train_loss:0.145016\n",
      "Epoch [2/2], Iter [617/3125], train_loss:0.142289\n",
      "Epoch [2/2], Iter [618/3125], train_loss:0.144029\n",
      "Epoch [2/2], Iter [619/3125], train_loss:0.144449\n",
      "Epoch [2/2], Iter [620/3125], train_loss:0.142859\n",
      "Epoch [2/2], Iter [621/3125], train_loss:0.144012\n",
      "Epoch [2/2], Iter [622/3125], train_loss:0.144772\n",
      "Epoch [2/2], Iter [623/3125], train_loss:0.144845\n",
      "Epoch [2/2], Iter [624/3125], train_loss:0.144259\n",
      "Epoch [2/2], Iter [625/3125], train_loss:0.144050\n",
      "Epoch [2/2], Iter [626/3125], train_loss:0.144166\n",
      "Epoch [2/2], Iter [627/3125], train_loss:0.144068\n",
      "Epoch [2/2], Iter [628/3125], train_loss:0.143068\n",
      "Epoch [2/2], Iter [629/3125], train_loss:0.143842\n",
      "Epoch [2/2], Iter [630/3125], train_loss:0.146118\n",
      "Epoch [2/2], Iter [631/3125], train_loss:0.145230\n",
      "Epoch [2/2], Iter [632/3125], train_loss:0.145201\n",
      "Epoch [2/2], Iter [633/3125], train_loss:0.144982\n",
      "Epoch [2/2], Iter [634/3125], train_loss:0.143677\n",
      "Epoch [2/2], Iter [635/3125], train_loss:0.143034\n",
      "Epoch [2/2], Iter [636/3125], train_loss:0.144059\n",
      "Epoch [2/2], Iter [637/3125], train_loss:0.143087\n",
      "Epoch [2/2], Iter [638/3125], train_loss:0.142711\n",
      "Epoch [2/2], Iter [639/3125], train_loss:0.145849\n",
      "Epoch [2/2], Iter [640/3125], train_loss:0.144002\n",
      "Epoch [2/2], Iter [641/3125], train_loss:0.143108\n",
      "Epoch [2/2], Iter [642/3125], train_loss:0.143065\n",
      "Epoch [2/2], Iter [643/3125], train_loss:0.144259\n",
      "Epoch [2/2], Iter [644/3125], train_loss:0.142584\n",
      "Epoch [2/2], Iter [645/3125], train_loss:0.144349\n",
      "Epoch [2/2], Iter [646/3125], train_loss:0.144053\n",
      "Epoch [2/2], Iter [647/3125], train_loss:0.146316\n",
      "Epoch [2/2], Iter [648/3125], train_loss:0.145791\n",
      "Epoch [2/2], Iter [649/3125], train_loss:0.145476\n",
      "Epoch [2/2], Iter [650/3125], train_loss:0.143280\n",
      "Epoch [2/2], Iter [651/3125], train_loss:0.142678\n",
      "Epoch [2/2], Iter [652/3125], train_loss:0.143372\n",
      "Epoch [2/2], Iter [653/3125], train_loss:0.144887\n",
      "Epoch [2/2], Iter [654/3125], train_loss:0.143362\n",
      "Epoch [2/2], Iter [655/3125], train_loss:0.144784\n",
      "Epoch [2/2], Iter [656/3125], train_loss:0.143451\n",
      "Epoch [2/2], Iter [657/3125], train_loss:0.143692\n",
      "Epoch [2/2], Iter [658/3125], train_loss:0.144773\n",
      "Epoch [2/2], Iter [659/3125], train_loss:0.144038\n",
      "Epoch [2/2], Iter [660/3125], train_loss:0.146447\n",
      "Epoch [2/2], Iter [661/3125], train_loss:0.143771\n",
      "Epoch [2/2], Iter [662/3125], train_loss:0.144965\n",
      "Epoch [2/2], Iter [663/3125], train_loss:0.144452\n",
      "Epoch [2/2], Iter [664/3125], train_loss:0.144512\n",
      "Epoch [2/2], Iter [665/3125], train_loss:0.144677\n",
      "Epoch [2/2], Iter [666/3125], train_loss:0.143963\n",
      "Epoch [2/2], Iter [667/3125], train_loss:0.144869\n",
      "Epoch [2/2], Iter [668/3125], train_loss:0.143007\n",
      "Epoch [2/2], Iter [669/3125], train_loss:0.143534\n",
      "Epoch [2/2], Iter [670/3125], train_loss:0.142152\n",
      "Epoch [2/2], Iter [671/3125], train_loss:0.144871\n",
      "Epoch [2/2], Iter [672/3125], train_loss:0.145373\n",
      "Epoch [2/2], Iter [673/3125], train_loss:0.143338\n",
      "Epoch [2/2], Iter [674/3125], train_loss:0.143339\n",
      "Epoch [2/2], Iter [675/3125], train_loss:0.143253\n",
      "Epoch [2/2], Iter [676/3125], train_loss:0.141972\n",
      "Epoch [2/2], Iter [677/3125], train_loss:0.143554\n",
      "Epoch [2/2], Iter [678/3125], train_loss:0.145031\n",
      "Epoch [2/2], Iter [679/3125], train_loss:0.144166\n",
      "Epoch [2/2], Iter [680/3125], train_loss:0.143361\n",
      "Epoch [2/2], Iter [681/3125], train_loss:0.143698\n",
      "Epoch [2/2], Iter [682/3125], train_loss:0.143834\n",
      "Epoch [2/2], Iter [683/3125], train_loss:0.144067\n",
      "Epoch [2/2], Iter [684/3125], train_loss:0.144394\n",
      "Epoch [2/2], Iter [685/3125], train_loss:0.144498\n",
      "Epoch [2/2], Iter [686/3125], train_loss:0.143548\n",
      "Epoch [2/2], Iter [687/3125], train_loss:0.143643\n",
      "Epoch [2/2], Iter [688/3125], train_loss:0.144880\n",
      "Epoch [2/2], Iter [689/3125], train_loss:0.143967\n",
      "Epoch [2/2], Iter [690/3125], train_loss:0.145142\n",
      "Epoch [2/2], Iter [691/3125], train_loss:0.142875\n",
      "Epoch [2/2], Iter [692/3125], train_loss:0.144476\n",
      "Epoch [2/2], Iter [693/3125], train_loss:0.144537\n",
      "Epoch [2/2], Iter [694/3125], train_loss:0.142424\n",
      "Epoch [2/2], Iter [695/3125], train_loss:0.142462\n",
      "Epoch [2/2], Iter [696/3125], train_loss:0.143670\n",
      "Epoch [2/2], Iter [697/3125], train_loss:0.145955\n",
      "Epoch [2/2], Iter [698/3125], train_loss:0.144261\n",
      "Epoch [2/2], Iter [699/3125], train_loss:0.142811\n",
      "Epoch [2/2], Iter [700/3125], train_loss:0.143184\n",
      "Epoch [2/2], Iter [701/3125], train_loss:0.145173\n",
      "Epoch [2/2], Iter [702/3125], train_loss:0.143229\n",
      "Epoch [2/2], Iter [703/3125], train_loss:0.144804\n",
      "Epoch [2/2], Iter [704/3125], train_loss:0.142970\n",
      "Epoch [2/2], Iter [705/3125], train_loss:0.145588\n",
      "Epoch [2/2], Iter [706/3125], train_loss:0.143295\n",
      "Epoch [2/2], Iter [707/3125], train_loss:0.144500\n",
      "Epoch [2/2], Iter [708/3125], train_loss:0.145919\n",
      "Epoch [2/2], Iter [709/3125], train_loss:0.144242\n",
      "Epoch [2/2], Iter [710/3125], train_loss:0.143712\n",
      "Epoch [2/2], Iter [711/3125], train_loss:0.144582\n",
      "Epoch [2/2], Iter [712/3125], train_loss:0.144564\n",
      "Epoch [2/2], Iter [713/3125], train_loss:0.144096\n",
      "Epoch [2/2], Iter [714/3125], train_loss:0.144862\n",
      "Epoch [2/2], Iter [715/3125], train_loss:0.143179\n",
      "Epoch [2/2], Iter [716/3125], train_loss:0.143493\n",
      "Epoch [2/2], Iter [717/3125], train_loss:0.143224\n",
      "Epoch [2/2], Iter [718/3125], train_loss:0.144559\n",
      "Epoch [2/2], Iter [719/3125], train_loss:0.143396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [720/3125], train_loss:0.143267\n",
      "Epoch [2/2], Iter [721/3125], train_loss:0.142994\n",
      "Epoch [2/2], Iter [722/3125], train_loss:0.143926\n",
      "Epoch [2/2], Iter [723/3125], train_loss:0.143666\n",
      "Epoch [2/2], Iter [724/3125], train_loss:0.143765\n",
      "Epoch [2/2], Iter [725/3125], train_loss:0.144841\n",
      "Epoch [2/2], Iter [726/3125], train_loss:0.142475\n",
      "Epoch [2/2], Iter [727/3125], train_loss:0.143215\n",
      "Epoch [2/2], Iter [728/3125], train_loss:0.145398\n",
      "Epoch [2/2], Iter [729/3125], train_loss:0.143368\n",
      "Epoch [2/2], Iter [730/3125], train_loss:0.144948\n",
      "Epoch [2/2], Iter [731/3125], train_loss:0.143911\n",
      "Epoch [2/2], Iter [732/3125], train_loss:0.142944\n",
      "Epoch [2/2], Iter [733/3125], train_loss:0.144724\n",
      "Epoch [2/2], Iter [734/3125], train_loss:0.143874\n",
      "Epoch [2/2], Iter [735/3125], train_loss:0.144617\n",
      "Epoch [2/2], Iter [736/3125], train_loss:0.142974\n",
      "Epoch [2/2], Iter [737/3125], train_loss:0.144212\n",
      "Epoch [2/2], Iter [738/3125], train_loss:0.144664\n",
      "Epoch [2/2], Iter [739/3125], train_loss:0.143400\n",
      "Epoch [2/2], Iter [740/3125], train_loss:0.143854\n",
      "Epoch [2/2], Iter [741/3125], train_loss:0.143065\n",
      "Epoch [2/2], Iter [742/3125], train_loss:0.144349\n",
      "Epoch [2/2], Iter [743/3125], train_loss:0.144993\n",
      "Epoch [2/2], Iter [744/3125], train_loss:0.143606\n",
      "Epoch [2/2], Iter [745/3125], train_loss:0.142807\n",
      "Epoch [2/2], Iter [746/3125], train_loss:0.144251\n",
      "Epoch [2/2], Iter [747/3125], train_loss:0.145019\n",
      "Epoch [2/2], Iter [748/3125], train_loss:0.144918\n",
      "Epoch [2/2], Iter [749/3125], train_loss:0.144156\n",
      "Epoch [2/2], Iter [750/3125], train_loss:0.144647\n",
      "Epoch [2/2], Iter [751/3125], train_loss:0.143165\n",
      "Epoch [2/2], Iter [752/3125], train_loss:0.144428\n",
      "Epoch [2/2], Iter [753/3125], train_loss:0.143930\n",
      "Epoch [2/2], Iter [754/3125], train_loss:0.144378\n",
      "Epoch [2/2], Iter [755/3125], train_loss:0.142231\n",
      "Epoch [2/2], Iter [756/3125], train_loss:0.143772\n",
      "Epoch [2/2], Iter [757/3125], train_loss:0.144687\n",
      "Epoch [2/2], Iter [758/3125], train_loss:0.143434\n",
      "Epoch [2/2], Iter [759/3125], train_loss:0.143924\n",
      "Epoch [2/2], Iter [760/3125], train_loss:0.144559\n",
      "Epoch [2/2], Iter [761/3125], train_loss:0.142837\n",
      "Epoch [2/2], Iter [762/3125], train_loss:0.144935\n",
      "Epoch [2/2], Iter [763/3125], train_loss:0.143922\n",
      "Epoch [2/2], Iter [764/3125], train_loss:0.144866\n",
      "Epoch [2/2], Iter [765/3125], train_loss:0.145512\n",
      "Epoch [2/2], Iter [766/3125], train_loss:0.144120\n",
      "Epoch [2/2], Iter [767/3125], train_loss:0.143350\n",
      "Epoch [2/2], Iter [768/3125], train_loss:0.144803\n",
      "Epoch [2/2], Iter [769/3125], train_loss:0.143112\n",
      "Epoch [2/2], Iter [770/3125], train_loss:0.143387\n",
      "Epoch [2/2], Iter [771/3125], train_loss:0.144477\n",
      "Epoch [2/2], Iter [772/3125], train_loss:0.143748\n",
      "Epoch [2/2], Iter [773/3125], train_loss:0.143389\n",
      "Epoch [2/2], Iter [774/3125], train_loss:0.143670\n",
      "Epoch [2/2], Iter [775/3125], train_loss:0.143680\n",
      "Epoch [2/2], Iter [776/3125], train_loss:0.143734\n",
      "Epoch [2/2], Iter [777/3125], train_loss:0.145057\n",
      "Epoch [2/2], Iter [778/3125], train_loss:0.143116\n",
      "Epoch [2/2], Iter [779/3125], train_loss:0.144200\n",
      "Epoch [2/2], Iter [780/3125], train_loss:0.145103\n",
      "Epoch [2/2], Iter [781/3125], train_loss:0.144524\n",
      "Epoch [2/2], Iter [782/3125], train_loss:0.145180\n",
      "Epoch [2/2], Iter [783/3125], train_loss:0.143349\n",
      "Epoch [2/2], Iter [784/3125], train_loss:0.144012\n",
      "Epoch [2/2], Iter [785/3125], train_loss:0.143522\n",
      "Epoch [2/2], Iter [786/3125], train_loss:0.143487\n",
      "Epoch [2/2], Iter [787/3125], train_loss:0.143846\n",
      "Epoch [2/2], Iter [788/3125], train_loss:0.144794\n",
      "Epoch [2/2], Iter [789/3125], train_loss:0.144351\n",
      "Epoch [2/2], Iter [790/3125], train_loss:0.143773\n",
      "Epoch [2/2], Iter [791/3125], train_loss:0.143940\n",
      "Epoch [2/2], Iter [792/3125], train_loss:0.143259\n",
      "Epoch [2/2], Iter [793/3125], train_loss:0.144891\n",
      "Epoch [2/2], Iter [794/3125], train_loss:0.144218\n",
      "Epoch [2/2], Iter [795/3125], train_loss:0.143386\n",
      "Epoch [2/2], Iter [796/3125], train_loss:0.143912\n",
      "Epoch [2/2], Iter [797/3125], train_loss:0.142223\n",
      "Epoch [2/2], Iter [798/3125], train_loss:0.143929\n",
      "Epoch [2/2], Iter [799/3125], train_loss:0.144927\n",
      "Epoch [2/2], Iter [800/3125], train_loss:0.143389\n",
      "Epoch [2/2], Iter [801/3125], train_loss:0.143749\n",
      "Epoch [2/2], Iter [802/3125], train_loss:0.144987\n",
      "Epoch [2/2], Iter [803/3125], train_loss:0.143915\n",
      "Epoch [2/2], Iter [804/3125], train_loss:0.145053\n",
      "Epoch [2/2], Iter [805/3125], train_loss:0.144036\n",
      "Epoch [2/2], Iter [806/3125], train_loss:0.143924\n",
      "Epoch [2/2], Iter [807/3125], train_loss:0.143434\n",
      "Epoch [2/2], Iter [808/3125], train_loss:0.143943\n",
      "Epoch [2/2], Iter [809/3125], train_loss:0.144334\n",
      "Epoch [2/2], Iter [810/3125], train_loss:0.144917\n",
      "Epoch [2/2], Iter [811/3125], train_loss:0.145826\n",
      "Epoch [2/2], Iter [812/3125], train_loss:0.145581\n",
      "Epoch [2/2], Iter [813/3125], train_loss:0.146060\n",
      "Epoch [2/2], Iter [814/3125], train_loss:0.144250\n",
      "Epoch [2/2], Iter [815/3125], train_loss:0.141958\n",
      "Epoch [2/2], Iter [816/3125], train_loss:0.145689\n",
      "Epoch [2/2], Iter [817/3125], train_loss:0.144842\n",
      "Epoch [2/2], Iter [818/3125], train_loss:0.144912\n",
      "Epoch [2/2], Iter [819/3125], train_loss:0.143375\n",
      "Epoch [2/2], Iter [820/3125], train_loss:0.143788\n",
      "Epoch [2/2], Iter [821/3125], train_loss:0.143441\n",
      "Epoch [2/2], Iter [822/3125], train_loss:0.144806\n",
      "Epoch [2/2], Iter [823/3125], train_loss:0.143358\n",
      "Epoch [2/2], Iter [824/3125], train_loss:0.143137\n",
      "Epoch [2/2], Iter [825/3125], train_loss:0.144180\n",
      "Epoch [2/2], Iter [826/3125], train_loss:0.145062\n",
      "Epoch [2/2], Iter [827/3125], train_loss:0.142895\n",
      "Epoch [2/2], Iter [828/3125], train_loss:0.143402\n",
      "Epoch [2/2], Iter [829/3125], train_loss:0.143416\n",
      "Epoch [2/2], Iter [830/3125], train_loss:0.144050\n",
      "Epoch [2/2], Iter [831/3125], train_loss:0.143708\n",
      "Epoch [2/2], Iter [832/3125], train_loss:0.143947\n",
      "Epoch [2/2], Iter [833/3125], train_loss:0.145754\n",
      "Epoch [2/2], Iter [834/3125], train_loss:0.143288\n",
      "Epoch [2/2], Iter [835/3125], train_loss:0.143747\n",
      "Epoch [2/2], Iter [836/3125], train_loss:0.142995\n",
      "Epoch [2/2], Iter [837/3125], train_loss:0.144162\n",
      "Epoch [2/2], Iter [838/3125], train_loss:0.144027\n",
      "Epoch [2/2], Iter [839/3125], train_loss:0.145651\n",
      "Epoch [2/2], Iter [840/3125], train_loss:0.143520\n",
      "Epoch [2/2], Iter [841/3125], train_loss:0.143792\n",
      "Epoch [2/2], Iter [842/3125], train_loss:0.144514\n",
      "Epoch [2/2], Iter [843/3125], train_loss:0.144795\n",
      "Epoch [2/2], Iter [844/3125], train_loss:0.144750\n",
      "Epoch [2/2], Iter [845/3125], train_loss:0.142491\n",
      "Epoch [2/2], Iter [846/3125], train_loss:0.143089\n",
      "Epoch [2/2], Iter [847/3125], train_loss:0.144769\n",
      "Epoch [2/2], Iter [848/3125], train_loss:0.143831\n",
      "Epoch [2/2], Iter [849/3125], train_loss:0.143597\n",
      "Epoch [2/2], Iter [850/3125], train_loss:0.143608\n",
      "Epoch [2/2], Iter [851/3125], train_loss:0.143320\n",
      "Epoch [2/2], Iter [852/3125], train_loss:0.142881\n",
      "Epoch [2/2], Iter [853/3125], train_loss:0.144472\n",
      "Epoch [2/2], Iter [854/3125], train_loss:0.144411\n",
      "Epoch [2/2], Iter [855/3125], train_loss:0.143662\n",
      "Epoch [2/2], Iter [856/3125], train_loss:0.144109\n",
      "Epoch [2/2], Iter [857/3125], train_loss:0.145710\n",
      "Epoch [2/2], Iter [858/3125], train_loss:0.145560\n",
      "Epoch [2/2], Iter [859/3125], train_loss:0.143021\n",
      "Epoch [2/2], Iter [860/3125], train_loss:0.142464\n",
      "Epoch [2/2], Iter [861/3125], train_loss:0.145166\n",
      "Epoch [2/2], Iter [862/3125], train_loss:0.143172\n",
      "Epoch [2/2], Iter [863/3125], train_loss:0.144870\n",
      "Epoch [2/2], Iter [864/3125], train_loss:0.144822\n",
      "Epoch [2/2], Iter [865/3125], train_loss:0.143919\n",
      "Epoch [2/2], Iter [866/3125], train_loss:0.144814\n",
      "Epoch [2/2], Iter [867/3125], train_loss:0.144500\n",
      "Epoch [2/2], Iter [868/3125], train_loss:0.145007\n",
      "Epoch [2/2], Iter [869/3125], train_loss:0.144964\n",
      "Epoch [2/2], Iter [870/3125], train_loss:0.144415\n",
      "Epoch [2/2], Iter [871/3125], train_loss:0.143916\n",
      "Epoch [2/2], Iter [872/3125], train_loss:0.144496\n",
      "Epoch [2/2], Iter [873/3125], train_loss:0.143508\n",
      "Epoch [2/2], Iter [874/3125], train_loss:0.142936\n",
      "Epoch [2/2], Iter [875/3125], train_loss:0.144071\n",
      "Epoch [2/2], Iter [876/3125], train_loss:0.144006\n",
      "Epoch [2/2], Iter [877/3125], train_loss:0.145821\n",
      "Epoch [2/2], Iter [878/3125], train_loss:0.143727\n",
      "Epoch [2/2], Iter [879/3125], train_loss:0.144866\n",
      "Epoch [2/2], Iter [880/3125], train_loss:0.143628\n",
      "Epoch [2/2], Iter [881/3125], train_loss:0.143840\n",
      "Epoch [2/2], Iter [882/3125], train_loss:0.145723\n",
      "Epoch [2/2], Iter [883/3125], train_loss:0.144466\n",
      "Epoch [2/2], Iter [884/3125], train_loss:0.144918\n",
      "Epoch [2/2], Iter [885/3125], train_loss:0.142710\n",
      "Epoch [2/2], Iter [886/3125], train_loss:0.143034\n",
      "Epoch [2/2], Iter [887/3125], train_loss:0.143835\n",
      "Epoch [2/2], Iter [888/3125], train_loss:0.145353\n",
      "Epoch [2/2], Iter [889/3125], train_loss:0.144169\n",
      "Epoch [2/2], Iter [890/3125], train_loss:0.142281\n",
      "Epoch [2/2], Iter [891/3125], train_loss:0.144426\n",
      "Epoch [2/2], Iter [892/3125], train_loss:0.143583\n",
      "Epoch [2/2], Iter [893/3125], train_loss:0.145848\n",
      "Epoch [2/2], Iter [894/3125], train_loss:0.143024\n",
      "Epoch [2/2], Iter [895/3125], train_loss:0.144102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [896/3125], train_loss:0.143205\n",
      "Epoch [2/2], Iter [897/3125], train_loss:0.142443\n",
      "Epoch [2/2], Iter [898/3125], train_loss:0.144856\n",
      "Epoch [2/2], Iter [899/3125], train_loss:0.143078\n",
      "Epoch [2/2], Iter [900/3125], train_loss:0.145195\n",
      "Epoch [2/2], Iter [901/3125], train_loss:0.144094\n",
      "Epoch [2/2], Iter [902/3125], train_loss:0.142664\n",
      "Epoch [2/2], Iter [903/3125], train_loss:0.145138\n",
      "Epoch [2/2], Iter [904/3125], train_loss:0.144074\n",
      "Epoch [2/2], Iter [905/3125], train_loss:0.143978\n",
      "Epoch [2/2], Iter [906/3125], train_loss:0.143167\n",
      "Epoch [2/2], Iter [907/3125], train_loss:0.143749\n",
      "Epoch [2/2], Iter [908/3125], train_loss:0.143886\n",
      "Epoch [2/2], Iter [909/3125], train_loss:0.143040\n",
      "Epoch [2/2], Iter [910/3125], train_loss:0.143592\n",
      "Epoch [2/2], Iter [911/3125], train_loss:0.142112\n",
      "Epoch [2/2], Iter [912/3125], train_loss:0.143336\n",
      "Epoch [2/2], Iter [913/3125], train_loss:0.142810\n",
      "Epoch [2/2], Iter [914/3125], train_loss:0.143817\n",
      "Epoch [2/2], Iter [915/3125], train_loss:0.144812\n",
      "Epoch [2/2], Iter [916/3125], train_loss:0.144238\n",
      "Epoch [2/2], Iter [917/3125], train_loss:0.143021\n",
      "Epoch [2/2], Iter [918/3125], train_loss:0.143042\n",
      "Epoch [2/2], Iter [919/3125], train_loss:0.145907\n",
      "Epoch [2/2], Iter [920/3125], train_loss:0.144108\n",
      "Epoch [2/2], Iter [921/3125], train_loss:0.145027\n",
      "Epoch [2/2], Iter [922/3125], train_loss:0.144774\n",
      "Epoch [2/2], Iter [923/3125], train_loss:0.144327\n",
      "Epoch [2/2], Iter [924/3125], train_loss:0.142845\n",
      "Epoch [2/2], Iter [925/3125], train_loss:0.143247\n",
      "Epoch [2/2], Iter [926/3125], train_loss:0.142875\n",
      "Epoch [2/2], Iter [927/3125], train_loss:0.144399\n",
      "Epoch [2/2], Iter [928/3125], train_loss:0.144550\n",
      "Epoch [2/2], Iter [929/3125], train_loss:0.144905\n",
      "Epoch [2/2], Iter [930/3125], train_loss:0.145250\n",
      "Epoch [2/2], Iter [931/3125], train_loss:0.143463\n",
      "Epoch [2/2], Iter [932/3125], train_loss:0.143861\n",
      "Epoch [2/2], Iter [933/3125], train_loss:0.143720\n",
      "Epoch [2/2], Iter [934/3125], train_loss:0.144922\n",
      "Epoch [2/2], Iter [935/3125], train_loss:0.144956\n",
      "Epoch [2/2], Iter [936/3125], train_loss:0.143981\n",
      "Epoch [2/2], Iter [937/3125], train_loss:0.143353\n",
      "Epoch [2/2], Iter [938/3125], train_loss:0.143818\n",
      "Epoch [2/2], Iter [939/3125], train_loss:0.143882\n",
      "Epoch [2/2], Iter [940/3125], train_loss:0.144058\n",
      "Epoch [2/2], Iter [941/3125], train_loss:0.144865\n",
      "Epoch [2/2], Iter [942/3125], train_loss:0.144071\n",
      "Epoch [2/2], Iter [943/3125], train_loss:0.142958\n",
      "Epoch [2/2], Iter [944/3125], train_loss:0.144109\n",
      "Epoch [2/2], Iter [945/3125], train_loss:0.145524\n",
      "Epoch [2/2], Iter [946/3125], train_loss:0.142769\n",
      "Epoch [2/2], Iter [947/3125], train_loss:0.143620\n",
      "Epoch [2/2], Iter [948/3125], train_loss:0.142708\n",
      "Epoch [2/2], Iter [949/3125], train_loss:0.142831\n",
      "Epoch [2/2], Iter [950/3125], train_loss:0.142785\n",
      "Epoch [2/2], Iter [951/3125], train_loss:0.145156\n",
      "Epoch [2/2], Iter [952/3125], train_loss:0.144914\n",
      "Epoch [2/2], Iter [953/3125], train_loss:0.143185\n",
      "Epoch [2/2], Iter [954/3125], train_loss:0.145865\n",
      "Epoch [2/2], Iter [955/3125], train_loss:0.145371\n",
      "Epoch [2/2], Iter [956/3125], train_loss:0.144361\n",
      "Epoch [2/2], Iter [957/3125], train_loss:0.144172\n",
      "Epoch [2/2], Iter [958/3125], train_loss:0.145445\n",
      "Epoch [2/2], Iter [959/3125], train_loss:0.144771\n",
      "Epoch [2/2], Iter [960/3125], train_loss:0.142874\n",
      "Epoch [2/2], Iter [961/3125], train_loss:0.144219\n",
      "Epoch [2/2], Iter [962/3125], train_loss:0.144364\n",
      "Epoch [2/2], Iter [963/3125], train_loss:0.142446\n",
      "Epoch [2/2], Iter [964/3125], train_loss:0.143894\n",
      "Epoch [2/2], Iter [965/3125], train_loss:0.143875\n",
      "Epoch [2/2], Iter [966/3125], train_loss:0.143711\n",
      "Epoch [2/2], Iter [967/3125], train_loss:0.142735\n",
      "Epoch [2/2], Iter [968/3125], train_loss:0.145481\n",
      "Epoch [2/2], Iter [969/3125], train_loss:0.143839\n",
      "Epoch [2/2], Iter [970/3125], train_loss:0.144763\n",
      "Epoch [2/2], Iter [971/3125], train_loss:0.143900\n",
      "Epoch [2/2], Iter [972/3125], train_loss:0.144393\n",
      "Epoch [2/2], Iter [973/3125], train_loss:0.144021\n",
      "Epoch [2/2], Iter [974/3125], train_loss:0.143456\n",
      "Epoch [2/2], Iter [975/3125], train_loss:0.146024\n",
      "Epoch [2/2], Iter [976/3125], train_loss:0.143741\n",
      "Epoch [2/2], Iter [977/3125], train_loss:0.144007\n",
      "Epoch [2/2], Iter [978/3125], train_loss:0.145184\n",
      "Epoch [2/2], Iter [979/3125], train_loss:0.143735\n",
      "Epoch [2/2], Iter [980/3125], train_loss:0.145223\n",
      "Epoch [2/2], Iter [981/3125], train_loss:0.144920\n",
      "Epoch [2/2], Iter [982/3125], train_loss:0.143569\n",
      "Epoch [2/2], Iter [983/3125], train_loss:0.144221\n",
      "Epoch [2/2], Iter [984/3125], train_loss:0.144826\n",
      "Epoch [2/2], Iter [985/3125], train_loss:0.143533\n",
      "Epoch [2/2], Iter [986/3125], train_loss:0.144295\n",
      "Epoch [2/2], Iter [987/3125], train_loss:0.143945\n",
      "Epoch [2/2], Iter [988/3125], train_loss:0.143548\n",
      "Epoch [2/2], Iter [989/3125], train_loss:0.143876\n",
      "Epoch [2/2], Iter [990/3125], train_loss:0.143601\n",
      "Epoch [2/2], Iter [991/3125], train_loss:0.145518\n",
      "Epoch [2/2], Iter [992/3125], train_loss:0.143026\n",
      "Epoch [2/2], Iter [993/3125], train_loss:0.143593\n",
      "Epoch [2/2], Iter [994/3125], train_loss:0.144557\n",
      "Epoch [2/2], Iter [995/3125], train_loss:0.145228\n",
      "Epoch [2/2], Iter [996/3125], train_loss:0.145280\n",
      "Epoch [2/2], Iter [997/3125], train_loss:0.144012\n",
      "Epoch [2/2], Iter [998/3125], train_loss:0.143741\n",
      "Epoch [2/2], Iter [999/3125], train_loss:0.143405\n",
      "Epoch [2/2], Iter [1000/3125], train_loss:0.142532\n",
      "Epoch [2/2], Iter [1001/3125], train_loss:0.143043\n",
      "Epoch [2/2], Iter [1002/3125], train_loss:0.144380\n",
      "Epoch [2/2], Iter [1003/3125], train_loss:0.144819\n",
      "Epoch [2/2], Iter [1004/3125], train_loss:0.141802\n",
      "Epoch [2/2], Iter [1005/3125], train_loss:0.144960\n",
      "Epoch [2/2], Iter [1006/3125], train_loss:0.144278\n",
      "Epoch [2/2], Iter [1007/3125], train_loss:0.143576\n",
      "Epoch [2/2], Iter [1008/3125], train_loss:0.143783\n",
      "Epoch [2/2], Iter [1009/3125], train_loss:0.143960\n",
      "Epoch [2/2], Iter [1010/3125], train_loss:0.144080\n",
      "Epoch [2/2], Iter [1011/3125], train_loss:0.143721\n",
      "Epoch [2/2], Iter [1012/3125], train_loss:0.143780\n",
      "Epoch [2/2], Iter [1013/3125], train_loss:0.144782\n",
      "Epoch [2/2], Iter [1014/3125], train_loss:0.143780\n",
      "Epoch [2/2], Iter [1015/3125], train_loss:0.143817\n",
      "Epoch [2/2], Iter [1016/3125], train_loss:0.144177\n",
      "Epoch [2/2], Iter [1017/3125], train_loss:0.143617\n",
      "Epoch [2/2], Iter [1018/3125], train_loss:0.144449\n",
      "Epoch [2/2], Iter [1019/3125], train_loss:0.145686\n",
      "Epoch [2/2], Iter [1020/3125], train_loss:0.145213\n",
      "Epoch [2/2], Iter [1021/3125], train_loss:0.141766\n",
      "Epoch [2/2], Iter [1022/3125], train_loss:0.145235\n",
      "Epoch [2/2], Iter [1023/3125], train_loss:0.143860\n",
      "Epoch [2/2], Iter [1024/3125], train_loss:0.144057\n",
      "Epoch [2/2], Iter [1025/3125], train_loss:0.144450\n",
      "Epoch [2/2], Iter [1026/3125], train_loss:0.142477\n",
      "Epoch [2/2], Iter [1027/3125], train_loss:0.144013\n",
      "Epoch [2/2], Iter [1028/3125], train_loss:0.144021\n",
      "Epoch [2/2], Iter [1029/3125], train_loss:0.144336\n",
      "Epoch [2/2], Iter [1030/3125], train_loss:0.146158\n",
      "Epoch [2/2], Iter [1031/3125], train_loss:0.143887\n",
      "Epoch [2/2], Iter [1032/3125], train_loss:0.143873\n",
      "Epoch [2/2], Iter [1033/3125], train_loss:0.145107\n",
      "Epoch [2/2], Iter [1034/3125], train_loss:0.143779\n",
      "Epoch [2/2], Iter [1035/3125], train_loss:0.142766\n",
      "Epoch [2/2], Iter [1036/3125], train_loss:0.144471\n",
      "Epoch [2/2], Iter [1037/3125], train_loss:0.143596\n",
      "Epoch [2/2], Iter [1038/3125], train_loss:0.145957\n",
      "Epoch [2/2], Iter [1039/3125], train_loss:0.143347\n",
      "Epoch [2/2], Iter [1040/3125], train_loss:0.143542\n",
      "Epoch [2/2], Iter [1041/3125], train_loss:0.143421\n",
      "Epoch [2/2], Iter [1042/3125], train_loss:0.143427\n",
      "Epoch [2/2], Iter [1043/3125], train_loss:0.144500\n",
      "Epoch [2/2], Iter [1044/3125], train_loss:0.144140\n",
      "Epoch [2/2], Iter [1045/3125], train_loss:0.143041\n",
      "Epoch [2/2], Iter [1046/3125], train_loss:0.143847\n",
      "Epoch [2/2], Iter [1047/3125], train_loss:0.144373\n",
      "Epoch [2/2], Iter [1048/3125], train_loss:0.144869\n",
      "Epoch [2/2], Iter [1049/3125], train_loss:0.144478\n",
      "Epoch [2/2], Iter [1050/3125], train_loss:0.144762\n",
      "Epoch [2/2], Iter [1051/3125], train_loss:0.143445\n",
      "Epoch [2/2], Iter [1052/3125], train_loss:0.144270\n",
      "Epoch [2/2], Iter [1053/3125], train_loss:0.144825\n",
      "Epoch [2/2], Iter [1054/3125], train_loss:0.144109\n",
      "Epoch [2/2], Iter [1055/3125], train_loss:0.143146\n",
      "Epoch [2/2], Iter [1056/3125], train_loss:0.143213\n",
      "Epoch [2/2], Iter [1057/3125], train_loss:0.144859\n",
      "Epoch [2/2], Iter [1058/3125], train_loss:0.143349\n",
      "Epoch [2/2], Iter [1059/3125], train_loss:0.143133\n",
      "Epoch [2/2], Iter [1060/3125], train_loss:0.143595\n",
      "Epoch [2/2], Iter [1061/3125], train_loss:0.145616\n",
      "Epoch [2/2], Iter [1062/3125], train_loss:0.143205\n",
      "Epoch [2/2], Iter [1063/3125], train_loss:0.143062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [1064/3125], train_loss:0.143045\n",
      "Epoch [2/2], Iter [1065/3125], train_loss:0.146569\n",
      "Epoch [2/2], Iter [1066/3125], train_loss:0.145604\n",
      "Epoch [2/2], Iter [1067/3125], train_loss:0.144625\n",
      "Epoch [2/2], Iter [1068/3125], train_loss:0.143025\n",
      "Epoch [2/2], Iter [1069/3125], train_loss:0.143737\n",
      "Epoch [2/2], Iter [1070/3125], train_loss:0.145351\n",
      "Epoch [2/2], Iter [1071/3125], train_loss:0.144250\n",
      "Epoch [2/2], Iter [1072/3125], train_loss:0.143552\n",
      "Epoch [2/2], Iter [1073/3125], train_loss:0.143157\n",
      "Epoch [2/2], Iter [1074/3125], train_loss:0.144244\n",
      "Epoch [2/2], Iter [1075/3125], train_loss:0.143400\n",
      "Epoch [2/2], Iter [1076/3125], train_loss:0.144469\n",
      "Epoch [2/2], Iter [1077/3125], train_loss:0.144852\n",
      "Epoch [2/2], Iter [1078/3125], train_loss:0.145474\n",
      "Epoch [2/2], Iter [1079/3125], train_loss:0.144307\n",
      "Epoch [2/2], Iter [1080/3125], train_loss:0.140464\n",
      "Epoch [2/2], Iter [1081/3125], train_loss:0.144020\n",
      "Epoch [2/2], Iter [1082/3125], train_loss:0.143939\n",
      "Epoch [2/2], Iter [1083/3125], train_loss:0.145024\n",
      "Epoch [2/2], Iter [1084/3125], train_loss:0.144160\n",
      "Epoch [2/2], Iter [1085/3125], train_loss:0.144110\n",
      "Epoch [2/2], Iter [1086/3125], train_loss:0.144451\n",
      "Epoch [2/2], Iter [1087/3125], train_loss:0.144270\n",
      "Epoch [2/2], Iter [1088/3125], train_loss:0.142694\n",
      "Epoch [2/2], Iter [1089/3125], train_loss:0.143431\n",
      "Epoch [2/2], Iter [1090/3125], train_loss:0.144271\n",
      "Epoch [2/2], Iter [1091/3125], train_loss:0.144283\n",
      "Epoch [2/2], Iter [1092/3125], train_loss:0.142714\n",
      "Epoch [2/2], Iter [1093/3125], train_loss:0.145125\n",
      "Epoch [2/2], Iter [1094/3125], train_loss:0.144752\n",
      "Epoch [2/2], Iter [1095/3125], train_loss:0.143940\n",
      "Epoch [2/2], Iter [1096/3125], train_loss:0.144835\n",
      "Epoch [2/2], Iter [1097/3125], train_loss:0.144163\n",
      "Epoch [2/2], Iter [1098/3125], train_loss:0.143951\n",
      "Epoch [2/2], Iter [1099/3125], train_loss:0.144525\n",
      "Epoch [2/2], Iter [1100/3125], train_loss:0.143184\n",
      "Epoch [2/2], Iter [1101/3125], train_loss:0.143421\n",
      "Epoch [2/2], Iter [1102/3125], train_loss:0.143188\n",
      "Epoch [2/2], Iter [1103/3125], train_loss:0.144350\n",
      "Epoch [2/2], Iter [1104/3125], train_loss:0.143698\n",
      "Epoch [2/2], Iter [1105/3125], train_loss:0.143619\n",
      "Epoch [2/2], Iter [1106/3125], train_loss:0.144381\n",
      "Epoch [2/2], Iter [1107/3125], train_loss:0.143402\n",
      "Epoch [2/2], Iter [1108/3125], train_loss:0.143067\n",
      "Epoch [2/2], Iter [1109/3125], train_loss:0.143487\n",
      "Epoch [2/2], Iter [1110/3125], train_loss:0.144852\n",
      "Epoch [2/2], Iter [1111/3125], train_loss:0.143008\n",
      "Epoch [2/2], Iter [1112/3125], train_loss:0.144438\n",
      "Epoch [2/2], Iter [1113/3125], train_loss:0.144850\n",
      "Epoch [2/2], Iter [1114/3125], train_loss:0.144670\n",
      "Epoch [2/2], Iter [1115/3125], train_loss:0.142198\n",
      "Epoch [2/2], Iter [1116/3125], train_loss:0.144608\n",
      "Epoch [2/2], Iter [1117/3125], train_loss:0.143666\n",
      "Epoch [2/2], Iter [1118/3125], train_loss:0.142855\n",
      "Epoch [2/2], Iter [1119/3125], train_loss:0.145352\n",
      "Epoch [2/2], Iter [1120/3125], train_loss:0.143657\n",
      "Epoch [2/2], Iter [1121/3125], train_loss:0.143576\n",
      "Epoch [2/2], Iter [1122/3125], train_loss:0.143392\n",
      "Epoch [2/2], Iter [1123/3125], train_loss:0.144627\n",
      "Epoch [2/2], Iter [1124/3125], train_loss:0.143726\n",
      "Epoch [2/2], Iter [1125/3125], train_loss:0.143910\n",
      "Epoch [2/2], Iter [1126/3125], train_loss:0.144333\n",
      "Epoch [2/2], Iter [1127/3125], train_loss:0.143680\n",
      "Epoch [2/2], Iter [1128/3125], train_loss:0.144527\n",
      "Epoch [2/2], Iter [1129/3125], train_loss:0.143622\n",
      "Epoch [2/2], Iter [1130/3125], train_loss:0.143464\n",
      "Epoch [2/2], Iter [1131/3125], train_loss:0.143297\n",
      "Epoch [2/2], Iter [1132/3125], train_loss:0.144031\n",
      "Epoch [2/2], Iter [1133/3125], train_loss:0.144371\n",
      "Epoch [2/2], Iter [1134/3125], train_loss:0.144738\n",
      "Epoch [2/2], Iter [1135/3125], train_loss:0.143272\n",
      "Epoch [2/2], Iter [1136/3125], train_loss:0.145885\n",
      "Epoch [2/2], Iter [1137/3125], train_loss:0.142756\n",
      "Epoch [2/2], Iter [1138/3125], train_loss:0.143760\n",
      "Epoch [2/2], Iter [1139/3125], train_loss:0.143883\n",
      "Epoch [2/2], Iter [1140/3125], train_loss:0.143024\n",
      "Epoch [2/2], Iter [1141/3125], train_loss:0.143664\n",
      "Epoch [2/2], Iter [1142/3125], train_loss:0.144673\n",
      "Epoch [2/2], Iter [1143/3125], train_loss:0.144699\n",
      "Epoch [2/2], Iter [1144/3125], train_loss:0.143573\n",
      "Epoch [2/2], Iter [1145/3125], train_loss:0.142644\n",
      "Epoch [2/2], Iter [1146/3125], train_loss:0.144378\n",
      "Epoch [2/2], Iter [1147/3125], train_loss:0.143995\n",
      "Epoch [2/2], Iter [1148/3125], train_loss:0.143567\n",
      "Epoch [2/2], Iter [1149/3125], train_loss:0.144108\n",
      "Epoch [2/2], Iter [1150/3125], train_loss:0.145801\n",
      "Epoch [2/2], Iter [1151/3125], train_loss:0.144333\n",
      "Epoch [2/2], Iter [1152/3125], train_loss:0.143444\n",
      "Epoch [2/2], Iter [1153/3125], train_loss:0.144656\n",
      "Epoch [2/2], Iter [1154/3125], train_loss:0.142272\n",
      "Epoch [2/2], Iter [1155/3125], train_loss:0.143761\n",
      "Epoch [2/2], Iter [1156/3125], train_loss:0.144362\n",
      "Epoch [2/2], Iter [1157/3125], train_loss:0.144099\n",
      "Epoch [2/2], Iter [1158/3125], train_loss:0.142645\n",
      "Epoch [2/2], Iter [1159/3125], train_loss:0.143214\n",
      "Epoch [2/2], Iter [1160/3125], train_loss:0.144676\n",
      "Epoch [2/2], Iter [1161/3125], train_loss:0.144431\n",
      "Epoch [2/2], Iter [1162/3125], train_loss:0.144604\n",
      "Epoch [2/2], Iter [1163/3125], train_loss:0.142910\n",
      "Epoch [2/2], Iter [1164/3125], train_loss:0.144232\n",
      "Epoch [2/2], Iter [1165/3125], train_loss:0.143682\n",
      "Epoch [2/2], Iter [1166/3125], train_loss:0.143886\n",
      "Epoch [2/2], Iter [1167/3125], train_loss:0.144619\n",
      "Epoch [2/2], Iter [1168/3125], train_loss:0.144848\n",
      "Epoch [2/2], Iter [1169/3125], train_loss:0.143901\n",
      "Epoch [2/2], Iter [1170/3125], train_loss:0.143976\n",
      "Epoch [2/2], Iter [1171/3125], train_loss:0.142220\n",
      "Epoch [2/2], Iter [1172/3125], train_loss:0.144058\n",
      "Epoch [2/2], Iter [1173/3125], train_loss:0.144155\n",
      "Epoch [2/2], Iter [1174/3125], train_loss:0.143692\n",
      "Epoch [2/2], Iter [1175/3125], train_loss:0.144054\n",
      "Epoch [2/2], Iter [1176/3125], train_loss:0.144151\n",
      "Epoch [2/2], Iter [1177/3125], train_loss:0.145446\n",
      "Epoch [2/2], Iter [1178/3125], train_loss:0.144557\n",
      "Epoch [2/2], Iter [1179/3125], train_loss:0.144299\n",
      "Epoch [2/2], Iter [1180/3125], train_loss:0.144260\n",
      "Epoch [2/2], Iter [1181/3125], train_loss:0.143512\n",
      "Epoch [2/2], Iter [1182/3125], train_loss:0.142922\n",
      "Epoch [2/2], Iter [1183/3125], train_loss:0.143153\n",
      "Epoch [2/2], Iter [1184/3125], train_loss:0.145165\n",
      "Epoch [2/2], Iter [1185/3125], train_loss:0.144162\n",
      "Epoch [2/2], Iter [1186/3125], train_loss:0.143602\n",
      "Epoch [2/2], Iter [1187/3125], train_loss:0.143957\n",
      "Epoch [2/2], Iter [1188/3125], train_loss:0.143368\n",
      "Epoch [2/2], Iter [1189/3125], train_loss:0.144678\n",
      "Epoch [2/2], Iter [1190/3125], train_loss:0.143795\n",
      "Epoch [2/2], Iter [1191/3125], train_loss:0.144031\n",
      "Epoch [2/2], Iter [1192/3125], train_loss:0.144546\n",
      "Epoch [2/2], Iter [1193/3125], train_loss:0.143669\n",
      "Epoch [2/2], Iter [1194/3125], train_loss:0.144071\n",
      "Epoch [2/2], Iter [1195/3125], train_loss:0.144071\n",
      "Epoch [2/2], Iter [1196/3125], train_loss:0.144860\n",
      "Epoch [2/2], Iter [1197/3125], train_loss:0.143157\n",
      "Epoch [2/2], Iter [1198/3125], train_loss:0.143769\n",
      "Epoch [2/2], Iter [1199/3125], train_loss:0.145062\n",
      "Epoch [2/2], Iter [1200/3125], train_loss:0.145164\n",
      "Epoch [2/2], Iter [1201/3125], train_loss:0.144138\n",
      "Epoch [2/2], Iter [1202/3125], train_loss:0.143191\n",
      "Epoch [2/2], Iter [1203/3125], train_loss:0.144360\n",
      "Epoch [2/2], Iter [1204/3125], train_loss:0.144559\n",
      "Epoch [2/2], Iter [1205/3125], train_loss:0.144149\n",
      "Epoch [2/2], Iter [1206/3125], train_loss:0.144673\n",
      "Epoch [2/2], Iter [1207/3125], train_loss:0.145474\n",
      "Epoch [2/2], Iter [1208/3125], train_loss:0.145475\n",
      "Epoch [2/2], Iter [1209/3125], train_loss:0.144956\n",
      "Epoch [2/2], Iter [1210/3125], train_loss:0.144823\n",
      "Epoch [2/2], Iter [1211/3125], train_loss:0.143778\n",
      "Epoch [2/2], Iter [1212/3125], train_loss:0.144050\n",
      "Epoch [2/2], Iter [1213/3125], train_loss:0.144715\n",
      "Epoch [2/2], Iter [1214/3125], train_loss:0.143988\n",
      "Epoch [2/2], Iter [1215/3125], train_loss:0.144010\n",
      "Epoch [2/2], Iter [1216/3125], train_loss:0.143207\n",
      "Epoch [2/2], Iter [1217/3125], train_loss:0.144755\n",
      "Epoch [2/2], Iter [1218/3125], train_loss:0.143676\n",
      "Epoch [2/2], Iter [1219/3125], train_loss:0.144578\n",
      "Epoch [2/2], Iter [1220/3125], train_loss:0.143535\n",
      "Epoch [2/2], Iter [1221/3125], train_loss:0.142160\n",
      "Epoch [2/2], Iter [1222/3125], train_loss:0.145188\n",
      "Epoch [2/2], Iter [1223/3125], train_loss:0.143241\n",
      "Epoch [2/2], Iter [1224/3125], train_loss:0.143976\n",
      "Epoch [2/2], Iter [1225/3125], train_loss:0.144194\n",
      "Epoch [2/2], Iter [1226/3125], train_loss:0.145142\n",
      "Epoch [2/2], Iter [1227/3125], train_loss:0.143563\n",
      "Epoch [2/2], Iter [1228/3125], train_loss:0.143161\n",
      "Epoch [2/2], Iter [1229/3125], train_loss:0.145480\n",
      "Epoch [2/2], Iter [1230/3125], train_loss:0.144564\n",
      "Epoch [2/2], Iter [1231/3125], train_loss:0.144323\n",
      "Epoch [2/2], Iter [1232/3125], train_loss:0.144664\n",
      "Epoch [2/2], Iter [1233/3125], train_loss:0.144850\n",
      "Epoch [2/2], Iter [1234/3125], train_loss:0.143488\n",
      "Epoch [2/2], Iter [1235/3125], train_loss:0.144086\n",
      "Epoch [2/2], Iter [1236/3125], train_loss:0.144653\n",
      "Epoch [2/2], Iter [1237/3125], train_loss:0.144709\n",
      "Epoch [2/2], Iter [1238/3125], train_loss:0.143278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [1239/3125], train_loss:0.144182\n",
      "Epoch [2/2], Iter [1240/3125], train_loss:0.143390\n",
      "Epoch [2/2], Iter [1241/3125], train_loss:0.143305\n",
      "Epoch [2/2], Iter [1242/3125], train_loss:0.143237\n",
      "Epoch [2/2], Iter [1243/3125], train_loss:0.143531\n",
      "Epoch [2/2], Iter [1244/3125], train_loss:0.144406\n",
      "Epoch [2/2], Iter [1245/3125], train_loss:0.143115\n",
      "Epoch [2/2], Iter [1246/3125], train_loss:0.142730\n",
      "Epoch [2/2], Iter [1247/3125], train_loss:0.143613\n",
      "Epoch [2/2], Iter [1248/3125], train_loss:0.143240\n",
      "Epoch [2/2], Iter [1249/3125], train_loss:0.143213\n",
      "Epoch [2/2], Iter [1250/3125], train_loss:0.144133\n",
      "Epoch [2/2], Iter [1251/3125], train_loss:0.143535\n",
      "Epoch [2/2], Iter [1252/3125], train_loss:0.143049\n",
      "Epoch [2/2], Iter [1253/3125], train_loss:0.143468\n",
      "Epoch [2/2], Iter [1254/3125], train_loss:0.144630\n",
      "Epoch [2/2], Iter [1255/3125], train_loss:0.144798\n",
      "Epoch [2/2], Iter [1256/3125], train_loss:0.144535\n",
      "Epoch [2/2], Iter [1257/3125], train_loss:0.142839\n",
      "Epoch [2/2], Iter [1258/3125], train_loss:0.144121\n",
      "Epoch [2/2], Iter [1259/3125], train_loss:0.144341\n",
      "Epoch [2/2], Iter [1260/3125], train_loss:0.144689\n",
      "Epoch [2/2], Iter [1261/3125], train_loss:0.143752\n",
      "Epoch [2/2], Iter [1262/3125], train_loss:0.144255\n",
      "Epoch [2/2], Iter [1263/3125], train_loss:0.143473\n",
      "Epoch [2/2], Iter [1264/3125], train_loss:0.143533\n",
      "Epoch [2/2], Iter [1265/3125], train_loss:0.143804\n",
      "Epoch [2/2], Iter [1266/3125], train_loss:0.144255\n",
      "Epoch [2/2], Iter [1267/3125], train_loss:0.144965\n",
      "Epoch [2/2], Iter [1268/3125], train_loss:0.142363\n",
      "Epoch [2/2], Iter [1269/3125], train_loss:0.144312\n",
      "Epoch [2/2], Iter [1270/3125], train_loss:0.144221\n",
      "Epoch [2/2], Iter [1271/3125], train_loss:0.144654\n",
      "Epoch [2/2], Iter [1272/3125], train_loss:0.144905\n",
      "Epoch [2/2], Iter [1273/3125], train_loss:0.143601\n",
      "Epoch [2/2], Iter [1274/3125], train_loss:0.143854\n",
      "Epoch [2/2], Iter [1275/3125], train_loss:0.143672\n",
      "Epoch [2/2], Iter [1276/3125], train_loss:0.144512\n",
      "Epoch [2/2], Iter [1277/3125], train_loss:0.144133\n",
      "Epoch [2/2], Iter [1278/3125], train_loss:0.144601\n",
      "Epoch [2/2], Iter [1279/3125], train_loss:0.144248\n",
      "Epoch [2/2], Iter [1280/3125], train_loss:0.144611\n",
      "Epoch [2/2], Iter [1281/3125], train_loss:0.143288\n",
      "Epoch [2/2], Iter [1282/3125], train_loss:0.144499\n",
      "Epoch [2/2], Iter [1283/3125], train_loss:0.141426\n",
      "Epoch [2/2], Iter [1284/3125], train_loss:0.142135\n",
      "Epoch [2/2], Iter [1285/3125], train_loss:0.144302\n",
      "Epoch [2/2], Iter [1286/3125], train_loss:0.144291\n",
      "Epoch [2/2], Iter [1287/3125], train_loss:0.143971\n",
      "Epoch [2/2], Iter [1288/3125], train_loss:0.142933\n",
      "Epoch [2/2], Iter [1289/3125], train_loss:0.144482\n",
      "Epoch [2/2], Iter [1290/3125], train_loss:0.143505\n",
      "Epoch [2/2], Iter [1291/3125], train_loss:0.143936\n",
      "Epoch [2/2], Iter [1292/3125], train_loss:0.144435\n",
      "Epoch [2/2], Iter [1293/3125], train_loss:0.144964\n",
      "Epoch [2/2], Iter [1294/3125], train_loss:0.144515\n",
      "Epoch [2/2], Iter [1295/3125], train_loss:0.144666\n",
      "Epoch [2/2], Iter [1296/3125], train_loss:0.143770\n",
      "Epoch [2/2], Iter [1297/3125], train_loss:0.142225\n",
      "Epoch [2/2], Iter [1298/3125], train_loss:0.144575\n",
      "Epoch [2/2], Iter [1299/3125], train_loss:0.144167\n",
      "Epoch [2/2], Iter [1300/3125], train_loss:0.145479\n",
      "Epoch [2/2], Iter [1301/3125], train_loss:0.143094\n",
      "Epoch [2/2], Iter [1302/3125], train_loss:0.141536\n",
      "Epoch [2/2], Iter [1303/3125], train_loss:0.143286\n",
      "Epoch [2/2], Iter [1304/3125], train_loss:0.144264\n",
      "Epoch [2/2], Iter [1305/3125], train_loss:0.143971\n",
      "Epoch [2/2], Iter [1306/3125], train_loss:0.144161\n",
      "Epoch [2/2], Iter [1307/3125], train_loss:0.145425\n",
      "Epoch [2/2], Iter [1308/3125], train_loss:0.143700\n",
      "Epoch [2/2], Iter [1309/3125], train_loss:0.143438\n",
      "Epoch [2/2], Iter [1310/3125], train_loss:0.144484\n",
      "Epoch [2/2], Iter [1311/3125], train_loss:0.143372\n",
      "Epoch [2/2], Iter [1312/3125], train_loss:0.146056\n",
      "Epoch [2/2], Iter [1313/3125], train_loss:0.145149\n",
      "Epoch [2/2], Iter [1314/3125], train_loss:0.143424\n",
      "Epoch [2/2], Iter [1315/3125], train_loss:0.143828\n",
      "Epoch [2/2], Iter [1316/3125], train_loss:0.143580\n",
      "Epoch [2/2], Iter [1317/3125], train_loss:0.142744\n",
      "Epoch [2/2], Iter [1318/3125], train_loss:0.146520\n",
      "Epoch [2/2], Iter [1319/3125], train_loss:0.144645\n",
      "Epoch [2/2], Iter [1320/3125], train_loss:0.143810\n",
      "Epoch [2/2], Iter [1321/3125], train_loss:0.145239\n",
      "Epoch [2/2], Iter [1322/3125], train_loss:0.144691\n",
      "Epoch [2/2], Iter [1323/3125], train_loss:0.144090\n",
      "Epoch [2/2], Iter [1324/3125], train_loss:0.145062\n",
      "Epoch [2/2], Iter [1325/3125], train_loss:0.144542\n",
      "Epoch [2/2], Iter [1326/3125], train_loss:0.144344\n",
      "Epoch [2/2], Iter [1327/3125], train_loss:0.143428\n",
      "Epoch [2/2], Iter [1328/3125], train_loss:0.143312\n",
      "Epoch [2/2], Iter [1329/3125], train_loss:0.143602\n",
      "Epoch [2/2], Iter [1330/3125], train_loss:0.143795\n",
      "Epoch [2/2], Iter [1331/3125], train_loss:0.145098\n",
      "Epoch [2/2], Iter [1332/3125], train_loss:0.144977\n",
      "Epoch [2/2], Iter [1333/3125], train_loss:0.144974\n",
      "Epoch [2/2], Iter [1334/3125], train_loss:0.142867\n",
      "Epoch [2/2], Iter [1335/3125], train_loss:0.143239\n",
      "Epoch [2/2], Iter [1336/3125], train_loss:0.142443\n",
      "Epoch [2/2], Iter [1337/3125], train_loss:0.144701\n",
      "Epoch [2/2], Iter [1338/3125], train_loss:0.142330\n",
      "Epoch [2/2], Iter [1339/3125], train_loss:0.144032\n",
      "Epoch [2/2], Iter [1340/3125], train_loss:0.143005\n",
      "Epoch [2/2], Iter [1341/3125], train_loss:0.144512\n",
      "Epoch [2/2], Iter [1342/3125], train_loss:0.143483\n",
      "Epoch [2/2], Iter [1343/3125], train_loss:0.144308\n",
      "Epoch [2/2], Iter [1344/3125], train_loss:0.144420\n",
      "Epoch [2/2], Iter [1345/3125], train_loss:0.144894\n",
      "Epoch [2/2], Iter [1346/3125], train_loss:0.143585\n",
      "Epoch [2/2], Iter [1347/3125], train_loss:0.143240\n",
      "Epoch [2/2], Iter [1348/3125], train_loss:0.142712\n",
      "Epoch [2/2], Iter [1349/3125], train_loss:0.144040\n",
      "Epoch [2/2], Iter [1350/3125], train_loss:0.144057\n",
      "Epoch [2/2], Iter [1351/3125], train_loss:0.144392\n",
      "Epoch [2/2], Iter [1352/3125], train_loss:0.144904\n",
      "Epoch [2/2], Iter [1353/3125], train_loss:0.143184\n",
      "Epoch [2/2], Iter [1354/3125], train_loss:0.143634\n",
      "Epoch [2/2], Iter [1355/3125], train_loss:0.143185\n",
      "Epoch [2/2], Iter [1356/3125], train_loss:0.144599\n",
      "Epoch [2/2], Iter [1357/3125], train_loss:0.143511\n",
      "Epoch [2/2], Iter [1358/3125], train_loss:0.145653\n",
      "Epoch [2/2], Iter [1359/3125], train_loss:0.143879\n",
      "Epoch [2/2], Iter [1360/3125], train_loss:0.145002\n",
      "Epoch [2/2], Iter [1361/3125], train_loss:0.143762\n",
      "Epoch [2/2], Iter [1362/3125], train_loss:0.143703\n",
      "Epoch [2/2], Iter [1363/3125], train_loss:0.146071\n",
      "Epoch [2/2], Iter [1364/3125], train_loss:0.144951\n",
      "Epoch [2/2], Iter [1365/3125], train_loss:0.144275\n",
      "Epoch [2/2], Iter [1366/3125], train_loss:0.144600\n",
      "Epoch [2/2], Iter [1367/3125], train_loss:0.144682\n",
      "Epoch [2/2], Iter [1368/3125], train_loss:0.144977\n",
      "Epoch [2/2], Iter [1369/3125], train_loss:0.143727\n",
      "Epoch [2/2], Iter [1370/3125], train_loss:0.143970\n",
      "Epoch [2/2], Iter [1371/3125], train_loss:0.142410\n",
      "Epoch [2/2], Iter [1372/3125], train_loss:0.143624\n",
      "Epoch [2/2], Iter [1373/3125], train_loss:0.143759\n",
      "Epoch [2/2], Iter [1374/3125], train_loss:0.143400\n",
      "Epoch [2/2], Iter [1375/3125], train_loss:0.143994\n",
      "Epoch [2/2], Iter [1376/3125], train_loss:0.144392\n",
      "Epoch [2/2], Iter [1377/3125], train_loss:0.144370\n",
      "Epoch [2/2], Iter [1378/3125], train_loss:0.144168\n",
      "Epoch [2/2], Iter [1379/3125], train_loss:0.144561\n",
      "Epoch [2/2], Iter [1380/3125], train_loss:0.144439\n",
      "Epoch [2/2], Iter [1381/3125], train_loss:0.143579\n",
      "Epoch [2/2], Iter [1382/3125], train_loss:0.143650\n",
      "Epoch [2/2], Iter [1383/3125], train_loss:0.143047\n",
      "Epoch [2/2], Iter [1384/3125], train_loss:0.143943\n",
      "Epoch [2/2], Iter [1385/3125], train_loss:0.143016\n",
      "Epoch [2/2], Iter [1386/3125], train_loss:0.143455\n",
      "Epoch [2/2], Iter [1387/3125], train_loss:0.143654\n",
      "Epoch [2/2], Iter [1388/3125], train_loss:0.144865\n",
      "Epoch [2/2], Iter [1389/3125], train_loss:0.144114\n",
      "Epoch [2/2], Iter [1390/3125], train_loss:0.143076\n",
      "Epoch [2/2], Iter [1391/3125], train_loss:0.144873\n",
      "Epoch [2/2], Iter [1392/3125], train_loss:0.143778\n",
      "Epoch [2/2], Iter [1393/3125], train_loss:0.144736\n",
      "Epoch [2/2], Iter [1394/3125], train_loss:0.144445\n",
      "Epoch [2/2], Iter [1395/3125], train_loss:0.143090\n",
      "Epoch [2/2], Iter [1396/3125], train_loss:0.144244\n",
      "Epoch [2/2], Iter [1397/3125], train_loss:0.143671\n",
      "Epoch [2/2], Iter [1398/3125], train_loss:0.142998\n",
      "Epoch [2/2], Iter [1399/3125], train_loss:0.142637\n",
      "Epoch [2/2], Iter [1400/3125], train_loss:0.142158\n",
      "Epoch [2/2], Iter [1401/3125], train_loss:0.143556\n",
      "Epoch [2/2], Iter [1402/3125], train_loss:0.144248\n",
      "Epoch [2/2], Iter [1403/3125], train_loss:0.145108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [1404/3125], train_loss:0.144224\n",
      "Epoch [2/2], Iter [1405/3125], train_loss:0.144076\n",
      "Epoch [2/2], Iter [1406/3125], train_loss:0.144493\n",
      "Epoch [2/2], Iter [1407/3125], train_loss:0.144611\n",
      "Epoch [2/2], Iter [1408/3125], train_loss:0.143476\n",
      "Epoch [2/2], Iter [1409/3125], train_loss:0.144010\n",
      "Epoch [2/2], Iter [1410/3125], train_loss:0.143999\n",
      "Epoch [2/2], Iter [1411/3125], train_loss:0.143238\n",
      "Epoch [2/2], Iter [1412/3125], train_loss:0.144882\n",
      "Epoch [2/2], Iter [1413/3125], train_loss:0.143426\n",
      "Epoch [2/2], Iter [1414/3125], train_loss:0.144926\n",
      "Epoch [2/2], Iter [1415/3125], train_loss:0.143962\n",
      "Epoch [2/2], Iter [1416/3125], train_loss:0.143496\n",
      "Epoch [2/2], Iter [1417/3125], train_loss:0.144390\n",
      "Epoch [2/2], Iter [1418/3125], train_loss:0.143774\n",
      "Epoch [2/2], Iter [1419/3125], train_loss:0.142988\n",
      "Epoch [2/2], Iter [1420/3125], train_loss:0.145371\n",
      "Epoch [2/2], Iter [1421/3125], train_loss:0.145207\n",
      "Epoch [2/2], Iter [1422/3125], train_loss:0.143282\n",
      "Epoch [2/2], Iter [1423/3125], train_loss:0.143822\n",
      "Epoch [2/2], Iter [1424/3125], train_loss:0.145006\n",
      "Epoch [2/2], Iter [1425/3125], train_loss:0.144167\n",
      "Epoch [2/2], Iter [1426/3125], train_loss:0.143448\n",
      "Epoch [2/2], Iter [1427/3125], train_loss:0.144182\n",
      "Epoch [2/2], Iter [1428/3125], train_loss:0.144478\n",
      "Epoch [2/2], Iter [1429/3125], train_loss:0.144654\n",
      "Epoch [2/2], Iter [1430/3125], train_loss:0.144624\n",
      "Epoch [2/2], Iter [1431/3125], train_loss:0.142541\n",
      "Epoch [2/2], Iter [1432/3125], train_loss:0.143123\n",
      "Epoch [2/2], Iter [1433/3125], train_loss:0.143962\n",
      "Epoch [2/2], Iter [1434/3125], train_loss:0.142532\n",
      "Epoch [2/2], Iter [1435/3125], train_loss:0.143867\n",
      "Epoch [2/2], Iter [1436/3125], train_loss:0.144505\n",
      "Epoch [2/2], Iter [1437/3125], train_loss:0.144881\n",
      "Epoch [2/2], Iter [1438/3125], train_loss:0.143580\n",
      "Epoch [2/2], Iter [1439/3125], train_loss:0.144980\n",
      "Epoch [2/2], Iter [1440/3125], train_loss:0.143051\n",
      "Epoch [2/2], Iter [1441/3125], train_loss:0.144043\n",
      "Epoch [2/2], Iter [1442/3125], train_loss:0.145192\n",
      "Epoch [2/2], Iter [1443/3125], train_loss:0.143308\n",
      "Epoch [2/2], Iter [1444/3125], train_loss:0.143645\n",
      "Epoch [2/2], Iter [1445/3125], train_loss:0.145108\n",
      "Epoch [2/2], Iter [1446/3125], train_loss:0.144424\n",
      "Epoch [2/2], Iter [1447/3125], train_loss:0.143163\n",
      "Epoch [2/2], Iter [1448/3125], train_loss:0.143986\n",
      "Epoch [2/2], Iter [1449/3125], train_loss:0.145225\n",
      "Epoch [2/2], Iter [1450/3125], train_loss:0.144762\n",
      "Epoch [2/2], Iter [1451/3125], train_loss:0.144455\n",
      "Epoch [2/2], Iter [1452/3125], train_loss:0.144518\n",
      "Epoch [2/2], Iter [1453/3125], train_loss:0.144894\n",
      "Epoch [2/2], Iter [1454/3125], train_loss:0.144123\n",
      "Epoch [2/2], Iter [1455/3125], train_loss:0.143015\n",
      "Epoch [2/2], Iter [1456/3125], train_loss:0.144820\n",
      "Epoch [2/2], Iter [1457/3125], train_loss:0.143410\n",
      "Epoch [2/2], Iter [1458/3125], train_loss:0.144632\n",
      "Epoch [2/2], Iter [1459/3125], train_loss:0.143141\n",
      "Epoch [2/2], Iter [1460/3125], train_loss:0.144972\n",
      "Epoch [2/2], Iter [1461/3125], train_loss:0.143225\n",
      "Epoch [2/2], Iter [1462/3125], train_loss:0.143958\n",
      "Epoch [2/2], Iter [1463/3125], train_loss:0.142512\n",
      "Epoch [2/2], Iter [1464/3125], train_loss:0.143411\n",
      "Epoch [2/2], Iter [1465/3125], train_loss:0.142847\n",
      "Epoch [2/2], Iter [1466/3125], train_loss:0.144018\n",
      "Epoch [2/2], Iter [1467/3125], train_loss:0.145072\n",
      "Epoch [2/2], Iter [1468/3125], train_loss:0.143092\n",
      "Epoch [2/2], Iter [1469/3125], train_loss:0.145660\n",
      "Epoch [2/2], Iter [1470/3125], train_loss:0.143690\n",
      "Epoch [2/2], Iter [1471/3125], train_loss:0.143059\n",
      "Epoch [2/2], Iter [1472/3125], train_loss:0.144111\n",
      "Epoch [2/2], Iter [1473/3125], train_loss:0.143230\n",
      "Epoch [2/2], Iter [1474/3125], train_loss:0.144964\n",
      "Epoch [2/2], Iter [1475/3125], train_loss:0.144935\n",
      "Epoch [2/2], Iter [1476/3125], train_loss:0.143775\n",
      "Epoch [2/2], Iter [1477/3125], train_loss:0.145583\n",
      "Epoch [2/2], Iter [1478/3125], train_loss:0.146360\n",
      "Epoch [2/2], Iter [1479/3125], train_loss:0.143343\n",
      "Epoch [2/2], Iter [1480/3125], train_loss:0.142667\n",
      "Epoch [2/2], Iter [1481/3125], train_loss:0.145049\n",
      "Epoch [2/2], Iter [1482/3125], train_loss:0.143740\n",
      "Epoch [2/2], Iter [1483/3125], train_loss:0.143041\n",
      "Epoch [2/2], Iter [1484/3125], train_loss:0.143718\n",
      "Epoch [2/2], Iter [1485/3125], train_loss:0.143261\n",
      "Epoch [2/2], Iter [1486/3125], train_loss:0.143784\n",
      "Epoch [2/2], Iter [1487/3125], train_loss:0.144107\n",
      "Epoch [2/2], Iter [1488/3125], train_loss:0.143838\n",
      "Epoch [2/2], Iter [1489/3125], train_loss:0.143429\n",
      "Epoch [2/2], Iter [1490/3125], train_loss:0.143870\n",
      "Epoch [2/2], Iter [1491/3125], train_loss:0.144620\n",
      "Epoch [2/2], Iter [1492/3125], train_loss:0.143092\n",
      "Epoch [2/2], Iter [1493/3125], train_loss:0.144625\n",
      "Epoch [2/2], Iter [1494/3125], train_loss:0.142957\n",
      "Epoch [2/2], Iter [1495/3125], train_loss:0.143762\n",
      "Epoch [2/2], Iter [1496/3125], train_loss:0.144969\n",
      "Epoch [2/2], Iter [1497/3125], train_loss:0.143529\n",
      "Epoch [2/2], Iter [1498/3125], train_loss:0.144395\n",
      "Epoch [2/2], Iter [1499/3125], train_loss:0.143522\n",
      "Epoch [2/2], Iter [1500/3125], train_loss:0.144052\n",
      "Epoch [2/2], Iter [1501/3125], train_loss:0.144351\n",
      "Epoch [2/2], Iter [1502/3125], train_loss:0.144342\n",
      "Epoch [2/2], Iter [1503/3125], train_loss:0.145258\n",
      "Epoch [2/2], Iter [1504/3125], train_loss:0.144768\n",
      "Epoch [2/2], Iter [1505/3125], train_loss:0.142788\n",
      "Epoch [2/2], Iter [1506/3125], train_loss:0.143232\n",
      "Epoch [2/2], Iter [1507/3125], train_loss:0.143706\n",
      "Epoch [2/2], Iter [1508/3125], train_loss:0.144717\n",
      "Epoch [2/2], Iter [1509/3125], train_loss:0.142298\n",
      "Epoch [2/2], Iter [1510/3125], train_loss:0.143473\n",
      "Epoch [2/2], Iter [1511/3125], train_loss:0.143566\n",
      "Epoch [2/2], Iter [1512/3125], train_loss:0.145061\n",
      "Epoch [2/2], Iter [1513/3125], train_loss:0.143717\n",
      "Epoch [2/2], Iter [1514/3125], train_loss:0.143789\n",
      "Epoch [2/2], Iter [1515/3125], train_loss:0.144153\n",
      "Epoch [2/2], Iter [1516/3125], train_loss:0.144010\n",
      "Epoch [2/2], Iter [1517/3125], train_loss:0.145339\n",
      "Epoch [2/2], Iter [1518/3125], train_loss:0.144790\n",
      "Epoch [2/2], Iter [1519/3125], train_loss:0.144613\n",
      "Epoch [2/2], Iter [1520/3125], train_loss:0.144458\n",
      "Epoch [2/2], Iter [1521/3125], train_loss:0.143617\n",
      "Epoch [2/2], Iter [1522/3125], train_loss:0.144393\n",
      "Epoch [2/2], Iter [1523/3125], train_loss:0.144923\n",
      "Epoch [2/2], Iter [1524/3125], train_loss:0.144086\n",
      "Epoch [2/2], Iter [1525/3125], train_loss:0.144168\n",
      "Epoch [2/2], Iter [1526/3125], train_loss:0.145591\n",
      "Epoch [2/2], Iter [1527/3125], train_loss:0.144592\n",
      "Epoch [2/2], Iter [1528/3125], train_loss:0.143333\n",
      "Epoch [2/2], Iter [1529/3125], train_loss:0.143921\n",
      "Epoch [2/2], Iter [1530/3125], train_loss:0.143867\n",
      "Epoch [2/2], Iter [1531/3125], train_loss:0.144897\n",
      "Epoch [2/2], Iter [1532/3125], train_loss:0.144512\n",
      "Epoch [2/2], Iter [1533/3125], train_loss:0.144396\n",
      "Epoch [2/2], Iter [1534/3125], train_loss:0.142820\n",
      "Epoch [2/2], Iter [1535/3125], train_loss:0.143814\n",
      "Epoch [2/2], Iter [1536/3125], train_loss:0.144077\n",
      "Epoch [2/2], Iter [1537/3125], train_loss:0.144587\n",
      "Epoch [2/2], Iter [1538/3125], train_loss:0.143372\n",
      "Epoch [2/2], Iter [1539/3125], train_loss:0.143143\n",
      "Epoch [2/2], Iter [1540/3125], train_loss:0.143894\n",
      "Epoch [2/2], Iter [1541/3125], train_loss:0.143649\n",
      "Epoch [2/2], Iter [1542/3125], train_loss:0.144446\n",
      "Epoch [2/2], Iter [1543/3125], train_loss:0.143698\n",
      "Epoch [2/2], Iter [1544/3125], train_loss:0.143678\n",
      "Epoch [2/2], Iter [1545/3125], train_loss:0.143362\n",
      "Epoch [2/2], Iter [1546/3125], train_loss:0.145480\n",
      "Epoch [2/2], Iter [1547/3125], train_loss:0.144887\n",
      "Epoch [2/2], Iter [1548/3125], train_loss:0.145609\n",
      "Epoch [2/2], Iter [1549/3125], train_loss:0.142282\n",
      "Epoch [2/2], Iter [1550/3125], train_loss:0.143851\n",
      "Epoch [2/2], Iter [1551/3125], train_loss:0.145323\n",
      "Epoch [2/2], Iter [1552/3125], train_loss:0.143295\n",
      "Epoch [2/2], Iter [1553/3125], train_loss:0.142548\n",
      "Epoch [2/2], Iter [1554/3125], train_loss:0.142854\n",
      "Epoch [2/2], Iter [1555/3125], train_loss:0.144956\n",
      "Epoch [2/2], Iter [1556/3125], train_loss:0.144172\n",
      "Epoch [2/2], Iter [1557/3125], train_loss:0.144124\n",
      "Epoch [2/2], Iter [1558/3125], train_loss:0.142860\n",
      "Epoch [2/2], Iter [1559/3125], train_loss:0.144293\n",
      "Epoch [2/2], Iter [1560/3125], train_loss:0.144333\n",
      "Epoch [2/2], Iter [1561/3125], train_loss:0.144925\n",
      "Epoch [2/2], Iter [1562/3125], train_loss:0.145640\n",
      "Epoch [2/2], Iter [1563/3125], train_loss:0.143875\n",
      "Epoch [2/2], Iter [1564/3125], train_loss:0.144529\n",
      "Epoch [2/2], Iter [1565/3125], train_loss:0.143827\n",
      "Epoch [2/2], Iter [1566/3125], train_loss:0.144849\n",
      "Epoch [2/2], Iter [1567/3125], train_loss:0.143590\n",
      "Epoch [2/2], Iter [1568/3125], train_loss:0.144417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [1569/3125], train_loss:0.145970\n",
      "Epoch [2/2], Iter [1570/3125], train_loss:0.144244\n",
      "Epoch [2/2], Iter [1571/3125], train_loss:0.143344\n",
      "Epoch [2/2], Iter [1572/3125], train_loss:0.142591\n",
      "Epoch [2/2], Iter [1573/3125], train_loss:0.143932\n",
      "Epoch [2/2], Iter [1574/3125], train_loss:0.144230\n",
      "Epoch [2/2], Iter [1575/3125], train_loss:0.144525\n",
      "Epoch [2/2], Iter [1576/3125], train_loss:0.144858\n",
      "Epoch [2/2], Iter [1577/3125], train_loss:0.144251\n",
      "Epoch [2/2], Iter [1578/3125], train_loss:0.142077\n",
      "Epoch [2/2], Iter [1579/3125], train_loss:0.144723\n",
      "Epoch [2/2], Iter [1580/3125], train_loss:0.145696\n",
      "Epoch [2/2], Iter [1581/3125], train_loss:0.143639\n",
      "Epoch [2/2], Iter [1582/3125], train_loss:0.144549\n",
      "Epoch [2/2], Iter [1583/3125], train_loss:0.143477\n",
      "Epoch [2/2], Iter [1584/3125], train_loss:0.143847\n",
      "Epoch [2/2], Iter [1585/3125], train_loss:0.145948\n",
      "Epoch [2/2], Iter [1586/3125], train_loss:0.144670\n",
      "Epoch [2/2], Iter [1587/3125], train_loss:0.143221\n",
      "Epoch [2/2], Iter [1588/3125], train_loss:0.143941\n",
      "Epoch [2/2], Iter [1589/3125], train_loss:0.141726\n",
      "Epoch [2/2], Iter [1590/3125], train_loss:0.144155\n",
      "Epoch [2/2], Iter [1591/3125], train_loss:0.144350\n",
      "Epoch [2/2], Iter [1592/3125], train_loss:0.143389\n",
      "Epoch [2/2], Iter [1593/3125], train_loss:0.143927\n",
      "Epoch [2/2], Iter [1594/3125], train_loss:0.144768\n",
      "Epoch [2/2], Iter [1595/3125], train_loss:0.144148\n",
      "Epoch [2/2], Iter [1596/3125], train_loss:0.144596\n",
      "Epoch [2/2], Iter [1597/3125], train_loss:0.146021\n",
      "Epoch [2/2], Iter [1598/3125], train_loss:0.142670\n",
      "Epoch [2/2], Iter [1599/3125], train_loss:0.143982\n",
      "Epoch [2/2], Iter [1600/3125], train_loss:0.145169\n",
      "Epoch [2/2], Iter [1601/3125], train_loss:0.144900\n",
      "Epoch [2/2], Iter [1602/3125], train_loss:0.145800\n",
      "Epoch [2/2], Iter [1603/3125], train_loss:0.143200\n",
      "Epoch [2/2], Iter [1604/3125], train_loss:0.143483\n",
      "Epoch [2/2], Iter [1605/3125], train_loss:0.144298\n",
      "Epoch [2/2], Iter [1606/3125], train_loss:0.143917\n",
      "Epoch [2/2], Iter [1607/3125], train_loss:0.143219\n",
      "Epoch [2/2], Iter [1608/3125], train_loss:0.142594\n",
      "Epoch [2/2], Iter [1609/3125], train_loss:0.144973\n",
      "Epoch [2/2], Iter [1610/3125], train_loss:0.144240\n",
      "Epoch [2/2], Iter [1611/3125], train_loss:0.143771\n",
      "Epoch [2/2], Iter [1612/3125], train_loss:0.145052\n",
      "Epoch [2/2], Iter [1613/3125], train_loss:0.143684\n",
      "Epoch [2/2], Iter [1614/3125], train_loss:0.145314\n",
      "Epoch [2/2], Iter [1615/3125], train_loss:0.143995\n",
      "Epoch [2/2], Iter [1616/3125], train_loss:0.143902\n",
      "Epoch [2/2], Iter [1617/3125], train_loss:0.143034\n",
      "Epoch [2/2], Iter [1618/3125], train_loss:0.143240\n",
      "Epoch [2/2], Iter [1619/3125], train_loss:0.142989\n",
      "Epoch [2/2], Iter [1620/3125], train_loss:0.144766\n",
      "Epoch [2/2], Iter [1621/3125], train_loss:0.144724\n",
      "Epoch [2/2], Iter [1622/3125], train_loss:0.143182\n",
      "Epoch [2/2], Iter [1623/3125], train_loss:0.143691\n",
      "Epoch [2/2], Iter [1624/3125], train_loss:0.143313\n",
      "Epoch [2/2], Iter [1625/3125], train_loss:0.144600\n",
      "Epoch [2/2], Iter [1626/3125], train_loss:0.144507\n",
      "Epoch [2/2], Iter [1627/3125], train_loss:0.144461\n",
      "Epoch [2/2], Iter [1628/3125], train_loss:0.144210\n",
      "Epoch [2/2], Iter [1629/3125], train_loss:0.145761\n",
      "Epoch [2/2], Iter [1630/3125], train_loss:0.144629\n",
      "Epoch [2/2], Iter [1631/3125], train_loss:0.142671\n",
      "Epoch [2/2], Iter [1632/3125], train_loss:0.142218\n",
      "Epoch [2/2], Iter [1633/3125], train_loss:0.142813\n",
      "Epoch [2/2], Iter [1634/3125], train_loss:0.144300\n",
      "Epoch [2/2], Iter [1635/3125], train_loss:0.143609\n",
      "Epoch [2/2], Iter [1636/3125], train_loss:0.144959\n",
      "Epoch [2/2], Iter [1637/3125], train_loss:0.144677\n",
      "Epoch [2/2], Iter [1638/3125], train_loss:0.142806\n",
      "Epoch [2/2], Iter [1639/3125], train_loss:0.144656\n",
      "Epoch [2/2], Iter [1640/3125], train_loss:0.144723\n",
      "Epoch [2/2], Iter [1641/3125], train_loss:0.143753\n",
      "Epoch [2/2], Iter [1642/3125], train_loss:0.143140\n",
      "Epoch [2/2], Iter [1643/3125], train_loss:0.144360\n",
      "Epoch [2/2], Iter [1644/3125], train_loss:0.144185\n",
      "Epoch [2/2], Iter [1645/3125], train_loss:0.143346\n",
      "Epoch [2/2], Iter [1646/3125], train_loss:0.144754\n",
      "Epoch [2/2], Iter [1647/3125], train_loss:0.145256\n",
      "Epoch [2/2], Iter [1648/3125], train_loss:0.143491\n",
      "Epoch [2/2], Iter [1649/3125], train_loss:0.143713\n",
      "Epoch [2/2], Iter [1650/3125], train_loss:0.143843\n",
      "Epoch [2/2], Iter [1651/3125], train_loss:0.143463\n",
      "Epoch [2/2], Iter [1652/3125], train_loss:0.144074\n",
      "Epoch [2/2], Iter [1653/3125], train_loss:0.142749\n",
      "Epoch [2/2], Iter [1654/3125], train_loss:0.143595\n",
      "Epoch [2/2], Iter [1655/3125], train_loss:0.143375\n",
      "Epoch [2/2], Iter [1656/3125], train_loss:0.144216\n",
      "Epoch [2/2], Iter [1657/3125], train_loss:0.143677\n",
      "Epoch [2/2], Iter [1658/3125], train_loss:0.145061\n",
      "Epoch [2/2], Iter [1659/3125], train_loss:0.144145\n",
      "Epoch [2/2], Iter [1660/3125], train_loss:0.144357\n",
      "Epoch [2/2], Iter [1661/3125], train_loss:0.143481\n",
      "Epoch [2/2], Iter [1662/3125], train_loss:0.142965\n",
      "Epoch [2/2], Iter [1663/3125], train_loss:0.140949\n",
      "Epoch [2/2], Iter [1664/3125], train_loss:0.144910\n",
      "Epoch [2/2], Iter [1665/3125], train_loss:0.145498\n",
      "Epoch [2/2], Iter [1666/3125], train_loss:0.143810\n",
      "Epoch [2/2], Iter [1667/3125], train_loss:0.143683\n",
      "Epoch [2/2], Iter [1668/3125], train_loss:0.143595\n",
      "Epoch [2/2], Iter [1669/3125], train_loss:0.143079\n",
      "Epoch [2/2], Iter [1670/3125], train_loss:0.142659\n",
      "Epoch [2/2], Iter [1671/3125], train_loss:0.143650\n",
      "Epoch [2/2], Iter [1672/3125], train_loss:0.144643\n",
      "Epoch [2/2], Iter [1673/3125], train_loss:0.144583\n",
      "Epoch [2/2], Iter [1674/3125], train_loss:0.144009\n",
      "Epoch [2/2], Iter [1675/3125], train_loss:0.143706\n",
      "Epoch [2/2], Iter [1676/3125], train_loss:0.144569\n",
      "Epoch [2/2], Iter [1677/3125], train_loss:0.145149\n",
      "Epoch [2/2], Iter [1678/3125], train_loss:0.144741\n",
      "Epoch [2/2], Iter [1679/3125], train_loss:0.143030\n",
      "Epoch [2/2], Iter [1680/3125], train_loss:0.143173\n",
      "Epoch [2/2], Iter [1681/3125], train_loss:0.144688\n",
      "Epoch [2/2], Iter [1682/3125], train_loss:0.144191\n",
      "Epoch [2/2], Iter [1683/3125], train_loss:0.144271\n",
      "Epoch [2/2], Iter [1684/3125], train_loss:0.144012\n",
      "Epoch [2/2], Iter [1685/3125], train_loss:0.142892\n",
      "Epoch [2/2], Iter [1686/3125], train_loss:0.143888\n",
      "Epoch [2/2], Iter [1687/3125], train_loss:0.145360\n",
      "Epoch [2/2], Iter [1688/3125], train_loss:0.144280\n",
      "Epoch [2/2], Iter [1689/3125], train_loss:0.143511\n",
      "Epoch [2/2], Iter [1690/3125], train_loss:0.144147\n",
      "Epoch [2/2], Iter [1691/3125], train_loss:0.144728\n",
      "Epoch [2/2], Iter [1692/3125], train_loss:0.142895\n",
      "Epoch [2/2], Iter [1693/3125], train_loss:0.144041\n",
      "Epoch [2/2], Iter [1694/3125], train_loss:0.143809\n",
      "Epoch [2/2], Iter [1695/3125], train_loss:0.144913\n",
      "Epoch [2/2], Iter [1696/3125], train_loss:0.143670\n",
      "Epoch [2/2], Iter [1697/3125], train_loss:0.142642\n",
      "Epoch [2/2], Iter [1698/3125], train_loss:0.142171\n",
      "Epoch [2/2], Iter [1699/3125], train_loss:0.142963\n",
      "Epoch [2/2], Iter [1700/3125], train_loss:0.145045\n",
      "Epoch [2/2], Iter [1701/3125], train_loss:0.142733\n",
      "Epoch [2/2], Iter [1702/3125], train_loss:0.145905\n",
      "Epoch [2/2], Iter [1703/3125], train_loss:0.142903\n",
      "Epoch [2/2], Iter [1704/3125], train_loss:0.143554\n",
      "Epoch [2/2], Iter [1705/3125], train_loss:0.143543\n",
      "Epoch [2/2], Iter [1706/3125], train_loss:0.143569\n",
      "Epoch [2/2], Iter [1707/3125], train_loss:0.142604\n",
      "Epoch [2/2], Iter [1708/3125], train_loss:0.145226\n",
      "Epoch [2/2], Iter [1709/3125], train_loss:0.143365\n",
      "Epoch [2/2], Iter [1710/3125], train_loss:0.145092\n",
      "Epoch [2/2], Iter [1711/3125], train_loss:0.144135\n",
      "Epoch [2/2], Iter [1712/3125], train_loss:0.144325\n",
      "Epoch [2/2], Iter [1713/3125], train_loss:0.144395\n",
      "Epoch [2/2], Iter [1714/3125], train_loss:0.144800\n",
      "Epoch [2/2], Iter [1715/3125], train_loss:0.144285\n",
      "Epoch [2/2], Iter [1716/3125], train_loss:0.145025\n",
      "Epoch [2/2], Iter [1717/3125], train_loss:0.144917\n",
      "Epoch [2/2], Iter [1718/3125], train_loss:0.142594\n",
      "Epoch [2/2], Iter [1719/3125], train_loss:0.144418\n",
      "Epoch [2/2], Iter [1720/3125], train_loss:0.144089\n",
      "Epoch [2/2], Iter [1721/3125], train_loss:0.143343\n",
      "Epoch [2/2], Iter [1722/3125], train_loss:0.146075\n",
      "Epoch [2/2], Iter [1723/3125], train_loss:0.144098\n",
      "Epoch [2/2], Iter [1724/3125], train_loss:0.142774\n",
      "Epoch [2/2], Iter [1725/3125], train_loss:0.143729\n",
      "Epoch [2/2], Iter [1726/3125], train_loss:0.144722\n",
      "Epoch [2/2], Iter [1727/3125], train_loss:0.143653\n",
      "Epoch [2/2], Iter [1728/3125], train_loss:0.145430\n",
      "Epoch [2/2], Iter [1729/3125], train_loss:0.144288\n",
      "Epoch [2/2], Iter [1730/3125], train_loss:0.144305\n",
      "Epoch [2/2], Iter [1731/3125], train_loss:0.143979\n",
      "Epoch [2/2], Iter [1732/3125], train_loss:0.143898\n",
      "Epoch [2/2], Iter [1733/3125], train_loss:0.143614\n",
      "Epoch [2/2], Iter [1734/3125], train_loss:0.144904\n",
      "Epoch [2/2], Iter [1735/3125], train_loss:0.142601\n",
      "Epoch [2/2], Iter [1736/3125], train_loss:0.142786\n",
      "Epoch [2/2], Iter [1737/3125], train_loss:0.143392\n",
      "Epoch [2/2], Iter [1738/3125], train_loss:0.144226\n",
      "Epoch [2/2], Iter [1739/3125], train_loss:0.142600\n",
      "Epoch [2/2], Iter [1740/3125], train_loss:0.145753\n",
      "Epoch [2/2], Iter [1741/3125], train_loss:0.143444\n",
      "Epoch [2/2], Iter [1742/3125], train_loss:0.144276\n",
      "Epoch [2/2], Iter [1743/3125], train_loss:0.144560\n",
      "Epoch [2/2], Iter [1744/3125], train_loss:0.144241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [1745/3125], train_loss:0.144294\n",
      "Epoch [2/2], Iter [1746/3125], train_loss:0.147011\n",
      "Epoch [2/2], Iter [1747/3125], train_loss:0.144049\n",
      "Epoch [2/2], Iter [1748/3125], train_loss:0.143922\n",
      "Epoch [2/2], Iter [1749/3125], train_loss:0.143436\n",
      "Epoch [2/2], Iter [1750/3125], train_loss:0.144973\n",
      "Epoch [2/2], Iter [1751/3125], train_loss:0.144619\n",
      "Epoch [2/2], Iter [1752/3125], train_loss:0.144191\n",
      "Epoch [2/2], Iter [1753/3125], train_loss:0.144302\n",
      "Epoch [2/2], Iter [1754/3125], train_loss:0.144738\n",
      "Epoch [2/2], Iter [1755/3125], train_loss:0.143002\n",
      "Epoch [2/2], Iter [1756/3125], train_loss:0.143834\n",
      "Epoch [2/2], Iter [1757/3125], train_loss:0.143469\n",
      "Epoch [2/2], Iter [1758/3125], train_loss:0.144034\n",
      "Epoch [2/2], Iter [1759/3125], train_loss:0.142793\n",
      "Epoch [2/2], Iter [1760/3125], train_loss:0.141467\n",
      "Epoch [2/2], Iter [1761/3125], train_loss:0.144870\n",
      "Epoch [2/2], Iter [1762/3125], train_loss:0.143171\n",
      "Epoch [2/2], Iter [1763/3125], train_loss:0.143685\n",
      "Epoch [2/2], Iter [1764/3125], train_loss:0.144183\n",
      "Epoch [2/2], Iter [1765/3125], train_loss:0.144289\n",
      "Epoch [2/2], Iter [1766/3125], train_loss:0.143621\n",
      "Epoch [2/2], Iter [1767/3125], train_loss:0.144246\n",
      "Epoch [2/2], Iter [1768/3125], train_loss:0.145193\n",
      "Epoch [2/2], Iter [1769/3125], train_loss:0.144656\n",
      "Epoch [2/2], Iter [1770/3125], train_loss:0.144475\n",
      "Epoch [2/2], Iter [1771/3125], train_loss:0.145120\n",
      "Epoch [2/2], Iter [1772/3125], train_loss:0.143828\n",
      "Epoch [2/2], Iter [1773/3125], train_loss:0.143670\n",
      "Epoch [2/2], Iter [1774/3125], train_loss:0.143777\n",
      "Epoch [2/2], Iter [1775/3125], train_loss:0.143214\n",
      "Epoch [2/2], Iter [1776/3125], train_loss:0.143906\n",
      "Epoch [2/2], Iter [1777/3125], train_loss:0.144846\n",
      "Epoch [2/2], Iter [1778/3125], train_loss:0.142436\n",
      "Epoch [2/2], Iter [1779/3125], train_loss:0.143395\n",
      "Epoch [2/2], Iter [1780/3125], train_loss:0.144661\n",
      "Epoch [2/2], Iter [1781/3125], train_loss:0.143419\n",
      "Epoch [2/2], Iter [1782/3125], train_loss:0.143105\n",
      "Epoch [2/2], Iter [1783/3125], train_loss:0.143792\n",
      "Epoch [2/2], Iter [1784/3125], train_loss:0.143663\n",
      "Epoch [2/2], Iter [1785/3125], train_loss:0.144105\n",
      "Epoch [2/2], Iter [1786/3125], train_loss:0.143944\n",
      "Epoch [2/2], Iter [1787/3125], train_loss:0.143312\n",
      "Epoch [2/2], Iter [1788/3125], train_loss:0.144241\n",
      "Epoch [2/2], Iter [1789/3125], train_loss:0.144535\n",
      "Epoch [2/2], Iter [1790/3125], train_loss:0.144604\n",
      "Epoch [2/2], Iter [1791/3125], train_loss:0.145777\n",
      "Epoch [2/2], Iter [1792/3125], train_loss:0.143929\n",
      "Epoch [2/2], Iter [1793/3125], train_loss:0.143975\n",
      "Epoch [2/2], Iter [1794/3125], train_loss:0.144485\n",
      "Epoch [2/2], Iter [1795/3125], train_loss:0.143039\n",
      "Epoch [2/2], Iter [1796/3125], train_loss:0.145047\n",
      "Epoch [2/2], Iter [1797/3125], train_loss:0.143836\n",
      "Epoch [2/2], Iter [1798/3125], train_loss:0.143774\n",
      "Epoch [2/2], Iter [1799/3125], train_loss:0.143190\n",
      "Epoch [2/2], Iter [1800/3125], train_loss:0.146021\n",
      "Epoch [2/2], Iter [1801/3125], train_loss:0.144339\n",
      "Epoch [2/2], Iter [1802/3125], train_loss:0.145313\n",
      "Epoch [2/2], Iter [1803/3125], train_loss:0.143605\n",
      "Epoch [2/2], Iter [1804/3125], train_loss:0.144443\n",
      "Epoch [2/2], Iter [1805/3125], train_loss:0.144673\n",
      "Epoch [2/2], Iter [1806/3125], train_loss:0.142808\n",
      "Epoch [2/2], Iter [1807/3125], train_loss:0.143502\n",
      "Epoch [2/2], Iter [1808/3125], train_loss:0.144679\n",
      "Epoch [2/2], Iter [1809/3125], train_loss:0.142384\n",
      "Epoch [2/2], Iter [1810/3125], train_loss:0.144275\n",
      "Epoch [2/2], Iter [1811/3125], train_loss:0.143812\n",
      "Epoch [2/2], Iter [1812/3125], train_loss:0.143853\n",
      "Epoch [2/2], Iter [1813/3125], train_loss:0.144061\n",
      "Epoch [2/2], Iter [1814/3125], train_loss:0.143389\n",
      "Epoch [2/2], Iter [1815/3125], train_loss:0.144237\n",
      "Epoch [2/2], Iter [1816/3125], train_loss:0.142822\n",
      "Epoch [2/2], Iter [1817/3125], train_loss:0.142862\n",
      "Epoch [2/2], Iter [1818/3125], train_loss:0.144373\n",
      "Epoch [2/2], Iter [1819/3125], train_loss:0.144545\n",
      "Epoch [2/2], Iter [1820/3125], train_loss:0.145337\n",
      "Epoch [2/2], Iter [1821/3125], train_loss:0.145013\n",
      "Epoch [2/2], Iter [1822/3125], train_loss:0.144136\n",
      "Epoch [2/2], Iter [1823/3125], train_loss:0.143575\n",
      "Epoch [2/2], Iter [1824/3125], train_loss:0.142543\n",
      "Epoch [2/2], Iter [1825/3125], train_loss:0.145931\n",
      "Epoch [2/2], Iter [1826/3125], train_loss:0.142817\n",
      "Epoch [2/2], Iter [1827/3125], train_loss:0.144611\n",
      "Epoch [2/2], Iter [1828/3125], train_loss:0.143725\n",
      "Epoch [2/2], Iter [1829/3125], train_loss:0.143339\n",
      "Epoch [2/2], Iter [1830/3125], train_loss:0.145793\n",
      "Epoch [2/2], Iter [1831/3125], train_loss:0.145594\n",
      "Epoch [2/2], Iter [1832/3125], train_loss:0.142882\n",
      "Epoch [2/2], Iter [1833/3125], train_loss:0.142571\n",
      "Epoch [2/2], Iter [1834/3125], train_loss:0.141873\n",
      "Epoch [2/2], Iter [1835/3125], train_loss:0.143355\n",
      "Epoch [2/2], Iter [1836/3125], train_loss:0.143486\n",
      "Epoch [2/2], Iter [1837/3125], train_loss:0.142957\n",
      "Epoch [2/2], Iter [1838/3125], train_loss:0.144629\n",
      "Epoch [2/2], Iter [1839/3125], train_loss:0.143120\n",
      "Epoch [2/2], Iter [1840/3125], train_loss:0.142994\n",
      "Epoch [2/2], Iter [1841/3125], train_loss:0.143001\n",
      "Epoch [2/2], Iter [1842/3125], train_loss:0.144429\n",
      "Epoch [2/2], Iter [1843/3125], train_loss:0.143984\n",
      "Epoch [2/2], Iter [1844/3125], train_loss:0.145033\n",
      "Epoch [2/2], Iter [1845/3125], train_loss:0.142981\n",
      "Epoch [2/2], Iter [1846/3125], train_loss:0.143791\n",
      "Epoch [2/2], Iter [1847/3125], train_loss:0.143854\n",
      "Epoch [2/2], Iter [1848/3125], train_loss:0.144744\n",
      "Epoch [2/2], Iter [1849/3125], train_loss:0.144888\n",
      "Epoch [2/2], Iter [1850/3125], train_loss:0.142504\n",
      "Epoch [2/2], Iter [1851/3125], train_loss:0.143558\n",
      "Epoch [2/2], Iter [1852/3125], train_loss:0.144247\n",
      "Epoch [2/2], Iter [1853/3125], train_loss:0.143418\n",
      "Epoch [2/2], Iter [1854/3125], train_loss:0.143178\n",
      "Epoch [2/2], Iter [1855/3125], train_loss:0.144778\n",
      "Epoch [2/2], Iter [1856/3125], train_loss:0.143147\n",
      "Epoch [2/2], Iter [1857/3125], train_loss:0.144465\n",
      "Epoch [2/2], Iter [1858/3125], train_loss:0.144383\n",
      "Epoch [2/2], Iter [1859/3125], train_loss:0.143474\n",
      "Epoch [2/2], Iter [1860/3125], train_loss:0.143580\n",
      "Epoch [2/2], Iter [1861/3125], train_loss:0.143511\n",
      "Epoch [2/2], Iter [1862/3125], train_loss:0.145334\n",
      "Epoch [2/2], Iter [1863/3125], train_loss:0.144813\n",
      "Epoch [2/2], Iter [1864/3125], train_loss:0.143570\n",
      "Epoch [2/2], Iter [1865/3125], train_loss:0.144367\n",
      "Epoch [2/2], Iter [1866/3125], train_loss:0.142533\n",
      "Epoch [2/2], Iter [1867/3125], train_loss:0.143180\n",
      "Epoch [2/2], Iter [1868/3125], train_loss:0.143788\n",
      "Epoch [2/2], Iter [1869/3125], train_loss:0.143076\n",
      "Epoch [2/2], Iter [1870/3125], train_loss:0.143247\n",
      "Epoch [2/2], Iter [1871/3125], train_loss:0.143606\n",
      "Epoch [2/2], Iter [1872/3125], train_loss:0.143348\n",
      "Epoch [2/2], Iter [1873/3125], train_loss:0.143839\n",
      "Epoch [2/2], Iter [1874/3125], train_loss:0.143273\n",
      "Epoch [2/2], Iter [1875/3125], train_loss:0.144698\n",
      "Epoch [2/2], Iter [1876/3125], train_loss:0.143382\n",
      "Epoch [2/2], Iter [1877/3125], train_loss:0.145090\n",
      "Epoch [2/2], Iter [1878/3125], train_loss:0.144422\n",
      "Epoch [2/2], Iter [1879/3125], train_loss:0.143689\n",
      "Epoch [2/2], Iter [1880/3125], train_loss:0.143566\n",
      "Epoch [2/2], Iter [1881/3125], train_loss:0.144025\n",
      "Epoch [2/2], Iter [1882/3125], train_loss:0.144836\n",
      "Epoch [2/2], Iter [1883/3125], train_loss:0.143785\n",
      "Epoch [2/2], Iter [1884/3125], train_loss:0.143019\n",
      "Epoch [2/2], Iter [1885/3125], train_loss:0.144741\n",
      "Epoch [2/2], Iter [1886/3125], train_loss:0.143245\n",
      "Epoch [2/2], Iter [1887/3125], train_loss:0.142849\n",
      "Epoch [2/2], Iter [1888/3125], train_loss:0.142892\n",
      "Epoch [2/2], Iter [1889/3125], train_loss:0.144177\n",
      "Epoch [2/2], Iter [1890/3125], train_loss:0.143776\n",
      "Epoch [2/2], Iter [1891/3125], train_loss:0.143469\n",
      "Epoch [2/2], Iter [1892/3125], train_loss:0.143111\n",
      "Epoch [2/2], Iter [1893/3125], train_loss:0.143234\n",
      "Epoch [2/2], Iter [1894/3125], train_loss:0.144358\n",
      "Epoch [2/2], Iter [1895/3125], train_loss:0.144230\n",
      "Epoch [2/2], Iter [1896/3125], train_loss:0.143980\n",
      "Epoch [2/2], Iter [1897/3125], train_loss:0.142479\n",
      "Epoch [2/2], Iter [1898/3125], train_loss:0.143477\n",
      "Epoch [2/2], Iter [1899/3125], train_loss:0.144065\n",
      "Epoch [2/2], Iter [1900/3125], train_loss:0.142980\n",
      "Epoch [2/2], Iter [1901/3125], train_loss:0.143388\n",
      "Epoch [2/2], Iter [1902/3125], train_loss:0.145161\n",
      "Epoch [2/2], Iter [1903/3125], train_loss:0.143670\n",
      "Epoch [2/2], Iter [1904/3125], train_loss:0.143928\n",
      "Epoch [2/2], Iter [1905/3125], train_loss:0.142772\n",
      "Epoch [2/2], Iter [1906/3125], train_loss:0.144642\n",
      "Epoch [2/2], Iter [1907/3125], train_loss:0.146789\n",
      "Epoch [2/2], Iter [1908/3125], train_loss:0.144160\n",
      "Epoch [2/2], Iter [1909/3125], train_loss:0.145816\n",
      "Epoch [2/2], Iter [1910/3125], train_loss:0.142449\n",
      "Epoch [2/2], Iter [1911/3125], train_loss:0.144959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [1912/3125], train_loss:0.143710\n",
      "Epoch [2/2], Iter [1913/3125], train_loss:0.143145\n",
      "Epoch [2/2], Iter [1914/3125], train_loss:0.144562\n",
      "Epoch [2/2], Iter [1915/3125], train_loss:0.144927\n",
      "Epoch [2/2], Iter [1916/3125], train_loss:0.143002\n",
      "Epoch [2/2], Iter [1917/3125], train_loss:0.142790\n",
      "Epoch [2/2], Iter [1918/3125], train_loss:0.144505\n",
      "Epoch [2/2], Iter [1919/3125], train_loss:0.143337\n",
      "Epoch [2/2], Iter [1920/3125], train_loss:0.143202\n",
      "Epoch [2/2], Iter [1921/3125], train_loss:0.144669\n",
      "Epoch [2/2], Iter [1922/3125], train_loss:0.144273\n",
      "Epoch [2/2], Iter [1923/3125], train_loss:0.143966\n",
      "Epoch [2/2], Iter [1924/3125], train_loss:0.144727\n",
      "Epoch [2/2], Iter [1925/3125], train_loss:0.143673\n",
      "Epoch [2/2], Iter [1926/3125], train_loss:0.145069\n",
      "Epoch [2/2], Iter [1927/3125], train_loss:0.142539\n",
      "Epoch [2/2], Iter [1928/3125], train_loss:0.144243\n",
      "Epoch [2/2], Iter [1929/3125], train_loss:0.143493\n",
      "Epoch [2/2], Iter [1930/3125], train_loss:0.142178\n",
      "Epoch [2/2], Iter [1931/3125], train_loss:0.143286\n",
      "Epoch [2/2], Iter [1932/3125], train_loss:0.143628\n",
      "Epoch [2/2], Iter [1933/3125], train_loss:0.143518\n",
      "Epoch [2/2], Iter [1934/3125], train_loss:0.143249\n",
      "Epoch [2/2], Iter [1935/3125], train_loss:0.142435\n",
      "Epoch [2/2], Iter [1936/3125], train_loss:0.145046\n",
      "Epoch [2/2], Iter [1937/3125], train_loss:0.143988\n",
      "Epoch [2/2], Iter [1938/3125], train_loss:0.143175\n",
      "Epoch [2/2], Iter [1939/3125], train_loss:0.143225\n",
      "Epoch [2/2], Iter [1940/3125], train_loss:0.143061\n",
      "Epoch [2/2], Iter [1941/3125], train_loss:0.141823\n",
      "Epoch [2/2], Iter [1942/3125], train_loss:0.143870\n",
      "Epoch [2/2], Iter [1943/3125], train_loss:0.144697\n",
      "Epoch [2/2], Iter [1944/3125], train_loss:0.144600\n",
      "Epoch [2/2], Iter [1945/3125], train_loss:0.143343\n",
      "Epoch [2/2], Iter [1946/3125], train_loss:0.143568\n",
      "Epoch [2/2], Iter [1947/3125], train_loss:0.143276\n",
      "Epoch [2/2], Iter [1948/3125], train_loss:0.143607\n",
      "Epoch [2/2], Iter [1949/3125], train_loss:0.143581\n",
      "Epoch [2/2], Iter [1950/3125], train_loss:0.143530\n",
      "Epoch [2/2], Iter [1951/3125], train_loss:0.143873\n",
      "Epoch [2/2], Iter [1952/3125], train_loss:0.144977\n",
      "Epoch [2/2], Iter [1953/3125], train_loss:0.142883\n",
      "Epoch [2/2], Iter [1954/3125], train_loss:0.141392\n",
      "Epoch [2/2], Iter [1955/3125], train_loss:0.144246\n",
      "Epoch [2/2], Iter [1956/3125], train_loss:0.145660\n",
      "Epoch [2/2], Iter [1957/3125], train_loss:0.144898\n",
      "Epoch [2/2], Iter [1958/3125], train_loss:0.144334\n",
      "Epoch [2/2], Iter [1959/3125], train_loss:0.144056\n",
      "Epoch [2/2], Iter [1960/3125], train_loss:0.145232\n",
      "Epoch [2/2], Iter [1961/3125], train_loss:0.144632\n",
      "Epoch [2/2], Iter [1962/3125], train_loss:0.145379\n",
      "Epoch [2/2], Iter [1963/3125], train_loss:0.144076\n",
      "Epoch [2/2], Iter [1964/3125], train_loss:0.143894\n",
      "Epoch [2/2], Iter [1965/3125], train_loss:0.144036\n",
      "Epoch [2/2], Iter [1966/3125], train_loss:0.143180\n",
      "Epoch [2/2], Iter [1967/3125], train_loss:0.142957\n",
      "Epoch [2/2], Iter [1968/3125], train_loss:0.143700\n",
      "Epoch [2/2], Iter [1969/3125], train_loss:0.142173\n",
      "Epoch [2/2], Iter [1970/3125], train_loss:0.144054\n",
      "Epoch [2/2], Iter [1971/3125], train_loss:0.143785\n",
      "Epoch [2/2], Iter [1972/3125], train_loss:0.144305\n",
      "Epoch [2/2], Iter [1973/3125], train_loss:0.144354\n",
      "Epoch [2/2], Iter [1974/3125], train_loss:0.144661\n",
      "Epoch [2/2], Iter [1975/3125], train_loss:0.145333\n",
      "Epoch [2/2], Iter [1976/3125], train_loss:0.143648\n",
      "Epoch [2/2], Iter [1977/3125], train_loss:0.143599\n",
      "Epoch [2/2], Iter [1978/3125], train_loss:0.142619\n",
      "Epoch [2/2], Iter [1979/3125], train_loss:0.142466\n",
      "Epoch [2/2], Iter [1980/3125], train_loss:0.144322\n",
      "Epoch [2/2], Iter [1981/3125], train_loss:0.143626\n",
      "Epoch [2/2], Iter [1982/3125], train_loss:0.142893\n",
      "Epoch [2/2], Iter [1983/3125], train_loss:0.143376\n",
      "Epoch [2/2], Iter [1984/3125], train_loss:0.145314\n",
      "Epoch [2/2], Iter [1985/3125], train_loss:0.143157\n",
      "Epoch [2/2], Iter [1986/3125], train_loss:0.143892\n",
      "Epoch [2/2], Iter [1987/3125], train_loss:0.143935\n",
      "Epoch [2/2], Iter [1988/3125], train_loss:0.142155\n",
      "Epoch [2/2], Iter [1989/3125], train_loss:0.143460\n",
      "Epoch [2/2], Iter [1990/3125], train_loss:0.144000\n",
      "Epoch [2/2], Iter [1991/3125], train_loss:0.143138\n",
      "Epoch [2/2], Iter [1992/3125], train_loss:0.143906\n",
      "Epoch [2/2], Iter [1993/3125], train_loss:0.143194\n",
      "Epoch [2/2], Iter [1994/3125], train_loss:0.143298\n",
      "Epoch [2/2], Iter [1995/3125], train_loss:0.143189\n",
      "Epoch [2/2], Iter [1996/3125], train_loss:0.144503\n",
      "Epoch [2/2], Iter [1997/3125], train_loss:0.144551\n",
      "Epoch [2/2], Iter [1998/3125], train_loss:0.143623\n",
      "Epoch [2/2], Iter [1999/3125], train_loss:0.141744\n",
      "Epoch [2/2], Iter [2000/3125], train_loss:0.143443\n",
      "Epoch [2/2], Iter [2001/3125], train_loss:0.144217\n",
      "Epoch [2/2], Iter [2002/3125], train_loss:0.143770\n",
      "Epoch [2/2], Iter [2003/3125], train_loss:0.143037\n",
      "Epoch [2/2], Iter [2004/3125], train_loss:0.143179\n",
      "Epoch [2/2], Iter [2005/3125], train_loss:0.143628\n",
      "Epoch [2/2], Iter [2006/3125], train_loss:0.144115\n",
      "Epoch [2/2], Iter [2007/3125], train_loss:0.143993\n",
      "Epoch [2/2], Iter [2008/3125], train_loss:0.144313\n",
      "Epoch [2/2], Iter [2009/3125], train_loss:0.142595\n",
      "Epoch [2/2], Iter [2010/3125], train_loss:0.145398\n",
      "Epoch [2/2], Iter [2011/3125], train_loss:0.143585\n",
      "Epoch [2/2], Iter [2012/3125], train_loss:0.145001\n",
      "Epoch [2/2], Iter [2013/3125], train_loss:0.144265\n",
      "Epoch [2/2], Iter [2014/3125], train_loss:0.141851\n",
      "Epoch [2/2], Iter [2015/3125], train_loss:0.144408\n",
      "Epoch [2/2], Iter [2016/3125], train_loss:0.144054\n",
      "Epoch [2/2], Iter [2017/3125], train_loss:0.145708\n",
      "Epoch [2/2], Iter [2018/3125], train_loss:0.142599\n",
      "Epoch [2/2], Iter [2019/3125], train_loss:0.143674\n",
      "Epoch [2/2], Iter [2020/3125], train_loss:0.145677\n",
      "Epoch [2/2], Iter [2021/3125], train_loss:0.144192\n",
      "Epoch [2/2], Iter [2022/3125], train_loss:0.143500\n",
      "Epoch [2/2], Iter [2023/3125], train_loss:0.143814\n",
      "Epoch [2/2], Iter [2024/3125], train_loss:0.145454\n",
      "Epoch [2/2], Iter [2025/3125], train_loss:0.144395\n",
      "Epoch [2/2], Iter [2026/3125], train_loss:0.145561\n",
      "Epoch [2/2], Iter [2027/3125], train_loss:0.143654\n",
      "Epoch [2/2], Iter [2028/3125], train_loss:0.143817\n",
      "Epoch [2/2], Iter [2029/3125], train_loss:0.143754\n",
      "Epoch [2/2], Iter [2030/3125], train_loss:0.144056\n",
      "Epoch [2/2], Iter [2031/3125], train_loss:0.143576\n",
      "Epoch [2/2], Iter [2032/3125], train_loss:0.145281\n",
      "Epoch [2/2], Iter [2033/3125], train_loss:0.144675\n",
      "Epoch [2/2], Iter [2034/3125], train_loss:0.142258\n",
      "Epoch [2/2], Iter [2035/3125], train_loss:0.142776\n",
      "Epoch [2/2], Iter [2036/3125], train_loss:0.142593\n",
      "Epoch [2/2], Iter [2037/3125], train_loss:0.144716\n",
      "Epoch [2/2], Iter [2038/3125], train_loss:0.142913\n",
      "Epoch [2/2], Iter [2039/3125], train_loss:0.143191\n",
      "Epoch [2/2], Iter [2040/3125], train_loss:0.144380\n",
      "Epoch [2/2], Iter [2041/3125], train_loss:0.144269\n",
      "Epoch [2/2], Iter [2042/3125], train_loss:0.143796\n",
      "Epoch [2/2], Iter [2043/3125], train_loss:0.142845\n",
      "Epoch [2/2], Iter [2044/3125], train_loss:0.143915\n",
      "Epoch [2/2], Iter [2045/3125], train_loss:0.142469\n",
      "Epoch [2/2], Iter [2046/3125], train_loss:0.143813\n",
      "Epoch [2/2], Iter [2047/3125], train_loss:0.144092\n",
      "Epoch [2/2], Iter [2048/3125], train_loss:0.145247\n",
      "Epoch [2/2], Iter [2049/3125], train_loss:0.144154\n",
      "Epoch [2/2], Iter [2050/3125], train_loss:0.144097\n",
      "Epoch [2/2], Iter [2051/3125], train_loss:0.145417\n",
      "Epoch [2/2], Iter [2052/3125], train_loss:0.144442\n",
      "Epoch [2/2], Iter [2053/3125], train_loss:0.144458\n",
      "Epoch [2/2], Iter [2054/3125], train_loss:0.142642\n",
      "Epoch [2/2], Iter [2055/3125], train_loss:0.144288\n",
      "Epoch [2/2], Iter [2056/3125], train_loss:0.144785\n",
      "Epoch [2/2], Iter [2057/3125], train_loss:0.144280\n",
      "Epoch [2/2], Iter [2058/3125], train_loss:0.143392\n",
      "Epoch [2/2], Iter [2059/3125], train_loss:0.143633\n",
      "Epoch [2/2], Iter [2060/3125], train_loss:0.143533\n",
      "Epoch [2/2], Iter [2061/3125], train_loss:0.142724\n",
      "Epoch [2/2], Iter [2062/3125], train_loss:0.143398\n",
      "Epoch [2/2], Iter [2063/3125], train_loss:0.141937\n",
      "Epoch [2/2], Iter [2064/3125], train_loss:0.146386\n",
      "Epoch [2/2], Iter [2065/3125], train_loss:0.143689\n",
      "Epoch [2/2], Iter [2066/3125], train_loss:0.144915\n",
      "Epoch [2/2], Iter [2067/3125], train_loss:0.143902\n",
      "Epoch [2/2], Iter [2068/3125], train_loss:0.143836\n",
      "Epoch [2/2], Iter [2069/3125], train_loss:0.144641\n",
      "Epoch [2/2], Iter [2070/3125], train_loss:0.144885\n",
      "Epoch [2/2], Iter [2071/3125], train_loss:0.142455\n",
      "Epoch [2/2], Iter [2072/3125], train_loss:0.145082\n",
      "Epoch [2/2], Iter [2073/3125], train_loss:0.143478\n",
      "Epoch [2/2], Iter [2074/3125], train_loss:0.142282\n",
      "Epoch [2/2], Iter [2075/3125], train_loss:0.144358\n",
      "Epoch [2/2], Iter [2076/3125], train_loss:0.144413\n",
      "Epoch [2/2], Iter [2077/3125], train_loss:0.141976\n",
      "Epoch [2/2], Iter [2078/3125], train_loss:0.143569\n",
      "Epoch [2/2], Iter [2079/3125], train_loss:0.143069\n",
      "Epoch [2/2], Iter [2080/3125], train_loss:0.143813\n",
      "Epoch [2/2], Iter [2081/3125], train_loss:0.143204\n",
      "Epoch [2/2], Iter [2082/3125], train_loss:0.144597\n",
      "Epoch [2/2], Iter [2083/3125], train_loss:0.142164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [2084/3125], train_loss:0.142986\n",
      "Epoch [2/2], Iter [2085/3125], train_loss:0.145435\n",
      "Epoch [2/2], Iter [2086/3125], train_loss:0.144279\n",
      "Epoch [2/2], Iter [2087/3125], train_loss:0.142707\n",
      "Epoch [2/2], Iter [2088/3125], train_loss:0.144029\n",
      "Epoch [2/2], Iter [2089/3125], train_loss:0.143849\n",
      "Epoch [2/2], Iter [2090/3125], train_loss:0.143174\n",
      "Epoch [2/2], Iter [2091/3125], train_loss:0.144878\n",
      "Epoch [2/2], Iter [2092/3125], train_loss:0.144295\n",
      "Epoch [2/2], Iter [2093/3125], train_loss:0.143926\n",
      "Epoch [2/2], Iter [2094/3125], train_loss:0.143205\n",
      "Epoch [2/2], Iter [2095/3125], train_loss:0.143756\n",
      "Epoch [2/2], Iter [2096/3125], train_loss:0.145025\n",
      "Epoch [2/2], Iter [2097/3125], train_loss:0.143542\n",
      "Epoch [2/2], Iter [2098/3125], train_loss:0.144891\n",
      "Epoch [2/2], Iter [2099/3125], train_loss:0.144579\n",
      "Epoch [2/2], Iter [2100/3125], train_loss:0.144199\n",
      "Epoch [2/2], Iter [2101/3125], train_loss:0.143553\n",
      "Epoch [2/2], Iter [2102/3125], train_loss:0.144253\n",
      "Epoch [2/2], Iter [2103/3125], train_loss:0.142801\n",
      "Epoch [2/2], Iter [2104/3125], train_loss:0.145148\n",
      "Epoch [2/2], Iter [2105/3125], train_loss:0.143120\n",
      "Epoch [2/2], Iter [2106/3125], train_loss:0.144509\n",
      "Epoch [2/2], Iter [2107/3125], train_loss:0.144546\n",
      "Epoch [2/2], Iter [2108/3125], train_loss:0.144700\n",
      "Epoch [2/2], Iter [2109/3125], train_loss:0.142751\n",
      "Epoch [2/2], Iter [2110/3125], train_loss:0.143733\n",
      "Epoch [2/2], Iter [2111/3125], train_loss:0.144205\n",
      "Epoch [2/2], Iter [2112/3125], train_loss:0.143943\n",
      "Epoch [2/2], Iter [2113/3125], train_loss:0.144607\n",
      "Epoch [2/2], Iter [2114/3125], train_loss:0.144479\n",
      "Epoch [2/2], Iter [2115/3125], train_loss:0.144543\n",
      "Epoch [2/2], Iter [2116/3125], train_loss:0.144202\n",
      "Epoch [2/2], Iter [2117/3125], train_loss:0.144710\n",
      "Epoch [2/2], Iter [2118/3125], train_loss:0.143742\n",
      "Epoch [2/2], Iter [2119/3125], train_loss:0.143010\n",
      "Epoch [2/2], Iter [2120/3125], train_loss:0.142891\n",
      "Epoch [2/2], Iter [2121/3125], train_loss:0.142637\n",
      "Epoch [2/2], Iter [2122/3125], train_loss:0.145938\n",
      "Epoch [2/2], Iter [2123/3125], train_loss:0.144707\n",
      "Epoch [2/2], Iter [2124/3125], train_loss:0.145039\n",
      "Epoch [2/2], Iter [2125/3125], train_loss:0.143045\n",
      "Epoch [2/2], Iter [2126/3125], train_loss:0.144765\n",
      "Epoch [2/2], Iter [2127/3125], train_loss:0.143857\n",
      "Epoch [2/2], Iter [2128/3125], train_loss:0.145931\n",
      "Epoch [2/2], Iter [2129/3125], train_loss:0.143868\n",
      "Epoch [2/2], Iter [2130/3125], train_loss:0.143914\n",
      "Epoch [2/2], Iter [2131/3125], train_loss:0.143403\n",
      "Epoch [2/2], Iter [2132/3125], train_loss:0.144710\n",
      "Epoch [2/2], Iter [2133/3125], train_loss:0.143081\n",
      "Epoch [2/2], Iter [2134/3125], train_loss:0.143237\n",
      "Epoch [2/2], Iter [2135/3125], train_loss:0.143371\n",
      "Epoch [2/2], Iter [2136/3125], train_loss:0.143309\n",
      "Epoch [2/2], Iter [2137/3125], train_loss:0.144645\n",
      "Epoch [2/2], Iter [2138/3125], train_loss:0.143924\n",
      "Epoch [2/2], Iter [2139/3125], train_loss:0.144020\n",
      "Epoch [2/2], Iter [2140/3125], train_loss:0.143444\n",
      "Epoch [2/2], Iter [2141/3125], train_loss:0.144704\n",
      "Epoch [2/2], Iter [2142/3125], train_loss:0.144555\n",
      "Epoch [2/2], Iter [2143/3125], train_loss:0.143897\n",
      "Epoch [2/2], Iter [2144/3125], train_loss:0.144816\n",
      "Epoch [2/2], Iter [2145/3125], train_loss:0.143228\n",
      "Epoch [2/2], Iter [2146/3125], train_loss:0.144852\n",
      "Epoch [2/2], Iter [2147/3125], train_loss:0.143970\n",
      "Epoch [2/2], Iter [2148/3125], train_loss:0.143922\n",
      "Epoch [2/2], Iter [2149/3125], train_loss:0.142973\n",
      "Epoch [2/2], Iter [2150/3125], train_loss:0.142869\n",
      "Epoch [2/2], Iter [2151/3125], train_loss:0.144569\n",
      "Epoch [2/2], Iter [2152/3125], train_loss:0.144135\n",
      "Epoch [2/2], Iter [2153/3125], train_loss:0.143709\n",
      "Epoch [2/2], Iter [2154/3125], train_loss:0.143231\n",
      "Epoch [2/2], Iter [2155/3125], train_loss:0.144033\n",
      "Epoch [2/2], Iter [2156/3125], train_loss:0.143800\n",
      "Epoch [2/2], Iter [2157/3125], train_loss:0.142335\n",
      "Epoch [2/2], Iter [2158/3125], train_loss:0.143829\n",
      "Epoch [2/2], Iter [2159/3125], train_loss:0.143795\n",
      "Epoch [2/2], Iter [2160/3125], train_loss:0.144572\n",
      "Epoch [2/2], Iter [2161/3125], train_loss:0.145309\n",
      "Epoch [2/2], Iter [2162/3125], train_loss:0.143869\n",
      "Epoch [2/2], Iter [2163/3125], train_loss:0.144020\n",
      "Epoch [2/2], Iter [2164/3125], train_loss:0.146067\n",
      "Epoch [2/2], Iter [2165/3125], train_loss:0.144176\n",
      "Epoch [2/2], Iter [2166/3125], train_loss:0.142907\n",
      "Epoch [2/2], Iter [2167/3125], train_loss:0.143700\n",
      "Epoch [2/2], Iter [2168/3125], train_loss:0.143070\n",
      "Epoch [2/2], Iter [2169/3125], train_loss:0.144742\n",
      "Epoch [2/2], Iter [2170/3125], train_loss:0.143639\n",
      "Epoch [2/2], Iter [2171/3125], train_loss:0.144585\n",
      "Epoch [2/2], Iter [2172/3125], train_loss:0.143827\n",
      "Epoch [2/2], Iter [2173/3125], train_loss:0.144718\n",
      "Epoch [2/2], Iter [2174/3125], train_loss:0.144009\n",
      "Epoch [2/2], Iter [2175/3125], train_loss:0.142810\n",
      "Epoch [2/2], Iter [2176/3125], train_loss:0.143629\n",
      "Epoch [2/2], Iter [2177/3125], train_loss:0.142941\n",
      "Epoch [2/2], Iter [2178/3125], train_loss:0.144095\n",
      "Epoch [2/2], Iter [2179/3125], train_loss:0.144581\n",
      "Epoch [2/2], Iter [2180/3125], train_loss:0.143965\n",
      "Epoch [2/2], Iter [2181/3125], train_loss:0.144846\n",
      "Epoch [2/2], Iter [2182/3125], train_loss:0.143931\n",
      "Epoch [2/2], Iter [2183/3125], train_loss:0.142009\n",
      "Epoch [2/2], Iter [2184/3125], train_loss:0.143682\n",
      "Epoch [2/2], Iter [2185/3125], train_loss:0.144866\n",
      "Epoch [2/2], Iter [2186/3125], train_loss:0.143285\n",
      "Epoch [2/2], Iter [2187/3125], train_loss:0.143980\n",
      "Epoch [2/2], Iter [2188/3125], train_loss:0.144817\n",
      "Epoch [2/2], Iter [2189/3125], train_loss:0.145019\n",
      "Epoch [2/2], Iter [2190/3125], train_loss:0.144999\n",
      "Epoch [2/2], Iter [2191/3125], train_loss:0.145081\n",
      "Epoch [2/2], Iter [2192/3125], train_loss:0.141944\n",
      "Epoch [2/2], Iter [2193/3125], train_loss:0.144687\n",
      "Epoch [2/2], Iter [2194/3125], train_loss:0.144231\n",
      "Epoch [2/2], Iter [2195/3125], train_loss:0.145550\n",
      "Epoch [2/2], Iter [2196/3125], train_loss:0.144428\n",
      "Epoch [2/2], Iter [2197/3125], train_loss:0.145807\n",
      "Epoch [2/2], Iter [2198/3125], train_loss:0.144364\n",
      "Epoch [2/2], Iter [2199/3125], train_loss:0.143291\n",
      "Epoch [2/2], Iter [2200/3125], train_loss:0.143534\n",
      "Epoch [2/2], Iter [2201/3125], train_loss:0.143455\n",
      "Epoch [2/2], Iter [2202/3125], train_loss:0.143904\n",
      "Epoch [2/2], Iter [2203/3125], train_loss:0.143328\n",
      "Epoch [2/2], Iter [2204/3125], train_loss:0.143064\n",
      "Epoch [2/2], Iter [2205/3125], train_loss:0.143851\n",
      "Epoch [2/2], Iter [2206/3125], train_loss:0.144323\n",
      "Epoch [2/2], Iter [2207/3125], train_loss:0.143660\n",
      "Epoch [2/2], Iter [2208/3125], train_loss:0.144082\n",
      "Epoch [2/2], Iter [2209/3125], train_loss:0.141660\n",
      "Epoch [2/2], Iter [2210/3125], train_loss:0.142067\n",
      "Epoch [2/2], Iter [2211/3125], train_loss:0.145217\n",
      "Epoch [2/2], Iter [2212/3125], train_loss:0.143930\n",
      "Epoch [2/2], Iter [2213/3125], train_loss:0.144479\n",
      "Epoch [2/2], Iter [2214/3125], train_loss:0.142971\n",
      "Epoch [2/2], Iter [2215/3125], train_loss:0.144440\n",
      "Epoch [2/2], Iter [2216/3125], train_loss:0.145585\n",
      "Epoch [2/2], Iter [2217/3125], train_loss:0.143695\n",
      "Epoch [2/2], Iter [2218/3125], train_loss:0.144657\n",
      "Epoch [2/2], Iter [2219/3125], train_loss:0.143759\n",
      "Epoch [2/2], Iter [2220/3125], train_loss:0.142972\n",
      "Epoch [2/2], Iter [2221/3125], train_loss:0.142991\n",
      "Epoch [2/2], Iter [2222/3125], train_loss:0.144310\n",
      "Epoch [2/2], Iter [2223/3125], train_loss:0.142637\n",
      "Epoch [2/2], Iter [2224/3125], train_loss:0.143736\n",
      "Epoch [2/2], Iter [2225/3125], train_loss:0.144026\n",
      "Epoch [2/2], Iter [2226/3125], train_loss:0.144579\n",
      "Epoch [2/2], Iter [2227/3125], train_loss:0.144426\n",
      "Epoch [2/2], Iter [2228/3125], train_loss:0.145196\n",
      "Epoch [2/2], Iter [2229/3125], train_loss:0.143174\n",
      "Epoch [2/2], Iter [2230/3125], train_loss:0.144385\n",
      "Epoch [2/2], Iter [2231/3125], train_loss:0.144645\n",
      "Epoch [2/2], Iter [2232/3125], train_loss:0.145466\n",
      "Epoch [2/2], Iter [2233/3125], train_loss:0.143701\n",
      "Epoch [2/2], Iter [2234/3125], train_loss:0.142670\n",
      "Epoch [2/2], Iter [2235/3125], train_loss:0.144093\n",
      "Epoch [2/2], Iter [2236/3125], train_loss:0.144230\n",
      "Epoch [2/2], Iter [2237/3125], train_loss:0.144075\n",
      "Epoch [2/2], Iter [2238/3125], train_loss:0.143467\n",
      "Epoch [2/2], Iter [2239/3125], train_loss:0.145725\n",
      "Epoch [2/2], Iter [2240/3125], train_loss:0.144279\n",
      "Epoch [2/2], Iter [2241/3125], train_loss:0.143253\n",
      "Epoch [2/2], Iter [2242/3125], train_loss:0.144957\n",
      "Epoch [2/2], Iter [2243/3125], train_loss:0.143138\n",
      "Epoch [2/2], Iter [2244/3125], train_loss:0.144682\n",
      "Epoch [2/2], Iter [2245/3125], train_loss:0.144299\n",
      "Epoch [2/2], Iter [2246/3125], train_loss:0.143897\n",
      "Epoch [2/2], Iter [2247/3125], train_loss:0.144694\n",
      "Epoch [2/2], Iter [2248/3125], train_loss:0.143510\n",
      "Epoch [2/2], Iter [2249/3125], train_loss:0.145111\n",
      "Epoch [2/2], Iter [2250/3125], train_loss:0.144044\n",
      "Epoch [2/2], Iter [2251/3125], train_loss:0.144510\n",
      "Epoch [2/2], Iter [2252/3125], train_loss:0.145036\n",
      "Epoch [2/2], Iter [2253/3125], train_loss:0.144101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [2254/3125], train_loss:0.143367\n",
      "Epoch [2/2], Iter [2255/3125], train_loss:0.143656\n",
      "Epoch [2/2], Iter [2256/3125], train_loss:0.144857\n",
      "Epoch [2/2], Iter [2257/3125], train_loss:0.143877\n",
      "Epoch [2/2], Iter [2258/3125], train_loss:0.144580\n",
      "Epoch [2/2], Iter [2259/3125], train_loss:0.142902\n",
      "Epoch [2/2], Iter [2260/3125], train_loss:0.143284\n",
      "Epoch [2/2], Iter [2261/3125], train_loss:0.144460\n",
      "Epoch [2/2], Iter [2262/3125], train_loss:0.144655\n",
      "Epoch [2/2], Iter [2263/3125], train_loss:0.143450\n",
      "Epoch [2/2], Iter [2264/3125], train_loss:0.143677\n",
      "Epoch [2/2], Iter [2265/3125], train_loss:0.142612\n",
      "Epoch [2/2], Iter [2266/3125], train_loss:0.145227\n",
      "Epoch [2/2], Iter [2267/3125], train_loss:0.145378\n",
      "Epoch [2/2], Iter [2268/3125], train_loss:0.143607\n",
      "Epoch [2/2], Iter [2269/3125], train_loss:0.144358\n",
      "Epoch [2/2], Iter [2270/3125], train_loss:0.143349\n",
      "Epoch [2/2], Iter [2271/3125], train_loss:0.144656\n",
      "Epoch [2/2], Iter [2272/3125], train_loss:0.145226\n",
      "Epoch [2/2], Iter [2273/3125], train_loss:0.144804\n",
      "Epoch [2/2], Iter [2274/3125], train_loss:0.143659\n",
      "Epoch [2/2], Iter [2275/3125], train_loss:0.142760\n",
      "Epoch [2/2], Iter [2276/3125], train_loss:0.143187\n",
      "Epoch [2/2], Iter [2277/3125], train_loss:0.142157\n",
      "Epoch [2/2], Iter [2278/3125], train_loss:0.143078\n",
      "Epoch [2/2], Iter [2279/3125], train_loss:0.144634\n",
      "Epoch [2/2], Iter [2280/3125], train_loss:0.143568\n",
      "Epoch [2/2], Iter [2281/3125], train_loss:0.145882\n",
      "Epoch [2/2], Iter [2282/3125], train_loss:0.143718\n",
      "Epoch [2/2], Iter [2283/3125], train_loss:0.142592\n",
      "Epoch [2/2], Iter [2284/3125], train_loss:0.144449\n",
      "Epoch [2/2], Iter [2285/3125], train_loss:0.144099\n",
      "Epoch [2/2], Iter [2286/3125], train_loss:0.142290\n",
      "Epoch [2/2], Iter [2287/3125], train_loss:0.143606\n",
      "Epoch [2/2], Iter [2288/3125], train_loss:0.144412\n",
      "Epoch [2/2], Iter [2289/3125], train_loss:0.143611\n",
      "Epoch [2/2], Iter [2290/3125], train_loss:0.144549\n",
      "Epoch [2/2], Iter [2291/3125], train_loss:0.144663\n",
      "Epoch [2/2], Iter [2292/3125], train_loss:0.145338\n",
      "Epoch [2/2], Iter [2293/3125], train_loss:0.144477\n",
      "Epoch [2/2], Iter [2294/3125], train_loss:0.144940\n",
      "Epoch [2/2], Iter [2295/3125], train_loss:0.144991\n",
      "Epoch [2/2], Iter [2296/3125], train_loss:0.143786\n",
      "Epoch [2/2], Iter [2297/3125], train_loss:0.145082\n",
      "Epoch [2/2], Iter [2298/3125], train_loss:0.144728\n",
      "Epoch [2/2], Iter [2299/3125], train_loss:0.142870\n",
      "Epoch [2/2], Iter [2300/3125], train_loss:0.144427\n",
      "Epoch [2/2], Iter [2301/3125], train_loss:0.145488\n",
      "Epoch [2/2], Iter [2302/3125], train_loss:0.144222\n",
      "Epoch [2/2], Iter [2303/3125], train_loss:0.143573\n",
      "Epoch [2/2], Iter [2304/3125], train_loss:0.143508\n",
      "Epoch [2/2], Iter [2305/3125], train_loss:0.143954\n",
      "Epoch [2/2], Iter [2306/3125], train_loss:0.144740\n",
      "Epoch [2/2], Iter [2307/3125], train_loss:0.144331\n",
      "Epoch [2/2], Iter [2308/3125], train_loss:0.144445\n",
      "Epoch [2/2], Iter [2309/3125], train_loss:0.144474\n",
      "Epoch [2/2], Iter [2310/3125], train_loss:0.144869\n",
      "Epoch [2/2], Iter [2311/3125], train_loss:0.143953\n",
      "Epoch [2/2], Iter [2312/3125], train_loss:0.143779\n",
      "Epoch [2/2], Iter [2313/3125], train_loss:0.143991\n",
      "Epoch [2/2], Iter [2314/3125], train_loss:0.144171\n",
      "Epoch [2/2], Iter [2315/3125], train_loss:0.145175\n",
      "Epoch [2/2], Iter [2316/3125], train_loss:0.144353\n",
      "Epoch [2/2], Iter [2317/3125], train_loss:0.144047\n",
      "Epoch [2/2], Iter [2318/3125], train_loss:0.144451\n",
      "Epoch [2/2], Iter [2319/3125], train_loss:0.143149\n",
      "Epoch [2/2], Iter [2320/3125], train_loss:0.143826\n",
      "Epoch [2/2], Iter [2321/3125], train_loss:0.143467\n",
      "Epoch [2/2], Iter [2322/3125], train_loss:0.143935\n",
      "Epoch [2/2], Iter [2323/3125], train_loss:0.144745\n",
      "Epoch [2/2], Iter [2324/3125], train_loss:0.144149\n",
      "Epoch [2/2], Iter [2325/3125], train_loss:0.144542\n",
      "Epoch [2/2], Iter [2326/3125], train_loss:0.145089\n",
      "Epoch [2/2], Iter [2327/3125], train_loss:0.144498\n",
      "Epoch [2/2], Iter [2328/3125], train_loss:0.144996\n",
      "Epoch [2/2], Iter [2329/3125], train_loss:0.145103\n",
      "Epoch [2/2], Iter [2330/3125], train_loss:0.143868\n",
      "Epoch [2/2], Iter [2331/3125], train_loss:0.144489\n",
      "Epoch [2/2], Iter [2332/3125], train_loss:0.143350\n",
      "Epoch [2/2], Iter [2333/3125], train_loss:0.143874\n",
      "Epoch [2/2], Iter [2334/3125], train_loss:0.142919\n",
      "Epoch [2/2], Iter [2335/3125], train_loss:0.144895\n",
      "Epoch [2/2], Iter [2336/3125], train_loss:0.144440\n",
      "Epoch [2/2], Iter [2337/3125], train_loss:0.144409\n",
      "Epoch [2/2], Iter [2338/3125], train_loss:0.143201\n",
      "Epoch [2/2], Iter [2339/3125], train_loss:0.144896\n",
      "Epoch [2/2], Iter [2340/3125], train_loss:0.144125\n",
      "Epoch [2/2], Iter [2341/3125], train_loss:0.144632\n",
      "Epoch [2/2], Iter [2342/3125], train_loss:0.143659\n",
      "Epoch [2/2], Iter [2343/3125], train_loss:0.144349\n",
      "Epoch [2/2], Iter [2344/3125], train_loss:0.143097\n",
      "Epoch [2/2], Iter [2345/3125], train_loss:0.142588\n",
      "Epoch [2/2], Iter [2346/3125], train_loss:0.143264\n",
      "Epoch [2/2], Iter [2347/3125], train_loss:0.143908\n",
      "Epoch [2/2], Iter [2348/3125], train_loss:0.145813\n",
      "Epoch [2/2], Iter [2349/3125], train_loss:0.143834\n",
      "Epoch [2/2], Iter [2350/3125], train_loss:0.143958\n",
      "Epoch [2/2], Iter [2351/3125], train_loss:0.143865\n",
      "Epoch [2/2], Iter [2352/3125], train_loss:0.145248\n",
      "Epoch [2/2], Iter [2353/3125], train_loss:0.142903\n",
      "Epoch [2/2], Iter [2354/3125], train_loss:0.145560\n",
      "Epoch [2/2], Iter [2355/3125], train_loss:0.143387\n",
      "Epoch [2/2], Iter [2356/3125], train_loss:0.143637\n",
      "Epoch [2/2], Iter [2357/3125], train_loss:0.143502\n",
      "Epoch [2/2], Iter [2358/3125], train_loss:0.144201\n",
      "Epoch [2/2], Iter [2359/3125], train_loss:0.144030\n",
      "Epoch [2/2], Iter [2360/3125], train_loss:0.143843\n",
      "Epoch [2/2], Iter [2361/3125], train_loss:0.143087\n",
      "Epoch [2/2], Iter [2362/3125], train_loss:0.145274\n",
      "Epoch [2/2], Iter [2363/3125], train_loss:0.144097\n",
      "Epoch [2/2], Iter [2364/3125], train_loss:0.144268\n",
      "Epoch [2/2], Iter [2365/3125], train_loss:0.144621\n",
      "Epoch [2/2], Iter [2366/3125], train_loss:0.145721\n",
      "Epoch [2/2], Iter [2367/3125], train_loss:0.144405\n",
      "Epoch [2/2], Iter [2368/3125], train_loss:0.142735\n",
      "Epoch [2/2], Iter [2369/3125], train_loss:0.144261\n",
      "Epoch [2/2], Iter [2370/3125], train_loss:0.144959\n",
      "Epoch [2/2], Iter [2371/3125], train_loss:0.142302\n",
      "Epoch [2/2], Iter [2372/3125], train_loss:0.142354\n",
      "Epoch [2/2], Iter [2373/3125], train_loss:0.144971\n",
      "Epoch [2/2], Iter [2374/3125], train_loss:0.144480\n",
      "Epoch [2/2], Iter [2375/3125], train_loss:0.145347\n",
      "Epoch [2/2], Iter [2376/3125], train_loss:0.144126\n",
      "Epoch [2/2], Iter [2377/3125], train_loss:0.144073\n",
      "Epoch [2/2], Iter [2378/3125], train_loss:0.143606\n",
      "Epoch [2/2], Iter [2379/3125], train_loss:0.144807\n",
      "Epoch [2/2], Iter [2380/3125], train_loss:0.142590\n",
      "Epoch [2/2], Iter [2381/3125], train_loss:0.143607\n",
      "Epoch [2/2], Iter [2382/3125], train_loss:0.142216\n",
      "Epoch [2/2], Iter [2383/3125], train_loss:0.144876\n",
      "Epoch [2/2], Iter [2384/3125], train_loss:0.143650\n",
      "Epoch [2/2], Iter [2385/3125], train_loss:0.143239\n",
      "Epoch [2/2], Iter [2386/3125], train_loss:0.142877\n",
      "Epoch [2/2], Iter [2387/3125], train_loss:0.143959\n",
      "Epoch [2/2], Iter [2388/3125], train_loss:0.142593\n",
      "Epoch [2/2], Iter [2389/3125], train_loss:0.142905\n",
      "Epoch [2/2], Iter [2390/3125], train_loss:0.143955\n",
      "Epoch [2/2], Iter [2391/3125], train_loss:0.143703\n",
      "Epoch [2/2], Iter [2392/3125], train_loss:0.144549\n",
      "Epoch [2/2], Iter [2393/3125], train_loss:0.142389\n",
      "Epoch [2/2], Iter [2394/3125], train_loss:0.143723\n",
      "Epoch [2/2], Iter [2395/3125], train_loss:0.144485\n",
      "Epoch [2/2], Iter [2396/3125], train_loss:0.143154\n",
      "Epoch [2/2], Iter [2397/3125], train_loss:0.142404\n",
      "Epoch [2/2], Iter [2398/3125], train_loss:0.143443\n",
      "Epoch [2/2], Iter [2399/3125], train_loss:0.143993\n",
      "Epoch [2/2], Iter [2400/3125], train_loss:0.145362\n",
      "Epoch [2/2], Iter [2401/3125], train_loss:0.143572\n",
      "Epoch [2/2], Iter [2402/3125], train_loss:0.144773\n",
      "Epoch [2/2], Iter [2403/3125], train_loss:0.144982\n",
      "Epoch [2/2], Iter [2404/3125], train_loss:0.144189\n",
      "Epoch [2/2], Iter [2405/3125], train_loss:0.145097\n",
      "Epoch [2/2], Iter [2406/3125], train_loss:0.142458\n",
      "Epoch [2/2], Iter [2407/3125], train_loss:0.144123\n",
      "Epoch [2/2], Iter [2408/3125], train_loss:0.143570\n",
      "Epoch [2/2], Iter [2409/3125], train_loss:0.143977\n",
      "Epoch [2/2], Iter [2410/3125], train_loss:0.143775\n",
      "Epoch [2/2], Iter [2411/3125], train_loss:0.144086\n",
      "Epoch [2/2], Iter [2412/3125], train_loss:0.143934\n",
      "Epoch [2/2], Iter [2413/3125], train_loss:0.142569\n",
      "Epoch [2/2], Iter [2414/3125], train_loss:0.143906\n",
      "Epoch [2/2], Iter [2415/3125], train_loss:0.144137\n",
      "Epoch [2/2], Iter [2416/3125], train_loss:0.144763\n",
      "Epoch [2/2], Iter [2417/3125], train_loss:0.142357\n",
      "Epoch [2/2], Iter [2418/3125], train_loss:0.144124\n",
      "Epoch [2/2], Iter [2419/3125], train_loss:0.145028\n",
      "Epoch [2/2], Iter [2420/3125], train_loss:0.143956\n",
      "Epoch [2/2], Iter [2421/3125], train_loss:0.144183\n",
      "Epoch [2/2], Iter [2422/3125], train_loss:0.144917\n",
      "Epoch [2/2], Iter [2423/3125], train_loss:0.145662\n",
      "Epoch [2/2], Iter [2424/3125], train_loss:0.143718\n",
      "Epoch [2/2], Iter [2425/3125], train_loss:0.144243\n",
      "Epoch [2/2], Iter [2426/3125], train_loss:0.143399\n",
      "Epoch [2/2], Iter [2427/3125], train_loss:0.143253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [2428/3125], train_loss:0.143786\n",
      "Epoch [2/2], Iter [2429/3125], train_loss:0.143678\n",
      "Epoch [2/2], Iter [2430/3125], train_loss:0.145007\n",
      "Epoch [2/2], Iter [2431/3125], train_loss:0.143509\n",
      "Epoch [2/2], Iter [2432/3125], train_loss:0.142896\n",
      "Epoch [2/2], Iter [2433/3125], train_loss:0.144657\n",
      "Epoch [2/2], Iter [2434/3125], train_loss:0.144977\n",
      "Epoch [2/2], Iter [2435/3125], train_loss:0.143149\n",
      "Epoch [2/2], Iter [2436/3125], train_loss:0.143983\n",
      "Epoch [2/2], Iter [2437/3125], train_loss:0.145426\n",
      "Epoch [2/2], Iter [2438/3125], train_loss:0.143099\n",
      "Epoch [2/2], Iter [2439/3125], train_loss:0.142941\n",
      "Epoch [2/2], Iter [2440/3125], train_loss:0.144217\n",
      "Epoch [2/2], Iter [2441/3125], train_loss:0.144029\n",
      "Epoch [2/2], Iter [2442/3125], train_loss:0.143203\n",
      "Epoch [2/2], Iter [2443/3125], train_loss:0.143934\n",
      "Epoch [2/2], Iter [2444/3125], train_loss:0.143677\n",
      "Epoch [2/2], Iter [2445/3125], train_loss:0.143183\n",
      "Epoch [2/2], Iter [2446/3125], train_loss:0.142921\n",
      "Epoch [2/2], Iter [2447/3125], train_loss:0.142833\n",
      "Epoch [2/2], Iter [2448/3125], train_loss:0.143297\n",
      "Epoch [2/2], Iter [2449/3125], train_loss:0.142691\n",
      "Epoch [2/2], Iter [2450/3125], train_loss:0.143324\n",
      "Epoch [2/2], Iter [2451/3125], train_loss:0.142923\n",
      "Epoch [2/2], Iter [2452/3125], train_loss:0.143174\n",
      "Epoch [2/2], Iter [2453/3125], train_loss:0.143733\n",
      "Epoch [2/2], Iter [2454/3125], train_loss:0.143393\n",
      "Epoch [2/2], Iter [2455/3125], train_loss:0.142499\n",
      "Epoch [2/2], Iter [2456/3125], train_loss:0.144318\n",
      "Epoch [2/2], Iter [2457/3125], train_loss:0.144801\n",
      "Epoch [2/2], Iter [2458/3125], train_loss:0.142444\n",
      "Epoch [2/2], Iter [2459/3125], train_loss:0.144774\n",
      "Epoch [2/2], Iter [2460/3125], train_loss:0.143614\n",
      "Epoch [2/2], Iter [2461/3125], train_loss:0.144424\n",
      "Epoch [2/2], Iter [2462/3125], train_loss:0.144264\n",
      "Epoch [2/2], Iter [2463/3125], train_loss:0.145145\n",
      "Epoch [2/2], Iter [2464/3125], train_loss:0.143424\n",
      "Epoch [2/2], Iter [2465/3125], train_loss:0.144898\n",
      "Epoch [2/2], Iter [2466/3125], train_loss:0.144302\n",
      "Epoch [2/2], Iter [2467/3125], train_loss:0.142954\n",
      "Epoch [2/2], Iter [2468/3125], train_loss:0.142309\n",
      "Epoch [2/2], Iter [2469/3125], train_loss:0.143899\n",
      "Epoch [2/2], Iter [2470/3125], train_loss:0.144543\n",
      "Epoch [2/2], Iter [2471/3125], train_loss:0.143813\n",
      "Epoch [2/2], Iter [2472/3125], train_loss:0.142858\n",
      "Epoch [2/2], Iter [2473/3125], train_loss:0.143873\n",
      "Epoch [2/2], Iter [2474/3125], train_loss:0.143924\n",
      "Epoch [2/2], Iter [2475/3125], train_loss:0.144660\n",
      "Epoch [2/2], Iter [2476/3125], train_loss:0.145363\n",
      "Epoch [2/2], Iter [2477/3125], train_loss:0.143406\n",
      "Epoch [2/2], Iter [2478/3125], train_loss:0.143804\n",
      "Epoch [2/2], Iter [2479/3125], train_loss:0.143565\n",
      "Epoch [2/2], Iter [2480/3125], train_loss:0.144751\n",
      "Epoch [2/2], Iter [2481/3125], train_loss:0.145873\n",
      "Epoch [2/2], Iter [2482/3125], train_loss:0.145524\n",
      "Epoch [2/2], Iter [2483/3125], train_loss:0.143698\n",
      "Epoch [2/2], Iter [2484/3125], train_loss:0.144506\n",
      "Epoch [2/2], Iter [2485/3125], train_loss:0.145167\n",
      "Epoch [2/2], Iter [2486/3125], train_loss:0.144761\n",
      "Epoch [2/2], Iter [2487/3125], train_loss:0.142630\n",
      "Epoch [2/2], Iter [2488/3125], train_loss:0.144422\n",
      "Epoch [2/2], Iter [2489/3125], train_loss:0.145254\n",
      "Epoch [2/2], Iter [2490/3125], train_loss:0.143716\n",
      "Epoch [2/2], Iter [2491/3125], train_loss:0.143713\n",
      "Epoch [2/2], Iter [2492/3125], train_loss:0.144301\n",
      "Epoch [2/2], Iter [2493/3125], train_loss:0.143569\n",
      "Epoch [2/2], Iter [2494/3125], train_loss:0.144284\n",
      "Epoch [2/2], Iter [2495/3125], train_loss:0.143723\n",
      "Epoch [2/2], Iter [2496/3125], train_loss:0.144073\n",
      "Epoch [2/2], Iter [2497/3125], train_loss:0.144391\n",
      "Epoch [2/2], Iter [2498/3125], train_loss:0.144560\n",
      "Epoch [2/2], Iter [2499/3125], train_loss:0.144345\n",
      "Epoch [2/2], Iter [2500/3125], train_loss:0.143863\n",
      "Epoch [2/2], Iter [2501/3125], train_loss:0.143853\n",
      "Epoch [2/2], Iter [2502/3125], train_loss:0.143527\n",
      "Epoch [2/2], Iter [2503/3125], train_loss:0.143956\n",
      "Epoch [2/2], Iter [2504/3125], train_loss:0.143408\n",
      "Epoch [2/2], Iter [2505/3125], train_loss:0.143890\n",
      "Epoch [2/2], Iter [2506/3125], train_loss:0.144171\n",
      "Epoch [2/2], Iter [2507/3125], train_loss:0.143764\n",
      "Epoch [2/2], Iter [2508/3125], train_loss:0.142924\n",
      "Epoch [2/2], Iter [2509/3125], train_loss:0.143631\n",
      "Epoch [2/2], Iter [2510/3125], train_loss:0.143783\n",
      "Epoch [2/2], Iter [2511/3125], train_loss:0.144315\n",
      "Epoch [2/2], Iter [2512/3125], train_loss:0.144409\n",
      "Epoch [2/2], Iter [2513/3125], train_loss:0.142731\n",
      "Epoch [2/2], Iter [2514/3125], train_loss:0.142139\n",
      "Epoch [2/2], Iter [2515/3125], train_loss:0.143639\n",
      "Epoch [2/2], Iter [2516/3125], train_loss:0.143730\n",
      "Epoch [2/2], Iter [2517/3125], train_loss:0.143806\n",
      "Epoch [2/2], Iter [2518/3125], train_loss:0.143131\n",
      "Epoch [2/2], Iter [2519/3125], train_loss:0.145565\n",
      "Epoch [2/2], Iter [2520/3125], train_loss:0.143488\n",
      "Epoch [2/2], Iter [2521/3125], train_loss:0.143310\n",
      "Epoch [2/2], Iter [2522/3125], train_loss:0.145334\n",
      "Epoch [2/2], Iter [2523/3125], train_loss:0.142504\n",
      "Epoch [2/2], Iter [2524/3125], train_loss:0.145166\n",
      "Epoch [2/2], Iter [2525/3125], train_loss:0.145414\n",
      "Epoch [2/2], Iter [2526/3125], train_loss:0.143506\n",
      "Epoch [2/2], Iter [2527/3125], train_loss:0.144008\n",
      "Epoch [2/2], Iter [2528/3125], train_loss:0.144002\n",
      "Epoch [2/2], Iter [2529/3125], train_loss:0.143958\n",
      "Epoch [2/2], Iter [2530/3125], train_loss:0.144255\n",
      "Epoch [2/2], Iter [2531/3125], train_loss:0.143726\n",
      "Epoch [2/2], Iter [2532/3125], train_loss:0.144191\n",
      "Epoch [2/2], Iter [2533/3125], train_loss:0.144404\n",
      "Epoch [2/2], Iter [2534/3125], train_loss:0.144897\n",
      "Epoch [2/2], Iter [2535/3125], train_loss:0.145457\n",
      "Epoch [2/2], Iter [2536/3125], train_loss:0.144169\n",
      "Epoch [2/2], Iter [2537/3125], train_loss:0.143679\n",
      "Epoch [2/2], Iter [2538/3125], train_loss:0.143467\n",
      "Epoch [2/2], Iter [2539/3125], train_loss:0.145044\n",
      "Epoch [2/2], Iter [2540/3125], train_loss:0.144788\n",
      "Epoch [2/2], Iter [2541/3125], train_loss:0.144915\n",
      "Epoch [2/2], Iter [2542/3125], train_loss:0.145001\n",
      "Epoch [2/2], Iter [2543/3125], train_loss:0.142430\n",
      "Epoch [2/2], Iter [2544/3125], train_loss:0.144315\n",
      "Epoch [2/2], Iter [2545/3125], train_loss:0.144152\n",
      "Epoch [2/2], Iter [2546/3125], train_loss:0.143252\n",
      "Epoch [2/2], Iter [2547/3125], train_loss:0.142558\n",
      "Epoch [2/2], Iter [2548/3125], train_loss:0.142750\n",
      "Epoch [2/2], Iter [2549/3125], train_loss:0.143672\n",
      "Epoch [2/2], Iter [2550/3125], train_loss:0.142909\n",
      "Epoch [2/2], Iter [2551/3125], train_loss:0.144024\n",
      "Epoch [2/2], Iter [2552/3125], train_loss:0.143333\n",
      "Epoch [2/2], Iter [2553/3125], train_loss:0.143146\n",
      "Epoch [2/2], Iter [2554/3125], train_loss:0.144683\n",
      "Epoch [2/2], Iter [2555/3125], train_loss:0.141342\n",
      "Epoch [2/2], Iter [2556/3125], train_loss:0.145508\n",
      "Epoch [2/2], Iter [2557/3125], train_loss:0.142983\n",
      "Epoch [2/2], Iter [2558/3125], train_loss:0.143911\n",
      "Epoch [2/2], Iter [2559/3125], train_loss:0.145043\n",
      "Epoch [2/2], Iter [2560/3125], train_loss:0.144314\n",
      "Epoch [2/2], Iter [2561/3125], train_loss:0.143582\n",
      "Epoch [2/2], Iter [2562/3125], train_loss:0.143734\n",
      "Epoch [2/2], Iter [2563/3125], train_loss:0.144559\n",
      "Epoch [2/2], Iter [2564/3125], train_loss:0.144222\n",
      "Epoch [2/2], Iter [2565/3125], train_loss:0.143617\n",
      "Epoch [2/2], Iter [2566/3125], train_loss:0.145698\n",
      "Epoch [2/2], Iter [2567/3125], train_loss:0.142734\n",
      "Epoch [2/2], Iter [2568/3125], train_loss:0.143191\n",
      "Epoch [2/2], Iter [2569/3125], train_loss:0.143741\n",
      "Epoch [2/2], Iter [2570/3125], train_loss:0.145360\n",
      "Epoch [2/2], Iter [2571/3125], train_loss:0.143696\n",
      "Epoch [2/2], Iter [2572/3125], train_loss:0.143713\n",
      "Epoch [2/2], Iter [2573/3125], train_loss:0.144214\n",
      "Epoch [2/2], Iter [2574/3125], train_loss:0.144293\n",
      "Epoch [2/2], Iter [2575/3125], train_loss:0.143878\n",
      "Epoch [2/2], Iter [2576/3125], train_loss:0.144945\n",
      "Epoch [2/2], Iter [2577/3125], train_loss:0.143234\n",
      "Epoch [2/2], Iter [2578/3125], train_loss:0.143173\n",
      "Epoch [2/2], Iter [2579/3125], train_loss:0.144268\n",
      "Epoch [2/2], Iter [2580/3125], train_loss:0.143051\n",
      "Epoch [2/2], Iter [2581/3125], train_loss:0.142470\n",
      "Epoch [2/2], Iter [2582/3125], train_loss:0.142976\n",
      "Epoch [2/2], Iter [2583/3125], train_loss:0.144189\n",
      "Epoch [2/2], Iter [2584/3125], train_loss:0.143918\n",
      "Epoch [2/2], Iter [2585/3125], train_loss:0.143635\n",
      "Epoch [2/2], Iter [2586/3125], train_loss:0.144248\n",
      "Epoch [2/2], Iter [2587/3125], train_loss:0.143650\n",
      "Epoch [2/2], Iter [2588/3125], train_loss:0.144601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [2589/3125], train_loss:0.145503\n",
      "Epoch [2/2], Iter [2590/3125], train_loss:0.145498\n",
      "Epoch [2/2], Iter [2591/3125], train_loss:0.143501\n",
      "Epoch [2/2], Iter [2592/3125], train_loss:0.143780\n",
      "Epoch [2/2], Iter [2593/3125], train_loss:0.143399\n",
      "Epoch [2/2], Iter [2594/3125], train_loss:0.144164\n",
      "Epoch [2/2], Iter [2595/3125], train_loss:0.144976\n",
      "Epoch [2/2], Iter [2596/3125], train_loss:0.141807\n",
      "Epoch [2/2], Iter [2597/3125], train_loss:0.143069\n",
      "Epoch [2/2], Iter [2598/3125], train_loss:0.144576\n",
      "Epoch [2/2], Iter [2599/3125], train_loss:0.142891\n",
      "Epoch [2/2], Iter [2600/3125], train_loss:0.144699\n",
      "Epoch [2/2], Iter [2601/3125], train_loss:0.145018\n",
      "Epoch [2/2], Iter [2602/3125], train_loss:0.143250\n",
      "Epoch [2/2], Iter [2603/3125], train_loss:0.145304\n",
      "Epoch [2/2], Iter [2604/3125], train_loss:0.145309\n",
      "Epoch [2/2], Iter [2605/3125], train_loss:0.143330\n",
      "Epoch [2/2], Iter [2606/3125], train_loss:0.144615\n",
      "Epoch [2/2], Iter [2607/3125], train_loss:0.143880\n",
      "Epoch [2/2], Iter [2608/3125], train_loss:0.144727\n",
      "Epoch [2/2], Iter [2609/3125], train_loss:0.143941\n",
      "Epoch [2/2], Iter [2610/3125], train_loss:0.145917\n",
      "Epoch [2/2], Iter [2611/3125], train_loss:0.143412\n",
      "Epoch [2/2], Iter [2612/3125], train_loss:0.144002\n",
      "Epoch [2/2], Iter [2613/3125], train_loss:0.143999\n",
      "Epoch [2/2], Iter [2614/3125], train_loss:0.144451\n",
      "Epoch [2/2], Iter [2615/3125], train_loss:0.143472\n",
      "Epoch [2/2], Iter [2616/3125], train_loss:0.143986\n",
      "Epoch [2/2], Iter [2617/3125], train_loss:0.143610\n",
      "Epoch [2/2], Iter [2618/3125], train_loss:0.142022\n",
      "Epoch [2/2], Iter [2619/3125], train_loss:0.144573\n",
      "Epoch [2/2], Iter [2620/3125], train_loss:0.142853\n",
      "Epoch [2/2], Iter [2621/3125], train_loss:0.143647\n",
      "Epoch [2/2], Iter [2622/3125], train_loss:0.144557\n",
      "Epoch [2/2], Iter [2623/3125], train_loss:0.143086\n",
      "Epoch [2/2], Iter [2624/3125], train_loss:0.143519\n",
      "Epoch [2/2], Iter [2625/3125], train_loss:0.144618\n",
      "Epoch [2/2], Iter [2626/3125], train_loss:0.144308\n",
      "Epoch [2/2], Iter [2627/3125], train_loss:0.144449\n",
      "Epoch [2/2], Iter [2628/3125], train_loss:0.144138\n",
      "Epoch [2/2], Iter [2629/3125], train_loss:0.144282\n",
      "Epoch [2/2], Iter [2630/3125], train_loss:0.143200\n",
      "Epoch [2/2], Iter [2631/3125], train_loss:0.144256\n",
      "Epoch [2/2], Iter [2632/3125], train_loss:0.143565\n",
      "Epoch [2/2], Iter [2633/3125], train_loss:0.145340\n",
      "Epoch [2/2], Iter [2634/3125], train_loss:0.145085\n",
      "Epoch [2/2], Iter [2635/3125], train_loss:0.144876\n",
      "Epoch [2/2], Iter [2636/3125], train_loss:0.145008\n",
      "Epoch [2/2], Iter [2637/3125], train_loss:0.142134\n",
      "Epoch [2/2], Iter [2638/3125], train_loss:0.143878\n",
      "Epoch [2/2], Iter [2639/3125], train_loss:0.144203\n",
      "Epoch [2/2], Iter [2640/3125], train_loss:0.143035\n",
      "Epoch [2/2], Iter [2641/3125], train_loss:0.143685\n",
      "Epoch [2/2], Iter [2642/3125], train_loss:0.144459\n",
      "Epoch [2/2], Iter [2643/3125], train_loss:0.144398\n",
      "Epoch [2/2], Iter [2644/3125], train_loss:0.145091\n",
      "Epoch [2/2], Iter [2645/3125], train_loss:0.143971\n",
      "Epoch [2/2], Iter [2646/3125], train_loss:0.143874\n",
      "Epoch [2/2], Iter [2647/3125], train_loss:0.144741\n",
      "Epoch [2/2], Iter [2648/3125], train_loss:0.144404\n",
      "Epoch [2/2], Iter [2649/3125], train_loss:0.143375\n",
      "Epoch [2/2], Iter [2650/3125], train_loss:0.144617\n",
      "Epoch [2/2], Iter [2651/3125], train_loss:0.143806\n",
      "Epoch [2/2], Iter [2652/3125], train_loss:0.144034\n",
      "Epoch [2/2], Iter [2653/3125], train_loss:0.143843\n",
      "Epoch [2/2], Iter [2654/3125], train_loss:0.142692\n",
      "Epoch [2/2], Iter [2655/3125], train_loss:0.143222\n",
      "Epoch [2/2], Iter [2656/3125], train_loss:0.145206\n",
      "Epoch [2/2], Iter [2657/3125], train_loss:0.145512\n",
      "Epoch [2/2], Iter [2658/3125], train_loss:0.143711\n",
      "Epoch [2/2], Iter [2659/3125], train_loss:0.144955\n",
      "Epoch [2/2], Iter [2660/3125], train_loss:0.144315\n",
      "Epoch [2/2], Iter [2661/3125], train_loss:0.144256\n",
      "Epoch [2/2], Iter [2662/3125], train_loss:0.143601\n",
      "Epoch [2/2], Iter [2663/3125], train_loss:0.143666\n",
      "Epoch [2/2], Iter [2664/3125], train_loss:0.143908\n",
      "Epoch [2/2], Iter [2665/3125], train_loss:0.142114\n",
      "Epoch [2/2], Iter [2666/3125], train_loss:0.142947\n",
      "Epoch [2/2], Iter [2667/3125], train_loss:0.145146\n",
      "Epoch [2/2], Iter [2668/3125], train_loss:0.143745\n",
      "Epoch [2/2], Iter [2669/3125], train_loss:0.143548\n",
      "Epoch [2/2], Iter [2670/3125], train_loss:0.142585\n",
      "Epoch [2/2], Iter [2671/3125], train_loss:0.143853\n",
      "Epoch [2/2], Iter [2672/3125], train_loss:0.145082\n",
      "Epoch [2/2], Iter [2673/3125], train_loss:0.144757\n",
      "Epoch [2/2], Iter [2674/3125], train_loss:0.143737\n",
      "Epoch [2/2], Iter [2675/3125], train_loss:0.142948\n",
      "Epoch [2/2], Iter [2676/3125], train_loss:0.144497\n",
      "Epoch [2/2], Iter [2677/3125], train_loss:0.144008\n",
      "Epoch [2/2], Iter [2678/3125], train_loss:0.144244\n",
      "Epoch [2/2], Iter [2679/3125], train_loss:0.144097\n",
      "Epoch [2/2], Iter [2680/3125], train_loss:0.143033\n",
      "Epoch [2/2], Iter [2681/3125], train_loss:0.144395\n",
      "Epoch [2/2], Iter [2682/3125], train_loss:0.144258\n",
      "Epoch [2/2], Iter [2683/3125], train_loss:0.143784\n",
      "Epoch [2/2], Iter [2684/3125], train_loss:0.142221\n",
      "Epoch [2/2], Iter [2685/3125], train_loss:0.144328\n",
      "Epoch [2/2], Iter [2686/3125], train_loss:0.143765\n",
      "Epoch [2/2], Iter [2687/3125], train_loss:0.144085\n",
      "Epoch [2/2], Iter [2688/3125], train_loss:0.144608\n",
      "Epoch [2/2], Iter [2689/3125], train_loss:0.142943\n",
      "Epoch [2/2], Iter [2690/3125], train_loss:0.143987\n",
      "Epoch [2/2], Iter [2691/3125], train_loss:0.144158\n",
      "Epoch [2/2], Iter [2692/3125], train_loss:0.144427\n",
      "Epoch [2/2], Iter [2693/3125], train_loss:0.145372\n",
      "Epoch [2/2], Iter [2694/3125], train_loss:0.144125\n",
      "Epoch [2/2], Iter [2695/3125], train_loss:0.143905\n",
      "Epoch [2/2], Iter [2696/3125], train_loss:0.143793\n",
      "Epoch [2/2], Iter [2697/3125], train_loss:0.144980\n",
      "Epoch [2/2], Iter [2698/3125], train_loss:0.144655\n",
      "Epoch [2/2], Iter [2699/3125], train_loss:0.144537\n",
      "Epoch [2/2], Iter [2700/3125], train_loss:0.142938\n",
      "Epoch [2/2], Iter [2701/3125], train_loss:0.143960\n",
      "Epoch [2/2], Iter [2702/3125], train_loss:0.146030\n",
      "Epoch [2/2], Iter [2703/3125], train_loss:0.143715\n",
      "Epoch [2/2], Iter [2704/3125], train_loss:0.143876\n",
      "Epoch [2/2], Iter [2705/3125], train_loss:0.143287\n",
      "Epoch [2/2], Iter [2706/3125], train_loss:0.143944\n",
      "Epoch [2/2], Iter [2707/3125], train_loss:0.143888\n",
      "Epoch [2/2], Iter [2708/3125], train_loss:0.143948\n",
      "Epoch [2/2], Iter [2709/3125], train_loss:0.143969\n",
      "Epoch [2/2], Iter [2710/3125], train_loss:0.144056\n",
      "Epoch [2/2], Iter [2711/3125], train_loss:0.143444\n",
      "Epoch [2/2], Iter [2712/3125], train_loss:0.142905\n",
      "Epoch [2/2], Iter [2713/3125], train_loss:0.144493\n",
      "Epoch [2/2], Iter [2714/3125], train_loss:0.143736\n",
      "Epoch [2/2], Iter [2715/3125], train_loss:0.142457\n",
      "Epoch [2/2], Iter [2716/3125], train_loss:0.144782\n",
      "Epoch [2/2], Iter [2717/3125], train_loss:0.143842\n",
      "Epoch [2/2], Iter [2718/3125], train_loss:0.143838\n",
      "Epoch [2/2], Iter [2719/3125], train_loss:0.143792\n",
      "Epoch [2/2], Iter [2720/3125], train_loss:0.142379\n",
      "Epoch [2/2], Iter [2721/3125], train_loss:0.143916\n",
      "Epoch [2/2], Iter [2722/3125], train_loss:0.143682\n",
      "Epoch [2/2], Iter [2723/3125], train_loss:0.143480\n",
      "Epoch [2/2], Iter [2724/3125], train_loss:0.143619\n",
      "Epoch [2/2], Iter [2725/3125], train_loss:0.143522\n",
      "Epoch [2/2], Iter [2726/3125], train_loss:0.143987\n",
      "Epoch [2/2], Iter [2727/3125], train_loss:0.145278\n",
      "Epoch [2/2], Iter [2728/3125], train_loss:0.145003\n",
      "Epoch [2/2], Iter [2729/3125], train_loss:0.144210\n",
      "Epoch [2/2], Iter [2730/3125], train_loss:0.143408\n",
      "Epoch [2/2], Iter [2731/3125], train_loss:0.144209\n",
      "Epoch [2/2], Iter [2732/3125], train_loss:0.143156\n",
      "Epoch [2/2], Iter [2733/3125], train_loss:0.143543\n",
      "Epoch [2/2], Iter [2734/3125], train_loss:0.143016\n",
      "Epoch [2/2], Iter [2735/3125], train_loss:0.145466\n",
      "Epoch [2/2], Iter [2736/3125], train_loss:0.142460\n",
      "Epoch [2/2], Iter [2737/3125], train_loss:0.144555\n",
      "Epoch [2/2], Iter [2738/3125], train_loss:0.144993\n",
      "Epoch [2/2], Iter [2739/3125], train_loss:0.143628\n",
      "Epoch [2/2], Iter [2740/3125], train_loss:0.143066\n",
      "Epoch [2/2], Iter [2741/3125], train_loss:0.143506\n",
      "Epoch [2/2], Iter [2742/3125], train_loss:0.143340\n",
      "Epoch [2/2], Iter [2743/3125], train_loss:0.144110\n",
      "Epoch [2/2], Iter [2744/3125], train_loss:0.143407\n",
      "Epoch [2/2], Iter [2745/3125], train_loss:0.146082\n",
      "Epoch [2/2], Iter [2746/3125], train_loss:0.144750\n",
      "Epoch [2/2], Iter [2747/3125], train_loss:0.144163\n",
      "Epoch [2/2], Iter [2748/3125], train_loss:0.144741\n",
      "Epoch [2/2], Iter [2749/3125], train_loss:0.143731\n",
      "Epoch [2/2], Iter [2750/3125], train_loss:0.143819\n",
      "Epoch [2/2], Iter [2751/3125], train_loss:0.144941\n",
      "Epoch [2/2], Iter [2752/3125], train_loss:0.143765\n",
      "Epoch [2/2], Iter [2753/3125], train_loss:0.144402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [2754/3125], train_loss:0.143569\n",
      "Epoch [2/2], Iter [2755/3125], train_loss:0.144361\n",
      "Epoch [2/2], Iter [2756/3125], train_loss:0.143461\n",
      "Epoch [2/2], Iter [2757/3125], train_loss:0.143996\n",
      "Epoch [2/2], Iter [2758/3125], train_loss:0.143918\n",
      "Epoch [2/2], Iter [2759/3125], train_loss:0.143663\n",
      "Epoch [2/2], Iter [2760/3125], train_loss:0.144662\n",
      "Epoch [2/2], Iter [2761/3125], train_loss:0.145421\n",
      "Epoch [2/2], Iter [2762/3125], train_loss:0.143937\n",
      "Epoch [2/2], Iter [2763/3125], train_loss:0.144078\n",
      "Epoch [2/2], Iter [2764/3125], train_loss:0.144043\n",
      "Epoch [2/2], Iter [2765/3125], train_loss:0.143312\n",
      "Epoch [2/2], Iter [2766/3125], train_loss:0.144220\n",
      "Epoch [2/2], Iter [2767/3125], train_loss:0.144149\n",
      "Epoch [2/2], Iter [2768/3125], train_loss:0.145407\n",
      "Epoch [2/2], Iter [2769/3125], train_loss:0.142391\n",
      "Epoch [2/2], Iter [2770/3125], train_loss:0.144604\n",
      "Epoch [2/2], Iter [2771/3125], train_loss:0.142564\n",
      "Epoch [2/2], Iter [2772/3125], train_loss:0.143830\n",
      "Epoch [2/2], Iter [2773/3125], train_loss:0.143837\n",
      "Epoch [2/2], Iter [2774/3125], train_loss:0.143566\n",
      "Epoch [2/2], Iter [2775/3125], train_loss:0.143981\n",
      "Epoch [2/2], Iter [2776/3125], train_loss:0.143335\n",
      "Epoch [2/2], Iter [2777/3125], train_loss:0.144060\n",
      "Epoch [2/2], Iter [2778/3125], train_loss:0.143980\n",
      "Epoch [2/2], Iter [2779/3125], train_loss:0.144464\n",
      "Epoch [2/2], Iter [2780/3125], train_loss:0.142828\n",
      "Epoch [2/2], Iter [2781/3125], train_loss:0.143742\n",
      "Epoch [2/2], Iter [2782/3125], train_loss:0.142471\n",
      "Epoch [2/2], Iter [2783/3125], train_loss:0.143917\n",
      "Epoch [2/2], Iter [2784/3125], train_loss:0.145224\n",
      "Epoch [2/2], Iter [2785/3125], train_loss:0.143031\n",
      "Epoch [2/2], Iter [2786/3125], train_loss:0.144533\n",
      "Epoch [2/2], Iter [2787/3125], train_loss:0.145689\n",
      "Epoch [2/2], Iter [2788/3125], train_loss:0.145144\n",
      "Epoch [2/2], Iter [2789/3125], train_loss:0.144312\n",
      "Epoch [2/2], Iter [2790/3125], train_loss:0.144168\n",
      "Epoch [2/2], Iter [2791/3125], train_loss:0.144539\n",
      "Epoch [2/2], Iter [2792/3125], train_loss:0.143305\n",
      "Epoch [2/2], Iter [2793/3125], train_loss:0.143712\n",
      "Epoch [2/2], Iter [2794/3125], train_loss:0.142945\n",
      "Epoch [2/2], Iter [2795/3125], train_loss:0.143781\n",
      "Epoch [2/2], Iter [2796/3125], train_loss:0.144675\n",
      "Epoch [2/2], Iter [2797/3125], train_loss:0.143406\n",
      "Epoch [2/2], Iter [2798/3125], train_loss:0.143589\n",
      "Epoch [2/2], Iter [2799/3125], train_loss:0.144724\n",
      "Epoch [2/2], Iter [2800/3125], train_loss:0.143453\n",
      "Epoch [2/2], Iter [2801/3125], train_loss:0.143504\n",
      "Epoch [2/2], Iter [2802/3125], train_loss:0.142641\n",
      "Epoch [2/2], Iter [2803/3125], train_loss:0.144278\n",
      "Epoch [2/2], Iter [2804/3125], train_loss:0.143949\n",
      "Epoch [2/2], Iter [2805/3125], train_loss:0.145114\n",
      "Epoch [2/2], Iter [2806/3125], train_loss:0.143570\n",
      "Epoch [2/2], Iter [2807/3125], train_loss:0.144809\n",
      "Epoch [2/2], Iter [2808/3125], train_loss:0.145062\n",
      "Epoch [2/2], Iter [2809/3125], train_loss:0.143598\n",
      "Epoch [2/2], Iter [2810/3125], train_loss:0.143091\n",
      "Epoch [2/2], Iter [2811/3125], train_loss:0.145521\n",
      "Epoch [2/2], Iter [2812/3125], train_loss:0.143517\n",
      "Epoch [2/2], Iter [2813/3125], train_loss:0.144563\n",
      "Epoch [2/2], Iter [2814/3125], train_loss:0.142491\n",
      "Epoch [2/2], Iter [2815/3125], train_loss:0.143310\n",
      "Epoch [2/2], Iter [2816/3125], train_loss:0.142361\n",
      "Epoch [2/2], Iter [2817/3125], train_loss:0.145816\n",
      "Epoch [2/2], Iter [2818/3125], train_loss:0.143951\n",
      "Epoch [2/2], Iter [2819/3125], train_loss:0.144273\n",
      "Epoch [2/2], Iter [2820/3125], train_loss:0.144258\n",
      "Epoch [2/2], Iter [2821/3125], train_loss:0.144990\n",
      "Epoch [2/2], Iter [2822/3125], train_loss:0.144649\n",
      "Epoch [2/2], Iter [2823/3125], train_loss:0.144268\n",
      "Epoch [2/2], Iter [2824/3125], train_loss:0.144846\n",
      "Epoch [2/2], Iter [2825/3125], train_loss:0.145498\n",
      "Epoch [2/2], Iter [2826/3125], train_loss:0.144054\n",
      "Epoch [2/2], Iter [2827/3125], train_loss:0.144249\n",
      "Epoch [2/2], Iter [2828/3125], train_loss:0.143567\n",
      "Epoch [2/2], Iter [2829/3125], train_loss:0.144163\n",
      "Epoch [2/2], Iter [2830/3125], train_loss:0.144500\n",
      "Epoch [2/2], Iter [2831/3125], train_loss:0.143301\n",
      "Epoch [2/2], Iter [2832/3125], train_loss:0.144451\n",
      "Epoch [2/2], Iter [2833/3125], train_loss:0.143117\n",
      "Epoch [2/2], Iter [2834/3125], train_loss:0.144211\n",
      "Epoch [2/2], Iter [2835/3125], train_loss:0.143344\n",
      "Epoch [2/2], Iter [2836/3125], train_loss:0.143845\n",
      "Epoch [2/2], Iter [2837/3125], train_loss:0.144491\n",
      "Epoch [2/2], Iter [2838/3125], train_loss:0.144406\n",
      "Epoch [2/2], Iter [2839/3125], train_loss:0.144543\n",
      "Epoch [2/2], Iter [2840/3125], train_loss:0.144433\n",
      "Epoch [2/2], Iter [2841/3125], train_loss:0.143377\n",
      "Epoch [2/2], Iter [2842/3125], train_loss:0.144345\n",
      "Epoch [2/2], Iter [2843/3125], train_loss:0.143906\n",
      "Epoch [2/2], Iter [2844/3125], train_loss:0.142954\n",
      "Epoch [2/2], Iter [2845/3125], train_loss:0.145130\n",
      "Epoch [2/2], Iter [2846/3125], train_loss:0.143829\n",
      "Epoch [2/2], Iter [2847/3125], train_loss:0.143189\n",
      "Epoch [2/2], Iter [2848/3125], train_loss:0.143883\n",
      "Epoch [2/2], Iter [2849/3125], train_loss:0.142889\n",
      "Epoch [2/2], Iter [2850/3125], train_loss:0.144162\n",
      "Epoch [2/2], Iter [2851/3125], train_loss:0.144342\n",
      "Epoch [2/2], Iter [2852/3125], train_loss:0.144999\n",
      "Epoch [2/2], Iter [2853/3125], train_loss:0.144573\n",
      "Epoch [2/2], Iter [2854/3125], train_loss:0.143451\n",
      "Epoch [2/2], Iter [2855/3125], train_loss:0.143861\n",
      "Epoch [2/2], Iter [2856/3125], train_loss:0.144036\n",
      "Epoch [2/2], Iter [2857/3125], train_loss:0.142964\n",
      "Epoch [2/2], Iter [2858/3125], train_loss:0.143109\n",
      "Epoch [2/2], Iter [2859/3125], train_loss:0.146044\n",
      "Epoch [2/2], Iter [2860/3125], train_loss:0.143581\n",
      "Epoch [2/2], Iter [2861/3125], train_loss:0.145697\n",
      "Epoch [2/2], Iter [2862/3125], train_loss:0.143465\n",
      "Epoch [2/2], Iter [2863/3125], train_loss:0.142660\n",
      "Epoch [2/2], Iter [2864/3125], train_loss:0.143502\n",
      "Epoch [2/2], Iter [2865/3125], train_loss:0.144672\n",
      "Epoch [2/2], Iter [2866/3125], train_loss:0.143915\n",
      "Epoch [2/2], Iter [2867/3125], train_loss:0.144964\n",
      "Epoch [2/2], Iter [2868/3125], train_loss:0.143561\n",
      "Epoch [2/2], Iter [2869/3125], train_loss:0.142898\n",
      "Epoch [2/2], Iter [2870/3125], train_loss:0.142502\n",
      "Epoch [2/2], Iter [2871/3125], train_loss:0.144280\n",
      "Epoch [2/2], Iter [2872/3125], train_loss:0.144423\n",
      "Epoch [2/2], Iter [2873/3125], train_loss:0.144675\n",
      "Epoch [2/2], Iter [2874/3125], train_loss:0.144498\n",
      "Epoch [2/2], Iter [2875/3125], train_loss:0.143663\n",
      "Epoch [2/2], Iter [2876/3125], train_loss:0.145344\n",
      "Epoch [2/2], Iter [2877/3125], train_loss:0.144761\n",
      "Epoch [2/2], Iter [2878/3125], train_loss:0.144350\n",
      "Epoch [2/2], Iter [2879/3125], train_loss:0.143869\n",
      "Epoch [2/2], Iter [2880/3125], train_loss:0.144515\n",
      "Epoch [2/2], Iter [2881/3125], train_loss:0.143155\n",
      "Epoch [2/2], Iter [2882/3125], train_loss:0.146263\n",
      "Epoch [2/2], Iter [2883/3125], train_loss:0.142620\n",
      "Epoch [2/2], Iter [2884/3125], train_loss:0.144729\n",
      "Epoch [2/2], Iter [2885/3125], train_loss:0.144024\n",
      "Epoch [2/2], Iter [2886/3125], train_loss:0.144685\n",
      "Epoch [2/2], Iter [2887/3125], train_loss:0.143649\n",
      "Epoch [2/2], Iter [2888/3125], train_loss:0.144011\n",
      "Epoch [2/2], Iter [2889/3125], train_loss:0.144125\n",
      "Epoch [2/2], Iter [2890/3125], train_loss:0.143334\n",
      "Epoch [2/2], Iter [2891/3125], train_loss:0.143502\n",
      "Epoch [2/2], Iter [2892/3125], train_loss:0.142073\n",
      "Epoch [2/2], Iter [2893/3125], train_loss:0.143722\n",
      "Epoch [2/2], Iter [2894/3125], train_loss:0.143738\n",
      "Epoch [2/2], Iter [2895/3125], train_loss:0.143789\n",
      "Epoch [2/2], Iter [2896/3125], train_loss:0.143474\n",
      "Epoch [2/2], Iter [2897/3125], train_loss:0.145739\n",
      "Epoch [2/2], Iter [2898/3125], train_loss:0.144217\n",
      "Epoch [2/2], Iter [2899/3125], train_loss:0.144712\n",
      "Epoch [2/2], Iter [2900/3125], train_loss:0.142782\n",
      "Epoch [2/2], Iter [2901/3125], train_loss:0.145229\n",
      "Epoch [2/2], Iter [2902/3125], train_loss:0.144463\n",
      "Epoch [2/2], Iter [2903/3125], train_loss:0.142779\n",
      "Epoch [2/2], Iter [2904/3125], train_loss:0.145458\n",
      "Epoch [2/2], Iter [2905/3125], train_loss:0.144598\n",
      "Epoch [2/2], Iter [2906/3125], train_loss:0.144281\n",
      "Epoch [2/2], Iter [2907/3125], train_loss:0.145006\n",
      "Epoch [2/2], Iter [2908/3125], train_loss:0.145010\n",
      "Epoch [2/2], Iter [2909/3125], train_loss:0.143878\n",
      "Epoch [2/2], Iter [2910/3125], train_loss:0.143817\n",
      "Epoch [2/2], Iter [2911/3125], train_loss:0.141731\n",
      "Epoch [2/2], Iter [2912/3125], train_loss:0.143625\n",
      "Epoch [2/2], Iter [2913/3125], train_loss:0.144800\n",
      "Epoch [2/2], Iter [2914/3125], train_loss:0.145004\n",
      "Epoch [2/2], Iter [2915/3125], train_loss:0.144139\n",
      "Epoch [2/2], Iter [2916/3125], train_loss:0.143994\n",
      "Epoch [2/2], Iter [2917/3125], train_loss:0.143267\n",
      "Epoch [2/2], Iter [2918/3125], train_loss:0.143400\n",
      "Epoch [2/2], Iter [2919/3125], train_loss:0.144035\n",
      "Epoch [2/2], Iter [2920/3125], train_loss:0.144422\n",
      "Epoch [2/2], Iter [2921/3125], train_loss:0.143991\n",
      "Epoch [2/2], Iter [2922/3125], train_loss:0.144323\n",
      "Epoch [2/2], Iter [2923/3125], train_loss:0.143828\n",
      "Epoch [2/2], Iter [2924/3125], train_loss:0.143552\n",
      "Epoch [2/2], Iter [2925/3125], train_loss:0.143502\n",
      "Epoch [2/2], Iter [2926/3125], train_loss:0.143068\n",
      "Epoch [2/2], Iter [2927/3125], train_loss:0.142581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [2928/3125], train_loss:0.142395\n",
      "Epoch [2/2], Iter [2929/3125], train_loss:0.144055\n",
      "Epoch [2/2], Iter [2930/3125], train_loss:0.145205\n",
      "Epoch [2/2], Iter [2931/3125], train_loss:0.145022\n",
      "Epoch [2/2], Iter [2932/3125], train_loss:0.142993\n",
      "Epoch [2/2], Iter [2933/3125], train_loss:0.145359\n",
      "Epoch [2/2], Iter [2934/3125], train_loss:0.143582\n",
      "Epoch [2/2], Iter [2935/3125], train_loss:0.144003\n",
      "Epoch [2/2], Iter [2936/3125], train_loss:0.144678\n",
      "Epoch [2/2], Iter [2937/3125], train_loss:0.145830\n",
      "Epoch [2/2], Iter [2938/3125], train_loss:0.145228\n",
      "Epoch [2/2], Iter [2939/3125], train_loss:0.142945\n",
      "Epoch [2/2], Iter [2940/3125], train_loss:0.143438\n",
      "Epoch [2/2], Iter [2941/3125], train_loss:0.143648\n",
      "Epoch [2/2], Iter [2942/3125], train_loss:0.143192\n",
      "Epoch [2/2], Iter [2943/3125], train_loss:0.144691\n",
      "Epoch [2/2], Iter [2944/3125], train_loss:0.144329\n",
      "Epoch [2/2], Iter [2945/3125], train_loss:0.142627\n",
      "Epoch [2/2], Iter [2946/3125], train_loss:0.143956\n",
      "Epoch [2/2], Iter [2947/3125], train_loss:0.144493\n",
      "Epoch [2/2], Iter [2948/3125], train_loss:0.143299\n",
      "Epoch [2/2], Iter [2949/3125], train_loss:0.144162\n",
      "Epoch [2/2], Iter [2950/3125], train_loss:0.142042\n",
      "Epoch [2/2], Iter [2951/3125], train_loss:0.144334\n",
      "Epoch [2/2], Iter [2952/3125], train_loss:0.144875\n",
      "Epoch [2/2], Iter [2953/3125], train_loss:0.145065\n",
      "Epoch [2/2], Iter [2954/3125], train_loss:0.141406\n",
      "Epoch [2/2], Iter [2955/3125], train_loss:0.143867\n",
      "Epoch [2/2], Iter [2956/3125], train_loss:0.143801\n",
      "Epoch [2/2], Iter [2957/3125], train_loss:0.143506\n",
      "Epoch [2/2], Iter [2958/3125], train_loss:0.143520\n",
      "Epoch [2/2], Iter [2959/3125], train_loss:0.142298\n",
      "Epoch [2/2], Iter [2960/3125], train_loss:0.143482\n",
      "Epoch [2/2], Iter [2961/3125], train_loss:0.143171\n",
      "Epoch [2/2], Iter [2962/3125], train_loss:0.144211\n",
      "Epoch [2/2], Iter [2963/3125], train_loss:0.143223\n",
      "Epoch [2/2], Iter [2964/3125], train_loss:0.145201\n",
      "Epoch [2/2], Iter [2965/3125], train_loss:0.145251\n",
      "Epoch [2/2], Iter [2966/3125], train_loss:0.144852\n",
      "Epoch [2/2], Iter [2967/3125], train_loss:0.144187\n",
      "Epoch [2/2], Iter [2968/3125], train_loss:0.144134\n",
      "Epoch [2/2], Iter [2969/3125], train_loss:0.143054\n",
      "Epoch [2/2], Iter [2970/3125], train_loss:0.143322\n",
      "Epoch [2/2], Iter [2971/3125], train_loss:0.142917\n",
      "Epoch [2/2], Iter [2972/3125], train_loss:0.143671\n",
      "Epoch [2/2], Iter [2973/3125], train_loss:0.143126\n",
      "Epoch [2/2], Iter [2974/3125], train_loss:0.142976\n",
      "Epoch [2/2], Iter [2975/3125], train_loss:0.144522\n",
      "Epoch [2/2], Iter [2976/3125], train_loss:0.144707\n",
      "Epoch [2/2], Iter [2977/3125], train_loss:0.144557\n",
      "Epoch [2/2], Iter [2978/3125], train_loss:0.143343\n",
      "Epoch [2/2], Iter [2979/3125], train_loss:0.144280\n",
      "Epoch [2/2], Iter [2980/3125], train_loss:0.144604\n",
      "Epoch [2/2], Iter [2981/3125], train_loss:0.143725\n",
      "Epoch [2/2], Iter [2982/3125], train_loss:0.143836\n",
      "Epoch [2/2], Iter [2983/3125], train_loss:0.143435\n",
      "Epoch [2/2], Iter [2984/3125], train_loss:0.144910\n",
      "Epoch [2/2], Iter [2985/3125], train_loss:0.144691\n",
      "Epoch [2/2], Iter [2986/3125], train_loss:0.145156\n",
      "Epoch [2/2], Iter [2987/3125], train_loss:0.144572\n",
      "Epoch [2/2], Iter [2988/3125], train_loss:0.143817\n",
      "Epoch [2/2], Iter [2989/3125], train_loss:0.143631\n",
      "Epoch [2/2], Iter [2990/3125], train_loss:0.142738\n",
      "Epoch [2/2], Iter [2991/3125], train_loss:0.144112\n",
      "Epoch [2/2], Iter [2992/3125], train_loss:0.145617\n",
      "Epoch [2/2], Iter [2993/3125], train_loss:0.144968\n",
      "Epoch [2/2], Iter [2994/3125], train_loss:0.144099\n",
      "Epoch [2/2], Iter [2995/3125], train_loss:0.143708\n",
      "Epoch [2/2], Iter [2996/3125], train_loss:0.143237\n",
      "Epoch [2/2], Iter [2997/3125], train_loss:0.144706\n",
      "Epoch [2/2], Iter [2998/3125], train_loss:0.144476\n",
      "Epoch [2/2], Iter [2999/3125], train_loss:0.143216\n",
      "Epoch [2/2], Iter [3000/3125], train_loss:0.144481\n",
      "Epoch [2/2], Iter [3001/3125], train_loss:0.143564\n",
      "Epoch [2/2], Iter [3002/3125], train_loss:0.142953\n",
      "Epoch [2/2], Iter [3003/3125], train_loss:0.145222\n",
      "Epoch [2/2], Iter [3004/3125], train_loss:0.144825\n",
      "Epoch [2/2], Iter [3005/3125], train_loss:0.144132\n",
      "Epoch [2/2], Iter [3006/3125], train_loss:0.145152\n",
      "Epoch [2/2], Iter [3007/3125], train_loss:0.144966\n",
      "Epoch [2/2], Iter [3008/3125], train_loss:0.145967\n",
      "Epoch [2/2], Iter [3009/3125], train_loss:0.145188\n",
      "Epoch [2/2], Iter [3010/3125], train_loss:0.144468\n",
      "Epoch [2/2], Iter [3011/3125], train_loss:0.144354\n",
      "Epoch [2/2], Iter [3012/3125], train_loss:0.143756\n",
      "Epoch [2/2], Iter [3013/3125], train_loss:0.143457\n",
      "Epoch [2/2], Iter [3014/3125], train_loss:0.143985\n",
      "Epoch [2/2], Iter [3015/3125], train_loss:0.142689\n",
      "Epoch [2/2], Iter [3016/3125], train_loss:0.144128\n",
      "Epoch [2/2], Iter [3017/3125], train_loss:0.144633\n",
      "Epoch [2/2], Iter [3018/3125], train_loss:0.144697\n",
      "Epoch [2/2], Iter [3019/3125], train_loss:0.145104\n",
      "Epoch [2/2], Iter [3020/3125], train_loss:0.143473\n",
      "Epoch [2/2], Iter [3021/3125], train_loss:0.142638\n",
      "Epoch [2/2], Iter [3022/3125], train_loss:0.142962\n",
      "Epoch [2/2], Iter [3023/3125], train_loss:0.144798\n",
      "Epoch [2/2], Iter [3024/3125], train_loss:0.144014\n",
      "Epoch [2/2], Iter [3025/3125], train_loss:0.144740\n",
      "Epoch [2/2], Iter [3026/3125], train_loss:0.144111\n",
      "Epoch [2/2], Iter [3027/3125], train_loss:0.143986\n",
      "Epoch [2/2], Iter [3028/3125], train_loss:0.144290\n",
      "Epoch [2/2], Iter [3029/3125], train_loss:0.143178\n",
      "Epoch [2/2], Iter [3030/3125], train_loss:0.143427\n",
      "Epoch [2/2], Iter [3031/3125], train_loss:0.145655\n",
      "Epoch [2/2], Iter [3032/3125], train_loss:0.142819\n",
      "Epoch [2/2], Iter [3033/3125], train_loss:0.144428\n",
      "Epoch [2/2], Iter [3034/3125], train_loss:0.144493\n",
      "Epoch [2/2], Iter [3035/3125], train_loss:0.143484\n",
      "Epoch [2/2], Iter [3036/3125], train_loss:0.144426\n",
      "Epoch [2/2], Iter [3037/3125], train_loss:0.144143\n",
      "Epoch [2/2], Iter [3038/3125], train_loss:0.143297\n",
      "Epoch [2/2], Iter [3039/3125], train_loss:0.143039\n",
      "Epoch [2/2], Iter [3040/3125], train_loss:0.144309\n",
      "Epoch [2/2], Iter [3041/3125], train_loss:0.144258\n",
      "Epoch [2/2], Iter [3042/3125], train_loss:0.144678\n",
      "Epoch [2/2], Iter [3043/3125], train_loss:0.143115\n",
      "Epoch [2/2], Iter [3044/3125], train_loss:0.144998\n",
      "Epoch [2/2], Iter [3045/3125], train_loss:0.143846\n",
      "Epoch [2/2], Iter [3046/3125], train_loss:0.143866\n",
      "Epoch [2/2], Iter [3047/3125], train_loss:0.142039\n",
      "Epoch [2/2], Iter [3048/3125], train_loss:0.146401\n",
      "Epoch [2/2], Iter [3049/3125], train_loss:0.143695\n",
      "Epoch [2/2], Iter [3050/3125], train_loss:0.144152\n",
      "Epoch [2/2], Iter [3051/3125], train_loss:0.144485\n",
      "Epoch [2/2], Iter [3052/3125], train_loss:0.144059\n",
      "Epoch [2/2], Iter [3053/3125], train_loss:0.143821\n",
      "Epoch [2/2], Iter [3054/3125], train_loss:0.143333\n",
      "Epoch [2/2], Iter [3055/3125], train_loss:0.145701\n",
      "Epoch [2/2], Iter [3056/3125], train_loss:0.144350\n",
      "Epoch [2/2], Iter [3057/3125], train_loss:0.143321\n",
      "Epoch [2/2], Iter [3058/3125], train_loss:0.143907\n",
      "Epoch [2/2], Iter [3059/3125], train_loss:0.142723\n",
      "Epoch [2/2], Iter [3060/3125], train_loss:0.143353\n",
      "Epoch [2/2], Iter [3061/3125], train_loss:0.144106\n",
      "Epoch [2/2], Iter [3062/3125], train_loss:0.141419\n",
      "Epoch [2/2], Iter [3063/3125], train_loss:0.142874\n",
      "Epoch [2/2], Iter [3064/3125], train_loss:0.142823\n",
      "Epoch [2/2], Iter [3065/3125], train_loss:0.144118\n",
      "Epoch [2/2], Iter [3066/3125], train_loss:0.143670\n",
      "Epoch [2/2], Iter [3067/3125], train_loss:0.145667\n",
      "Epoch [2/2], Iter [3068/3125], train_loss:0.145281\n",
      "Epoch [2/2], Iter [3069/3125], train_loss:0.143752\n",
      "Epoch [2/2], Iter [3070/3125], train_loss:0.143281\n",
      "Epoch [2/2], Iter [3071/3125], train_loss:0.143851\n",
      "Epoch [2/2], Iter [3072/3125], train_loss:0.143387\n",
      "Epoch [2/2], Iter [3073/3125], train_loss:0.142484\n",
      "Epoch [2/2], Iter [3074/3125], train_loss:0.144439\n",
      "Epoch [2/2], Iter [3075/3125], train_loss:0.143893\n",
      "Epoch [2/2], Iter [3076/3125], train_loss:0.144586\n",
      "Epoch [2/2], Iter [3077/3125], train_loss:0.143649\n",
      "Epoch [2/2], Iter [3078/3125], train_loss:0.145061\n",
      "Epoch [2/2], Iter [3079/3125], train_loss:0.144307\n",
      "Epoch [2/2], Iter [3080/3125], train_loss:0.144320\n",
      "Epoch [2/2], Iter [3081/3125], train_loss:0.145027\n",
      "Epoch [2/2], Iter [3082/3125], train_loss:0.144721\n",
      "Epoch [2/2], Iter [3083/3125], train_loss:0.143484\n",
      "Epoch [2/2], Iter [3084/3125], train_loss:0.143049\n",
      "Epoch [2/2], Iter [3085/3125], train_loss:0.144602\n",
      "Epoch [2/2], Iter [3086/3125], train_loss:0.144194\n",
      "Epoch [2/2], Iter [3087/3125], train_loss:0.144785\n",
      "Epoch [2/2], Iter [3088/3125], train_loss:0.144173\n",
      "Epoch [2/2], Iter [3089/3125], train_loss:0.144810\n",
      "Epoch [2/2], Iter [3090/3125], train_loss:0.145279\n",
      "Epoch [2/2], Iter [3091/3125], train_loss:0.144983\n",
      "Epoch [2/2], Iter [3092/3125], train_loss:0.144047\n",
      "Epoch [2/2], Iter [3093/3125], train_loss:0.143504\n",
      "Epoch [2/2], Iter [3094/3125], train_loss:0.144061\n",
      "Epoch [2/2], Iter [3095/3125], train_loss:0.143841\n",
      "Epoch [2/2], Iter [3096/3125], train_loss:0.144564\n",
      "Epoch [2/2], Iter [3097/3125], train_loss:0.145044\n",
      "Epoch [2/2], Iter [3098/3125], train_loss:0.143459\n",
      "Epoch [2/2], Iter [3099/3125], train_loss:0.145157\n",
      "Epoch [2/2], Iter [3100/3125], train_loss:0.143719\n",
      "Epoch [2/2], Iter [3101/3125], train_loss:0.142832\n",
      "Epoch [2/2], Iter [3102/3125], train_loss:0.143030\n",
      "Epoch [2/2], Iter [3103/3125], train_loss:0.144082\n",
      "Epoch [2/2], Iter [3104/3125], train_loss:0.142795\n",
      "Epoch [2/2], Iter [3105/3125], train_loss:0.143760\n",
      "Epoch [2/2], Iter [3106/3125], train_loss:0.143561\n",
      "Epoch [2/2], Iter [3107/3125], train_loss:0.143349\n",
      "Epoch [2/2], Iter [3108/3125], train_loss:0.143313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Iter [3109/3125], train_loss:0.142720\n",
      "Epoch [2/2], Iter [3110/3125], train_loss:0.144314\n",
      "Epoch [2/2], Iter [3111/3125], train_loss:0.142593\n",
      "Epoch [2/2], Iter [3112/3125], train_loss:0.143792\n",
      "Epoch [2/2], Iter [3113/3125], train_loss:0.143503\n",
      "Epoch [2/2], Iter [3114/3125], train_loss:0.143659\n",
      "Epoch [2/2], Iter [3115/3125], train_loss:0.143497\n",
      "Epoch [2/2], Iter [3116/3125], train_loss:0.143465\n",
      "Epoch [2/2], Iter [3117/3125], train_loss:0.143449\n",
      "Epoch [2/2], Iter [3118/3125], train_loss:0.143808\n",
      "Epoch [2/2], Iter [3119/3125], train_loss:0.144106\n",
      "Epoch [2/2], Iter [3120/3125], train_loss:0.143023\n",
      "Epoch [2/2], Iter [3121/3125], train_loss:0.144430\n",
      "Epoch [2/2], Iter [3122/3125], train_loss:0.143815\n",
      "Epoch [2/2], Iter [3123/3125], train_loss:0.144958\n",
      "Epoch [2/2], Iter [3124/3125], train_loss:0.144607\n",
      "Epoch [2/2], Iter [3125/3125], train_loss:0.144700\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1449, test_acc:0.0000%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1445, test_acc:3.1250%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1442, test_acc:4.1667%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1447, test_acc:3.1250%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1445, test_acc:7.5000%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1444, test_acc:8.3333%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1444, test_acc:7.1429%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1443, test_acc:8.5938%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1442, test_acc:9.7222%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.6250%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2273%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.4167%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.0962%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.8214%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1442, test_acc:9.1667%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.3750%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.5588%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.0278%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.2105%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.0625%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:8.9286%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.0909%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.5109%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.3750%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.5000%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3365%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4167%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2679%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.5603%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.2083%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.8790%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9609%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6591%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.5588%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6429%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8958%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6284%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7039%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7756%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6875%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.6037%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.3750%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.3023%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.6591%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.5833%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.6467%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.8404%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1562%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2041%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1250%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.0490%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.9760%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4953%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.4167%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.4545%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.2679%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.1974%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.0216%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.2754%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.1042%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.0410%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:10.0806%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.9206%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.7656%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.8077%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.9432%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.7948%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.7426%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.7826%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.8214%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.8592%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0694%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.9315%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.8818%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.8333%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.7862%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.6591%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.6154%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.8101%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.8438%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.7222%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1441, test_acc:9.7561%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7892%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7470%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8529%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8837%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8420%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8722%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7612%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6528%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6841%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6467%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6774%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8404%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9342%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8958%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9227%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8852%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9116%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8750%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8391%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8039%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7694%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7356%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7619%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7288%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6963%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6644%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.5757%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7159%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8536%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7656%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7898%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7039%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6739%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6983%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7756%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7458%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7164%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6875%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7624%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7336%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8577%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7782%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7500%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.7222%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6457%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.6680%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.5930%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8077%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.8760%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9432%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0094%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0280%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0000%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0643%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0365%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0543%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1619%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1786%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1507%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1673%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1399%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1562%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2155%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2740%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2466%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3463%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3188%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2917%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2649%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2796%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2533%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2679%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2823%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2564%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2309%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3244%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3774%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4297%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4814%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4552%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4678%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4421%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4924%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4292%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4042%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4539%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5399%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4779%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5263%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6105%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5853%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5963%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5357%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5824%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5932%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6039%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6145%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5556%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5318%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5426%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5874%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5978%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5743%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.5175%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5949%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6051%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5489%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5921%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5366%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5143%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5246%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5026%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4808%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4273%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4695%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4798%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4585%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4688%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4167%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3960%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3448%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3554%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3049%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2852%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2657%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3365%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3469%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3274%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3377%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3479%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3580%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3680%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3488%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3877%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3975%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4358%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4167%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4261%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4921%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5011%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4540%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4353%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5000%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4812%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4626%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4441%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4803%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4891%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5249%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5065%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5687%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6303%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6117%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6197%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6540%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6355%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6433%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6250%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6328%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6147%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6224%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5789%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6122%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6199%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6022%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5847%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5924%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6500%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6823%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6399%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6472%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6053%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.6127%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.5713%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.6031%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.5862%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5936%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6010%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.6082%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.5677%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5751%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5824%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5896%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5733%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5571%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5410%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5716%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5556%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5397%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5009%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5082%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4927%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4773%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4620%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4919%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5216%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5511%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5134%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5205%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4832%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4682%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4974%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5044%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.5114%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4747%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4601%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4455%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4310%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4811%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4452%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4096%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4167%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.4025%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4307%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4167%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4027%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.4097%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.3750%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1439, test_acc:10.3821%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3477%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3548%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3413%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3279%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3350%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3420%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.3084%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2751%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2823%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2693%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2364%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2236%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2508%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2381%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2255%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2129%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.2005%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1881%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1758%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1830%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1514%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1780%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1852%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1731%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1610%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1491%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1562%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1634%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1894%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1586%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1280%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1164%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1048%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0933%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1004%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0890%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1146%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1217%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0919%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0990%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0694%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0765%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0654%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0543%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0614%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0684%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0395%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0287%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0357%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0071%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9787%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9681%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9753%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9648%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9895%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0140%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0384%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0453%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0521%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0589%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0656%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0723%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0618%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0685%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0581%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0647%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0543%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0271%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0169%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9899%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9798%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9698%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9432%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9333%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9235%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9138%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9372%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9274%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9507%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9738%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9967%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0033%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9935%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9838%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9903%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9968%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9710%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9775%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9840%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0064%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0287%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0350%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0095%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0000%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0063%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9969%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0345%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0094%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0000%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9906%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9969%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9721%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9938%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9846%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9754%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9662%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0031%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0092%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0152%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0061%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9970%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0333%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0091%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0151%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0060%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9970%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0030%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0239%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0744%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0653%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0711%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0621%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0973%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0735%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0499%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0410%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0321%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0233%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0000%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0203%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0405%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0462%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0662%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0431%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0344%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0257%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0171%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0370%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0142%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0340%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0537%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0451%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0648%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0983%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0757%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0531%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0307%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0362%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0417%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0333%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0525%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0442%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0496%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0412%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0329%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0246%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0437%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0354%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0408%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0597%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0379%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0297%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0081%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0269%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0054%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0241%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0027%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0080%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0266%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0318%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0106%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0423%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0211%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0395%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0446%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0498%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0418%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0861%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1172%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0962%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0882%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0932%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0852%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0773%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1080%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0873%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0794%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0971%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1148%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1324%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1245%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1166%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1215%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1263%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1310%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1861%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1657%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1578%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1625%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1672%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1718%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1640%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1687%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1485%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1655%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1578%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1378%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1302%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1103%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.1027%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0830%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0755%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0681%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0607%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0654%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0580%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0507%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0313%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0361%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0168%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9976%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0024%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0072%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0000%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0048%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0213%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0142%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0307%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0354%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0400%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0329%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0141%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0070%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0000%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9930%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9977%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9791%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9722%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9653%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9931%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9862%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9908%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9724%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0115%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0275%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0320%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0365%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0296%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0114%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0045%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0091%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0249%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0406%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0225%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0045%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0090%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0022%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9843%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9888%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9933%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0089%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0022%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0066%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0442%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0486%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0529%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0572%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0725%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0658%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0701%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0634%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0676%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0719%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0652%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0586%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0520%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0454%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0389%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0323%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0151%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0086%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0129%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0064%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0107%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0043%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9979%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9915%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9958%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0106%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0042%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0084%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0232%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0168%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0000%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0042%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0084%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9916%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9958%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9792%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9730%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9772%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9917%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9752%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9690%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9835%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9773%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9609%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9651%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9693%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9734%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9980%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0020%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9857%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0102%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0041%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9980%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0020%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0061%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0101%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9940%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:9.9779%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0020%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0060%\n",
      "Epoch [2/2], train_loss:0.1440, train_acc:10.0000%, test_loss:0.1440, test_acc:10.0000%\n"
     ]
    }
   ],
   "source": [
    "#训练&验证\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "half_model = DemoModel().to(device)\n",
    "\n",
    "# 损失函数：自定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 优化器\n",
    "optimizer = torch.optim.Adam(Resnet50_new.parameters(), lr=lr)\n",
    "epoch = max_epochs\n",
    "\n",
    "total_step = len(train_loader)\n",
    "train_all_loss = []\n",
    "test_all_loss = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    half_model.train()\n",
    "    train_total_loss = 0\n",
    "    train_total_num = 0\n",
    "    train_total_correct = 0\n",
    "\n",
    "    for iter, (images,labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        with autocast():\n",
    "            outputs = half_model(images)\n",
    "            loss = criterion(outputs,labels)\n",
    "            train_total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "            #backword\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            train_total_num += labels.shape[0]\n",
    "            train_total_loss += loss.item()\n",
    "            print(\"Epoch [{}/{}], Iter [{}/{}], train_loss:{:4f}\".format(i+1,epoch,iter+1,total_step,loss.item()/labels.shape[0]))\n",
    "    \n",
    "    half_model.eval()\n",
    "    test_total_loss = 0\n",
    "    test_total_correct = 0\n",
    "    test_total_num = 0\n",
    "    for iter,(images,labels) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        with autocast():\n",
    "            outputs = half_model(images)\n",
    "            loss = criterion(outputs,labels)\n",
    "            test_total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            test_total_loss += loss.item()\n",
    "            test_total_num += labels.shape[0]\n",
    "            print(\"Epoch [{}/{}], train_loss:{:.4f}, train_acc:{:.4f}%, test_loss:{:.4f}, test_acc:{:.4f}%\".format(\n",
    "                i+1, epoch, train_total_loss / train_total_num, train_total_correct / train_total_num * 100, test_total_loss / test_total_num, test_total_correct / test_total_num * 100\n",
    "    \n",
    "    ))\n",
    "    train_all_loss.append(np.round(train_total_loss / train_total_num,4))\n",
    "    test_all_loss.append(np.round(test_total_loss / test_total_num,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1353fc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
