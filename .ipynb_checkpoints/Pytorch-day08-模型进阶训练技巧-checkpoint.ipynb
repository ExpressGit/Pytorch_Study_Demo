{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c2a0956",
   "metadata": {},
   "source": [
    "## PyTorch 模型进阶训练技巧\n",
    "- 自定义损失函数\n",
    "- 动态调整学习率\n"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "a2f7cecb",
   "metadata": {},
   "source": [
    "典型案例：loss上下震荡\n",
    "![image-2.png](attachment:image-2.png)"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "8f4914cb",
   "metadata": {},
   "source": [
    "### 1、自定义损失函数\n",
    "- 1、PyTorch已经提供了很多常用的损失函数，但是有些非通用的损失函数并未提供，比如：DiceLoss、HuberLoss...等\n",
    "- 2、模型如果出现loss震荡，在经过调整数据集或超参后，现象依然存在，非通用损失函数或自定义损失函数针对特定模型会有更好的效果\n",
    "\n",
    "比如：DiceLoss是医学影像分割常用的损失函数，定义如下：\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "- Dice系数, 是一种集合相似度度量函数，通常用于计算两个样本的相似度(值范围为 [0, 1])：\n",
    "- ∣X∩Y∣表示X和Y之间的交集，∣ X ∣ 和∣ Y ∣ 分别表示X和Y的元素个数，其中，分子中的系数 2，是因为分母存在重复计算 X 和 Y 之间的共同元素的原因."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24a7ac6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0e71fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DiceLoss 实现 Vnet 医学影像分割模型的损失函数\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        intersection = (inputs * targets).sum()                  \n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "926a9fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义实现多分类损失函数 处理多分类\n",
    "# cross_entropy + L2正则化\n",
    "class MyLoss(torch.nn.Module):\n",
    "    def __init__(self, weight_decay=0.01):\n",
    "        super(MyLoss, self).__init__()\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets)\n",
    "        l2_loss = torch.tensor(0., requires_grad=True).to(inputs.device)\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                l2_loss += torch.norm(param)\n",
    "        loss = ce_loss + self.weight_decay * l2_loss\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e1541d",
   "metadata": {},
   "source": [
    "注：\n",
    "- 在自定义损失函数时，涉及到数学运算时，我们最好全程使用PyTorch提供的张量计算接口\n",
    "- 利用Pytorch张量自带的求导机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dabfe331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#超参数定义\n",
    "# 批次的大小\n",
    "batch_size = 16 #可选32、64、128\n",
    "# 优化器的学习率\n",
    "lr = 1e-4\n",
    "#运行epoch\n",
    "max_epochs = 2\n",
    "# 方案二：使用“device”，后续对要使用GPU的变量用.to(device)即可\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\") # 指明调用的GPU为1号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "110c6501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据读取\n",
    "#cifar10数据集为例给出构建Dataset类的方式\n",
    "from torchvision import datasets\n",
    "\n",
    "#“data_transform”可以对图像进行一定的变换，如翻转、裁剪、归一化等操作，可自己定义\n",
    "data_transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "                   ])\n",
    "\n",
    "\n",
    "train_cifar_dataset = datasets.CIFAR10('cifar10',train=True, download=False,transform=data_transform)\n",
    "test_cifar_dataset = datasets.CIFAR10('cifar10',train=False, download=False,transform=data_transform)\n",
    "\n",
    "#构建好Dataset后，就可以使用DataLoader来按批次读入数据了\n",
    "train_loader = torch.utils.data.DataLoader(train_cifar_dataset, \n",
    "                                           batch_size=batch_size, num_workers=4, \n",
    "                                           shuffle=True, drop_last=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_cifar_dataset, \n",
    "                                         batch_size=batch_size, num_workers=4, \n",
    "                                         shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3fdbd5c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\xulele\\Anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\Users\\xulele\\Anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# restnet50 pretrained\n",
    "Resnet50 = torchvision.models.resnet50(pretrained=True)\n",
    "Resnet50.fc.out_features=10\n",
    "print(Resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7006d3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [1/3125], train_loss:0.710159\n",
      "Epoch [1/10], Iter [2/3125], train_loss:0.761919\n",
      "Epoch [1/10], Iter [3/3125], train_loss:0.748266\n",
      "Epoch [1/10], Iter [4/3125], train_loss:0.777146\n",
      "Epoch [1/10], Iter [5/3125], train_loss:0.699766\n",
      "Epoch [1/10], Iter [6/3125], train_loss:0.741773\n",
      "Epoch [1/10], Iter [7/3125], train_loss:0.687201\n",
      "Epoch [1/10], Iter [8/3125], train_loss:0.618017\n",
      "Epoch [1/10], Iter [9/3125], train_loss:0.653016\n",
      "Epoch [1/10], Iter [10/3125], train_loss:0.690120\n",
      "Epoch [1/10], Iter [11/3125], train_loss:0.648009\n",
      "Epoch [1/10], Iter [12/3125], train_loss:0.694650\n",
      "Epoch [1/10], Iter [13/3125], train_loss:0.502452\n",
      "Epoch [1/10], Iter [14/3125], train_loss:0.538519\n",
      "Epoch [1/10], Iter [15/3125], train_loss:0.596250\n",
      "Epoch [1/10], Iter [16/3125], train_loss:0.607648\n",
      "Epoch [1/10], Iter [17/3125], train_loss:0.574751\n",
      "Epoch [1/10], Iter [18/3125], train_loss:0.584658\n",
      "Epoch [1/10], Iter [19/3125], train_loss:0.428719\n",
      "Epoch [1/10], Iter [20/3125], train_loss:0.530868\n",
      "Epoch [1/10], Iter [21/3125], train_loss:0.496522\n",
      "Epoch [1/10], Iter [22/3125], train_loss:0.463315\n",
      "Epoch [1/10], Iter [23/3125], train_loss:0.453258\n",
      "Epoch [1/10], Iter [24/3125], train_loss:0.409726\n",
      "Epoch [1/10], Iter [25/3125], train_loss:0.422388\n",
      "Epoch [1/10], Iter [26/3125], train_loss:0.414946\n",
      "Epoch [1/10], Iter [27/3125], train_loss:0.512142\n",
      "Epoch [1/10], Iter [28/3125], train_loss:0.400936\n",
      "Epoch [1/10], Iter [29/3125], train_loss:0.405139\n",
      "Epoch [1/10], Iter [30/3125], train_loss:0.346599\n",
      "Epoch [1/10], Iter [31/3125], train_loss:0.388829\n",
      "Epoch [1/10], Iter [32/3125], train_loss:0.389818\n",
      "Epoch [1/10], Iter [33/3125], train_loss:0.420276\n",
      "Epoch [1/10], Iter [34/3125], train_loss:0.376930\n",
      "Epoch [1/10], Iter [35/3125], train_loss:0.385421\n",
      "Epoch [1/10], Iter [36/3125], train_loss:0.308666\n",
      "Epoch [1/10], Iter [37/3125], train_loss:0.287350\n",
      "Epoch [1/10], Iter [38/3125], train_loss:0.235770\n",
      "Epoch [1/10], Iter [39/3125], train_loss:0.238073\n",
      "Epoch [1/10], Iter [40/3125], train_loss:0.255732\n",
      "Epoch [1/10], Iter [41/3125], train_loss:0.351971\n",
      "Epoch [1/10], Iter [42/3125], train_loss:0.255061\n",
      "Epoch [1/10], Iter [43/3125], train_loss:0.372930\n",
      "Epoch [1/10], Iter [44/3125], train_loss:0.294059\n",
      "Epoch [1/10], Iter [45/3125], train_loss:0.291519\n",
      "Epoch [1/10], Iter [46/3125], train_loss:0.293720\n",
      "Epoch [1/10], Iter [47/3125], train_loss:0.313904\n",
      "Epoch [1/10], Iter [48/3125], train_loss:0.468409\n",
      "Epoch [1/10], Iter [49/3125], train_loss:0.289942\n",
      "Epoch [1/10], Iter [50/3125], train_loss:0.314422\n",
      "Epoch [1/10], Iter [51/3125], train_loss:0.193365\n",
      "Epoch [1/10], Iter [52/3125], train_loss:0.280942\n",
      "Epoch [1/10], Iter [53/3125], train_loss:0.194293\n",
      "Epoch [1/10], Iter [54/3125], train_loss:0.271868\n",
      "Epoch [1/10], Iter [55/3125], train_loss:0.244220\n",
      "Epoch [1/10], Iter [56/3125], train_loss:0.203591\n",
      "Epoch [1/10], Iter [57/3125], train_loss:0.253909\n",
      "Epoch [1/10], Iter [58/3125], train_loss:0.189856\n",
      "Epoch [1/10], Iter [59/3125], train_loss:0.251850\n",
      "Epoch [1/10], Iter [60/3125], train_loss:0.231074\n",
      "Epoch [1/10], Iter [61/3125], train_loss:0.226731\n",
      "Epoch [1/10], Iter [62/3125], train_loss:0.175667\n",
      "Epoch [1/10], Iter [63/3125], train_loss:0.184940\n",
      "Epoch [1/10], Iter [64/3125], train_loss:0.210438\n",
      "Epoch [1/10], Iter [65/3125], train_loss:0.190574\n",
      "Epoch [1/10], Iter [66/3125], train_loss:0.238683\n",
      "Epoch [1/10], Iter [67/3125], train_loss:0.195508\n",
      "Epoch [1/10], Iter [68/3125], train_loss:0.152640\n",
      "Epoch [1/10], Iter [69/3125], train_loss:0.240555\n",
      "Epoch [1/10], Iter [70/3125], train_loss:0.134351\n",
      "Epoch [1/10], Iter [71/3125], train_loss:0.183020\n",
      "Epoch [1/10], Iter [72/3125], train_loss:0.211488\n",
      "Epoch [1/10], Iter [73/3125], train_loss:0.140310\n",
      "Epoch [1/10], Iter [74/3125], train_loss:0.162346\n",
      "Epoch [1/10], Iter [75/3125], train_loss:0.175559\n",
      "Epoch [1/10], Iter [76/3125], train_loss:0.165264\n",
      "Epoch [1/10], Iter [77/3125], train_loss:0.232803\n",
      "Epoch [1/10], Iter [78/3125], train_loss:0.175323\n",
      "Epoch [1/10], Iter [79/3125], train_loss:0.215453\n",
      "Epoch [1/10], Iter [80/3125], train_loss:0.229922\n",
      "Epoch [1/10], Iter [81/3125], train_loss:0.166971\n",
      "Epoch [1/10], Iter [82/3125], train_loss:0.252459\n",
      "Epoch [1/10], Iter [83/3125], train_loss:0.175405\n",
      "Epoch [1/10], Iter [84/3125], train_loss:0.174851\n",
      "Epoch [1/10], Iter [85/3125], train_loss:0.219277\n",
      "Epoch [1/10], Iter [86/3125], train_loss:0.200698\n",
      "Epoch [1/10], Iter [87/3125], train_loss:0.164529\n",
      "Epoch [1/10], Iter [88/3125], train_loss:0.223835\n",
      "Epoch [1/10], Iter [89/3125], train_loss:0.132322\n",
      "Epoch [1/10], Iter [90/3125], train_loss:0.185210\n",
      "Epoch [1/10], Iter [91/3125], train_loss:0.125042\n",
      "Epoch [1/10], Iter [92/3125], train_loss:0.127481\n",
      "Epoch [1/10], Iter [93/3125], train_loss:0.213097\n",
      "Epoch [1/10], Iter [94/3125], train_loss:0.191506\n",
      "Epoch [1/10], Iter [95/3125], train_loss:0.169901\n",
      "Epoch [1/10], Iter [96/3125], train_loss:0.177843\n",
      "Epoch [1/10], Iter [97/3125], train_loss:0.192217\n",
      "Epoch [1/10], Iter [98/3125], train_loss:0.186991\n",
      "Epoch [1/10], Iter [99/3125], train_loss:0.127605\n",
      "Epoch [1/10], Iter [100/3125], train_loss:0.130038\n",
      "Epoch [1/10], Iter [101/3125], train_loss:0.139159\n",
      "Epoch [1/10], Iter [102/3125], train_loss:0.152760\n",
      "Epoch [1/10], Iter [103/3125], train_loss:0.152227\n",
      "Epoch [1/10], Iter [104/3125], train_loss:0.128511\n",
      "Epoch [1/10], Iter [105/3125], train_loss:0.126772\n",
      "Epoch [1/10], Iter [106/3125], train_loss:0.220105\n",
      "Epoch [1/10], Iter [107/3125], train_loss:0.163889\n",
      "Epoch [1/10], Iter [108/3125], train_loss:0.205263\n",
      "Epoch [1/10], Iter [109/3125], train_loss:0.181927\n",
      "Epoch [1/10], Iter [110/3125], train_loss:0.126500\n",
      "Epoch [1/10], Iter [111/3125], train_loss:0.154556\n",
      "Epoch [1/10], Iter [112/3125], train_loss:0.169978\n",
      "Epoch [1/10], Iter [113/3125], train_loss:0.166387\n",
      "Epoch [1/10], Iter [114/3125], train_loss:0.160409\n",
      "Epoch [1/10], Iter [115/3125], train_loss:0.123102\n",
      "Epoch [1/10], Iter [116/3125], train_loss:0.133461\n",
      "Epoch [1/10], Iter [117/3125], train_loss:0.136813\n",
      "Epoch [1/10], Iter [118/3125], train_loss:0.100353\n",
      "Epoch [1/10], Iter [119/3125], train_loss:0.126170\n",
      "Epoch [1/10], Iter [120/3125], train_loss:0.141422\n",
      "Epoch [1/10], Iter [121/3125], train_loss:0.157280\n",
      "Epoch [1/10], Iter [122/3125], train_loss:0.113595\n",
      "Epoch [1/10], Iter [123/3125], train_loss:0.159074\n",
      "Epoch [1/10], Iter [124/3125], train_loss:0.108684\n",
      "Epoch [1/10], Iter [125/3125], train_loss:0.175729\n",
      "Epoch [1/10], Iter [126/3125], train_loss:0.071910\n",
      "Epoch [1/10], Iter [127/3125], train_loss:0.124298\n",
      "Epoch [1/10], Iter [128/3125], train_loss:0.115980\n",
      "Epoch [1/10], Iter [129/3125], train_loss:0.132223\n",
      "Epoch [1/10], Iter [130/3125], train_loss:0.114184\n",
      "Epoch [1/10], Iter [131/3125], train_loss:0.123914\n",
      "Epoch [1/10], Iter [132/3125], train_loss:0.150845\n",
      "Epoch [1/10], Iter [133/3125], train_loss:0.208639\n",
      "Epoch [1/10], Iter [134/3125], train_loss:0.106705\n",
      "Epoch [1/10], Iter [135/3125], train_loss:0.177262\n",
      "Epoch [1/10], Iter [136/3125], train_loss:0.157350\n",
      "Epoch [1/10], Iter [137/3125], train_loss:0.149479\n",
      "Epoch [1/10], Iter [138/3125], train_loss:0.096941\n",
      "Epoch [1/10], Iter [139/3125], train_loss:0.174548\n",
      "Epoch [1/10], Iter [140/3125], train_loss:0.156214\n",
      "Epoch [1/10], Iter [141/3125], train_loss:0.135187\n",
      "Epoch [1/10], Iter [142/3125], train_loss:0.136901\n",
      "Epoch [1/10], Iter [143/3125], train_loss:0.122161\n",
      "Epoch [1/10], Iter [144/3125], train_loss:0.139143\n",
      "Epoch [1/10], Iter [145/3125], train_loss:0.119795\n",
      "Epoch [1/10], Iter [146/3125], train_loss:0.122523\n",
      "Epoch [1/10], Iter [147/3125], train_loss:0.136952\n",
      "Epoch [1/10], Iter [148/3125], train_loss:0.175852\n",
      "Epoch [1/10], Iter [149/3125], train_loss:0.107031\n",
      "Epoch [1/10], Iter [150/3125], train_loss:0.175130\n",
      "Epoch [1/10], Iter [151/3125], train_loss:0.159306\n",
      "Epoch [1/10], Iter [152/3125], train_loss:0.149552\n",
      "Epoch [1/10], Iter [153/3125], train_loss:0.166173\n",
      "Epoch [1/10], Iter [154/3125], train_loss:0.165044\n",
      "Epoch [1/10], Iter [155/3125], train_loss:0.116875\n",
      "Epoch [1/10], Iter [156/3125], train_loss:0.104037\n",
      "Epoch [1/10], Iter [157/3125], train_loss:0.129057\n",
      "Epoch [1/10], Iter [158/3125], train_loss:0.141920\n",
      "Epoch [1/10], Iter [159/3125], train_loss:0.102720\n",
      "Epoch [1/10], Iter [160/3125], train_loss:0.097012\n",
      "Epoch [1/10], Iter [161/3125], train_loss:0.157148\n",
      "Epoch [1/10], Iter [162/3125], train_loss:0.117710\n",
      "Epoch [1/10], Iter [163/3125], train_loss:0.112908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [164/3125], train_loss:0.096563\n",
      "Epoch [1/10], Iter [165/3125], train_loss:0.076501\n",
      "Epoch [1/10], Iter [166/3125], train_loss:0.147476\n",
      "Epoch [1/10], Iter [167/3125], train_loss:0.177934\n",
      "Epoch [1/10], Iter [168/3125], train_loss:0.121549\n",
      "Epoch [1/10], Iter [169/3125], train_loss:0.124102\n",
      "Epoch [1/10], Iter [170/3125], train_loss:0.097225\n",
      "Epoch [1/10], Iter [171/3125], train_loss:0.104199\n",
      "Epoch [1/10], Iter [172/3125], train_loss:0.150368\n",
      "Epoch [1/10], Iter [173/3125], train_loss:0.098011\n",
      "Epoch [1/10], Iter [174/3125], train_loss:0.131318\n",
      "Epoch [1/10], Iter [175/3125], train_loss:0.120925\n",
      "Epoch [1/10], Iter [176/3125], train_loss:0.120460\n",
      "Epoch [1/10], Iter [177/3125], train_loss:0.106729\n",
      "Epoch [1/10], Iter [178/3125], train_loss:0.161727\n",
      "Epoch [1/10], Iter [179/3125], train_loss:0.169705\n",
      "Epoch [1/10], Iter [180/3125], train_loss:0.142939\n",
      "Epoch [1/10], Iter [181/3125], train_loss:0.120374\n",
      "Epoch [1/10], Iter [182/3125], train_loss:0.120579\n",
      "Epoch [1/10], Iter [183/3125], train_loss:0.093452\n",
      "Epoch [1/10], Iter [184/3125], train_loss:0.102697\n",
      "Epoch [1/10], Iter [185/3125], train_loss:0.129010\n",
      "Epoch [1/10], Iter [186/3125], train_loss:0.127772\n",
      "Epoch [1/10], Iter [187/3125], train_loss:0.121482\n",
      "Epoch [1/10], Iter [188/3125], train_loss:0.153874\n",
      "Epoch [1/10], Iter [189/3125], train_loss:0.122253\n",
      "Epoch [1/10], Iter [190/3125], train_loss:0.135232\n",
      "Epoch [1/10], Iter [191/3125], train_loss:0.095962\n",
      "Epoch [1/10], Iter [192/3125], train_loss:0.159813\n",
      "Epoch [1/10], Iter [193/3125], train_loss:0.110215\n",
      "Epoch [1/10], Iter [194/3125], train_loss:0.103142\n",
      "Epoch [1/10], Iter [195/3125], train_loss:0.106792\n",
      "Epoch [1/10], Iter [196/3125], train_loss:0.108262\n",
      "Epoch [1/10], Iter [197/3125], train_loss:0.109841\n",
      "Epoch [1/10], Iter [198/3125], train_loss:0.141134\n",
      "Epoch [1/10], Iter [199/3125], train_loss:0.104478\n",
      "Epoch [1/10], Iter [200/3125], train_loss:0.119154\n",
      "Epoch [1/10], Iter [201/3125], train_loss:0.143389\n",
      "Epoch [1/10], Iter [202/3125], train_loss:0.106533\n",
      "Epoch [1/10], Iter [203/3125], train_loss:0.104834\n",
      "Epoch [1/10], Iter [204/3125], train_loss:0.096285\n",
      "Epoch [1/10], Iter [205/3125], train_loss:0.192590\n",
      "Epoch [1/10], Iter [206/3125], train_loss:0.131787\n",
      "Epoch [1/10], Iter [207/3125], train_loss:0.093841\n",
      "Epoch [1/10], Iter [208/3125], train_loss:0.093261\n",
      "Epoch [1/10], Iter [209/3125], train_loss:0.090215\n",
      "Epoch [1/10], Iter [210/3125], train_loss:0.062551\n",
      "Epoch [1/10], Iter [211/3125], train_loss:0.103201\n",
      "Epoch [1/10], Iter [212/3125], train_loss:0.101281\n",
      "Epoch [1/10], Iter [213/3125], train_loss:0.112832\n",
      "Epoch [1/10], Iter [214/3125], train_loss:0.109726\n",
      "Epoch [1/10], Iter [215/3125], train_loss:0.193847\n",
      "Epoch [1/10], Iter [216/3125], train_loss:0.114712\n",
      "Epoch [1/10], Iter [217/3125], train_loss:0.096408\n",
      "Epoch [1/10], Iter [218/3125], train_loss:0.104277\n",
      "Epoch [1/10], Iter [219/3125], train_loss:0.101230\n",
      "Epoch [1/10], Iter [220/3125], train_loss:0.088779\n",
      "Epoch [1/10], Iter [221/3125], train_loss:0.122967\n",
      "Epoch [1/10], Iter [222/3125], train_loss:0.132155\n",
      "Epoch [1/10], Iter [223/3125], train_loss:0.106906\n",
      "Epoch [1/10], Iter [224/3125], train_loss:0.101865\n",
      "Epoch [1/10], Iter [225/3125], train_loss:0.094080\n",
      "Epoch [1/10], Iter [226/3125], train_loss:0.117470\n",
      "Epoch [1/10], Iter [227/3125], train_loss:0.107198\n",
      "Epoch [1/10], Iter [228/3125], train_loss:0.113856\n",
      "Epoch [1/10], Iter [229/3125], train_loss:0.113308\n",
      "Epoch [1/10], Iter [230/3125], train_loss:0.136503\n",
      "Epoch [1/10], Iter [231/3125], train_loss:0.096320\n",
      "Epoch [1/10], Iter [232/3125], train_loss:0.131607\n",
      "Epoch [1/10], Iter [233/3125], train_loss:0.140338\n",
      "Epoch [1/10], Iter [234/3125], train_loss:0.125807\n",
      "Epoch [1/10], Iter [235/3125], train_loss:0.109107\n",
      "Epoch [1/10], Iter [236/3125], train_loss:0.104653\n",
      "Epoch [1/10], Iter [237/3125], train_loss:0.112867\n",
      "Epoch [1/10], Iter [238/3125], train_loss:0.096239\n",
      "Epoch [1/10], Iter [239/3125], train_loss:0.113070\n",
      "Epoch [1/10], Iter [240/3125], train_loss:0.138504\n",
      "Epoch [1/10], Iter [241/3125], train_loss:0.116264\n",
      "Epoch [1/10], Iter [242/3125], train_loss:0.140497\n",
      "Epoch [1/10], Iter [243/3125], train_loss:0.111269\n",
      "Epoch [1/10], Iter [244/3125], train_loss:0.126607\n",
      "Epoch [1/10], Iter [245/3125], train_loss:0.166210\n",
      "Epoch [1/10], Iter [246/3125], train_loss:0.114601\n",
      "Epoch [1/10], Iter [247/3125], train_loss:0.086945\n",
      "Epoch [1/10], Iter [248/3125], train_loss:0.117582\n",
      "Epoch [1/10], Iter [249/3125], train_loss:0.103387\n",
      "Epoch [1/10], Iter [250/3125], train_loss:0.105529\n",
      "Epoch [1/10], Iter [251/3125], train_loss:0.095726\n",
      "Epoch [1/10], Iter [252/3125], train_loss:0.099371\n",
      "Epoch [1/10], Iter [253/3125], train_loss:0.086019\n",
      "Epoch [1/10], Iter [254/3125], train_loss:0.117785\n",
      "Epoch [1/10], Iter [255/3125], train_loss:0.095674\n",
      "Epoch [1/10], Iter [256/3125], train_loss:0.107202\n",
      "Epoch [1/10], Iter [257/3125], train_loss:0.106855\n",
      "Epoch [1/10], Iter [258/3125], train_loss:0.089076\n",
      "Epoch [1/10], Iter [259/3125], train_loss:0.085481\n",
      "Epoch [1/10], Iter [260/3125], train_loss:0.105372\n",
      "Epoch [1/10], Iter [261/3125], train_loss:0.135841\n",
      "Epoch [1/10], Iter [262/3125], train_loss:0.091050\n",
      "Epoch [1/10], Iter [263/3125], train_loss:0.104396\n",
      "Epoch [1/10], Iter [264/3125], train_loss:0.085995\n",
      "Epoch [1/10], Iter [265/3125], train_loss:0.082015\n",
      "Epoch [1/10], Iter [266/3125], train_loss:0.101983\n",
      "Epoch [1/10], Iter [267/3125], train_loss:0.082330\n",
      "Epoch [1/10], Iter [268/3125], train_loss:0.096020\n",
      "Epoch [1/10], Iter [269/3125], train_loss:0.107438\n",
      "Epoch [1/10], Iter [270/3125], train_loss:0.108927\n",
      "Epoch [1/10], Iter [271/3125], train_loss:0.090110\n",
      "Epoch [1/10], Iter [272/3125], train_loss:0.082612\n",
      "Epoch [1/10], Iter [273/3125], train_loss:0.124343\n",
      "Epoch [1/10], Iter [274/3125], train_loss:0.134607\n",
      "Epoch [1/10], Iter [275/3125], train_loss:0.103530\n",
      "Epoch [1/10], Iter [276/3125], train_loss:0.088286\n",
      "Epoch [1/10], Iter [277/3125], train_loss:0.120471\n",
      "Epoch [1/10], Iter [278/3125], train_loss:0.090534\n",
      "Epoch [1/10], Iter [279/3125], train_loss:0.098560\n",
      "Epoch [1/10], Iter [280/3125], train_loss:0.093890\n",
      "Epoch [1/10], Iter [281/3125], train_loss:0.114845\n",
      "Epoch [1/10], Iter [282/3125], train_loss:0.155583\n",
      "Epoch [1/10], Iter [283/3125], train_loss:0.084580\n",
      "Epoch [1/10], Iter [284/3125], train_loss:0.078266\n",
      "Epoch [1/10], Iter [285/3125], train_loss:0.089209\n",
      "Epoch [1/10], Iter [286/3125], train_loss:0.129949\n",
      "Epoch [1/10], Iter [287/3125], train_loss:0.068909\n",
      "Epoch [1/10], Iter [288/3125], train_loss:0.120867\n",
      "Epoch [1/10], Iter [289/3125], train_loss:0.107639\n",
      "Epoch [1/10], Iter [290/3125], train_loss:0.099353\n",
      "Epoch [1/10], Iter [291/3125], train_loss:0.132016\n",
      "Epoch [1/10], Iter [292/3125], train_loss:0.090960\n",
      "Epoch [1/10], Iter [293/3125], train_loss:0.101058\n",
      "Epoch [1/10], Iter [294/3125], train_loss:0.096238\n",
      "Epoch [1/10], Iter [295/3125], train_loss:0.084716\n",
      "Epoch [1/10], Iter [296/3125], train_loss:0.079769\n",
      "Epoch [1/10], Iter [297/3125], train_loss:0.124798\n",
      "Epoch [1/10], Iter [298/3125], train_loss:0.096835\n",
      "Epoch [1/10], Iter [299/3125], train_loss:0.089952\n",
      "Epoch [1/10], Iter [300/3125], train_loss:0.095460\n",
      "Epoch [1/10], Iter [301/3125], train_loss:0.086470\n",
      "Epoch [1/10], Iter [302/3125], train_loss:0.105848\n",
      "Epoch [1/10], Iter [303/3125], train_loss:0.130099\n",
      "Epoch [1/10], Iter [304/3125], train_loss:0.131335\n",
      "Epoch [1/10], Iter [305/3125], train_loss:0.103911\n",
      "Epoch [1/10], Iter [306/3125], train_loss:0.092839\n",
      "Epoch [1/10], Iter [307/3125], train_loss:0.128423\n",
      "Epoch [1/10], Iter [308/3125], train_loss:0.101717\n",
      "Epoch [1/10], Iter [309/3125], train_loss:0.102042\n",
      "Epoch [1/10], Iter [310/3125], train_loss:0.108195\n",
      "Epoch [1/10], Iter [311/3125], train_loss:0.116109\n",
      "Epoch [1/10], Iter [312/3125], train_loss:0.107782\n",
      "Epoch [1/10], Iter [313/3125], train_loss:0.102813\n",
      "Epoch [1/10], Iter [314/3125], train_loss:0.095960\n",
      "Epoch [1/10], Iter [315/3125], train_loss:0.086566\n",
      "Epoch [1/10], Iter [316/3125], train_loss:0.081492\n",
      "Epoch [1/10], Iter [317/3125], train_loss:0.077582\n",
      "Epoch [1/10], Iter [318/3125], train_loss:0.053461\n",
      "Epoch [1/10], Iter [319/3125], train_loss:0.084671\n",
      "Epoch [1/10], Iter [320/3125], train_loss:0.088476\n",
      "Epoch [1/10], Iter [321/3125], train_loss:0.105547\n",
      "Epoch [1/10], Iter [322/3125], train_loss:0.079457\n",
      "Epoch [1/10], Iter [323/3125], train_loss:0.080500\n",
      "Epoch [1/10], Iter [324/3125], train_loss:0.116692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [325/3125], train_loss:0.095060\n",
      "Epoch [1/10], Iter [326/3125], train_loss:0.090416\n",
      "Epoch [1/10], Iter [327/3125], train_loss:0.068069\n",
      "Epoch [1/10], Iter [328/3125], train_loss:0.110763\n",
      "Epoch [1/10], Iter [329/3125], train_loss:0.060889\n",
      "Epoch [1/10], Iter [330/3125], train_loss:0.110807\n",
      "Epoch [1/10], Iter [331/3125], train_loss:0.122002\n",
      "Epoch [1/10], Iter [332/3125], train_loss:0.115815\n",
      "Epoch [1/10], Iter [333/3125], train_loss:0.067004\n",
      "Epoch [1/10], Iter [334/3125], train_loss:0.063815\n",
      "Epoch [1/10], Iter [335/3125], train_loss:0.120017\n",
      "Epoch [1/10], Iter [336/3125], train_loss:0.104086\n",
      "Epoch [1/10], Iter [337/3125], train_loss:0.091577\n",
      "Epoch [1/10], Iter [338/3125], train_loss:0.084077\n",
      "Epoch [1/10], Iter [339/3125], train_loss:0.113410\n",
      "Epoch [1/10], Iter [340/3125], train_loss:0.061866\n",
      "Epoch [1/10], Iter [341/3125], train_loss:0.101881\n",
      "Epoch [1/10], Iter [342/3125], train_loss:0.107144\n",
      "Epoch [1/10], Iter [343/3125], train_loss:0.142906\n",
      "Epoch [1/10], Iter [344/3125], train_loss:0.072013\n",
      "Epoch [1/10], Iter [345/3125], train_loss:0.088949\n",
      "Epoch [1/10], Iter [346/3125], train_loss:0.067578\n",
      "Epoch [1/10], Iter [347/3125], train_loss:0.086871\n",
      "Epoch [1/10], Iter [348/3125], train_loss:0.068842\n",
      "Epoch [1/10], Iter [349/3125], train_loss:0.086257\n",
      "Epoch [1/10], Iter [350/3125], train_loss:0.112828\n",
      "Epoch [1/10], Iter [351/3125], train_loss:0.090362\n",
      "Epoch [1/10], Iter [352/3125], train_loss:0.092230\n",
      "Epoch [1/10], Iter [353/3125], train_loss:0.058990\n",
      "Epoch [1/10], Iter [354/3125], train_loss:0.114826\n",
      "Epoch [1/10], Iter [355/3125], train_loss:0.076303\n",
      "Epoch [1/10], Iter [356/3125], train_loss:0.115605\n",
      "Epoch [1/10], Iter [357/3125], train_loss:0.083856\n",
      "Epoch [1/10], Iter [358/3125], train_loss:0.114196\n",
      "Epoch [1/10], Iter [359/3125], train_loss:0.154424\n",
      "Epoch [1/10], Iter [360/3125], train_loss:0.103248\n",
      "Epoch [1/10], Iter [361/3125], train_loss:0.093536\n",
      "Epoch [1/10], Iter [362/3125], train_loss:0.064217\n",
      "Epoch [1/10], Iter [363/3125], train_loss:0.103777\n",
      "Epoch [1/10], Iter [364/3125], train_loss:0.049145\n",
      "Epoch [1/10], Iter [365/3125], train_loss:0.085676\n",
      "Epoch [1/10], Iter [366/3125], train_loss:0.095860\n",
      "Epoch [1/10], Iter [367/3125], train_loss:0.045282\n",
      "Epoch [1/10], Iter [368/3125], train_loss:0.102015\n",
      "Epoch [1/10], Iter [369/3125], train_loss:0.073394\n",
      "Epoch [1/10], Iter [370/3125], train_loss:0.080284\n",
      "Epoch [1/10], Iter [371/3125], train_loss:0.094347\n",
      "Epoch [1/10], Iter [372/3125], train_loss:0.085500\n",
      "Epoch [1/10], Iter [373/3125], train_loss:0.119371\n",
      "Epoch [1/10], Iter [374/3125], train_loss:0.095046\n",
      "Epoch [1/10], Iter [375/3125], train_loss:0.118757\n",
      "Epoch [1/10], Iter [376/3125], train_loss:0.107976\n",
      "Epoch [1/10], Iter [377/3125], train_loss:0.090448\n",
      "Epoch [1/10], Iter [378/3125], train_loss:0.085898\n",
      "Epoch [1/10], Iter [379/3125], train_loss:0.110092\n",
      "Epoch [1/10], Iter [380/3125], train_loss:0.093738\n",
      "Epoch [1/10], Iter [381/3125], train_loss:0.094126\n",
      "Epoch [1/10], Iter [382/3125], train_loss:0.087205\n",
      "Epoch [1/10], Iter [383/3125], train_loss:0.083657\n",
      "Epoch [1/10], Iter [384/3125], train_loss:0.080641\n",
      "Epoch [1/10], Iter [385/3125], train_loss:0.101648\n",
      "Epoch [1/10], Iter [386/3125], train_loss:0.102539\n",
      "Epoch [1/10], Iter [387/3125], train_loss:0.090064\n",
      "Epoch [1/10], Iter [388/3125], train_loss:0.140402\n",
      "Epoch [1/10], Iter [389/3125], train_loss:0.100177\n",
      "Epoch [1/10], Iter [390/3125], train_loss:0.106683\n",
      "Epoch [1/10], Iter [391/3125], train_loss:0.072911\n",
      "Epoch [1/10], Iter [392/3125], train_loss:0.094680\n",
      "Epoch [1/10], Iter [393/3125], train_loss:0.097260\n",
      "Epoch [1/10], Iter [394/3125], train_loss:0.104942\n",
      "Epoch [1/10], Iter [395/3125], train_loss:0.133387\n",
      "Epoch [1/10], Iter [396/3125], train_loss:0.131581\n",
      "Epoch [1/10], Iter [397/3125], train_loss:0.107176\n",
      "Epoch [1/10], Iter [398/3125], train_loss:0.076420\n",
      "Epoch [1/10], Iter [399/3125], train_loss:0.071057\n",
      "Epoch [1/10], Iter [400/3125], train_loss:0.102585\n",
      "Epoch [1/10], Iter [401/3125], train_loss:0.071347\n",
      "Epoch [1/10], Iter [402/3125], train_loss:0.104381\n",
      "Epoch [1/10], Iter [403/3125], train_loss:0.111743\n",
      "Epoch [1/10], Iter [404/3125], train_loss:0.081141\n",
      "Epoch [1/10], Iter [405/3125], train_loss:0.071977\n",
      "Epoch [1/10], Iter [406/3125], train_loss:0.095490\n",
      "Epoch [1/10], Iter [407/3125], train_loss:0.085300\n",
      "Epoch [1/10], Iter [408/3125], train_loss:0.068072\n",
      "Epoch [1/10], Iter [409/3125], train_loss:0.068445\n",
      "Epoch [1/10], Iter [410/3125], train_loss:0.092671\n",
      "Epoch [1/10], Iter [411/3125], train_loss:0.066765\n",
      "Epoch [1/10], Iter [412/3125], train_loss:0.107009\n",
      "Epoch [1/10], Iter [413/3125], train_loss:0.072693\n",
      "Epoch [1/10], Iter [414/3125], train_loss:0.088150\n",
      "Epoch [1/10], Iter [415/3125], train_loss:0.090847\n",
      "Epoch [1/10], Iter [416/3125], train_loss:0.077029\n",
      "Epoch [1/10], Iter [417/3125], train_loss:0.102404\n",
      "Epoch [1/10], Iter [418/3125], train_loss:0.138703\n",
      "Epoch [1/10], Iter [419/3125], train_loss:0.074720\n",
      "Epoch [1/10], Iter [420/3125], train_loss:0.103256\n",
      "Epoch [1/10], Iter [421/3125], train_loss:0.091416\n",
      "Epoch [1/10], Iter [422/3125], train_loss:0.104568\n",
      "Epoch [1/10], Iter [423/3125], train_loss:0.077688\n",
      "Epoch [1/10], Iter [424/3125], train_loss:0.090047\n",
      "Epoch [1/10], Iter [425/3125], train_loss:0.127545\n",
      "Epoch [1/10], Iter [426/3125], train_loss:0.088344\n",
      "Epoch [1/10], Iter [427/3125], train_loss:0.101759\n",
      "Epoch [1/10], Iter [428/3125], train_loss:0.079185\n",
      "Epoch [1/10], Iter [429/3125], train_loss:0.063097\n",
      "Epoch [1/10], Iter [430/3125], train_loss:0.121180\n",
      "Epoch [1/10], Iter [431/3125], train_loss:0.101340\n",
      "Epoch [1/10], Iter [432/3125], train_loss:0.128714\n",
      "Epoch [1/10], Iter [433/3125], train_loss:0.062577\n",
      "Epoch [1/10], Iter [434/3125], train_loss:0.091420\n",
      "Epoch [1/10], Iter [435/3125], train_loss:0.090504\n",
      "Epoch [1/10], Iter [436/3125], train_loss:0.119372\n",
      "Epoch [1/10], Iter [437/3125], train_loss:0.066290\n",
      "Epoch [1/10], Iter [438/3125], train_loss:0.119662\n",
      "Epoch [1/10], Iter [439/3125], train_loss:0.110264\n",
      "Epoch [1/10], Iter [440/3125], train_loss:0.079450\n",
      "Epoch [1/10], Iter [441/3125], train_loss:0.111833\n",
      "Epoch [1/10], Iter [442/3125], train_loss:0.094980\n",
      "Epoch [1/10], Iter [443/3125], train_loss:0.111621\n",
      "Epoch [1/10], Iter [444/3125], train_loss:0.082750\n",
      "Epoch [1/10], Iter [445/3125], train_loss:0.104502\n",
      "Epoch [1/10], Iter [446/3125], train_loss:0.114041\n",
      "Epoch [1/10], Iter [447/3125], train_loss:0.071238\n",
      "Epoch [1/10], Iter [448/3125], train_loss:0.088294\n",
      "Epoch [1/10], Iter [449/3125], train_loss:0.069142\n",
      "Epoch [1/10], Iter [450/3125], train_loss:0.129054\n",
      "Epoch [1/10], Iter [451/3125], train_loss:0.091864\n",
      "Epoch [1/10], Iter [452/3125], train_loss:0.080189\n",
      "Epoch [1/10], Iter [453/3125], train_loss:0.060313\n",
      "Epoch [1/10], Iter [454/3125], train_loss:0.129373\n",
      "Epoch [1/10], Iter [455/3125], train_loss:0.073149\n",
      "Epoch [1/10], Iter [456/3125], train_loss:0.073206\n",
      "Epoch [1/10], Iter [457/3125], train_loss:0.088790\n",
      "Epoch [1/10], Iter [458/3125], train_loss:0.066144\n",
      "Epoch [1/10], Iter [459/3125], train_loss:0.103504\n",
      "Epoch [1/10], Iter [460/3125], train_loss:0.060709\n",
      "Epoch [1/10], Iter [461/3125], train_loss:0.108793\n",
      "Epoch [1/10], Iter [462/3125], train_loss:0.093702\n",
      "Epoch [1/10], Iter [463/3125], train_loss:0.116326\n",
      "Epoch [1/10], Iter [464/3125], train_loss:0.104743\n",
      "Epoch [1/10], Iter [465/3125], train_loss:0.082492\n",
      "Epoch [1/10], Iter [466/3125], train_loss:0.092319\n",
      "Epoch [1/10], Iter [467/3125], train_loss:0.065833\n",
      "Epoch [1/10], Iter [468/3125], train_loss:0.051208\n",
      "Epoch [1/10], Iter [469/3125], train_loss:0.093229\n",
      "Epoch [1/10], Iter [470/3125], train_loss:0.095329\n",
      "Epoch [1/10], Iter [471/3125], train_loss:0.099470\n",
      "Epoch [1/10], Iter [472/3125], train_loss:0.072319\n",
      "Epoch [1/10], Iter [473/3125], train_loss:0.062743\n",
      "Epoch [1/10], Iter [474/3125], train_loss:0.108008\n",
      "Epoch [1/10], Iter [475/3125], train_loss:0.046297\n",
      "Epoch [1/10], Iter [476/3125], train_loss:0.077335\n",
      "Epoch [1/10], Iter [477/3125], train_loss:0.088254\n",
      "Epoch [1/10], Iter [478/3125], train_loss:0.101036\n",
      "Epoch [1/10], Iter [479/3125], train_loss:0.083029\n",
      "Epoch [1/10], Iter [480/3125], train_loss:0.097751\n",
      "Epoch [1/10], Iter [481/3125], train_loss:0.096469\n",
      "Epoch [1/10], Iter [482/3125], train_loss:0.087993\n",
      "Epoch [1/10], Iter [483/3125], train_loss:0.099732\n",
      "Epoch [1/10], Iter [484/3125], train_loss:0.073528\n",
      "Epoch [1/10], Iter [485/3125], train_loss:0.101679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [486/3125], train_loss:0.100552\n",
      "Epoch [1/10], Iter [487/3125], train_loss:0.087380\n",
      "Epoch [1/10], Iter [488/3125], train_loss:0.121468\n",
      "Epoch [1/10], Iter [489/3125], train_loss:0.097617\n",
      "Epoch [1/10], Iter [490/3125], train_loss:0.104743\n",
      "Epoch [1/10], Iter [491/3125], train_loss:0.078716\n",
      "Epoch [1/10], Iter [492/3125], train_loss:0.098265\n",
      "Epoch [1/10], Iter [493/3125], train_loss:0.082094\n",
      "Epoch [1/10], Iter [494/3125], train_loss:0.087327\n",
      "Epoch [1/10], Iter [495/3125], train_loss:0.069399\n",
      "Epoch [1/10], Iter [496/3125], train_loss:0.066200\n",
      "Epoch [1/10], Iter [497/3125], train_loss:0.068601\n",
      "Epoch [1/10], Iter [498/3125], train_loss:0.126001\n",
      "Epoch [1/10], Iter [499/3125], train_loss:0.085090\n",
      "Epoch [1/10], Iter [500/3125], train_loss:0.109014\n",
      "Epoch [1/10], Iter [501/3125], train_loss:0.106699\n",
      "Epoch [1/10], Iter [502/3125], train_loss:0.082973\n",
      "Epoch [1/10], Iter [503/3125], train_loss:0.095683\n",
      "Epoch [1/10], Iter [504/3125], train_loss:0.113937\n",
      "Epoch [1/10], Iter [505/3125], train_loss:0.032092\n",
      "Epoch [1/10], Iter [506/3125], train_loss:0.071751\n",
      "Epoch [1/10], Iter [507/3125], train_loss:0.082614\n",
      "Epoch [1/10], Iter [508/3125], train_loss:0.076657\n",
      "Epoch [1/10], Iter [509/3125], train_loss:0.078356\n",
      "Epoch [1/10], Iter [510/3125], train_loss:0.109523\n",
      "Epoch [1/10], Iter [511/3125], train_loss:0.108152\n",
      "Epoch [1/10], Iter [512/3125], train_loss:0.092030\n",
      "Epoch [1/10], Iter [513/3125], train_loss:0.115947\n",
      "Epoch [1/10], Iter [514/3125], train_loss:0.108748\n",
      "Epoch [1/10], Iter [515/3125], train_loss:0.091761\n",
      "Epoch [1/10], Iter [516/3125], train_loss:0.073188\n",
      "Epoch [1/10], Iter [517/3125], train_loss:0.120827\n",
      "Epoch [1/10], Iter [518/3125], train_loss:0.067271\n",
      "Epoch [1/10], Iter [519/3125], train_loss:0.050369\n",
      "Epoch [1/10], Iter [520/3125], train_loss:0.070868\n",
      "Epoch [1/10], Iter [521/3125], train_loss:0.113249\n",
      "Epoch [1/10], Iter [522/3125], train_loss:0.090670\n",
      "Epoch [1/10], Iter [523/3125], train_loss:0.104130\n",
      "Epoch [1/10], Iter [524/3125], train_loss:0.095427\n",
      "Epoch [1/10], Iter [525/3125], train_loss:0.141192\n",
      "Epoch [1/10], Iter [526/3125], train_loss:0.076236\n",
      "Epoch [1/10], Iter [527/3125], train_loss:0.117406\n",
      "Epoch [1/10], Iter [528/3125], train_loss:0.114006\n",
      "Epoch [1/10], Iter [529/3125], train_loss:0.066016\n",
      "Epoch [1/10], Iter [530/3125], train_loss:0.093731\n",
      "Epoch [1/10], Iter [531/3125], train_loss:0.072306\n",
      "Epoch [1/10], Iter [532/3125], train_loss:0.074725\n",
      "Epoch [1/10], Iter [533/3125], train_loss:0.090788\n",
      "Epoch [1/10], Iter [534/3125], train_loss:0.071732\n",
      "Epoch [1/10], Iter [535/3125], train_loss:0.083744\n",
      "Epoch [1/10], Iter [536/3125], train_loss:0.066183\n",
      "Epoch [1/10], Iter [537/3125], train_loss:0.116836\n",
      "Epoch [1/10], Iter [538/3125], train_loss:0.086225\n",
      "Epoch [1/10], Iter [539/3125], train_loss:0.097140\n",
      "Epoch [1/10], Iter [540/3125], train_loss:0.076652\n",
      "Epoch [1/10], Iter [541/3125], train_loss:0.058895\n",
      "Epoch [1/10], Iter [542/3125], train_loss:0.068447\n",
      "Epoch [1/10], Iter [543/3125], train_loss:0.071758\n",
      "Epoch [1/10], Iter [544/3125], train_loss:0.055181\n",
      "Epoch [1/10], Iter [545/3125], train_loss:0.058409\n",
      "Epoch [1/10], Iter [546/3125], train_loss:0.101034\n",
      "Epoch [1/10], Iter [547/3125], train_loss:0.078014\n",
      "Epoch [1/10], Iter [548/3125], train_loss:0.101554\n",
      "Epoch [1/10], Iter [549/3125], train_loss:0.099358\n",
      "Epoch [1/10], Iter [550/3125], train_loss:0.086353\n",
      "Epoch [1/10], Iter [551/3125], train_loss:0.087590\n",
      "Epoch [1/10], Iter [552/3125], train_loss:0.050383\n",
      "Epoch [1/10], Iter [553/3125], train_loss:0.100233\n",
      "Epoch [1/10], Iter [554/3125], train_loss:0.095480\n",
      "Epoch [1/10], Iter [555/3125], train_loss:0.093082\n",
      "Epoch [1/10], Iter [556/3125], train_loss:0.077300\n",
      "Epoch [1/10], Iter [557/3125], train_loss:0.097098\n",
      "Epoch [1/10], Iter [558/3125], train_loss:0.108629\n",
      "Epoch [1/10], Iter [559/3125], train_loss:0.080039\n",
      "Epoch [1/10], Iter [560/3125], train_loss:0.086488\n",
      "Epoch [1/10], Iter [561/3125], train_loss:0.105568\n",
      "Epoch [1/10], Iter [562/3125], train_loss:0.079867\n",
      "Epoch [1/10], Iter [563/3125], train_loss:0.094058\n",
      "Epoch [1/10], Iter [564/3125], train_loss:0.071488\n",
      "Epoch [1/10], Iter [565/3125], train_loss:0.068944\n",
      "Epoch [1/10], Iter [566/3125], train_loss:0.107989\n",
      "Epoch [1/10], Iter [567/3125], train_loss:0.072702\n",
      "Epoch [1/10], Iter [568/3125], train_loss:0.092457\n",
      "Epoch [1/10], Iter [569/3125], train_loss:0.116950\n",
      "Epoch [1/10], Iter [570/3125], train_loss:0.057468\n",
      "Epoch [1/10], Iter [571/3125], train_loss:0.067517\n",
      "Epoch [1/10], Iter [572/3125], train_loss:0.069241\n",
      "Epoch [1/10], Iter [573/3125], train_loss:0.112788\n",
      "Epoch [1/10], Iter [574/3125], train_loss:0.135044\n",
      "Epoch [1/10], Iter [575/3125], train_loss:0.139375\n",
      "Epoch [1/10], Iter [576/3125], train_loss:0.083855\n",
      "Epoch [1/10], Iter [577/3125], train_loss:0.111794\n",
      "Epoch [1/10], Iter [578/3125], train_loss:0.087120\n",
      "Epoch [1/10], Iter [579/3125], train_loss:0.089663\n",
      "Epoch [1/10], Iter [580/3125], train_loss:0.074575\n",
      "Epoch [1/10], Iter [581/3125], train_loss:0.064921\n",
      "Epoch [1/10], Iter [582/3125], train_loss:0.192595\n",
      "Epoch [1/10], Iter [583/3125], train_loss:0.107797\n",
      "Epoch [1/10], Iter [584/3125], train_loss:0.077203\n",
      "Epoch [1/10], Iter [585/3125], train_loss:0.123417\n",
      "Epoch [1/10], Iter [586/3125], train_loss:0.082694\n",
      "Epoch [1/10], Iter [587/3125], train_loss:0.075541\n",
      "Epoch [1/10], Iter [588/3125], train_loss:0.097291\n",
      "Epoch [1/10], Iter [589/3125], train_loss:0.052539\n",
      "Epoch [1/10], Iter [590/3125], train_loss:0.066947\n",
      "Epoch [1/10], Iter [591/3125], train_loss:0.061442\n",
      "Epoch [1/10], Iter [592/3125], train_loss:0.066907\n",
      "Epoch [1/10], Iter [593/3125], train_loss:0.059535\n",
      "Epoch [1/10], Iter [594/3125], train_loss:0.074935\n",
      "Epoch [1/10], Iter [595/3125], train_loss:0.084690\n",
      "Epoch [1/10], Iter [596/3125], train_loss:0.063918\n",
      "Epoch [1/10], Iter [597/3125], train_loss:0.063785\n",
      "Epoch [1/10], Iter [598/3125], train_loss:0.108638\n",
      "Epoch [1/10], Iter [599/3125], train_loss:0.086835\n",
      "Epoch [1/10], Iter [600/3125], train_loss:0.098556\n",
      "Epoch [1/10], Iter [601/3125], train_loss:0.075705\n",
      "Epoch [1/10], Iter [602/3125], train_loss:0.059754\n",
      "Epoch [1/10], Iter [603/3125], train_loss:0.054489\n",
      "Epoch [1/10], Iter [604/3125], train_loss:0.073924\n",
      "Epoch [1/10], Iter [605/3125], train_loss:0.094530\n",
      "Epoch [1/10], Iter [606/3125], train_loss:0.053714\n",
      "Epoch [1/10], Iter [607/3125], train_loss:0.090675\n",
      "Epoch [1/10], Iter [608/3125], train_loss:0.078084\n",
      "Epoch [1/10], Iter [609/3125], train_loss:0.066804\n",
      "Epoch [1/10], Iter [610/3125], train_loss:0.100219\n",
      "Epoch [1/10], Iter [611/3125], train_loss:0.075962\n",
      "Epoch [1/10], Iter [612/3125], train_loss:0.070294\n",
      "Epoch [1/10], Iter [613/3125], train_loss:0.071478\n",
      "Epoch [1/10], Iter [614/3125], train_loss:0.096717\n",
      "Epoch [1/10], Iter [615/3125], train_loss:0.086769\n",
      "Epoch [1/10], Iter [616/3125], train_loss:0.104664\n",
      "Epoch [1/10], Iter [617/3125], train_loss:0.072344\n",
      "Epoch [1/10], Iter [618/3125], train_loss:0.074144\n",
      "Epoch [1/10], Iter [619/3125], train_loss:0.084967\n",
      "Epoch [1/10], Iter [620/3125], train_loss:0.095983\n",
      "Epoch [1/10], Iter [621/3125], train_loss:0.068011\n",
      "Epoch [1/10], Iter [622/3125], train_loss:0.051430\n",
      "Epoch [1/10], Iter [623/3125], train_loss:0.072359\n",
      "Epoch [1/10], Iter [624/3125], train_loss:0.051836\n",
      "Epoch [1/10], Iter [625/3125], train_loss:0.103024\n",
      "Epoch [1/10], Iter [626/3125], train_loss:0.088216\n",
      "Epoch [1/10], Iter [627/3125], train_loss:0.061990\n",
      "Epoch [1/10], Iter [628/3125], train_loss:0.107665\n",
      "Epoch [1/10], Iter [629/3125], train_loss:0.076811\n",
      "Epoch [1/10], Iter [630/3125], train_loss:0.123782\n",
      "Epoch [1/10], Iter [631/3125], train_loss:0.094078\n",
      "Epoch [1/10], Iter [632/3125], train_loss:0.059769\n",
      "Epoch [1/10], Iter [633/3125], train_loss:0.066241\n",
      "Epoch [1/10], Iter [634/3125], train_loss:0.071580\n",
      "Epoch [1/10], Iter [635/3125], train_loss:0.076411\n",
      "Epoch [1/10], Iter [636/3125], train_loss:0.110754\n",
      "Epoch [1/10], Iter [637/3125], train_loss:0.065504\n",
      "Epoch [1/10], Iter [638/3125], train_loss:0.083259\n",
      "Epoch [1/10], Iter [639/3125], train_loss:0.107182\n",
      "Epoch [1/10], Iter [640/3125], train_loss:0.060376\n",
      "Epoch [1/10], Iter [641/3125], train_loss:0.077829\n",
      "Epoch [1/10], Iter [642/3125], train_loss:0.100774\n",
      "Epoch [1/10], Iter [643/3125], train_loss:0.087143\n",
      "Epoch [1/10], Iter [644/3125], train_loss:0.060597\n",
      "Epoch [1/10], Iter [645/3125], train_loss:0.101928\n",
      "Epoch [1/10], Iter [646/3125], train_loss:0.092720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [647/3125], train_loss:0.081452\n",
      "Epoch [1/10], Iter [648/3125], train_loss:0.097151\n",
      "Epoch [1/10], Iter [649/3125], train_loss:0.070104\n",
      "Epoch [1/10], Iter [650/3125], train_loss:0.094944\n",
      "Epoch [1/10], Iter [651/3125], train_loss:0.056059\n",
      "Epoch [1/10], Iter [652/3125], train_loss:0.065773\n",
      "Epoch [1/10], Iter [653/3125], train_loss:0.087860\n",
      "Epoch [1/10], Iter [654/3125], train_loss:0.088647\n",
      "Epoch [1/10], Iter [655/3125], train_loss:0.074508\n",
      "Epoch [1/10], Iter [656/3125], train_loss:0.078260\n",
      "Epoch [1/10], Iter [657/3125], train_loss:0.068859\n",
      "Epoch [1/10], Iter [658/3125], train_loss:0.080638\n",
      "Epoch [1/10], Iter [659/3125], train_loss:0.101420\n",
      "Epoch [1/10], Iter [660/3125], train_loss:0.084931\n",
      "Epoch [1/10], Iter [661/3125], train_loss:0.066806\n",
      "Epoch [1/10], Iter [662/3125], train_loss:0.105629\n",
      "Epoch [1/10], Iter [663/3125], train_loss:0.084870\n",
      "Epoch [1/10], Iter [664/3125], train_loss:0.071970\n",
      "Epoch [1/10], Iter [665/3125], train_loss:0.087836\n",
      "Epoch [1/10], Iter [666/3125], train_loss:0.100669\n",
      "Epoch [1/10], Iter [667/3125], train_loss:0.077280\n",
      "Epoch [1/10], Iter [668/3125], train_loss:0.116738\n",
      "Epoch [1/10], Iter [669/3125], train_loss:0.061395\n",
      "Epoch [1/10], Iter [670/3125], train_loss:0.090685\n",
      "Epoch [1/10], Iter [671/3125], train_loss:0.080947\n",
      "Epoch [1/10], Iter [672/3125], train_loss:0.095348\n",
      "Epoch [1/10], Iter [673/3125], train_loss:0.092972\n",
      "Epoch [1/10], Iter [674/3125], train_loss:0.107024\n",
      "Epoch [1/10], Iter [675/3125], train_loss:0.084352\n",
      "Epoch [1/10], Iter [676/3125], train_loss:0.059006\n",
      "Epoch [1/10], Iter [677/3125], train_loss:0.092779\n",
      "Epoch [1/10], Iter [678/3125], train_loss:0.077512\n",
      "Epoch [1/10], Iter [679/3125], train_loss:0.096963\n",
      "Epoch [1/10], Iter [680/3125], train_loss:0.096011\n",
      "Epoch [1/10], Iter [681/3125], train_loss:0.079866\n",
      "Epoch [1/10], Iter [682/3125], train_loss:0.075723\n",
      "Epoch [1/10], Iter [683/3125], train_loss:0.085611\n",
      "Epoch [1/10], Iter [684/3125], train_loss:0.123355\n",
      "Epoch [1/10], Iter [685/3125], train_loss:0.069978\n",
      "Epoch [1/10], Iter [686/3125], train_loss:0.077491\n",
      "Epoch [1/10], Iter [687/3125], train_loss:0.055490\n",
      "Epoch [1/10], Iter [688/3125], train_loss:0.067270\n",
      "Epoch [1/10], Iter [689/3125], train_loss:0.114452\n",
      "Epoch [1/10], Iter [690/3125], train_loss:0.079901\n",
      "Epoch [1/10], Iter [691/3125], train_loss:0.090492\n",
      "Epoch [1/10], Iter [692/3125], train_loss:0.072870\n",
      "Epoch [1/10], Iter [693/3125], train_loss:0.065780\n",
      "Epoch [1/10], Iter [694/3125], train_loss:0.078856\n",
      "Epoch [1/10], Iter [695/3125], train_loss:0.062660\n",
      "Epoch [1/10], Iter [696/3125], train_loss:0.094964\n",
      "Epoch [1/10], Iter [697/3125], train_loss:0.085245\n",
      "Epoch [1/10], Iter [698/3125], train_loss:0.096854\n",
      "Epoch [1/10], Iter [699/3125], train_loss:0.056521\n",
      "Epoch [1/10], Iter [700/3125], train_loss:0.064707\n",
      "Epoch [1/10], Iter [701/3125], train_loss:0.102361\n",
      "Epoch [1/10], Iter [702/3125], train_loss:0.083936\n",
      "Epoch [1/10], Iter [703/3125], train_loss:0.071545\n",
      "Epoch [1/10], Iter [704/3125], train_loss:0.056376\n",
      "Epoch [1/10], Iter [705/3125], train_loss:0.075224\n",
      "Epoch [1/10], Iter [706/3125], train_loss:0.088155\n",
      "Epoch [1/10], Iter [707/3125], train_loss:0.075692\n",
      "Epoch [1/10], Iter [708/3125], train_loss:0.077199\n",
      "Epoch [1/10], Iter [709/3125], train_loss:0.069121\n",
      "Epoch [1/10], Iter [710/3125], train_loss:0.077576\n",
      "Epoch [1/10], Iter [711/3125], train_loss:0.069567\n",
      "Epoch [1/10], Iter [712/3125], train_loss:0.075430\n",
      "Epoch [1/10], Iter [713/3125], train_loss:0.070002\n",
      "Epoch [1/10], Iter [714/3125], train_loss:0.083099\n",
      "Epoch [1/10], Iter [715/3125], train_loss:0.129424\n",
      "Epoch [1/10], Iter [716/3125], train_loss:0.076017\n",
      "Epoch [1/10], Iter [717/3125], train_loss:0.093424\n",
      "Epoch [1/10], Iter [718/3125], train_loss:0.046105\n",
      "Epoch [1/10], Iter [719/3125], train_loss:0.103817\n",
      "Epoch [1/10], Iter [720/3125], train_loss:0.063443\n",
      "Epoch [1/10], Iter [721/3125], train_loss:0.068008\n",
      "Epoch [1/10], Iter [722/3125], train_loss:0.080830\n",
      "Epoch [1/10], Iter [723/3125], train_loss:0.063206\n",
      "Epoch [1/10], Iter [724/3125], train_loss:0.046125\n",
      "Epoch [1/10], Iter [725/3125], train_loss:0.098638\n",
      "Epoch [1/10], Iter [726/3125], train_loss:0.059091\n",
      "Epoch [1/10], Iter [727/3125], train_loss:0.104707\n",
      "Epoch [1/10], Iter [728/3125], train_loss:0.060244\n",
      "Epoch [1/10], Iter [729/3125], train_loss:0.056369\n",
      "Epoch [1/10], Iter [730/3125], train_loss:0.066725\n",
      "Epoch [1/10], Iter [731/3125], train_loss:0.078067\n",
      "Epoch [1/10], Iter [732/3125], train_loss:0.074055\n",
      "Epoch [1/10], Iter [733/3125], train_loss:0.035916\n",
      "Epoch [1/10], Iter [734/3125], train_loss:0.066059\n",
      "Epoch [1/10], Iter [735/3125], train_loss:0.118576\n",
      "Epoch [1/10], Iter [736/3125], train_loss:0.095265\n",
      "Epoch [1/10], Iter [737/3125], train_loss:0.085072\n",
      "Epoch [1/10], Iter [738/3125], train_loss:0.076775\n",
      "Epoch [1/10], Iter [739/3125], train_loss:0.077835\n",
      "Epoch [1/10], Iter [740/3125], train_loss:0.071196\n",
      "Epoch [1/10], Iter [741/3125], train_loss:0.068851\n",
      "Epoch [1/10], Iter [742/3125], train_loss:0.041999\n",
      "Epoch [1/10], Iter [743/3125], train_loss:0.074546\n",
      "Epoch [1/10], Iter [744/3125], train_loss:0.098691\n",
      "Epoch [1/10], Iter [745/3125], train_loss:0.100539\n",
      "Epoch [1/10], Iter [746/3125], train_loss:0.079695\n",
      "Epoch [1/10], Iter [747/3125], train_loss:0.078971\n",
      "Epoch [1/10], Iter [748/3125], train_loss:0.081766\n",
      "Epoch [1/10], Iter [749/3125], train_loss:0.089490\n",
      "Epoch [1/10], Iter [750/3125], train_loss:0.077093\n",
      "Epoch [1/10], Iter [751/3125], train_loss:0.077361\n",
      "Epoch [1/10], Iter [752/3125], train_loss:0.114653\n",
      "Epoch [1/10], Iter [753/3125], train_loss:0.047497\n",
      "Epoch [1/10], Iter [754/3125], train_loss:0.121098\n",
      "Epoch [1/10], Iter [755/3125], train_loss:0.070111\n",
      "Epoch [1/10], Iter [756/3125], train_loss:0.069042\n",
      "Epoch [1/10], Iter [757/3125], train_loss:0.073422\n",
      "Epoch [1/10], Iter [758/3125], train_loss:0.070171\n",
      "Epoch [1/10], Iter [759/3125], train_loss:0.104445\n",
      "Epoch [1/10], Iter [760/3125], train_loss:0.075994\n",
      "Epoch [1/10], Iter [761/3125], train_loss:0.057151\n",
      "Epoch [1/10], Iter [762/3125], train_loss:0.086842\n",
      "Epoch [1/10], Iter [763/3125], train_loss:0.050175\n",
      "Epoch [1/10], Iter [764/3125], train_loss:0.114565\n",
      "Epoch [1/10], Iter [765/3125], train_loss:0.088730\n",
      "Epoch [1/10], Iter [766/3125], train_loss:0.084020\n",
      "Epoch [1/10], Iter [767/3125], train_loss:0.055446\n",
      "Epoch [1/10], Iter [768/3125], train_loss:0.073858\n",
      "Epoch [1/10], Iter [769/3125], train_loss:0.076490\n",
      "Epoch [1/10], Iter [770/3125], train_loss:0.117408\n",
      "Epoch [1/10], Iter [771/3125], train_loss:0.074123\n",
      "Epoch [1/10], Iter [772/3125], train_loss:0.091184\n",
      "Epoch [1/10], Iter [773/3125], train_loss:0.101151\n",
      "Epoch [1/10], Iter [774/3125], train_loss:0.069927\n",
      "Epoch [1/10], Iter [775/3125], train_loss:0.078611\n",
      "Epoch [1/10], Iter [776/3125], train_loss:0.076168\n",
      "Epoch [1/10], Iter [777/3125], train_loss:0.098598\n",
      "Epoch [1/10], Iter [778/3125], train_loss:0.080934\n",
      "Epoch [1/10], Iter [779/3125], train_loss:0.065147\n",
      "Epoch [1/10], Iter [780/3125], train_loss:0.092266\n",
      "Epoch [1/10], Iter [781/3125], train_loss:0.088162\n",
      "Epoch [1/10], Iter [782/3125], train_loss:0.048683\n",
      "Epoch [1/10], Iter [783/3125], train_loss:0.068024\n",
      "Epoch [1/10], Iter [784/3125], train_loss:0.061430\n",
      "Epoch [1/10], Iter [785/3125], train_loss:0.084588\n",
      "Epoch [1/10], Iter [786/3125], train_loss:0.055528\n",
      "Epoch [1/10], Iter [787/3125], train_loss:0.069858\n",
      "Epoch [1/10], Iter [788/3125], train_loss:0.066797\n",
      "Epoch [1/10], Iter [789/3125], train_loss:0.055900\n",
      "Epoch [1/10], Iter [790/3125], train_loss:0.081083\n",
      "Epoch [1/10], Iter [791/3125], train_loss:0.104611\n",
      "Epoch [1/10], Iter [792/3125], train_loss:0.069633\n",
      "Epoch [1/10], Iter [793/3125], train_loss:0.076716\n",
      "Epoch [1/10], Iter [794/3125], train_loss:0.058692\n",
      "Epoch [1/10], Iter [795/3125], train_loss:0.071644\n",
      "Epoch [1/10], Iter [796/3125], train_loss:0.075141\n",
      "Epoch [1/10], Iter [797/3125], train_loss:0.057095\n",
      "Epoch [1/10], Iter [798/3125], train_loss:0.091708\n",
      "Epoch [1/10], Iter [799/3125], train_loss:0.082720\n",
      "Epoch [1/10], Iter [800/3125], train_loss:0.082454\n",
      "Epoch [1/10], Iter [801/3125], train_loss:0.062604\n",
      "Epoch [1/10], Iter [802/3125], train_loss:0.064724\n",
      "Epoch [1/10], Iter [803/3125], train_loss:0.070556\n",
      "Epoch [1/10], Iter [804/3125], train_loss:0.062924\n",
      "Epoch [1/10], Iter [805/3125], train_loss:0.068634\n",
      "Epoch [1/10], Iter [806/3125], train_loss:0.125406\n",
      "Epoch [1/10], Iter [807/3125], train_loss:0.105064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [808/3125], train_loss:0.094673\n",
      "Epoch [1/10], Iter [809/3125], train_loss:0.058413\n",
      "Epoch [1/10], Iter [810/3125], train_loss:0.068775\n",
      "Epoch [1/10], Iter [811/3125], train_loss:0.082067\n",
      "Epoch [1/10], Iter [812/3125], train_loss:0.069499\n",
      "Epoch [1/10], Iter [813/3125], train_loss:0.046804\n",
      "Epoch [1/10], Iter [814/3125], train_loss:0.052497\n",
      "Epoch [1/10], Iter [815/3125], train_loss:0.039903\n",
      "Epoch [1/10], Iter [816/3125], train_loss:0.075335\n",
      "Epoch [1/10], Iter [817/3125], train_loss:0.118900\n",
      "Epoch [1/10], Iter [818/3125], train_loss:0.095827\n",
      "Epoch [1/10], Iter [819/3125], train_loss:0.080276\n",
      "Epoch [1/10], Iter [820/3125], train_loss:0.078976\n",
      "Epoch [1/10], Iter [821/3125], train_loss:0.067389\n",
      "Epoch [1/10], Iter [822/3125], train_loss:0.039839\n",
      "Epoch [1/10], Iter [823/3125], train_loss:0.084257\n",
      "Epoch [1/10], Iter [824/3125], train_loss:0.086442\n",
      "Epoch [1/10], Iter [825/3125], train_loss:0.067308\n",
      "Epoch [1/10], Iter [826/3125], train_loss:0.065607\n",
      "Epoch [1/10], Iter [827/3125], train_loss:0.076576\n",
      "Epoch [1/10], Iter [828/3125], train_loss:0.059056\n",
      "Epoch [1/10], Iter [829/3125], train_loss:0.045432\n",
      "Epoch [1/10], Iter [830/3125], train_loss:0.097930\n",
      "Epoch [1/10], Iter [831/3125], train_loss:0.029969\n",
      "Epoch [1/10], Iter [832/3125], train_loss:0.089879\n",
      "Epoch [1/10], Iter [833/3125], train_loss:0.065557\n",
      "Epoch [1/10], Iter [834/3125], train_loss:0.055370\n",
      "Epoch [1/10], Iter [835/3125], train_loss:0.078189\n",
      "Epoch [1/10], Iter [836/3125], train_loss:0.078902\n",
      "Epoch [1/10], Iter [837/3125], train_loss:0.049187\n",
      "Epoch [1/10], Iter [838/3125], train_loss:0.073233\n",
      "Epoch [1/10], Iter [839/3125], train_loss:0.042756\n",
      "Epoch [1/10], Iter [840/3125], train_loss:0.095991\n",
      "Epoch [1/10], Iter [841/3125], train_loss:0.054647\n",
      "Epoch [1/10], Iter [842/3125], train_loss:0.090404\n",
      "Epoch [1/10], Iter [843/3125], train_loss:0.084048\n",
      "Epoch [1/10], Iter [844/3125], train_loss:0.042351\n",
      "Epoch [1/10], Iter [845/3125], train_loss:0.110720\n",
      "Epoch [1/10], Iter [846/3125], train_loss:0.058698\n",
      "Epoch [1/10], Iter [847/3125], train_loss:0.065574\n",
      "Epoch [1/10], Iter [848/3125], train_loss:0.103704\n",
      "Epoch [1/10], Iter [849/3125], train_loss:0.092518\n",
      "Epoch [1/10], Iter [850/3125], train_loss:0.105825\n",
      "Epoch [1/10], Iter [851/3125], train_loss:0.092112\n",
      "Epoch [1/10], Iter [852/3125], train_loss:0.060410\n",
      "Epoch [1/10], Iter [853/3125], train_loss:0.053077\n",
      "Epoch [1/10], Iter [854/3125], train_loss:0.096419\n",
      "Epoch [1/10], Iter [855/3125], train_loss:0.070295\n",
      "Epoch [1/10], Iter [856/3125], train_loss:0.038191\n",
      "Epoch [1/10], Iter [857/3125], train_loss:0.067107\n",
      "Epoch [1/10], Iter [858/3125], train_loss:0.068591\n",
      "Epoch [1/10], Iter [859/3125], train_loss:0.118834\n",
      "Epoch [1/10], Iter [860/3125], train_loss:0.057502\n",
      "Epoch [1/10], Iter [861/3125], train_loss:0.112667\n",
      "Epoch [1/10], Iter [862/3125], train_loss:0.068514\n",
      "Epoch [1/10], Iter [863/3125], train_loss:0.078345\n",
      "Epoch [1/10], Iter [864/3125], train_loss:0.086322\n",
      "Epoch [1/10], Iter [865/3125], train_loss:0.060227\n",
      "Epoch [1/10], Iter [866/3125], train_loss:0.069537\n",
      "Epoch [1/10], Iter [867/3125], train_loss:0.051423\n",
      "Epoch [1/10], Iter [868/3125], train_loss:0.065481\n",
      "Epoch [1/10], Iter [869/3125], train_loss:0.078509\n",
      "Epoch [1/10], Iter [870/3125], train_loss:0.087949\n",
      "Epoch [1/10], Iter [871/3125], train_loss:0.089137\n",
      "Epoch [1/10], Iter [872/3125], train_loss:0.097406\n",
      "Epoch [1/10], Iter [873/3125], train_loss:0.058960\n",
      "Epoch [1/10], Iter [874/3125], train_loss:0.058738\n",
      "Epoch [1/10], Iter [875/3125], train_loss:0.061488\n",
      "Epoch [1/10], Iter [876/3125], train_loss:0.066018\n",
      "Epoch [1/10], Iter [877/3125], train_loss:0.074891\n",
      "Epoch [1/10], Iter [878/3125], train_loss:0.086487\n",
      "Epoch [1/10], Iter [879/3125], train_loss:0.036267\n",
      "Epoch [1/10], Iter [880/3125], train_loss:0.052825\n",
      "Epoch [1/10], Iter [881/3125], train_loss:0.086232\n",
      "Epoch [1/10], Iter [882/3125], train_loss:0.067304\n",
      "Epoch [1/10], Iter [883/3125], train_loss:0.090174\n",
      "Epoch [1/10], Iter [884/3125], train_loss:0.074173\n",
      "Epoch [1/10], Iter [885/3125], train_loss:0.103388\n",
      "Epoch [1/10], Iter [886/3125], train_loss:0.063061\n",
      "Epoch [1/10], Iter [887/3125], train_loss:0.111390\n",
      "Epoch [1/10], Iter [888/3125], train_loss:0.082873\n",
      "Epoch [1/10], Iter [889/3125], train_loss:0.067860\n",
      "Epoch [1/10], Iter [890/3125], train_loss:0.069580\n",
      "Epoch [1/10], Iter [891/3125], train_loss:0.071146\n",
      "Epoch [1/10], Iter [892/3125], train_loss:0.046750\n",
      "Epoch [1/10], Iter [893/3125], train_loss:0.069989\n",
      "Epoch [1/10], Iter [894/3125], train_loss:0.054033\n",
      "Epoch [1/10], Iter [895/3125], train_loss:0.091311\n",
      "Epoch [1/10], Iter [896/3125], train_loss:0.089567\n",
      "Epoch [1/10], Iter [897/3125], train_loss:0.082130\n",
      "Epoch [1/10], Iter [898/3125], train_loss:0.115708\n",
      "Epoch [1/10], Iter [899/3125], train_loss:0.099699\n",
      "Epoch [1/10], Iter [900/3125], train_loss:0.084736\n",
      "Epoch [1/10], Iter [901/3125], train_loss:0.099145\n",
      "Epoch [1/10], Iter [902/3125], train_loss:0.096519\n",
      "Epoch [1/10], Iter [903/3125], train_loss:0.070268\n",
      "Epoch [1/10], Iter [904/3125], train_loss:0.048972\n",
      "Epoch [1/10], Iter [905/3125], train_loss:0.055735\n",
      "Epoch [1/10], Iter [906/3125], train_loss:0.092406\n",
      "Epoch [1/10], Iter [907/3125], train_loss:0.094186\n",
      "Epoch [1/10], Iter [908/3125], train_loss:0.058645\n",
      "Epoch [1/10], Iter [909/3125], train_loss:0.059716\n",
      "Epoch [1/10], Iter [910/3125], train_loss:0.066300\n",
      "Epoch [1/10], Iter [911/3125], train_loss:0.055384\n",
      "Epoch [1/10], Iter [912/3125], train_loss:0.063149\n",
      "Epoch [1/10], Iter [913/3125], train_loss:0.078833\n",
      "Epoch [1/10], Iter [914/3125], train_loss:0.047108\n",
      "Epoch [1/10], Iter [915/3125], train_loss:0.095854\n",
      "Epoch [1/10], Iter [916/3125], train_loss:0.067950\n",
      "Epoch [1/10], Iter [917/3125], train_loss:0.089043\n",
      "Epoch [1/10], Iter [918/3125], train_loss:0.091433\n",
      "Epoch [1/10], Iter [919/3125], train_loss:0.071309\n",
      "Epoch [1/10], Iter [920/3125], train_loss:0.064289\n",
      "Epoch [1/10], Iter [921/3125], train_loss:0.075466\n",
      "Epoch [1/10], Iter [922/3125], train_loss:0.041136\n",
      "Epoch [1/10], Iter [923/3125], train_loss:0.069332\n",
      "Epoch [1/10], Iter [924/3125], train_loss:0.103374\n",
      "Epoch [1/10], Iter [925/3125], train_loss:0.048819\n",
      "Epoch [1/10], Iter [926/3125], train_loss:0.102714\n",
      "Epoch [1/10], Iter [927/3125], train_loss:0.059707\n",
      "Epoch [1/10], Iter [928/3125], train_loss:0.103872\n",
      "Epoch [1/10], Iter [929/3125], train_loss:0.071671\n",
      "Epoch [1/10], Iter [930/3125], train_loss:0.043527\n",
      "Epoch [1/10], Iter [931/3125], train_loss:0.101342\n",
      "Epoch [1/10], Iter [932/3125], train_loss:0.090892\n",
      "Epoch [1/10], Iter [933/3125], train_loss:0.084326\n",
      "Epoch [1/10], Iter [934/3125], train_loss:0.085523\n",
      "Epoch [1/10], Iter [935/3125], train_loss:0.104836\n",
      "Epoch [1/10], Iter [936/3125], train_loss:0.071485\n",
      "Epoch [1/10], Iter [937/3125], train_loss:0.075505\n",
      "Epoch [1/10], Iter [938/3125], train_loss:0.055048\n",
      "Epoch [1/10], Iter [939/3125], train_loss:0.052603\n",
      "Epoch [1/10], Iter [940/3125], train_loss:0.052872\n",
      "Epoch [1/10], Iter [941/3125], train_loss:0.046744\n",
      "Epoch [1/10], Iter [942/3125], train_loss:0.084774\n",
      "Epoch [1/10], Iter [943/3125], train_loss:0.089809\n",
      "Epoch [1/10], Iter [944/3125], train_loss:0.077171\n",
      "Epoch [1/10], Iter [945/3125], train_loss:0.053297\n",
      "Epoch [1/10], Iter [946/3125], train_loss:0.048126\n",
      "Epoch [1/10], Iter [947/3125], train_loss:0.069072\n",
      "Epoch [1/10], Iter [948/3125], train_loss:0.081771\n",
      "Epoch [1/10], Iter [949/3125], train_loss:0.086464\n",
      "Epoch [1/10], Iter [950/3125], train_loss:0.078226\n",
      "Epoch [1/10], Iter [951/3125], train_loss:0.070242\n",
      "Epoch [1/10], Iter [952/3125], train_loss:0.065498\n",
      "Epoch [1/10], Iter [953/3125], train_loss:0.057135\n",
      "Epoch [1/10], Iter [954/3125], train_loss:0.087012\n",
      "Epoch [1/10], Iter [955/3125], train_loss:0.087501\n",
      "Epoch [1/10], Iter [956/3125], train_loss:0.076051\n",
      "Epoch [1/10], Iter [957/3125], train_loss:0.093375\n",
      "Epoch [1/10], Iter [958/3125], train_loss:0.098896\n",
      "Epoch [1/10], Iter [959/3125], train_loss:0.094898\n",
      "Epoch [1/10], Iter [960/3125], train_loss:0.051544\n",
      "Epoch [1/10], Iter [961/3125], train_loss:0.112901\n",
      "Epoch [1/10], Iter [962/3125], train_loss:0.064911\n",
      "Epoch [1/10], Iter [963/3125], train_loss:0.127530\n",
      "Epoch [1/10], Iter [964/3125], train_loss:0.060438\n",
      "Epoch [1/10], Iter [965/3125], train_loss:0.073689\n",
      "Epoch [1/10], Iter [966/3125], train_loss:0.058125\n",
      "Epoch [1/10], Iter [967/3125], train_loss:0.076736\n",
      "Epoch [1/10], Iter [968/3125], train_loss:0.076557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [969/3125], train_loss:0.064269\n",
      "Epoch [1/10], Iter [970/3125], train_loss:0.078429\n",
      "Epoch [1/10], Iter [971/3125], train_loss:0.053220\n",
      "Epoch [1/10], Iter [972/3125], train_loss:0.059810\n",
      "Epoch [1/10], Iter [973/3125], train_loss:0.061482\n",
      "Epoch [1/10], Iter [974/3125], train_loss:0.059918\n",
      "Epoch [1/10], Iter [975/3125], train_loss:0.095541\n",
      "Epoch [1/10], Iter [976/3125], train_loss:0.066343\n",
      "Epoch [1/10], Iter [977/3125], train_loss:0.063362\n",
      "Epoch [1/10], Iter [978/3125], train_loss:0.049746\n",
      "Epoch [1/10], Iter [979/3125], train_loss:0.076230\n",
      "Epoch [1/10], Iter [980/3125], train_loss:0.085253\n",
      "Epoch [1/10], Iter [981/3125], train_loss:0.055329\n",
      "Epoch [1/10], Iter [982/3125], train_loss:0.073866\n",
      "Epoch [1/10], Iter [983/3125], train_loss:0.090456\n",
      "Epoch [1/10], Iter [984/3125], train_loss:0.065264\n",
      "Epoch [1/10], Iter [985/3125], train_loss:0.094808\n",
      "Epoch [1/10], Iter [986/3125], train_loss:0.083755\n",
      "Epoch [1/10], Iter [987/3125], train_loss:0.100000\n",
      "Epoch [1/10], Iter [988/3125], train_loss:0.044194\n",
      "Epoch [1/10], Iter [989/3125], train_loss:0.089688\n",
      "Epoch [1/10], Iter [990/3125], train_loss:0.061354\n",
      "Epoch [1/10], Iter [991/3125], train_loss:0.072798\n",
      "Epoch [1/10], Iter [992/3125], train_loss:0.055077\n",
      "Epoch [1/10], Iter [993/3125], train_loss:0.066739\n",
      "Epoch [1/10], Iter [994/3125], train_loss:0.085635\n",
      "Epoch [1/10], Iter [995/3125], train_loss:0.062349\n",
      "Epoch [1/10], Iter [996/3125], train_loss:0.055486\n",
      "Epoch [1/10], Iter [997/3125], train_loss:0.061249\n",
      "Epoch [1/10], Iter [998/3125], train_loss:0.046875\n",
      "Epoch [1/10], Iter [999/3125], train_loss:0.078696\n",
      "Epoch [1/10], Iter [1000/3125], train_loss:0.071514\n",
      "Epoch [1/10], Iter [1001/3125], train_loss:0.084848\n",
      "Epoch [1/10], Iter [1002/3125], train_loss:0.051532\n",
      "Epoch [1/10], Iter [1003/3125], train_loss:0.084807\n",
      "Epoch [1/10], Iter [1004/3125], train_loss:0.088694\n",
      "Epoch [1/10], Iter [1005/3125], train_loss:0.081654\n",
      "Epoch [1/10], Iter [1006/3125], train_loss:0.067032\n",
      "Epoch [1/10], Iter [1007/3125], train_loss:0.124414\n",
      "Epoch [1/10], Iter [1008/3125], train_loss:0.080349\n",
      "Epoch [1/10], Iter [1009/3125], train_loss:0.036862\n",
      "Epoch [1/10], Iter [1010/3125], train_loss:0.076840\n",
      "Epoch [1/10], Iter [1011/3125], train_loss:0.042844\n",
      "Epoch [1/10], Iter [1012/3125], train_loss:0.078605\n",
      "Epoch [1/10], Iter [1013/3125], train_loss:0.044502\n",
      "Epoch [1/10], Iter [1014/3125], train_loss:0.080783\n",
      "Epoch [1/10], Iter [1015/3125], train_loss:0.071481\n",
      "Epoch [1/10], Iter [1016/3125], train_loss:0.085543\n",
      "Epoch [1/10], Iter [1017/3125], train_loss:0.107438\n",
      "Epoch [1/10], Iter [1018/3125], train_loss:0.076212\n",
      "Epoch [1/10], Iter [1019/3125], train_loss:0.078109\n",
      "Epoch [1/10], Iter [1020/3125], train_loss:0.047839\n",
      "Epoch [1/10], Iter [1021/3125], train_loss:0.090297\n",
      "Epoch [1/10], Iter [1022/3125], train_loss:0.060652\n",
      "Epoch [1/10], Iter [1023/3125], train_loss:0.107761\n",
      "Epoch [1/10], Iter [1024/3125], train_loss:0.075100\n",
      "Epoch [1/10], Iter [1025/3125], train_loss:0.065084\n",
      "Epoch [1/10], Iter [1026/3125], train_loss:0.086126\n",
      "Epoch [1/10], Iter [1027/3125], train_loss:0.076870\n",
      "Epoch [1/10], Iter [1028/3125], train_loss:0.090435\n",
      "Epoch [1/10], Iter [1029/3125], train_loss:0.071291\n",
      "Epoch [1/10], Iter [1030/3125], train_loss:0.072460\n",
      "Epoch [1/10], Iter [1031/3125], train_loss:0.065093\n",
      "Epoch [1/10], Iter [1032/3125], train_loss:0.046128\n",
      "Epoch [1/10], Iter [1033/3125], train_loss:0.081843\n",
      "Epoch [1/10], Iter [1034/3125], train_loss:0.098334\n",
      "Epoch [1/10], Iter [1035/3125], train_loss:0.044121\n",
      "Epoch [1/10], Iter [1036/3125], train_loss:0.067291\n",
      "Epoch [1/10], Iter [1037/3125], train_loss:0.055147\n",
      "Epoch [1/10], Iter [1038/3125], train_loss:0.075272\n",
      "Epoch [1/10], Iter [1039/3125], train_loss:0.097143\n",
      "Epoch [1/10], Iter [1040/3125], train_loss:0.083308\n",
      "Epoch [1/10], Iter [1041/3125], train_loss:0.083002\n",
      "Epoch [1/10], Iter [1042/3125], train_loss:0.074888\n",
      "Epoch [1/10], Iter [1043/3125], train_loss:0.097697\n",
      "Epoch [1/10], Iter [1044/3125], train_loss:0.049311\n",
      "Epoch [1/10], Iter [1045/3125], train_loss:0.081692\n",
      "Epoch [1/10], Iter [1046/3125], train_loss:0.064942\n",
      "Epoch [1/10], Iter [1047/3125], train_loss:0.044580\n",
      "Epoch [1/10], Iter [1048/3125], train_loss:0.085176\n",
      "Epoch [1/10], Iter [1049/3125], train_loss:0.063269\n",
      "Epoch [1/10], Iter [1050/3125], train_loss:0.077601\n",
      "Epoch [1/10], Iter [1051/3125], train_loss:0.105948\n",
      "Epoch [1/10], Iter [1052/3125], train_loss:0.059415\n",
      "Epoch [1/10], Iter [1053/3125], train_loss:0.094063\n",
      "Epoch [1/10], Iter [1054/3125], train_loss:0.092959\n",
      "Epoch [1/10], Iter [1055/3125], train_loss:0.092067\n",
      "Epoch [1/10], Iter [1056/3125], train_loss:0.067009\n",
      "Epoch [1/10], Iter [1057/3125], train_loss:0.098917\n",
      "Epoch [1/10], Iter [1058/3125], train_loss:0.057587\n",
      "Epoch [1/10], Iter [1059/3125], train_loss:0.130291\n",
      "Epoch [1/10], Iter [1060/3125], train_loss:0.067882\n",
      "Epoch [1/10], Iter [1061/3125], train_loss:0.060654\n",
      "Epoch [1/10], Iter [1062/3125], train_loss:0.055052\n",
      "Epoch [1/10], Iter [1063/3125], train_loss:0.113558\n",
      "Epoch [1/10], Iter [1064/3125], train_loss:0.092149\n",
      "Epoch [1/10], Iter [1065/3125], train_loss:0.080471\n",
      "Epoch [1/10], Iter [1066/3125], train_loss:0.077791\n",
      "Epoch [1/10], Iter [1067/3125], train_loss:0.064857\n",
      "Epoch [1/10], Iter [1068/3125], train_loss:0.061791\n",
      "Epoch [1/10], Iter [1069/3125], train_loss:0.092346\n",
      "Epoch [1/10], Iter [1070/3125], train_loss:0.061829\n",
      "Epoch [1/10], Iter [1071/3125], train_loss:0.052066\n",
      "Epoch [1/10], Iter [1072/3125], train_loss:0.060261\n",
      "Epoch [1/10], Iter [1073/3125], train_loss:0.052576\n",
      "Epoch [1/10], Iter [1074/3125], train_loss:0.091335\n",
      "Epoch [1/10], Iter [1075/3125], train_loss:0.085970\n",
      "Epoch [1/10], Iter [1076/3125], train_loss:0.051026\n",
      "Epoch [1/10], Iter [1077/3125], train_loss:0.054480\n",
      "Epoch [1/10], Iter [1078/3125], train_loss:0.076401\n",
      "Epoch [1/10], Iter [1079/3125], train_loss:0.067915\n",
      "Epoch [1/10], Iter [1080/3125], train_loss:0.080814\n",
      "Epoch [1/10], Iter [1081/3125], train_loss:0.079265\n",
      "Epoch [1/10], Iter [1082/3125], train_loss:0.064177\n",
      "Epoch [1/10], Iter [1083/3125], train_loss:0.070294\n",
      "Epoch [1/10], Iter [1084/3125], train_loss:0.076654\n",
      "Epoch [1/10], Iter [1085/3125], train_loss:0.048900\n",
      "Epoch [1/10], Iter [1086/3125], train_loss:0.080051\n",
      "Epoch [1/10], Iter [1087/3125], train_loss:0.062221\n",
      "Epoch [1/10], Iter [1088/3125], train_loss:0.053528\n",
      "Epoch [1/10], Iter [1089/3125], train_loss:0.078500\n",
      "Epoch [1/10], Iter [1090/3125], train_loss:0.054167\n",
      "Epoch [1/10], Iter [1091/3125], train_loss:0.060830\n",
      "Epoch [1/10], Iter [1092/3125], train_loss:0.070064\n",
      "Epoch [1/10], Iter [1093/3125], train_loss:0.059513\n",
      "Epoch [1/10], Iter [1094/3125], train_loss:0.064300\n",
      "Epoch [1/10], Iter [1095/3125], train_loss:0.064953\n",
      "Epoch [1/10], Iter [1096/3125], train_loss:0.098469\n",
      "Epoch [1/10], Iter [1097/3125], train_loss:0.070608\n",
      "Epoch [1/10], Iter [1098/3125], train_loss:0.063558\n",
      "Epoch [1/10], Iter [1099/3125], train_loss:0.047807\n",
      "Epoch [1/10], Iter [1100/3125], train_loss:0.040138\n",
      "Epoch [1/10], Iter [1101/3125], train_loss:0.054244\n",
      "Epoch [1/10], Iter [1102/3125], train_loss:0.094688\n",
      "Epoch [1/10], Iter [1103/3125], train_loss:0.040553\n",
      "Epoch [1/10], Iter [1104/3125], train_loss:0.054478\n",
      "Epoch [1/10], Iter [1105/3125], train_loss:0.051893\n",
      "Epoch [1/10], Iter [1106/3125], train_loss:0.063331\n",
      "Epoch [1/10], Iter [1107/3125], train_loss:0.092488\n",
      "Epoch [1/10], Iter [1108/3125], train_loss:0.079674\n",
      "Epoch [1/10], Iter [1109/3125], train_loss:0.082050\n",
      "Epoch [1/10], Iter [1110/3125], train_loss:0.053623\n",
      "Epoch [1/10], Iter [1111/3125], train_loss:0.142942\n",
      "Epoch [1/10], Iter [1112/3125], train_loss:0.071629\n",
      "Epoch [1/10], Iter [1113/3125], train_loss:0.070982\n",
      "Epoch [1/10], Iter [1114/3125], train_loss:0.096225\n",
      "Epoch [1/10], Iter [1115/3125], train_loss:0.071539\n",
      "Epoch [1/10], Iter [1116/3125], train_loss:0.058115\n",
      "Epoch [1/10], Iter [1117/3125], train_loss:0.069117\n",
      "Epoch [1/10], Iter [1118/3125], train_loss:0.048873\n",
      "Epoch [1/10], Iter [1119/3125], train_loss:0.041571\n",
      "Epoch [1/10], Iter [1120/3125], train_loss:0.062927\n",
      "Epoch [1/10], Iter [1121/3125], train_loss:0.060754\n",
      "Epoch [1/10], Iter [1122/3125], train_loss:0.072750\n",
      "Epoch [1/10], Iter [1123/3125], train_loss:0.112615\n",
      "Epoch [1/10], Iter [1124/3125], train_loss:0.051256\n",
      "Epoch [1/10], Iter [1125/3125], train_loss:0.086577\n",
      "Epoch [1/10], Iter [1126/3125], train_loss:0.058549\n",
      "Epoch [1/10], Iter [1127/3125], train_loss:0.038518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [1128/3125], train_loss:0.080108\n",
      "Epoch [1/10], Iter [1129/3125], train_loss:0.088471\n",
      "Epoch [1/10], Iter [1130/3125], train_loss:0.062608\n",
      "Epoch [1/10], Iter [1131/3125], train_loss:0.029030\n",
      "Epoch [1/10], Iter [1132/3125], train_loss:0.102873\n",
      "Epoch [1/10], Iter [1133/3125], train_loss:0.044108\n",
      "Epoch [1/10], Iter [1134/3125], train_loss:0.062481\n",
      "Epoch [1/10], Iter [1135/3125], train_loss:0.070823\n",
      "Epoch [1/10], Iter [1136/3125], train_loss:0.056807\n",
      "Epoch [1/10], Iter [1137/3125], train_loss:0.086398\n",
      "Epoch [1/10], Iter [1138/3125], train_loss:0.070901\n",
      "Epoch [1/10], Iter [1139/3125], train_loss:0.057244\n",
      "Epoch [1/10], Iter [1140/3125], train_loss:0.084820\n",
      "Epoch [1/10], Iter [1141/3125], train_loss:0.060651\n",
      "Epoch [1/10], Iter [1142/3125], train_loss:0.050026\n",
      "Epoch [1/10], Iter [1143/3125], train_loss:0.051782\n",
      "Epoch [1/10], Iter [1144/3125], train_loss:0.078317\n",
      "Epoch [1/10], Iter [1145/3125], train_loss:0.101919\n",
      "Epoch [1/10], Iter [1146/3125], train_loss:0.066825\n",
      "Epoch [1/10], Iter [1147/3125], train_loss:0.058590\n",
      "Epoch [1/10], Iter [1148/3125], train_loss:0.065694\n",
      "Epoch [1/10], Iter [1149/3125], train_loss:0.073218\n",
      "Epoch [1/10], Iter [1150/3125], train_loss:0.055545\n",
      "Epoch [1/10], Iter [1151/3125], train_loss:0.091100\n",
      "Epoch [1/10], Iter [1152/3125], train_loss:0.064072\n",
      "Epoch [1/10], Iter [1153/3125], train_loss:0.056346\n",
      "Epoch [1/10], Iter [1154/3125], train_loss:0.051450\n",
      "Epoch [1/10], Iter [1155/3125], train_loss:0.092154\n",
      "Epoch [1/10], Iter [1156/3125], train_loss:0.042432\n",
      "Epoch [1/10], Iter [1157/3125], train_loss:0.089265\n",
      "Epoch [1/10], Iter [1158/3125], train_loss:0.060625\n",
      "Epoch [1/10], Iter [1159/3125], train_loss:0.099431\n",
      "Epoch [1/10], Iter [1160/3125], train_loss:0.083928\n",
      "Epoch [1/10], Iter [1161/3125], train_loss:0.035615\n",
      "Epoch [1/10], Iter [1162/3125], train_loss:0.085633\n",
      "Epoch [1/10], Iter [1163/3125], train_loss:0.072629\n",
      "Epoch [1/10], Iter [1164/3125], train_loss:0.025984\n",
      "Epoch [1/10], Iter [1165/3125], train_loss:0.039261\n",
      "Epoch [1/10], Iter [1166/3125], train_loss:0.069321\n",
      "Epoch [1/10], Iter [1167/3125], train_loss:0.069004\n",
      "Epoch [1/10], Iter [1168/3125], train_loss:0.089742\n",
      "Epoch [1/10], Iter [1169/3125], train_loss:0.079844\n",
      "Epoch [1/10], Iter [1170/3125], train_loss:0.072411\n",
      "Epoch [1/10], Iter [1171/3125], train_loss:0.067221\n",
      "Epoch [1/10], Iter [1172/3125], train_loss:0.042146\n",
      "Epoch [1/10], Iter [1173/3125], train_loss:0.057201\n",
      "Epoch [1/10], Iter [1174/3125], train_loss:0.080315\n",
      "Epoch [1/10], Iter [1175/3125], train_loss:0.071066\n",
      "Epoch [1/10], Iter [1176/3125], train_loss:0.052890\n",
      "Epoch [1/10], Iter [1177/3125], train_loss:0.068389\n",
      "Epoch [1/10], Iter [1178/3125], train_loss:0.064046\n",
      "Epoch [1/10], Iter [1179/3125], train_loss:0.077891\n",
      "Epoch [1/10], Iter [1180/3125], train_loss:0.048555\n",
      "Epoch [1/10], Iter [1181/3125], train_loss:0.050501\n",
      "Epoch [1/10], Iter [1182/3125], train_loss:0.048259\n",
      "Epoch [1/10], Iter [1183/3125], train_loss:0.062327\n",
      "Epoch [1/10], Iter [1184/3125], train_loss:0.109548\n",
      "Epoch [1/10], Iter [1185/3125], train_loss:0.065658\n",
      "Epoch [1/10], Iter [1186/3125], train_loss:0.093734\n",
      "Epoch [1/10], Iter [1187/3125], train_loss:0.063664\n",
      "Epoch [1/10], Iter [1188/3125], train_loss:0.037065\n",
      "Epoch [1/10], Iter [1189/3125], train_loss:0.057139\n",
      "Epoch [1/10], Iter [1190/3125], train_loss:0.036839\n",
      "Epoch [1/10], Iter [1191/3125], train_loss:0.067464\n",
      "Epoch [1/10], Iter [1192/3125], train_loss:0.066957\n",
      "Epoch [1/10], Iter [1193/3125], train_loss:0.084686\n",
      "Epoch [1/10], Iter [1194/3125], train_loss:0.052129\n",
      "Epoch [1/10], Iter [1195/3125], train_loss:0.088091\n",
      "Epoch [1/10], Iter [1196/3125], train_loss:0.108515\n",
      "Epoch [1/10], Iter [1197/3125], train_loss:0.066917\n",
      "Epoch [1/10], Iter [1198/3125], train_loss:0.081250\n",
      "Epoch [1/10], Iter [1199/3125], train_loss:0.060395\n",
      "Epoch [1/10], Iter [1200/3125], train_loss:0.111344\n",
      "Epoch [1/10], Iter [1201/3125], train_loss:0.067042\n",
      "Epoch [1/10], Iter [1202/3125], train_loss:0.056118\n",
      "Epoch [1/10], Iter [1203/3125], train_loss:0.100409\n",
      "Epoch [1/10], Iter [1204/3125], train_loss:0.079419\n",
      "Epoch [1/10], Iter [1205/3125], train_loss:0.044308\n",
      "Epoch [1/10], Iter [1206/3125], train_loss:0.053429\n",
      "Epoch [1/10], Iter [1207/3125], train_loss:0.045393\n",
      "Epoch [1/10], Iter [1208/3125], train_loss:0.056517\n",
      "Epoch [1/10], Iter [1209/3125], train_loss:0.051357\n",
      "Epoch [1/10], Iter [1210/3125], train_loss:0.074712\n",
      "Epoch [1/10], Iter [1211/3125], train_loss:0.067255\n",
      "Epoch [1/10], Iter [1212/3125], train_loss:0.066072\n",
      "Epoch [1/10], Iter [1213/3125], train_loss:0.036946\n",
      "Epoch [1/10], Iter [1214/3125], train_loss:0.074870\n",
      "Epoch [1/10], Iter [1215/3125], train_loss:0.095798\n",
      "Epoch [1/10], Iter [1216/3125], train_loss:0.058114\n",
      "Epoch [1/10], Iter [1217/3125], train_loss:0.067285\n",
      "Epoch [1/10], Iter [1218/3125], train_loss:0.076193\n",
      "Epoch [1/10], Iter [1219/3125], train_loss:0.069693\n",
      "Epoch [1/10], Iter [1220/3125], train_loss:0.072604\n",
      "Epoch [1/10], Iter [1221/3125], train_loss:0.064588\n",
      "Epoch [1/10], Iter [1222/3125], train_loss:0.070116\n",
      "Epoch [1/10], Iter [1223/3125], train_loss:0.078694\n",
      "Epoch [1/10], Iter [1224/3125], train_loss:0.073832\n",
      "Epoch [1/10], Iter [1225/3125], train_loss:0.057916\n",
      "Epoch [1/10], Iter [1226/3125], train_loss:0.074006\n",
      "Epoch [1/10], Iter [1227/3125], train_loss:0.094362\n",
      "Epoch [1/10], Iter [1228/3125], train_loss:0.052954\n",
      "Epoch [1/10], Iter [1229/3125], train_loss:0.066249\n",
      "Epoch [1/10], Iter [1230/3125], train_loss:0.037475\n",
      "Epoch [1/10], Iter [1231/3125], train_loss:0.037161\n",
      "Epoch [1/10], Iter [1232/3125], train_loss:0.080392\n",
      "Epoch [1/10], Iter [1233/3125], train_loss:0.064337\n",
      "Epoch [1/10], Iter [1234/3125], train_loss:0.036732\n",
      "Epoch [1/10], Iter [1235/3125], train_loss:0.080269\n",
      "Epoch [1/10], Iter [1236/3125], train_loss:0.073352\n",
      "Epoch [1/10], Iter [1237/3125], train_loss:0.071526\n",
      "Epoch [1/10], Iter [1238/3125], train_loss:0.064553\n",
      "Epoch [1/10], Iter [1239/3125], train_loss:0.094893\n",
      "Epoch [1/10], Iter [1240/3125], train_loss:0.061000\n",
      "Epoch [1/10], Iter [1241/3125], train_loss:0.069262\n",
      "Epoch [1/10], Iter [1242/3125], train_loss:0.079779\n",
      "Epoch [1/10], Iter [1243/3125], train_loss:0.066429\n",
      "Epoch [1/10], Iter [1244/3125], train_loss:0.046146\n",
      "Epoch [1/10], Iter [1245/3125], train_loss:0.054782\n",
      "Epoch [1/10], Iter [1246/3125], train_loss:0.080050\n",
      "Epoch [1/10], Iter [1247/3125], train_loss:0.081471\n",
      "Epoch [1/10], Iter [1248/3125], train_loss:0.065746\n",
      "Epoch [1/10], Iter [1249/3125], train_loss:0.037090\n",
      "Epoch [1/10], Iter [1250/3125], train_loss:0.076876\n",
      "Epoch [1/10], Iter [1251/3125], train_loss:0.051030\n",
      "Epoch [1/10], Iter [1252/3125], train_loss:0.042274\n",
      "Epoch [1/10], Iter [1253/3125], train_loss:0.068953\n",
      "Epoch [1/10], Iter [1254/3125], train_loss:0.077853\n",
      "Epoch [1/10], Iter [1255/3125], train_loss:0.078600\n",
      "Epoch [1/10], Iter [1256/3125], train_loss:0.029034\n",
      "Epoch [1/10], Iter [1257/3125], train_loss:0.067805\n",
      "Epoch [1/10], Iter [1258/3125], train_loss:0.105204\n",
      "Epoch [1/10], Iter [1259/3125], train_loss:0.044573\n",
      "Epoch [1/10], Iter [1260/3125], train_loss:0.098438\n",
      "Epoch [1/10], Iter [1261/3125], train_loss:0.044922\n",
      "Epoch [1/10], Iter [1262/3125], train_loss:0.077494\n",
      "Epoch [1/10], Iter [1263/3125], train_loss:0.068515\n",
      "Epoch [1/10], Iter [1264/3125], train_loss:0.082361\n",
      "Epoch [1/10], Iter [1265/3125], train_loss:0.065620\n",
      "Epoch [1/10], Iter [1266/3125], train_loss:0.061101\n",
      "Epoch [1/10], Iter [1267/3125], train_loss:0.072236\n",
      "Epoch [1/10], Iter [1268/3125], train_loss:0.057902\n",
      "Epoch [1/10], Iter [1269/3125], train_loss:0.078264\n",
      "Epoch [1/10], Iter [1270/3125], train_loss:0.053628\n",
      "Epoch [1/10], Iter [1271/3125], train_loss:0.076903\n",
      "Epoch [1/10], Iter [1272/3125], train_loss:0.055117\n",
      "Epoch [1/10], Iter [1273/3125], train_loss:0.122055\n",
      "Epoch [1/10], Iter [1274/3125], train_loss:0.041958\n",
      "Epoch [1/10], Iter [1275/3125], train_loss:0.110160\n",
      "Epoch [1/10], Iter [1276/3125], train_loss:0.080354\n",
      "Epoch [1/10], Iter [1277/3125], train_loss:0.036007\n",
      "Epoch [1/10], Iter [1278/3125], train_loss:0.051821\n",
      "Epoch [1/10], Iter [1279/3125], train_loss:0.103632\n",
      "Epoch [1/10], Iter [1280/3125], train_loss:0.105166\n",
      "Epoch [1/10], Iter [1281/3125], train_loss:0.068429\n",
      "Epoch [1/10], Iter [1282/3125], train_loss:0.072354\n",
      "Epoch [1/10], Iter [1283/3125], train_loss:0.058038\n",
      "Epoch [1/10], Iter [1284/3125], train_loss:0.071881\n",
      "Epoch [1/10], Iter [1285/3125], train_loss:0.033587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [1286/3125], train_loss:0.041231\n",
      "Epoch [1/10], Iter [1287/3125], train_loss:0.072158\n",
      "Epoch [1/10], Iter [1288/3125], train_loss:0.037460\n",
      "Epoch [1/10], Iter [1289/3125], train_loss:0.052904\n",
      "Epoch [1/10], Iter [1290/3125], train_loss:0.051290\n",
      "Epoch [1/10], Iter [1291/3125], train_loss:0.076521\n",
      "Epoch [1/10], Iter [1292/3125], train_loss:0.045308\n",
      "Epoch [1/10], Iter [1293/3125], train_loss:0.077797\n",
      "Epoch [1/10], Iter [1294/3125], train_loss:0.050401\n",
      "Epoch [1/10], Iter [1295/3125], train_loss:0.054285\n",
      "Epoch [1/10], Iter [1296/3125], train_loss:0.071456\n",
      "Epoch [1/10], Iter [1297/3125], train_loss:0.069530\n",
      "Epoch [1/10], Iter [1298/3125], train_loss:0.063551\n",
      "Epoch [1/10], Iter [1299/3125], train_loss:0.060730\n",
      "Epoch [1/10], Iter [1300/3125], train_loss:0.054880\n",
      "Epoch [1/10], Iter [1301/3125], train_loss:0.049532\n",
      "Epoch [1/10], Iter [1302/3125], train_loss:0.069171\n",
      "Epoch [1/10], Iter [1303/3125], train_loss:0.061904\n",
      "Epoch [1/10], Iter [1304/3125], train_loss:0.047012\n",
      "Epoch [1/10], Iter [1305/3125], train_loss:0.045866\n",
      "Epoch [1/10], Iter [1306/3125], train_loss:0.042385\n",
      "Epoch [1/10], Iter [1307/3125], train_loss:0.050176\n",
      "Epoch [1/10], Iter [1308/3125], train_loss:0.082048\n",
      "Epoch [1/10], Iter [1309/3125], train_loss:0.042563\n",
      "Epoch [1/10], Iter [1310/3125], train_loss:0.078971\n",
      "Epoch [1/10], Iter [1311/3125], train_loss:0.086524\n",
      "Epoch [1/10], Iter [1312/3125], train_loss:0.056474\n",
      "Epoch [1/10], Iter [1313/3125], train_loss:0.037732\n",
      "Epoch [1/10], Iter [1314/3125], train_loss:0.078819\n",
      "Epoch [1/10], Iter [1315/3125], train_loss:0.082700\n",
      "Epoch [1/10], Iter [1316/3125], train_loss:0.092105\n",
      "Epoch [1/10], Iter [1317/3125], train_loss:0.059939\n",
      "Epoch [1/10], Iter [1318/3125], train_loss:0.073690\n",
      "Epoch [1/10], Iter [1319/3125], train_loss:0.049467\n",
      "Epoch [1/10], Iter [1320/3125], train_loss:0.086146\n",
      "Epoch [1/10], Iter [1321/3125], train_loss:0.061879\n",
      "Epoch [1/10], Iter [1322/3125], train_loss:0.093417\n",
      "Epoch [1/10], Iter [1323/3125], train_loss:0.041446\n",
      "Epoch [1/10], Iter [1324/3125], train_loss:0.055495\n",
      "Epoch [1/10], Iter [1325/3125], train_loss:0.061338\n",
      "Epoch [1/10], Iter [1326/3125], train_loss:0.057086\n",
      "Epoch [1/10], Iter [1327/3125], train_loss:0.051174\n",
      "Epoch [1/10], Iter [1328/3125], train_loss:0.054015\n",
      "Epoch [1/10], Iter [1329/3125], train_loss:0.061765\n",
      "Epoch [1/10], Iter [1330/3125], train_loss:0.066730\n",
      "Epoch [1/10], Iter [1331/3125], train_loss:0.054490\n",
      "Epoch [1/10], Iter [1332/3125], train_loss:0.057822\n",
      "Epoch [1/10], Iter [1333/3125], train_loss:0.063132\n",
      "Epoch [1/10], Iter [1334/3125], train_loss:0.069564\n",
      "Epoch [1/10], Iter [1335/3125], train_loss:0.044150\n",
      "Epoch [1/10], Iter [1336/3125], train_loss:0.080780\n",
      "Epoch [1/10], Iter [1337/3125], train_loss:0.058406\n",
      "Epoch [1/10], Iter [1338/3125], train_loss:0.049550\n",
      "Epoch [1/10], Iter [1339/3125], train_loss:0.044474\n",
      "Epoch [1/10], Iter [1340/3125], train_loss:0.055215\n",
      "Epoch [1/10], Iter [1341/3125], train_loss:0.097746\n",
      "Epoch [1/10], Iter [1342/3125], train_loss:0.071166\n",
      "Epoch [1/10], Iter [1343/3125], train_loss:0.050535\n",
      "Epoch [1/10], Iter [1344/3125], train_loss:0.065595\n",
      "Epoch [1/10], Iter [1345/3125], train_loss:0.069312\n",
      "Epoch [1/10], Iter [1346/3125], train_loss:0.068984\n",
      "Epoch [1/10], Iter [1347/3125], train_loss:0.114133\n",
      "Epoch [1/10], Iter [1348/3125], train_loss:0.053902\n",
      "Epoch [1/10], Iter [1349/3125], train_loss:0.039486\n",
      "Epoch [1/10], Iter [1350/3125], train_loss:0.077412\n",
      "Epoch [1/10], Iter [1351/3125], train_loss:0.105866\n",
      "Epoch [1/10], Iter [1352/3125], train_loss:0.036934\n",
      "Epoch [1/10], Iter [1353/3125], train_loss:0.028790\n",
      "Epoch [1/10], Iter [1354/3125], train_loss:0.044115\n",
      "Epoch [1/10], Iter [1355/3125], train_loss:0.050180\n",
      "Epoch [1/10], Iter [1356/3125], train_loss:0.035173\n",
      "Epoch [1/10], Iter [1357/3125], train_loss:0.066359\n",
      "Epoch [1/10], Iter [1358/3125], train_loss:0.061649\n",
      "Epoch [1/10], Iter [1359/3125], train_loss:0.090383\n",
      "Epoch [1/10], Iter [1360/3125], train_loss:0.094560\n",
      "Epoch [1/10], Iter [1361/3125], train_loss:0.051187\n",
      "Epoch [1/10], Iter [1362/3125], train_loss:0.051535\n",
      "Epoch [1/10], Iter [1363/3125], train_loss:0.086489\n",
      "Epoch [1/10], Iter [1364/3125], train_loss:0.064312\n",
      "Epoch [1/10], Iter [1365/3125], train_loss:0.035589\n",
      "Epoch [1/10], Iter [1366/3125], train_loss:0.074556\n",
      "Epoch [1/10], Iter [1367/3125], train_loss:0.095972\n",
      "Epoch [1/10], Iter [1368/3125], train_loss:0.079113\n",
      "Epoch [1/10], Iter [1369/3125], train_loss:0.075476\n",
      "Epoch [1/10], Iter [1370/3125], train_loss:0.055053\n",
      "Epoch [1/10], Iter [1371/3125], train_loss:0.036419\n",
      "Epoch [1/10], Iter [1372/3125], train_loss:0.082008\n",
      "Epoch [1/10], Iter [1373/3125], train_loss:0.035035\n",
      "Epoch [1/10], Iter [1374/3125], train_loss:0.061965\n",
      "Epoch [1/10], Iter [1375/3125], train_loss:0.090616\n",
      "Epoch [1/10], Iter [1376/3125], train_loss:0.071584\n",
      "Epoch [1/10], Iter [1377/3125], train_loss:0.062969\n",
      "Epoch [1/10], Iter [1378/3125], train_loss:0.049597\n",
      "Epoch [1/10], Iter [1379/3125], train_loss:0.042371\n",
      "Epoch [1/10], Iter [1380/3125], train_loss:0.058470\n",
      "Epoch [1/10], Iter [1381/3125], train_loss:0.089132\n",
      "Epoch [1/10], Iter [1382/3125], train_loss:0.042923\n",
      "Epoch [1/10], Iter [1383/3125], train_loss:0.066922\n",
      "Epoch [1/10], Iter [1384/3125], train_loss:0.055818\n",
      "Epoch [1/10], Iter [1385/3125], train_loss:0.077349\n",
      "Epoch [1/10], Iter [1386/3125], train_loss:0.034871\n",
      "Epoch [1/10], Iter [1387/3125], train_loss:0.034735\n",
      "Epoch [1/10], Iter [1388/3125], train_loss:0.041610\n",
      "Epoch [1/10], Iter [1389/3125], train_loss:0.078672\n",
      "Epoch [1/10], Iter [1390/3125], train_loss:0.079922\n",
      "Epoch [1/10], Iter [1391/3125], train_loss:0.053695\n",
      "Epoch [1/10], Iter [1392/3125], train_loss:0.094359\n",
      "Epoch [1/10], Iter [1393/3125], train_loss:0.066231\n",
      "Epoch [1/10], Iter [1394/3125], train_loss:0.053103\n",
      "Epoch [1/10], Iter [1395/3125], train_loss:0.054961\n",
      "Epoch [1/10], Iter [1396/3125], train_loss:0.069908\n",
      "Epoch [1/10], Iter [1397/3125], train_loss:0.036498\n",
      "Epoch [1/10], Iter [1398/3125], train_loss:0.070611\n",
      "Epoch [1/10], Iter [1399/3125], train_loss:0.046233\n",
      "Epoch [1/10], Iter [1400/3125], train_loss:0.045637\n",
      "Epoch [1/10], Iter [1401/3125], train_loss:0.026635\n",
      "Epoch [1/10], Iter [1402/3125], train_loss:0.051463\n",
      "Epoch [1/10], Iter [1403/3125], train_loss:0.072863\n",
      "Epoch [1/10], Iter [1404/3125], train_loss:0.039532\n",
      "Epoch [1/10], Iter [1405/3125], train_loss:0.094029\n",
      "Epoch [1/10], Iter [1406/3125], train_loss:0.107056\n",
      "Epoch [1/10], Iter [1407/3125], train_loss:0.068884\n",
      "Epoch [1/10], Iter [1408/3125], train_loss:0.045376\n",
      "Epoch [1/10], Iter [1409/3125], train_loss:0.035768\n",
      "Epoch [1/10], Iter [1410/3125], train_loss:0.058423\n",
      "Epoch [1/10], Iter [1411/3125], train_loss:0.105580\n",
      "Epoch [1/10], Iter [1412/3125], train_loss:0.059442\n",
      "Epoch [1/10], Iter [1413/3125], train_loss:0.056727\n",
      "Epoch [1/10], Iter [1414/3125], train_loss:0.046670\n",
      "Epoch [1/10], Iter [1415/3125], train_loss:0.052132\n",
      "Epoch [1/10], Iter [1416/3125], train_loss:0.086853\n",
      "Epoch [1/10], Iter [1417/3125], train_loss:0.053923\n",
      "Epoch [1/10], Iter [1418/3125], train_loss:0.043211\n",
      "Epoch [1/10], Iter [1419/3125], train_loss:0.042907\n",
      "Epoch [1/10], Iter [1420/3125], train_loss:0.044250\n",
      "Epoch [1/10], Iter [1421/3125], train_loss:0.084763\n",
      "Epoch [1/10], Iter [1422/3125], train_loss:0.063013\n",
      "Epoch [1/10], Iter [1423/3125], train_loss:0.031712\n",
      "Epoch [1/10], Iter [1424/3125], train_loss:0.066372\n",
      "Epoch [1/10], Iter [1425/3125], train_loss:0.079808\n",
      "Epoch [1/10], Iter [1426/3125], train_loss:0.070664\n",
      "Epoch [1/10], Iter [1427/3125], train_loss:0.042726\n",
      "Epoch [1/10], Iter [1428/3125], train_loss:0.047623\n",
      "Epoch [1/10], Iter [1429/3125], train_loss:0.054263\n",
      "Epoch [1/10], Iter [1430/3125], train_loss:0.065956\n",
      "Epoch [1/10], Iter [1431/3125], train_loss:0.067826\n",
      "Epoch [1/10], Iter [1432/3125], train_loss:0.049903\n",
      "Epoch [1/10], Iter [1433/3125], train_loss:0.058264\n",
      "Epoch [1/10], Iter [1434/3125], train_loss:0.082112\n",
      "Epoch [1/10], Iter [1435/3125], train_loss:0.048372\n",
      "Epoch [1/10], Iter [1436/3125], train_loss:0.089613\n",
      "Epoch [1/10], Iter [1437/3125], train_loss:0.070496\n",
      "Epoch [1/10], Iter [1438/3125], train_loss:0.048467\n",
      "Epoch [1/10], Iter [1439/3125], train_loss:0.048719\n",
      "Epoch [1/10], Iter [1440/3125], train_loss:0.051029\n",
      "Epoch [1/10], Iter [1441/3125], train_loss:0.066726\n",
      "Epoch [1/10], Iter [1442/3125], train_loss:0.074743\n",
      "Epoch [1/10], Iter [1443/3125], train_loss:0.062530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [1444/3125], train_loss:0.031921\n",
      "Epoch [1/10], Iter [1445/3125], train_loss:0.082468\n",
      "Epoch [1/10], Iter [1446/3125], train_loss:0.066029\n",
      "Epoch [1/10], Iter [1447/3125], train_loss:0.079104\n",
      "Epoch [1/10], Iter [1448/3125], train_loss:0.050547\n",
      "Epoch [1/10], Iter [1449/3125], train_loss:0.070847\n",
      "Epoch [1/10], Iter [1450/3125], train_loss:0.066685\n",
      "Epoch [1/10], Iter [1451/3125], train_loss:0.062502\n",
      "Epoch [1/10], Iter [1452/3125], train_loss:0.039792\n",
      "Epoch [1/10], Iter [1453/3125], train_loss:0.074898\n",
      "Epoch [1/10], Iter [1454/3125], train_loss:0.082731\n",
      "Epoch [1/10], Iter [1455/3125], train_loss:0.051062\n",
      "Epoch [1/10], Iter [1456/3125], train_loss:0.081949\n",
      "Epoch [1/10], Iter [1457/3125], train_loss:0.048781\n",
      "Epoch [1/10], Iter [1458/3125], train_loss:0.031672\n",
      "Epoch [1/10], Iter [1459/3125], train_loss:0.081797\n",
      "Epoch [1/10], Iter [1460/3125], train_loss:0.043624\n",
      "Epoch [1/10], Iter [1461/3125], train_loss:0.042655\n",
      "Epoch [1/10], Iter [1462/3125], train_loss:0.065425\n",
      "Epoch [1/10], Iter [1463/3125], train_loss:0.051312\n",
      "Epoch [1/10], Iter [1464/3125], train_loss:0.069975\n",
      "Epoch [1/10], Iter [1465/3125], train_loss:0.054417\n",
      "Epoch [1/10], Iter [1466/3125], train_loss:0.068450\n",
      "Epoch [1/10], Iter [1467/3125], train_loss:0.055852\n",
      "Epoch [1/10], Iter [1468/3125], train_loss:0.056495\n",
      "Epoch [1/10], Iter [1469/3125], train_loss:0.048216\n",
      "Epoch [1/10], Iter [1470/3125], train_loss:0.116062\n",
      "Epoch [1/10], Iter [1471/3125], train_loss:0.076963\n",
      "Epoch [1/10], Iter [1472/3125], train_loss:0.061780\n",
      "Epoch [1/10], Iter [1473/3125], train_loss:0.057824\n",
      "Epoch [1/10], Iter [1474/3125], train_loss:0.051863\n",
      "Epoch [1/10], Iter [1475/3125], train_loss:0.064877\n",
      "Epoch [1/10], Iter [1476/3125], train_loss:0.026023\n",
      "Epoch [1/10], Iter [1477/3125], train_loss:0.071512\n",
      "Epoch [1/10], Iter [1478/3125], train_loss:0.046893\n",
      "Epoch [1/10], Iter [1479/3125], train_loss:0.086675\n",
      "Epoch [1/10], Iter [1480/3125], train_loss:0.056367\n",
      "Epoch [1/10], Iter [1481/3125], train_loss:0.086944\n",
      "Epoch [1/10], Iter [1482/3125], train_loss:0.059426\n",
      "Epoch [1/10], Iter [1483/3125], train_loss:0.062180\n",
      "Epoch [1/10], Iter [1484/3125], train_loss:0.036093\n",
      "Epoch [1/10], Iter [1485/3125], train_loss:0.053832\n",
      "Epoch [1/10], Iter [1486/3125], train_loss:0.059764\n",
      "Epoch [1/10], Iter [1487/3125], train_loss:0.069709\n",
      "Epoch [1/10], Iter [1488/3125], train_loss:0.058866\n",
      "Epoch [1/10], Iter [1489/3125], train_loss:0.042857\n",
      "Epoch [1/10], Iter [1490/3125], train_loss:0.051318\n",
      "Epoch [1/10], Iter [1491/3125], train_loss:0.046036\n",
      "Epoch [1/10], Iter [1492/3125], train_loss:0.067652\n",
      "Epoch [1/10], Iter [1493/3125], train_loss:0.068058\n",
      "Epoch [1/10], Iter [1494/3125], train_loss:0.058382\n",
      "Epoch [1/10], Iter [1495/3125], train_loss:0.071653\n",
      "Epoch [1/10], Iter [1496/3125], train_loss:0.030701\n",
      "Epoch [1/10], Iter [1497/3125], train_loss:0.085657\n",
      "Epoch [1/10], Iter [1498/3125], train_loss:0.051193\n",
      "Epoch [1/10], Iter [1499/3125], train_loss:0.047368\n",
      "Epoch [1/10], Iter [1500/3125], train_loss:0.056843\n",
      "Epoch [1/10], Iter [1501/3125], train_loss:0.077672\n",
      "Epoch [1/10], Iter [1502/3125], train_loss:0.046002\n",
      "Epoch [1/10], Iter [1503/3125], train_loss:0.050379\n",
      "Epoch [1/10], Iter [1504/3125], train_loss:0.067272\n",
      "Epoch [1/10], Iter [1505/3125], train_loss:0.039557\n",
      "Epoch [1/10], Iter [1506/3125], train_loss:0.072687\n",
      "Epoch [1/10], Iter [1507/3125], train_loss:0.049326\n",
      "Epoch [1/10], Iter [1508/3125], train_loss:0.072209\n",
      "Epoch [1/10], Iter [1509/3125], train_loss:0.092582\n",
      "Epoch [1/10], Iter [1510/3125], train_loss:0.049500\n",
      "Epoch [1/10], Iter [1511/3125], train_loss:0.037127\n",
      "Epoch [1/10], Iter [1512/3125], train_loss:0.062338\n",
      "Epoch [1/10], Iter [1513/3125], train_loss:0.047520\n",
      "Epoch [1/10], Iter [1514/3125], train_loss:0.069938\n",
      "Epoch [1/10], Iter [1515/3125], train_loss:0.058069\n",
      "Epoch [1/10], Iter [1516/3125], train_loss:0.070114\n",
      "Epoch [1/10], Iter [1517/3125], train_loss:0.071238\n",
      "Epoch [1/10], Iter [1518/3125], train_loss:0.036374\n",
      "Epoch [1/10], Iter [1519/3125], train_loss:0.067921\n",
      "Epoch [1/10], Iter [1520/3125], train_loss:0.103123\n",
      "Epoch [1/10], Iter [1521/3125], train_loss:0.084642\n",
      "Epoch [1/10], Iter [1522/3125], train_loss:0.052527\n",
      "Epoch [1/10], Iter [1523/3125], train_loss:0.060209\n",
      "Epoch [1/10], Iter [1524/3125], train_loss:0.078986\n",
      "Epoch [1/10], Iter [1525/3125], train_loss:0.055619\n",
      "Epoch [1/10], Iter [1526/3125], train_loss:0.035694\n",
      "Epoch [1/10], Iter [1527/3125], train_loss:0.067099\n",
      "Epoch [1/10], Iter [1528/3125], train_loss:0.058410\n",
      "Epoch [1/10], Iter [1529/3125], train_loss:0.073605\n",
      "Epoch [1/10], Iter [1530/3125], train_loss:0.048546\n",
      "Epoch [1/10], Iter [1531/3125], train_loss:0.059657\n",
      "Epoch [1/10], Iter [1532/3125], train_loss:0.064168\n",
      "Epoch [1/10], Iter [1533/3125], train_loss:0.037178\n",
      "Epoch [1/10], Iter [1534/3125], train_loss:0.053720\n",
      "Epoch [1/10], Iter [1535/3125], train_loss:0.076513\n",
      "Epoch [1/10], Iter [1536/3125], train_loss:0.058834\n",
      "Epoch [1/10], Iter [1537/3125], train_loss:0.071573\n",
      "Epoch [1/10], Iter [1538/3125], train_loss:0.060269\n",
      "Epoch [1/10], Iter [1539/3125], train_loss:0.052749\n",
      "Epoch [1/10], Iter [1540/3125], train_loss:0.037708\n",
      "Epoch [1/10], Iter [1541/3125], train_loss:0.066439\n",
      "Epoch [1/10], Iter [1542/3125], train_loss:0.090691\n",
      "Epoch [1/10], Iter [1543/3125], train_loss:0.056245\n",
      "Epoch [1/10], Iter [1544/3125], train_loss:0.055924\n",
      "Epoch [1/10], Iter [1545/3125], train_loss:0.041803\n",
      "Epoch [1/10], Iter [1546/3125], train_loss:0.048068\n",
      "Epoch [1/10], Iter [1547/3125], train_loss:0.036092\n",
      "Epoch [1/10], Iter [1548/3125], train_loss:0.043875\n",
      "Epoch [1/10], Iter [1549/3125], train_loss:0.079322\n",
      "Epoch [1/10], Iter [1550/3125], train_loss:0.039852\n",
      "Epoch [1/10], Iter [1551/3125], train_loss:0.103905\n",
      "Epoch [1/10], Iter [1552/3125], train_loss:0.091744\n",
      "Epoch [1/10], Iter [1553/3125], train_loss:0.055681\n",
      "Epoch [1/10], Iter [1554/3125], train_loss:0.092191\n",
      "Epoch [1/10], Iter [1555/3125], train_loss:0.062235\n",
      "Epoch [1/10], Iter [1556/3125], train_loss:0.057970\n",
      "Epoch [1/10], Iter [1557/3125], train_loss:0.067547\n",
      "Epoch [1/10], Iter [1558/3125], train_loss:0.055146\n",
      "Epoch [1/10], Iter [1559/3125], train_loss:0.054776\n",
      "Epoch [1/10], Iter [1560/3125], train_loss:0.027517\n",
      "Epoch [1/10], Iter [1561/3125], train_loss:0.072663\n",
      "Epoch [1/10], Iter [1562/3125], train_loss:0.058465\n",
      "Epoch [1/10], Iter [1563/3125], train_loss:0.046655\n",
      "Epoch [1/10], Iter [1564/3125], train_loss:0.119325\n",
      "Epoch [1/10], Iter [1565/3125], train_loss:0.054731\n",
      "Epoch [1/10], Iter [1566/3125], train_loss:0.081642\n",
      "Epoch [1/10], Iter [1567/3125], train_loss:0.048881\n",
      "Epoch [1/10], Iter [1568/3125], train_loss:0.058173\n",
      "Epoch [1/10], Iter [1569/3125], train_loss:0.069358\n",
      "Epoch [1/10], Iter [1570/3125], train_loss:0.061475\n",
      "Epoch [1/10], Iter [1571/3125], train_loss:0.065325\n",
      "Epoch [1/10], Iter [1572/3125], train_loss:0.070670\n",
      "Epoch [1/10], Iter [1573/3125], train_loss:0.081902\n",
      "Epoch [1/10], Iter [1574/3125], train_loss:0.049094\n",
      "Epoch [1/10], Iter [1575/3125], train_loss:0.056214\n",
      "Epoch [1/10], Iter [1576/3125], train_loss:0.069279\n",
      "Epoch [1/10], Iter [1577/3125], train_loss:0.056715\n",
      "Epoch [1/10], Iter [1578/3125], train_loss:0.099390\n",
      "Epoch [1/10], Iter [1579/3125], train_loss:0.051443\n",
      "Epoch [1/10], Iter [1580/3125], train_loss:0.066337\n",
      "Epoch [1/10], Iter [1581/3125], train_loss:0.032681\n",
      "Epoch [1/10], Iter [1582/3125], train_loss:0.036135\n",
      "Epoch [1/10], Iter [1583/3125], train_loss:0.133781\n",
      "Epoch [1/10], Iter [1584/3125], train_loss:0.039585\n",
      "Epoch [1/10], Iter [1585/3125], train_loss:0.040581\n",
      "Epoch [1/10], Iter [1586/3125], train_loss:0.045098\n",
      "Epoch [1/10], Iter [1587/3125], train_loss:0.079372\n",
      "Epoch [1/10], Iter [1588/3125], train_loss:0.083663\n",
      "Epoch [1/10], Iter [1589/3125], train_loss:0.057084\n",
      "Epoch [1/10], Iter [1590/3125], train_loss:0.070563\n",
      "Epoch [1/10], Iter [1591/3125], train_loss:0.065010\n",
      "Epoch [1/10], Iter [1592/3125], train_loss:0.047786\n",
      "Epoch [1/10], Iter [1593/3125], train_loss:0.060590\n",
      "Epoch [1/10], Iter [1594/3125], train_loss:0.081765\n",
      "Epoch [1/10], Iter [1595/3125], train_loss:0.056855\n",
      "Epoch [1/10], Iter [1596/3125], train_loss:0.039855\n",
      "Epoch [1/10], Iter [1597/3125], train_loss:0.046420\n",
      "Epoch [1/10], Iter [1598/3125], train_loss:0.043999\n",
      "Epoch [1/10], Iter [1599/3125], train_loss:0.046221\n",
      "Epoch [1/10], Iter [1600/3125], train_loss:0.064322\n",
      "Epoch [1/10], Iter [1601/3125], train_loss:0.026215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [1602/3125], train_loss:0.035398\n",
      "Epoch [1/10], Iter [1603/3125], train_loss:0.082975\n",
      "Epoch [1/10], Iter [1604/3125], train_loss:0.069643\n",
      "Epoch [1/10], Iter [1605/3125], train_loss:0.074299\n",
      "Epoch [1/10], Iter [1606/3125], train_loss:0.036288\n",
      "Epoch [1/10], Iter [1607/3125], train_loss:0.089655\n",
      "Epoch [1/10], Iter [1608/3125], train_loss:0.052850\n",
      "Epoch [1/10], Iter [1609/3125], train_loss:0.103227\n",
      "Epoch [1/10], Iter [1610/3125], train_loss:0.021318\n",
      "Epoch [1/10], Iter [1611/3125], train_loss:0.053062\n",
      "Epoch [1/10], Iter [1612/3125], train_loss:0.064742\n",
      "Epoch [1/10], Iter [1613/3125], train_loss:0.041883\n",
      "Epoch [1/10], Iter [1614/3125], train_loss:0.046411\n",
      "Epoch [1/10], Iter [1615/3125], train_loss:0.058942\n",
      "Epoch [1/10], Iter [1616/3125], train_loss:0.044977\n",
      "Epoch [1/10], Iter [1617/3125], train_loss:0.041410\n",
      "Epoch [1/10], Iter [1618/3125], train_loss:0.084004\n",
      "Epoch [1/10], Iter [1619/3125], train_loss:0.064973\n",
      "Epoch [1/10], Iter [1620/3125], train_loss:0.083455\n",
      "Epoch [1/10], Iter [1621/3125], train_loss:0.061671\n",
      "Epoch [1/10], Iter [1622/3125], train_loss:0.040480\n",
      "Epoch [1/10], Iter [1623/3125], train_loss:0.058023\n",
      "Epoch [1/10], Iter [1624/3125], train_loss:0.059297\n",
      "Epoch [1/10], Iter [1625/3125], train_loss:0.056020\n",
      "Epoch [1/10], Iter [1626/3125], train_loss:0.070588\n",
      "Epoch [1/10], Iter [1627/3125], train_loss:0.057357\n",
      "Epoch [1/10], Iter [1628/3125], train_loss:0.056434\n",
      "Epoch [1/10], Iter [1629/3125], train_loss:0.063109\n",
      "Epoch [1/10], Iter [1630/3125], train_loss:0.088339\n",
      "Epoch [1/10], Iter [1631/3125], train_loss:0.098464\n",
      "Epoch [1/10], Iter [1632/3125], train_loss:0.085437\n",
      "Epoch [1/10], Iter [1633/3125], train_loss:0.056909\n",
      "Epoch [1/10], Iter [1634/3125], train_loss:0.044746\n",
      "Epoch [1/10], Iter [1635/3125], train_loss:0.058112\n",
      "Epoch [1/10], Iter [1636/3125], train_loss:0.051674\n",
      "Epoch [1/10], Iter [1637/3125], train_loss:0.073020\n",
      "Epoch [1/10], Iter [1638/3125], train_loss:0.054744\n",
      "Epoch [1/10], Iter [1639/3125], train_loss:0.020978\n",
      "Epoch [1/10], Iter [1640/3125], train_loss:0.040359\n",
      "Epoch [1/10], Iter [1641/3125], train_loss:0.078304\n",
      "Epoch [1/10], Iter [1642/3125], train_loss:0.042950\n",
      "Epoch [1/10], Iter [1643/3125], train_loss:0.035843\n",
      "Epoch [1/10], Iter [1644/3125], train_loss:0.075233\n",
      "Epoch [1/10], Iter [1645/3125], train_loss:0.057683\n",
      "Epoch [1/10], Iter [1646/3125], train_loss:0.058583\n",
      "Epoch [1/10], Iter [1647/3125], train_loss:0.054886\n",
      "Epoch [1/10], Iter [1648/3125], train_loss:0.074777\n",
      "Epoch [1/10], Iter [1649/3125], train_loss:0.035126\n",
      "Epoch [1/10], Iter [1650/3125], train_loss:0.030282\n",
      "Epoch [1/10], Iter [1651/3125], train_loss:0.065689\n",
      "Epoch [1/10], Iter [1652/3125], train_loss:0.038346\n",
      "Epoch [1/10], Iter [1653/3125], train_loss:0.077780\n",
      "Epoch [1/10], Iter [1654/3125], train_loss:0.057102\n",
      "Epoch [1/10], Iter [1655/3125], train_loss:0.054383\n",
      "Epoch [1/10], Iter [1656/3125], train_loss:0.033800\n",
      "Epoch [1/10], Iter [1657/3125], train_loss:0.047648\n",
      "Epoch [1/10], Iter [1658/3125], train_loss:0.040589\n",
      "Epoch [1/10], Iter [1659/3125], train_loss:0.057799\n",
      "Epoch [1/10], Iter [1660/3125], train_loss:0.060077\n",
      "Epoch [1/10], Iter [1661/3125], train_loss:0.045393\n",
      "Epoch [1/10], Iter [1662/3125], train_loss:0.051922\n",
      "Epoch [1/10], Iter [1663/3125], train_loss:0.122704\n",
      "Epoch [1/10], Iter [1664/3125], train_loss:0.048353\n",
      "Epoch [1/10], Iter [1665/3125], train_loss:0.021179\n",
      "Epoch [1/10], Iter [1666/3125], train_loss:0.076526\n",
      "Epoch [1/10], Iter [1667/3125], train_loss:0.079436\n",
      "Epoch [1/10], Iter [1668/3125], train_loss:0.039214\n",
      "Epoch [1/10], Iter [1669/3125], train_loss:0.042830\n",
      "Epoch [1/10], Iter [1670/3125], train_loss:0.042728\n",
      "Epoch [1/10], Iter [1671/3125], train_loss:0.048967\n",
      "Epoch [1/10], Iter [1672/3125], train_loss:0.054698\n",
      "Epoch [1/10], Iter [1673/3125], train_loss:0.041978\n",
      "Epoch [1/10], Iter [1674/3125], train_loss:0.073049\n",
      "Epoch [1/10], Iter [1675/3125], train_loss:0.037080\n",
      "Epoch [1/10], Iter [1676/3125], train_loss:0.027289\n",
      "Epoch [1/10], Iter [1677/3125], train_loss:0.060551\n",
      "Epoch [1/10], Iter [1678/3125], train_loss:0.045196\n",
      "Epoch [1/10], Iter [1679/3125], train_loss:0.080010\n",
      "Epoch [1/10], Iter [1680/3125], train_loss:0.053764\n",
      "Epoch [1/10], Iter [1681/3125], train_loss:0.073596\n",
      "Epoch [1/10], Iter [1682/3125], train_loss:0.070110\n",
      "Epoch [1/10], Iter [1683/3125], train_loss:0.047264\n",
      "Epoch [1/10], Iter [1684/3125], train_loss:0.061473\n",
      "Epoch [1/10], Iter [1685/3125], train_loss:0.041371\n",
      "Epoch [1/10], Iter [1686/3125], train_loss:0.049107\n",
      "Epoch [1/10], Iter [1687/3125], train_loss:0.051743\n",
      "Epoch [1/10], Iter [1688/3125], train_loss:0.109640\n",
      "Epoch [1/10], Iter [1689/3125], train_loss:0.048228\n",
      "Epoch [1/10], Iter [1690/3125], train_loss:0.050521\n",
      "Epoch [1/10], Iter [1691/3125], train_loss:0.079257\n",
      "Epoch [1/10], Iter [1692/3125], train_loss:0.042919\n",
      "Epoch [1/10], Iter [1693/3125], train_loss:0.058962\n",
      "Epoch [1/10], Iter [1694/3125], train_loss:0.072977\n",
      "Epoch [1/10], Iter [1695/3125], train_loss:0.029940\n",
      "Epoch [1/10], Iter [1696/3125], train_loss:0.072861\n",
      "Epoch [1/10], Iter [1697/3125], train_loss:0.075670\n",
      "Epoch [1/10], Iter [1698/3125], train_loss:0.065588\n",
      "Epoch [1/10], Iter [1699/3125], train_loss:0.067763\n",
      "Epoch [1/10], Iter [1700/3125], train_loss:0.037320\n",
      "Epoch [1/10], Iter [1701/3125], train_loss:0.084554\n",
      "Epoch [1/10], Iter [1702/3125], train_loss:0.046403\n",
      "Epoch [1/10], Iter [1703/3125], train_loss:0.040859\n",
      "Epoch [1/10], Iter [1704/3125], train_loss:0.058458\n",
      "Epoch [1/10], Iter [1705/3125], train_loss:0.066891\n",
      "Epoch [1/10], Iter [1706/3125], train_loss:0.100955\n",
      "Epoch [1/10], Iter [1707/3125], train_loss:0.062376\n",
      "Epoch [1/10], Iter [1708/3125], train_loss:0.068730\n",
      "Epoch [1/10], Iter [1709/3125], train_loss:0.038045\n",
      "Epoch [1/10], Iter [1710/3125], train_loss:0.060304\n",
      "Epoch [1/10], Iter [1711/3125], train_loss:0.046575\n",
      "Epoch [1/10], Iter [1712/3125], train_loss:0.048462\n",
      "Epoch [1/10], Iter [1713/3125], train_loss:0.072498\n",
      "Epoch [1/10], Iter [1714/3125], train_loss:0.052895\n",
      "Epoch [1/10], Iter [1715/3125], train_loss:0.065395\n",
      "Epoch [1/10], Iter [1716/3125], train_loss:0.076119\n",
      "Epoch [1/10], Iter [1717/3125], train_loss:0.084909\n",
      "Epoch [1/10], Iter [1718/3125], train_loss:0.058882\n",
      "Epoch [1/10], Iter [1719/3125], train_loss:0.064582\n",
      "Epoch [1/10], Iter [1720/3125], train_loss:0.056367\n",
      "Epoch [1/10], Iter [1721/3125], train_loss:0.059624\n",
      "Epoch [1/10], Iter [1722/3125], train_loss:0.058548\n",
      "Epoch [1/10], Iter [1723/3125], train_loss:0.071492\n",
      "Epoch [1/10], Iter [1724/3125], train_loss:0.087462\n",
      "Epoch [1/10], Iter [1725/3125], train_loss:0.038312\n",
      "Epoch [1/10], Iter [1726/3125], train_loss:0.039811\n",
      "Epoch [1/10], Iter [1727/3125], train_loss:0.047398\n",
      "Epoch [1/10], Iter [1728/3125], train_loss:0.054377\n",
      "Epoch [1/10], Iter [1729/3125], train_loss:0.061826\n",
      "Epoch [1/10], Iter [1730/3125], train_loss:0.051879\n",
      "Epoch [1/10], Iter [1731/3125], train_loss:0.105766\n",
      "Epoch [1/10], Iter [1732/3125], train_loss:0.058592\n",
      "Epoch [1/10], Iter [1733/3125], train_loss:0.058135\n",
      "Epoch [1/10], Iter [1734/3125], train_loss:0.077106\n",
      "Epoch [1/10], Iter [1735/3125], train_loss:0.053300\n",
      "Epoch [1/10], Iter [1736/3125], train_loss:0.099648\n",
      "Epoch [1/10], Iter [1737/3125], train_loss:0.038420\n",
      "Epoch [1/10], Iter [1738/3125], train_loss:0.074359\n",
      "Epoch [1/10], Iter [1739/3125], train_loss:0.075496\n",
      "Epoch [1/10], Iter [1740/3125], train_loss:0.026707\n",
      "Epoch [1/10], Iter [1741/3125], train_loss:0.051810\n",
      "Epoch [1/10], Iter [1742/3125], train_loss:0.061063\n",
      "Epoch [1/10], Iter [1743/3125], train_loss:0.070292\n",
      "Epoch [1/10], Iter [1744/3125], train_loss:0.042350\n",
      "Epoch [1/10], Iter [1745/3125], train_loss:0.059614\n",
      "Epoch [1/10], Iter [1746/3125], train_loss:0.025684\n",
      "Epoch [1/10], Iter [1747/3125], train_loss:0.044094\n",
      "Epoch [1/10], Iter [1748/3125], train_loss:0.039633\n",
      "Epoch [1/10], Iter [1749/3125], train_loss:0.061609\n",
      "Epoch [1/10], Iter [1750/3125], train_loss:0.059462\n",
      "Epoch [1/10], Iter [1751/3125], train_loss:0.085215\n",
      "Epoch [1/10], Iter [1752/3125], train_loss:0.061459\n",
      "Epoch [1/10], Iter [1753/3125], train_loss:0.051309\n",
      "Epoch [1/10], Iter [1754/3125], train_loss:0.055947\n",
      "Epoch [1/10], Iter [1755/3125], train_loss:0.082786\n",
      "Epoch [1/10], Iter [1756/3125], train_loss:0.097624\n",
      "Epoch [1/10], Iter [1757/3125], train_loss:0.061017\n",
      "Epoch [1/10], Iter [1758/3125], train_loss:0.070072\n",
      "Epoch [1/10], Iter [1759/3125], train_loss:0.075882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [1760/3125], train_loss:0.039222\n",
      "Epoch [1/10], Iter [1761/3125], train_loss:0.071271\n",
      "Epoch [1/10], Iter [1762/3125], train_loss:0.043728\n",
      "Epoch [1/10], Iter [1763/3125], train_loss:0.060507\n",
      "Epoch [1/10], Iter [1764/3125], train_loss:0.072506\n",
      "Epoch [1/10], Iter [1765/3125], train_loss:0.056758\n",
      "Epoch [1/10], Iter [1766/3125], train_loss:0.043773\n",
      "Epoch [1/10], Iter [1767/3125], train_loss:0.053143\n",
      "Epoch [1/10], Iter [1768/3125], train_loss:0.092098\n",
      "Epoch [1/10], Iter [1769/3125], train_loss:0.027869\n",
      "Epoch [1/10], Iter [1770/3125], train_loss:0.057473\n",
      "Epoch [1/10], Iter [1771/3125], train_loss:0.060365\n",
      "Epoch [1/10], Iter [1772/3125], train_loss:0.040789\n",
      "Epoch [1/10], Iter [1773/3125], train_loss:0.064049\n",
      "Epoch [1/10], Iter [1774/3125], train_loss:0.063056\n",
      "Epoch [1/10], Iter [1775/3125], train_loss:0.051557\n",
      "Epoch [1/10], Iter [1776/3125], train_loss:0.054645\n",
      "Epoch [1/10], Iter [1777/3125], train_loss:0.039127\n",
      "Epoch [1/10], Iter [1778/3125], train_loss:0.024407\n",
      "Epoch [1/10], Iter [1779/3125], train_loss:0.052543\n",
      "Epoch [1/10], Iter [1780/3125], train_loss:0.046873\n",
      "Epoch [1/10], Iter [1781/3125], train_loss:0.041262\n",
      "Epoch [1/10], Iter [1782/3125], train_loss:0.080122\n",
      "Epoch [1/10], Iter [1783/3125], train_loss:0.050520\n",
      "Epoch [1/10], Iter [1784/3125], train_loss:0.055967\n",
      "Epoch [1/10], Iter [1785/3125], train_loss:0.035253\n",
      "Epoch [1/10], Iter [1786/3125], train_loss:0.079063\n",
      "Epoch [1/10], Iter [1787/3125], train_loss:0.074867\n",
      "Epoch [1/10], Iter [1788/3125], train_loss:0.055334\n",
      "Epoch [1/10], Iter [1789/3125], train_loss:0.057995\n",
      "Epoch [1/10], Iter [1790/3125], train_loss:0.040717\n",
      "Epoch [1/10], Iter [1791/3125], train_loss:0.077024\n",
      "Epoch [1/10], Iter [1792/3125], train_loss:0.050221\n",
      "Epoch [1/10], Iter [1793/3125], train_loss:0.094391\n",
      "Epoch [1/10], Iter [1794/3125], train_loss:0.074695\n",
      "Epoch [1/10], Iter [1795/3125], train_loss:0.058015\n",
      "Epoch [1/10], Iter [1796/3125], train_loss:0.047358\n",
      "Epoch [1/10], Iter [1797/3125], train_loss:0.065972\n",
      "Epoch [1/10], Iter [1798/3125], train_loss:0.045176\n",
      "Epoch [1/10], Iter [1799/3125], train_loss:0.038734\n",
      "Epoch [1/10], Iter [1800/3125], train_loss:0.066014\n",
      "Epoch [1/10], Iter [1801/3125], train_loss:0.046584\n",
      "Epoch [1/10], Iter [1802/3125], train_loss:0.057352\n",
      "Epoch [1/10], Iter [1803/3125], train_loss:0.036245\n",
      "Epoch [1/10], Iter [1804/3125], train_loss:0.040863\n",
      "Epoch [1/10], Iter [1805/3125], train_loss:0.120763\n",
      "Epoch [1/10], Iter [1806/3125], train_loss:0.031612\n",
      "Epoch [1/10], Iter [1807/3125], train_loss:0.073508\n",
      "Epoch [1/10], Iter [1808/3125], train_loss:0.059417\n",
      "Epoch [1/10], Iter [1809/3125], train_loss:0.072521\n",
      "Epoch [1/10], Iter [1810/3125], train_loss:0.063052\n",
      "Epoch [1/10], Iter [1811/3125], train_loss:0.059529\n",
      "Epoch [1/10], Iter [1812/3125], train_loss:0.046363\n",
      "Epoch [1/10], Iter [1813/3125], train_loss:0.073090\n",
      "Epoch [1/10], Iter [1814/3125], train_loss:0.034225\n",
      "Epoch [1/10], Iter [1815/3125], train_loss:0.085764\n",
      "Epoch [1/10], Iter [1816/3125], train_loss:0.046848\n",
      "Epoch [1/10], Iter [1817/3125], train_loss:0.059717\n",
      "Epoch [1/10], Iter [1818/3125], train_loss:0.047675\n",
      "Epoch [1/10], Iter [1819/3125], train_loss:0.084691\n",
      "Epoch [1/10], Iter [1820/3125], train_loss:0.079962\n",
      "Epoch [1/10], Iter [1821/3125], train_loss:0.089780\n",
      "Epoch [1/10], Iter [1822/3125], train_loss:0.060596\n",
      "Epoch [1/10], Iter [1823/3125], train_loss:0.049416\n",
      "Epoch [1/10], Iter [1824/3125], train_loss:0.091829\n",
      "Epoch [1/10], Iter [1825/3125], train_loss:0.086237\n",
      "Epoch [1/10], Iter [1826/3125], train_loss:0.051125\n",
      "Epoch [1/10], Iter [1827/3125], train_loss:0.097379\n",
      "Epoch [1/10], Iter [1828/3125], train_loss:0.102906\n",
      "Epoch [1/10], Iter [1829/3125], train_loss:0.080723\n",
      "Epoch [1/10], Iter [1830/3125], train_loss:0.040206\n",
      "Epoch [1/10], Iter [1831/3125], train_loss:0.059156\n",
      "Epoch [1/10], Iter [1832/3125], train_loss:0.043076\n",
      "Epoch [1/10], Iter [1833/3125], train_loss:0.029663\n",
      "Epoch [1/10], Iter [1834/3125], train_loss:0.051820\n",
      "Epoch [1/10], Iter [1835/3125], train_loss:0.068084\n",
      "Epoch [1/10], Iter [1836/3125], train_loss:0.036504\n",
      "Epoch [1/10], Iter [1837/3125], train_loss:0.048193\n",
      "Epoch [1/10], Iter [1838/3125], train_loss:0.053339\n",
      "Epoch [1/10], Iter [1839/3125], train_loss:0.051840\n",
      "Epoch [1/10], Iter [1840/3125], train_loss:0.019614\n",
      "Epoch [1/10], Iter [1841/3125], train_loss:0.055469\n",
      "Epoch [1/10], Iter [1842/3125], train_loss:0.069309\n",
      "Epoch [1/10], Iter [1843/3125], train_loss:0.077044\n",
      "Epoch [1/10], Iter [1844/3125], train_loss:0.091119\n",
      "Epoch [1/10], Iter [1845/3125], train_loss:0.056013\n",
      "Epoch [1/10], Iter [1846/3125], train_loss:0.052507\n",
      "Epoch [1/10], Iter [1847/3125], train_loss:0.079659\n",
      "Epoch [1/10], Iter [1848/3125], train_loss:0.053403\n",
      "Epoch [1/10], Iter [1849/3125], train_loss:0.077848\n",
      "Epoch [1/10], Iter [1850/3125], train_loss:0.051112\n",
      "Epoch [1/10], Iter [1851/3125], train_loss:0.046792\n",
      "Epoch [1/10], Iter [1852/3125], train_loss:0.041306\n",
      "Epoch [1/10], Iter [1853/3125], train_loss:0.043293\n",
      "Epoch [1/10], Iter [1854/3125], train_loss:0.051519\n",
      "Epoch [1/10], Iter [1855/3125], train_loss:0.055836\n",
      "Epoch [1/10], Iter [1856/3125], train_loss:0.047736\n",
      "Epoch [1/10], Iter [1857/3125], train_loss:0.069006\n",
      "Epoch [1/10], Iter [1858/3125], train_loss:0.046833\n",
      "Epoch [1/10], Iter [1859/3125], train_loss:0.112520\n",
      "Epoch [1/10], Iter [1860/3125], train_loss:0.049536\n",
      "Epoch [1/10], Iter [1861/3125], train_loss:0.054126\n",
      "Epoch [1/10], Iter [1862/3125], train_loss:0.079082\n",
      "Epoch [1/10], Iter [1863/3125], train_loss:0.046699\n",
      "Epoch [1/10], Iter [1864/3125], train_loss:0.042452\n",
      "Epoch [1/10], Iter [1865/3125], train_loss:0.050977\n",
      "Epoch [1/10], Iter [1866/3125], train_loss:0.037490\n",
      "Epoch [1/10], Iter [1867/3125], train_loss:0.044270\n",
      "Epoch [1/10], Iter [1868/3125], train_loss:0.022775\n",
      "Epoch [1/10], Iter [1869/3125], train_loss:0.048254\n",
      "Epoch [1/10], Iter [1870/3125], train_loss:0.047147\n",
      "Epoch [1/10], Iter [1871/3125], train_loss:0.064558\n",
      "Epoch [1/10], Iter [1872/3125], train_loss:0.033295\n",
      "Epoch [1/10], Iter [1873/3125], train_loss:0.037831\n",
      "Epoch [1/10], Iter [1874/3125], train_loss:0.035450\n",
      "Epoch [1/10], Iter [1875/3125], train_loss:0.120475\n",
      "Epoch [1/10], Iter [1876/3125], train_loss:0.065689\n",
      "Epoch [1/10], Iter [1877/3125], train_loss:0.051821\n",
      "Epoch [1/10], Iter [1878/3125], train_loss:0.030954\n",
      "Epoch [1/10], Iter [1879/3125], train_loss:0.055886\n",
      "Epoch [1/10], Iter [1880/3125], train_loss:0.046567\n",
      "Epoch [1/10], Iter [1881/3125], train_loss:0.054960\n",
      "Epoch [1/10], Iter [1882/3125], train_loss:0.060007\n",
      "Epoch [1/10], Iter [1883/3125], train_loss:0.042093\n",
      "Epoch [1/10], Iter [1884/3125], train_loss:0.042883\n",
      "Epoch [1/10], Iter [1885/3125], train_loss:0.072663\n",
      "Epoch [1/10], Iter [1886/3125], train_loss:0.047739\n",
      "Epoch [1/10], Iter [1887/3125], train_loss:0.072337\n",
      "Epoch [1/10], Iter [1888/3125], train_loss:0.032112\n",
      "Epoch [1/10], Iter [1889/3125], train_loss:0.063742\n",
      "Epoch [1/10], Iter [1890/3125], train_loss:0.126797\n",
      "Epoch [1/10], Iter [1891/3125], train_loss:0.060045\n",
      "Epoch [1/10], Iter [1892/3125], train_loss:0.050613\n",
      "Epoch [1/10], Iter [1893/3125], train_loss:0.018665\n",
      "Epoch [1/10], Iter [1894/3125], train_loss:0.118631\n",
      "Epoch [1/10], Iter [1895/3125], train_loss:0.072257\n",
      "Epoch [1/10], Iter [1896/3125], train_loss:0.048342\n",
      "Epoch [1/10], Iter [1897/3125], train_loss:0.053053\n",
      "Epoch [1/10], Iter [1898/3125], train_loss:0.046766\n",
      "Epoch [1/10], Iter [1899/3125], train_loss:0.041298\n",
      "Epoch [1/10], Iter [1900/3125], train_loss:0.039161\n",
      "Epoch [1/10], Iter [1901/3125], train_loss:0.052756\n",
      "Epoch [1/10], Iter [1902/3125], train_loss:0.088474\n",
      "Epoch [1/10], Iter [1903/3125], train_loss:0.054476\n",
      "Epoch [1/10], Iter [1904/3125], train_loss:0.074824\n",
      "Epoch [1/10], Iter [1905/3125], train_loss:0.038476\n",
      "Epoch [1/10], Iter [1906/3125], train_loss:0.034390\n",
      "Epoch [1/10], Iter [1907/3125], train_loss:0.031541\n",
      "Epoch [1/10], Iter [1908/3125], train_loss:0.042509\n",
      "Epoch [1/10], Iter [1909/3125], train_loss:0.048603\n",
      "Epoch [1/10], Iter [1910/3125], train_loss:0.033619\n",
      "Epoch [1/10], Iter [1911/3125], train_loss:0.088345\n",
      "Epoch [1/10], Iter [1912/3125], train_loss:0.073088\n",
      "Epoch [1/10], Iter [1913/3125], train_loss:0.053431\n",
      "Epoch [1/10], Iter [1914/3125], train_loss:0.074593\n",
      "Epoch [1/10], Iter [1915/3125], train_loss:0.067950\n",
      "Epoch [1/10], Iter [1916/3125], train_loss:0.036191\n",
      "Epoch [1/10], Iter [1917/3125], train_loss:0.057052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [1918/3125], train_loss:0.062682\n",
      "Epoch [1/10], Iter [1919/3125], train_loss:0.073875\n",
      "Epoch [1/10], Iter [1920/3125], train_loss:0.059812\n",
      "Epoch [1/10], Iter [1921/3125], train_loss:0.049579\n",
      "Epoch [1/10], Iter [1922/3125], train_loss:0.111791\n",
      "Epoch [1/10], Iter [1923/3125], train_loss:0.076176\n",
      "Epoch [1/10], Iter [1924/3125], train_loss:0.049307\n",
      "Epoch [1/10], Iter [1925/3125], train_loss:0.037029\n",
      "Epoch [1/10], Iter [1926/3125], train_loss:0.078327\n",
      "Epoch [1/10], Iter [1927/3125], train_loss:0.073983\n",
      "Epoch [1/10], Iter [1928/3125], train_loss:0.071034\n",
      "Epoch [1/10], Iter [1929/3125], train_loss:0.072575\n",
      "Epoch [1/10], Iter [1930/3125], train_loss:0.035677\n",
      "Epoch [1/10], Iter [1931/3125], train_loss:0.078652\n",
      "Epoch [1/10], Iter [1932/3125], train_loss:0.050624\n",
      "Epoch [1/10], Iter [1933/3125], train_loss:0.061268\n",
      "Epoch [1/10], Iter [1934/3125], train_loss:0.030012\n",
      "Epoch [1/10], Iter [1935/3125], train_loss:0.064447\n",
      "Epoch [1/10], Iter [1936/3125], train_loss:0.067326\n",
      "Epoch [1/10], Iter [1937/3125], train_loss:0.047509\n",
      "Epoch [1/10], Iter [1938/3125], train_loss:0.080461\n",
      "Epoch [1/10], Iter [1939/3125], train_loss:0.065088\n",
      "Epoch [1/10], Iter [1940/3125], train_loss:0.045047\n",
      "Epoch [1/10], Iter [1941/3125], train_loss:0.048151\n",
      "Epoch [1/10], Iter [1942/3125], train_loss:0.041551\n",
      "Epoch [1/10], Iter [1943/3125], train_loss:0.062923\n",
      "Epoch [1/10], Iter [1944/3125], train_loss:0.047921\n",
      "Epoch [1/10], Iter [1945/3125], train_loss:0.055047\n",
      "Epoch [1/10], Iter [1946/3125], train_loss:0.047319\n",
      "Epoch [1/10], Iter [1947/3125], train_loss:0.079555\n",
      "Epoch [1/10], Iter [1948/3125], train_loss:0.060398\n",
      "Epoch [1/10], Iter [1949/3125], train_loss:0.024709\n",
      "Epoch [1/10], Iter [1950/3125], train_loss:0.057181\n",
      "Epoch [1/10], Iter [1951/3125], train_loss:0.073039\n",
      "Epoch [1/10], Iter [1952/3125], train_loss:0.080788\n",
      "Epoch [1/10], Iter [1953/3125], train_loss:0.027360\n",
      "Epoch [1/10], Iter [1954/3125], train_loss:0.099107\n",
      "Epoch [1/10], Iter [1955/3125], train_loss:0.039013\n",
      "Epoch [1/10], Iter [1956/3125], train_loss:0.085083\n",
      "Epoch [1/10], Iter [1957/3125], train_loss:0.061486\n",
      "Epoch [1/10], Iter [1958/3125], train_loss:0.054446\n",
      "Epoch [1/10], Iter [1959/3125], train_loss:0.069039\n",
      "Epoch [1/10], Iter [1960/3125], train_loss:0.040418\n",
      "Epoch [1/10], Iter [1961/3125], train_loss:0.073553\n",
      "Epoch [1/10], Iter [1962/3125], train_loss:0.045772\n",
      "Epoch [1/10], Iter [1963/3125], train_loss:0.060261\n",
      "Epoch [1/10], Iter [1964/3125], train_loss:0.065421\n",
      "Epoch [1/10], Iter [1965/3125], train_loss:0.076194\n",
      "Epoch [1/10], Iter [1966/3125], train_loss:0.064436\n",
      "Epoch [1/10], Iter [1967/3125], train_loss:0.076793\n",
      "Epoch [1/10], Iter [1968/3125], train_loss:0.055979\n",
      "Epoch [1/10], Iter [1969/3125], train_loss:0.029151\n",
      "Epoch [1/10], Iter [1970/3125], train_loss:0.038949\n",
      "Epoch [1/10], Iter [1971/3125], train_loss:0.041652\n",
      "Epoch [1/10], Iter [1972/3125], train_loss:0.057385\n",
      "Epoch [1/10], Iter [1973/3125], train_loss:0.063295\n",
      "Epoch [1/10], Iter [1974/3125], train_loss:0.065931\n",
      "Epoch [1/10], Iter [1975/3125], train_loss:0.063027\n",
      "Epoch [1/10], Iter [1976/3125], train_loss:0.069438\n",
      "Epoch [1/10], Iter [1977/3125], train_loss:0.043597\n",
      "Epoch [1/10], Iter [1978/3125], train_loss:0.077617\n",
      "Epoch [1/10], Iter [1979/3125], train_loss:0.075510\n",
      "Epoch [1/10], Iter [1980/3125], train_loss:0.064318\n",
      "Epoch [1/10], Iter [1981/3125], train_loss:0.057600\n",
      "Epoch [1/10], Iter [1982/3125], train_loss:0.051950\n",
      "Epoch [1/10], Iter [1983/3125], train_loss:0.060522\n",
      "Epoch [1/10], Iter [1984/3125], train_loss:0.043160\n",
      "Epoch [1/10], Iter [1985/3125], train_loss:0.046968\n",
      "Epoch [1/10], Iter [1986/3125], train_loss:0.030345\n",
      "Epoch [1/10], Iter [1987/3125], train_loss:0.067975\n",
      "Epoch [1/10], Iter [1988/3125], train_loss:0.070917\n",
      "Epoch [1/10], Iter [1989/3125], train_loss:0.050825\n",
      "Epoch [1/10], Iter [1990/3125], train_loss:0.056659\n",
      "Epoch [1/10], Iter [1991/3125], train_loss:0.075110\n",
      "Epoch [1/10], Iter [1992/3125], train_loss:0.018620\n",
      "Epoch [1/10], Iter [1993/3125], train_loss:0.086012\n",
      "Epoch [1/10], Iter [1994/3125], train_loss:0.061522\n",
      "Epoch [1/10], Iter [1995/3125], train_loss:0.115937\n",
      "Epoch [1/10], Iter [1996/3125], train_loss:0.045985\n",
      "Epoch [1/10], Iter [1997/3125], train_loss:0.053937\n",
      "Epoch [1/10], Iter [1998/3125], train_loss:0.070547\n",
      "Epoch [1/10], Iter [1999/3125], train_loss:0.042071\n",
      "Epoch [1/10], Iter [2000/3125], train_loss:0.043023\n",
      "Epoch [1/10], Iter [2001/3125], train_loss:0.081274\n",
      "Epoch [1/10], Iter [2002/3125], train_loss:0.066850\n",
      "Epoch [1/10], Iter [2003/3125], train_loss:0.033427\n",
      "Epoch [1/10], Iter [2004/3125], train_loss:0.061561\n",
      "Epoch [1/10], Iter [2005/3125], train_loss:0.062892\n",
      "Epoch [1/10], Iter [2006/3125], train_loss:0.029832\n",
      "Epoch [1/10], Iter [2007/3125], train_loss:0.084254\n",
      "Epoch [1/10], Iter [2008/3125], train_loss:0.086006\n",
      "Epoch [1/10], Iter [2009/3125], train_loss:0.075942\n",
      "Epoch [1/10], Iter [2010/3125], train_loss:0.086731\n",
      "Epoch [1/10], Iter [2011/3125], train_loss:0.061293\n",
      "Epoch [1/10], Iter [2012/3125], train_loss:0.031159\n",
      "Epoch [1/10], Iter [2013/3125], train_loss:0.094308\n",
      "Epoch [1/10], Iter [2014/3125], train_loss:0.058767\n",
      "Epoch [1/10], Iter [2015/3125], train_loss:0.042780\n",
      "Epoch [1/10], Iter [2016/3125], train_loss:0.053814\n",
      "Epoch [1/10], Iter [2017/3125], train_loss:0.044383\n",
      "Epoch [1/10], Iter [2018/3125], train_loss:0.054721\n",
      "Epoch [1/10], Iter [2019/3125], train_loss:0.037710\n",
      "Epoch [1/10], Iter [2020/3125], train_loss:0.050791\n",
      "Epoch [1/10], Iter [2021/3125], train_loss:0.088299\n",
      "Epoch [1/10], Iter [2022/3125], train_loss:0.023384\n",
      "Epoch [1/10], Iter [2023/3125], train_loss:0.059585\n",
      "Epoch [1/10], Iter [2024/3125], train_loss:0.047600\n",
      "Epoch [1/10], Iter [2025/3125], train_loss:0.050966\n",
      "Epoch [1/10], Iter [2026/3125], train_loss:0.069498\n",
      "Epoch [1/10], Iter [2027/3125], train_loss:0.059679\n",
      "Epoch [1/10], Iter [2028/3125], train_loss:0.054175\n",
      "Epoch [1/10], Iter [2029/3125], train_loss:0.048971\n",
      "Epoch [1/10], Iter [2030/3125], train_loss:0.055469\n",
      "Epoch [1/10], Iter [2031/3125], train_loss:0.042843\n",
      "Epoch [1/10], Iter [2032/3125], train_loss:0.054261\n",
      "Epoch [1/10], Iter [2033/3125], train_loss:0.034696\n",
      "Epoch [1/10], Iter [2034/3125], train_loss:0.050647\n",
      "Epoch [1/10], Iter [2035/3125], train_loss:0.075666\n",
      "Epoch [1/10], Iter [2036/3125], train_loss:0.082343\n",
      "Epoch [1/10], Iter [2037/3125], train_loss:0.050409\n",
      "Epoch [1/10], Iter [2038/3125], train_loss:0.050441\n",
      "Epoch [1/10], Iter [2039/3125], train_loss:0.068800\n",
      "Epoch [1/10], Iter [2040/3125], train_loss:0.064183\n",
      "Epoch [1/10], Iter [2041/3125], train_loss:0.033020\n",
      "Epoch [1/10], Iter [2042/3125], train_loss:0.068810\n",
      "Epoch [1/10], Iter [2043/3125], train_loss:0.036257\n",
      "Epoch [1/10], Iter [2044/3125], train_loss:0.060899\n",
      "Epoch [1/10], Iter [2045/3125], train_loss:0.061538\n",
      "Epoch [1/10], Iter [2046/3125], train_loss:0.044145\n",
      "Epoch [1/10], Iter [2047/3125], train_loss:0.039485\n",
      "Epoch [1/10], Iter [2048/3125], train_loss:0.042501\n",
      "Epoch [1/10], Iter [2049/3125], train_loss:0.063631\n",
      "Epoch [1/10], Iter [2050/3125], train_loss:0.046520\n",
      "Epoch [1/10], Iter [2051/3125], train_loss:0.055999\n",
      "Epoch [1/10], Iter [2052/3125], train_loss:0.063847\n",
      "Epoch [1/10], Iter [2053/3125], train_loss:0.069343\n",
      "Epoch [1/10], Iter [2054/3125], train_loss:0.052924\n",
      "Epoch [1/10], Iter [2055/3125], train_loss:0.036919\n",
      "Epoch [1/10], Iter [2056/3125], train_loss:0.054971\n",
      "Epoch [1/10], Iter [2057/3125], train_loss:0.048387\n",
      "Epoch [1/10], Iter [2058/3125], train_loss:0.084165\n",
      "Epoch [1/10], Iter [2059/3125], train_loss:0.044616\n",
      "Epoch [1/10], Iter [2060/3125], train_loss:0.033628\n",
      "Epoch [1/10], Iter [2061/3125], train_loss:0.027558\n",
      "Epoch [1/10], Iter [2062/3125], train_loss:0.055136\n",
      "Epoch [1/10], Iter [2063/3125], train_loss:0.062519\n",
      "Epoch [1/10], Iter [2064/3125], train_loss:0.050408\n",
      "Epoch [1/10], Iter [2065/3125], train_loss:0.033982\n",
      "Epoch [1/10], Iter [2066/3125], train_loss:0.087878\n",
      "Epoch [1/10], Iter [2067/3125], train_loss:0.044555\n",
      "Epoch [1/10], Iter [2068/3125], train_loss:0.036030\n",
      "Epoch [1/10], Iter [2069/3125], train_loss:0.047172\n",
      "Epoch [1/10], Iter [2070/3125], train_loss:0.057118\n",
      "Epoch [1/10], Iter [2071/3125], train_loss:0.050927\n",
      "Epoch [1/10], Iter [2072/3125], train_loss:0.055021\n",
      "Epoch [1/10], Iter [2073/3125], train_loss:0.042873\n",
      "Epoch [1/10], Iter [2074/3125], train_loss:0.069662\n",
      "Epoch [1/10], Iter [2075/3125], train_loss:0.086718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [2076/3125], train_loss:0.060907\n",
      "Epoch [1/10], Iter [2077/3125], train_loss:0.055302\n",
      "Epoch [1/10], Iter [2078/3125], train_loss:0.063130\n",
      "Epoch [1/10], Iter [2079/3125], train_loss:0.041546\n",
      "Epoch [1/10], Iter [2080/3125], train_loss:0.079889\n",
      "Epoch [1/10], Iter [2081/3125], train_loss:0.059205\n",
      "Epoch [1/10], Iter [2082/3125], train_loss:0.077855\n",
      "Epoch [1/10], Iter [2083/3125], train_loss:0.040796\n",
      "Epoch [1/10], Iter [2084/3125], train_loss:0.063951\n",
      "Epoch [1/10], Iter [2085/3125], train_loss:0.060815\n",
      "Epoch [1/10], Iter [2086/3125], train_loss:0.105773\n",
      "Epoch [1/10], Iter [2087/3125], train_loss:0.055865\n",
      "Epoch [1/10], Iter [2088/3125], train_loss:0.058389\n",
      "Epoch [1/10], Iter [2089/3125], train_loss:0.085886\n",
      "Epoch [1/10], Iter [2090/3125], train_loss:0.037964\n",
      "Epoch [1/10], Iter [2091/3125], train_loss:0.037571\n",
      "Epoch [1/10], Iter [2092/3125], train_loss:0.051286\n",
      "Epoch [1/10], Iter [2093/3125], train_loss:0.072742\n",
      "Epoch [1/10], Iter [2094/3125], train_loss:0.027918\n",
      "Epoch [1/10], Iter [2095/3125], train_loss:0.064145\n",
      "Epoch [1/10], Iter [2096/3125], train_loss:0.062825\n",
      "Epoch [1/10], Iter [2097/3125], train_loss:0.047760\n",
      "Epoch [1/10], Iter [2098/3125], train_loss:0.051347\n",
      "Epoch [1/10], Iter [2099/3125], train_loss:0.066230\n",
      "Epoch [1/10], Iter [2100/3125], train_loss:0.062902\n",
      "Epoch [1/10], Iter [2101/3125], train_loss:0.047526\n",
      "Epoch [1/10], Iter [2102/3125], train_loss:0.039127\n",
      "Epoch [1/10], Iter [2103/3125], train_loss:0.046777\n",
      "Epoch [1/10], Iter [2104/3125], train_loss:0.059681\n",
      "Epoch [1/10], Iter [2105/3125], train_loss:0.061811\n",
      "Epoch [1/10], Iter [2106/3125], train_loss:0.039108\n",
      "Epoch [1/10], Iter [2107/3125], train_loss:0.075459\n",
      "Epoch [1/10], Iter [2108/3125], train_loss:0.063627\n",
      "Epoch [1/10], Iter [2109/3125], train_loss:0.035721\n",
      "Epoch [1/10], Iter [2110/3125], train_loss:0.060149\n",
      "Epoch [1/10], Iter [2111/3125], train_loss:0.067085\n",
      "Epoch [1/10], Iter [2112/3125], train_loss:0.059505\n",
      "Epoch [1/10], Iter [2113/3125], train_loss:0.056017\n",
      "Epoch [1/10], Iter [2114/3125], train_loss:0.020455\n",
      "Epoch [1/10], Iter [2115/3125], train_loss:0.081689\n",
      "Epoch [1/10], Iter [2116/3125], train_loss:0.039513\n",
      "Epoch [1/10], Iter [2117/3125], train_loss:0.048386\n",
      "Epoch [1/10], Iter [2118/3125], train_loss:0.059267\n",
      "Epoch [1/10], Iter [2119/3125], train_loss:0.082934\n",
      "Epoch [1/10], Iter [2120/3125], train_loss:0.060041\n",
      "Epoch [1/10], Iter [2121/3125], train_loss:0.061388\n",
      "Epoch [1/10], Iter [2122/3125], train_loss:0.042897\n",
      "Epoch [1/10], Iter [2123/3125], train_loss:0.045056\n",
      "Epoch [1/10], Iter [2124/3125], train_loss:0.060849\n",
      "Epoch [1/10], Iter [2125/3125], train_loss:0.049667\n",
      "Epoch [1/10], Iter [2126/3125], train_loss:0.048343\n",
      "Epoch [1/10], Iter [2127/3125], train_loss:0.068228\n",
      "Epoch [1/10], Iter [2128/3125], train_loss:0.037251\n",
      "Epoch [1/10], Iter [2129/3125], train_loss:0.027494\n",
      "Epoch [1/10], Iter [2130/3125], train_loss:0.064851\n",
      "Epoch [1/10], Iter [2131/3125], train_loss:0.044079\n",
      "Epoch [1/10], Iter [2132/3125], train_loss:0.058055\n",
      "Epoch [1/10], Iter [2133/3125], train_loss:0.028688\n",
      "Epoch [1/10], Iter [2134/3125], train_loss:0.063009\n",
      "Epoch [1/10], Iter [2135/3125], train_loss:0.049375\n",
      "Epoch [1/10], Iter [2136/3125], train_loss:0.070779\n",
      "Epoch [1/10], Iter [2137/3125], train_loss:0.061121\n",
      "Epoch [1/10], Iter [2138/3125], train_loss:0.045141\n",
      "Epoch [1/10], Iter [2139/3125], train_loss:0.032898\n",
      "Epoch [1/10], Iter [2140/3125], train_loss:0.044351\n",
      "Epoch [1/10], Iter [2141/3125], train_loss:0.056783\n",
      "Epoch [1/10], Iter [2142/3125], train_loss:0.056133\n",
      "Epoch [1/10], Iter [2143/3125], train_loss:0.088715\n",
      "Epoch [1/10], Iter [2144/3125], train_loss:0.068217\n",
      "Epoch [1/10], Iter [2145/3125], train_loss:0.043055\n",
      "Epoch [1/10], Iter [2146/3125], train_loss:0.032986\n",
      "Epoch [1/10], Iter [2147/3125], train_loss:0.041009\n",
      "Epoch [1/10], Iter [2148/3125], train_loss:0.044360\n",
      "Epoch [1/10], Iter [2149/3125], train_loss:0.065169\n",
      "Epoch [1/10], Iter [2150/3125], train_loss:0.075291\n",
      "Epoch [1/10], Iter [2151/3125], train_loss:0.050981\n",
      "Epoch [1/10], Iter [2152/3125], train_loss:0.062930\n",
      "Epoch [1/10], Iter [2153/3125], train_loss:0.058825\n",
      "Epoch [1/10], Iter [2154/3125], train_loss:0.076227\n",
      "Epoch [1/10], Iter [2155/3125], train_loss:0.083203\n",
      "Epoch [1/10], Iter [2156/3125], train_loss:0.063778\n",
      "Epoch [1/10], Iter [2157/3125], train_loss:0.045961\n",
      "Epoch [1/10], Iter [2158/3125], train_loss:0.070411\n",
      "Epoch [1/10], Iter [2159/3125], train_loss:0.064471\n",
      "Epoch [1/10], Iter [2160/3125], train_loss:0.056950\n",
      "Epoch [1/10], Iter [2161/3125], train_loss:0.074447\n",
      "Epoch [1/10], Iter [2162/3125], train_loss:0.052749\n",
      "Epoch [1/10], Iter [2163/3125], train_loss:0.057865\n",
      "Epoch [1/10], Iter [2164/3125], train_loss:0.037370\n",
      "Epoch [1/10], Iter [2165/3125], train_loss:0.103615\n",
      "Epoch [1/10], Iter [2166/3125], train_loss:0.076190\n",
      "Epoch [1/10], Iter [2167/3125], train_loss:0.044481\n",
      "Epoch [1/10], Iter [2168/3125], train_loss:0.050516\n",
      "Epoch [1/10], Iter [2169/3125], train_loss:0.036114\n",
      "Epoch [1/10], Iter [2170/3125], train_loss:0.037495\n",
      "Epoch [1/10], Iter [2171/3125], train_loss:0.058162\n",
      "Epoch [1/10], Iter [2172/3125], train_loss:0.072126\n",
      "Epoch [1/10], Iter [2173/3125], train_loss:0.058480\n",
      "Epoch [1/10], Iter [2174/3125], train_loss:0.057047\n",
      "Epoch [1/10], Iter [2175/3125], train_loss:0.058543\n",
      "Epoch [1/10], Iter [2176/3125], train_loss:0.044135\n",
      "Epoch [1/10], Iter [2177/3125], train_loss:0.021453\n",
      "Epoch [1/10], Iter [2178/3125], train_loss:0.091287\n",
      "Epoch [1/10], Iter [2179/3125], train_loss:0.030686\n",
      "Epoch [1/10], Iter [2180/3125], train_loss:0.043142\n",
      "Epoch [1/10], Iter [2181/3125], train_loss:0.061297\n",
      "Epoch [1/10], Iter [2182/3125], train_loss:0.052431\n",
      "Epoch [1/10], Iter [2183/3125], train_loss:0.064683\n",
      "Epoch [1/10], Iter [2184/3125], train_loss:0.052090\n",
      "Epoch [1/10], Iter [2185/3125], train_loss:0.059552\n",
      "Epoch [1/10], Iter [2186/3125], train_loss:0.043549\n",
      "Epoch [1/10], Iter [2187/3125], train_loss:0.039106\n",
      "Epoch [1/10], Iter [2188/3125], train_loss:0.033696\n",
      "Epoch [1/10], Iter [2189/3125], train_loss:0.059473\n",
      "Epoch [1/10], Iter [2190/3125], train_loss:0.042966\n",
      "Epoch [1/10], Iter [2191/3125], train_loss:0.038413\n",
      "Epoch [1/10], Iter [2192/3125], train_loss:0.048166\n",
      "Epoch [1/10], Iter [2193/3125], train_loss:0.062529\n",
      "Epoch [1/10], Iter [2194/3125], train_loss:0.063281\n",
      "Epoch [1/10], Iter [2195/3125], train_loss:0.068794\n",
      "Epoch [1/10], Iter [2196/3125], train_loss:0.060039\n",
      "Epoch [1/10], Iter [2197/3125], train_loss:0.059375\n",
      "Epoch [1/10], Iter [2198/3125], train_loss:0.052642\n",
      "Epoch [1/10], Iter [2199/3125], train_loss:0.046952\n",
      "Epoch [1/10], Iter [2200/3125], train_loss:0.071861\n",
      "Epoch [1/10], Iter [2201/3125], train_loss:0.044257\n",
      "Epoch [1/10], Iter [2202/3125], train_loss:0.057232\n",
      "Epoch [1/10], Iter [2203/3125], train_loss:0.039750\n",
      "Epoch [1/10], Iter [2204/3125], train_loss:0.074284\n",
      "Epoch [1/10], Iter [2205/3125], train_loss:0.029797\n",
      "Epoch [1/10], Iter [2206/3125], train_loss:0.058231\n",
      "Epoch [1/10], Iter [2207/3125], train_loss:0.066111\n",
      "Epoch [1/10], Iter [2208/3125], train_loss:0.067477\n",
      "Epoch [1/10], Iter [2209/3125], train_loss:0.065425\n",
      "Epoch [1/10], Iter [2210/3125], train_loss:0.039687\n",
      "Epoch [1/10], Iter [2211/3125], train_loss:0.054980\n",
      "Epoch [1/10], Iter [2212/3125], train_loss:0.052664\n",
      "Epoch [1/10], Iter [2213/3125], train_loss:0.065844\n",
      "Epoch [1/10], Iter [2214/3125], train_loss:0.094000\n",
      "Epoch [1/10], Iter [2215/3125], train_loss:0.053468\n",
      "Epoch [1/10], Iter [2216/3125], train_loss:0.061695\n",
      "Epoch [1/10], Iter [2217/3125], train_loss:0.067787\n",
      "Epoch [1/10], Iter [2218/3125], train_loss:0.035557\n",
      "Epoch [1/10], Iter [2219/3125], train_loss:0.054791\n",
      "Epoch [1/10], Iter [2220/3125], train_loss:0.074102\n",
      "Epoch [1/10], Iter [2221/3125], train_loss:0.053827\n",
      "Epoch [1/10], Iter [2222/3125], train_loss:0.064904\n",
      "Epoch [1/10], Iter [2223/3125], train_loss:0.048594\n",
      "Epoch [1/10], Iter [2224/3125], train_loss:0.038459\n",
      "Epoch [1/10], Iter [2225/3125], train_loss:0.033388\n",
      "Epoch [1/10], Iter [2226/3125], train_loss:0.053181\n",
      "Epoch [1/10], Iter [2227/3125], train_loss:0.070912\n",
      "Epoch [1/10], Iter [2228/3125], train_loss:0.087150\n",
      "Epoch [1/10], Iter [2229/3125], train_loss:0.043372\n",
      "Epoch [1/10], Iter [2230/3125], train_loss:0.053783\n",
      "Epoch [1/10], Iter [2231/3125], train_loss:0.040672\n",
      "Epoch [1/10], Iter [2232/3125], train_loss:0.045534\n",
      "Epoch [1/10], Iter [2233/3125], train_loss:0.040906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [2234/3125], train_loss:0.046060\n",
      "Epoch [1/10], Iter [2235/3125], train_loss:0.073936\n",
      "Epoch [1/10], Iter [2236/3125], train_loss:0.048040\n",
      "Epoch [1/10], Iter [2237/3125], train_loss:0.044033\n",
      "Epoch [1/10], Iter [2238/3125], train_loss:0.058578\n",
      "Epoch [1/10], Iter [2239/3125], train_loss:0.046442\n",
      "Epoch [1/10], Iter [2240/3125], train_loss:0.070717\n",
      "Epoch [1/10], Iter [2241/3125], train_loss:0.057559\n",
      "Epoch [1/10], Iter [2242/3125], train_loss:0.071514\n",
      "Epoch [1/10], Iter [2243/3125], train_loss:0.072684\n",
      "Epoch [1/10], Iter [2244/3125], train_loss:0.071098\n",
      "Epoch [1/10], Iter [2245/3125], train_loss:0.029106\n",
      "Epoch [1/10], Iter [2246/3125], train_loss:0.047889\n",
      "Epoch [1/10], Iter [2247/3125], train_loss:0.074630\n",
      "Epoch [1/10], Iter [2248/3125], train_loss:0.039345\n",
      "Epoch [1/10], Iter [2249/3125], train_loss:0.076240\n",
      "Epoch [1/10], Iter [2250/3125], train_loss:0.046938\n",
      "Epoch [1/10], Iter [2251/3125], train_loss:0.051236\n",
      "Epoch [1/10], Iter [2252/3125], train_loss:0.060951\n",
      "Epoch [1/10], Iter [2253/3125], train_loss:0.072658\n",
      "Epoch [1/10], Iter [2254/3125], train_loss:0.072621\n",
      "Epoch [1/10], Iter [2255/3125], train_loss:0.071780\n",
      "Epoch [1/10], Iter [2256/3125], train_loss:0.047900\n",
      "Epoch [1/10], Iter [2257/3125], train_loss:0.083139\n",
      "Epoch [1/10], Iter [2258/3125], train_loss:0.042750\n",
      "Epoch [1/10], Iter [2259/3125], train_loss:0.030537\n",
      "Epoch [1/10], Iter [2260/3125], train_loss:0.071231\n",
      "Epoch [1/10], Iter [2261/3125], train_loss:0.058627\n",
      "Epoch [1/10], Iter [2262/3125], train_loss:0.061551\n",
      "Epoch [1/10], Iter [2263/3125], train_loss:0.057065\n",
      "Epoch [1/10], Iter [2264/3125], train_loss:0.063427\n",
      "Epoch [1/10], Iter [2265/3125], train_loss:0.052468\n",
      "Epoch [1/10], Iter [2266/3125], train_loss:0.052080\n",
      "Epoch [1/10], Iter [2267/3125], train_loss:0.033376\n",
      "Epoch [1/10], Iter [2268/3125], train_loss:0.041073\n",
      "Epoch [1/10], Iter [2269/3125], train_loss:0.065047\n",
      "Epoch [1/10], Iter [2270/3125], train_loss:0.062026\n",
      "Epoch [1/10], Iter [2271/3125], train_loss:0.109442\n",
      "Epoch [1/10], Iter [2272/3125], train_loss:0.056198\n",
      "Epoch [1/10], Iter [2273/3125], train_loss:0.063348\n",
      "Epoch [1/10], Iter [2274/3125], train_loss:0.039659\n",
      "Epoch [1/10], Iter [2275/3125], train_loss:0.062523\n",
      "Epoch [1/10], Iter [2276/3125], train_loss:0.057241\n",
      "Epoch [1/10], Iter [2277/3125], train_loss:0.026030\n",
      "Epoch [1/10], Iter [2278/3125], train_loss:0.060936\n",
      "Epoch [1/10], Iter [2279/3125], train_loss:0.037769\n",
      "Epoch [1/10], Iter [2280/3125], train_loss:0.047071\n",
      "Epoch [1/10], Iter [2281/3125], train_loss:0.067723\n",
      "Epoch [1/10], Iter [2282/3125], train_loss:0.071875\n",
      "Epoch [1/10], Iter [2283/3125], train_loss:0.049202\n",
      "Epoch [1/10], Iter [2284/3125], train_loss:0.060309\n",
      "Epoch [1/10], Iter [2285/3125], train_loss:0.068315\n",
      "Epoch [1/10], Iter [2286/3125], train_loss:0.072877\n",
      "Epoch [1/10], Iter [2287/3125], train_loss:0.063042\n",
      "Epoch [1/10], Iter [2288/3125], train_loss:0.078719\n",
      "Epoch [1/10], Iter [2289/3125], train_loss:0.026097\n",
      "Epoch [1/10], Iter [2290/3125], train_loss:0.060497\n",
      "Epoch [1/10], Iter [2291/3125], train_loss:0.078648\n",
      "Epoch [1/10], Iter [2292/3125], train_loss:0.068681\n",
      "Epoch [1/10], Iter [2293/3125], train_loss:0.044549\n",
      "Epoch [1/10], Iter [2294/3125], train_loss:0.079612\n",
      "Epoch [1/10], Iter [2295/3125], train_loss:0.036360\n",
      "Epoch [1/10], Iter [2296/3125], train_loss:0.029000\n",
      "Epoch [1/10], Iter [2297/3125], train_loss:0.055833\n",
      "Epoch [1/10], Iter [2298/3125], train_loss:0.078257\n",
      "Epoch [1/10], Iter [2299/3125], train_loss:0.064521\n",
      "Epoch [1/10], Iter [2300/3125], train_loss:0.053077\n",
      "Epoch [1/10], Iter [2301/3125], train_loss:0.061464\n",
      "Epoch [1/10], Iter [2302/3125], train_loss:0.054382\n",
      "Epoch [1/10], Iter [2303/3125], train_loss:0.029077\n",
      "Epoch [1/10], Iter [2304/3125], train_loss:0.047081\n",
      "Epoch [1/10], Iter [2305/3125], train_loss:0.034250\n",
      "Epoch [1/10], Iter [2306/3125], train_loss:0.067229\n",
      "Epoch [1/10], Iter [2307/3125], train_loss:0.038814\n",
      "Epoch [1/10], Iter [2308/3125], train_loss:0.059177\n",
      "Epoch [1/10], Iter [2309/3125], train_loss:0.029574\n",
      "Epoch [1/10], Iter [2310/3125], train_loss:0.034070\n",
      "Epoch [1/10], Iter [2311/3125], train_loss:0.077129\n",
      "Epoch [1/10], Iter [2312/3125], train_loss:0.036397\n",
      "Epoch [1/10], Iter [2313/3125], train_loss:0.065701\n",
      "Epoch [1/10], Iter [2314/3125], train_loss:0.044045\n",
      "Epoch [1/10], Iter [2315/3125], train_loss:0.078438\n",
      "Epoch [1/10], Iter [2316/3125], train_loss:0.099388\n",
      "Epoch [1/10], Iter [2317/3125], train_loss:0.053328\n",
      "Epoch [1/10], Iter [2318/3125], train_loss:0.033426\n",
      "Epoch [1/10], Iter [2319/3125], train_loss:0.045820\n",
      "Epoch [1/10], Iter [2320/3125], train_loss:0.071173\n",
      "Epoch [1/10], Iter [2321/3125], train_loss:0.058071\n",
      "Epoch [1/10], Iter [2322/3125], train_loss:0.032791\n",
      "Epoch [1/10], Iter [2323/3125], train_loss:0.049563\n",
      "Epoch [1/10], Iter [2324/3125], train_loss:0.037852\n",
      "Epoch [1/10], Iter [2325/3125], train_loss:0.071495\n",
      "Epoch [1/10], Iter [2326/3125], train_loss:0.051821\n",
      "Epoch [1/10], Iter [2327/3125], train_loss:0.049604\n",
      "Epoch [1/10], Iter [2328/3125], train_loss:0.084093\n",
      "Epoch [1/10], Iter [2329/3125], train_loss:0.050646\n",
      "Epoch [1/10], Iter [2330/3125], train_loss:0.035999\n",
      "Epoch [1/10], Iter [2331/3125], train_loss:0.079603\n",
      "Epoch [1/10], Iter [2332/3125], train_loss:0.036003\n",
      "Epoch [1/10], Iter [2333/3125], train_loss:0.029306\n",
      "Epoch [1/10], Iter [2334/3125], train_loss:0.080034\n",
      "Epoch [1/10], Iter [2335/3125], train_loss:0.056424\n",
      "Epoch [1/10], Iter [2336/3125], train_loss:0.067404\n",
      "Epoch [1/10], Iter [2337/3125], train_loss:0.048945\n",
      "Epoch [1/10], Iter [2338/3125], train_loss:0.034922\n",
      "Epoch [1/10], Iter [2339/3125], train_loss:0.060189\n",
      "Epoch [1/10], Iter [2340/3125], train_loss:0.041691\n",
      "Epoch [1/10], Iter [2341/3125], train_loss:0.076982\n",
      "Epoch [1/10], Iter [2342/3125], train_loss:0.075437\n",
      "Epoch [1/10], Iter [2343/3125], train_loss:0.056825\n",
      "Epoch [1/10], Iter [2344/3125], train_loss:0.038702\n",
      "Epoch [1/10], Iter [2345/3125], train_loss:0.048160\n",
      "Epoch [1/10], Iter [2346/3125], train_loss:0.054957\n",
      "Epoch [1/10], Iter [2347/3125], train_loss:0.073520\n",
      "Epoch [1/10], Iter [2348/3125], train_loss:0.025029\n",
      "Epoch [1/10], Iter [2349/3125], train_loss:0.078251\n",
      "Epoch [1/10], Iter [2350/3125], train_loss:0.058632\n",
      "Epoch [1/10], Iter [2351/3125], train_loss:0.027224\n",
      "Epoch [1/10], Iter [2352/3125], train_loss:0.078937\n",
      "Epoch [1/10], Iter [2353/3125], train_loss:0.047743\n",
      "Epoch [1/10], Iter [2354/3125], train_loss:0.051082\n",
      "Epoch [1/10], Iter [2355/3125], train_loss:0.079061\n",
      "Epoch [1/10], Iter [2356/3125], train_loss:0.073499\n",
      "Epoch [1/10], Iter [2357/3125], train_loss:0.043175\n",
      "Epoch [1/10], Iter [2358/3125], train_loss:0.056764\n",
      "Epoch [1/10], Iter [2359/3125], train_loss:0.019714\n",
      "Epoch [1/10], Iter [2360/3125], train_loss:0.063975\n",
      "Epoch [1/10], Iter [2361/3125], train_loss:0.051211\n",
      "Epoch [1/10], Iter [2362/3125], train_loss:0.057849\n",
      "Epoch [1/10], Iter [2363/3125], train_loss:0.069020\n",
      "Epoch [1/10], Iter [2364/3125], train_loss:0.062727\n",
      "Epoch [1/10], Iter [2365/3125], train_loss:0.038595\n",
      "Epoch [1/10], Iter [2366/3125], train_loss:0.029429\n",
      "Epoch [1/10], Iter [2367/3125], train_loss:0.039399\n",
      "Epoch [1/10], Iter [2368/3125], train_loss:0.065248\n",
      "Epoch [1/10], Iter [2369/3125], train_loss:0.031663\n",
      "Epoch [1/10], Iter [2370/3125], train_loss:0.027714\n",
      "Epoch [1/10], Iter [2371/3125], train_loss:0.041660\n",
      "Epoch [1/10], Iter [2372/3125], train_loss:0.023911\n",
      "Epoch [1/10], Iter [2373/3125], train_loss:0.043590\n",
      "Epoch [1/10], Iter [2374/3125], train_loss:0.027625\n",
      "Epoch [1/10], Iter [2375/3125], train_loss:0.027970\n",
      "Epoch [1/10], Iter [2376/3125], train_loss:0.086231\n",
      "Epoch [1/10], Iter [2377/3125], train_loss:0.030232\n",
      "Epoch [1/10], Iter [2378/3125], train_loss:0.048442\n",
      "Epoch [1/10], Iter [2379/3125], train_loss:0.037288\n",
      "Epoch [1/10], Iter [2380/3125], train_loss:0.036998\n",
      "Epoch [1/10], Iter [2381/3125], train_loss:0.062230\n",
      "Epoch [1/10], Iter [2382/3125], train_loss:0.077990\n",
      "Epoch [1/10], Iter [2383/3125], train_loss:0.037560\n",
      "Epoch [1/10], Iter [2384/3125], train_loss:0.060333\n",
      "Epoch [1/10], Iter [2385/3125], train_loss:0.067466\n",
      "Epoch [1/10], Iter [2386/3125], train_loss:0.044783\n",
      "Epoch [1/10], Iter [2387/3125], train_loss:0.061185\n",
      "Epoch [1/10], Iter [2388/3125], train_loss:0.020483\n",
      "Epoch [1/10], Iter [2389/3125], train_loss:0.040517\n",
      "Epoch [1/10], Iter [2390/3125], train_loss:0.080889\n",
      "Epoch [1/10], Iter [2391/3125], train_loss:0.078674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [2392/3125], train_loss:0.038500\n",
      "Epoch [1/10], Iter [2393/3125], train_loss:0.043009\n",
      "Epoch [1/10], Iter [2394/3125], train_loss:0.045287\n",
      "Epoch [1/10], Iter [2395/3125], train_loss:0.052948\n",
      "Epoch [1/10], Iter [2396/3125], train_loss:0.096492\n",
      "Epoch [1/10], Iter [2397/3125], train_loss:0.084607\n",
      "Epoch [1/10], Iter [2398/3125], train_loss:0.018984\n",
      "Epoch [1/10], Iter [2399/3125], train_loss:0.058866\n",
      "Epoch [1/10], Iter [2400/3125], train_loss:0.054521\n",
      "Epoch [1/10], Iter [2401/3125], train_loss:0.035970\n",
      "Epoch [1/10], Iter [2402/3125], train_loss:0.083726\n",
      "Epoch [1/10], Iter [2403/3125], train_loss:0.040679\n",
      "Epoch [1/10], Iter [2404/3125], train_loss:0.065046\n",
      "Epoch [1/10], Iter [2405/3125], train_loss:0.094652\n",
      "Epoch [1/10], Iter [2406/3125], train_loss:0.059551\n",
      "Epoch [1/10], Iter [2407/3125], train_loss:0.065810\n",
      "Epoch [1/10], Iter [2408/3125], train_loss:0.050208\n",
      "Epoch [1/10], Iter [2409/3125], train_loss:0.066216\n",
      "Epoch [1/10], Iter [2410/3125], train_loss:0.058400\n",
      "Epoch [1/10], Iter [2411/3125], train_loss:0.053513\n",
      "Epoch [1/10], Iter [2412/3125], train_loss:0.060500\n",
      "Epoch [1/10], Iter [2413/3125], train_loss:0.044563\n",
      "Epoch [1/10], Iter [2414/3125], train_loss:0.029764\n",
      "Epoch [1/10], Iter [2415/3125], train_loss:0.047340\n",
      "Epoch [1/10], Iter [2416/3125], train_loss:0.035138\n",
      "Epoch [1/10], Iter [2417/3125], train_loss:0.071377\n",
      "Epoch [1/10], Iter [2418/3125], train_loss:0.024064\n",
      "Epoch [1/10], Iter [2419/3125], train_loss:0.042528\n",
      "Epoch [1/10], Iter [2420/3125], train_loss:0.043153\n",
      "Epoch [1/10], Iter [2421/3125], train_loss:0.030465\n",
      "Epoch [1/10], Iter [2422/3125], train_loss:0.072440\n",
      "Epoch [1/10], Iter [2423/3125], train_loss:0.055920\n",
      "Epoch [1/10], Iter [2424/3125], train_loss:0.035570\n",
      "Epoch [1/10], Iter [2425/3125], train_loss:0.056007\n",
      "Epoch [1/10], Iter [2426/3125], train_loss:0.041977\n",
      "Epoch [1/10], Iter [2427/3125], train_loss:0.063373\n",
      "Epoch [1/10], Iter [2428/3125], train_loss:0.052605\n",
      "Epoch [1/10], Iter [2429/3125], train_loss:0.036802\n",
      "Epoch [1/10], Iter [2430/3125], train_loss:0.034278\n",
      "Epoch [1/10], Iter [2431/3125], train_loss:0.052479\n",
      "Epoch [1/10], Iter [2432/3125], train_loss:0.039629\n",
      "Epoch [1/10], Iter [2433/3125], train_loss:0.060461\n",
      "Epoch [1/10], Iter [2434/3125], train_loss:0.022422\n",
      "Epoch [1/10], Iter [2435/3125], train_loss:0.058592\n",
      "Epoch [1/10], Iter [2436/3125], train_loss:0.085719\n",
      "Epoch [1/10], Iter [2437/3125], train_loss:0.055790\n",
      "Epoch [1/10], Iter [2438/3125], train_loss:0.033942\n",
      "Epoch [1/10], Iter [2439/3125], train_loss:0.074614\n",
      "Epoch [1/10], Iter [2440/3125], train_loss:0.042400\n",
      "Epoch [1/10], Iter [2441/3125], train_loss:0.066518\n",
      "Epoch [1/10], Iter [2442/3125], train_loss:0.084506\n",
      "Epoch [1/10], Iter [2443/3125], train_loss:0.045445\n",
      "Epoch [1/10], Iter [2444/3125], train_loss:0.058341\n",
      "Epoch [1/10], Iter [2445/3125], train_loss:0.050448\n",
      "Epoch [1/10], Iter [2446/3125], train_loss:0.053517\n",
      "Epoch [1/10], Iter [2447/3125], train_loss:0.061119\n",
      "Epoch [1/10], Iter [2448/3125], train_loss:0.067219\n",
      "Epoch [1/10], Iter [2449/3125], train_loss:0.038764\n",
      "Epoch [1/10], Iter [2450/3125], train_loss:0.050990\n",
      "Epoch [1/10], Iter [2451/3125], train_loss:0.068929\n",
      "Epoch [1/10], Iter [2452/3125], train_loss:0.112174\n",
      "Epoch [1/10], Iter [2453/3125], train_loss:0.045488\n",
      "Epoch [1/10], Iter [2454/3125], train_loss:0.034194\n",
      "Epoch [1/10], Iter [2455/3125], train_loss:0.088972\n",
      "Epoch [1/10], Iter [2456/3125], train_loss:0.044014\n",
      "Epoch [1/10], Iter [2457/3125], train_loss:0.051432\n",
      "Epoch [1/10], Iter [2458/3125], train_loss:0.038895\n",
      "Epoch [1/10], Iter [2459/3125], train_loss:0.091389\n",
      "Epoch [1/10], Iter [2460/3125], train_loss:0.067894\n",
      "Epoch [1/10], Iter [2461/3125], train_loss:0.077940\n",
      "Epoch [1/10], Iter [2462/3125], train_loss:0.035168\n",
      "Epoch [1/10], Iter [2463/3125], train_loss:0.057799\n",
      "Epoch [1/10], Iter [2464/3125], train_loss:0.039412\n",
      "Epoch [1/10], Iter [2465/3125], train_loss:0.055779\n",
      "Epoch [1/10], Iter [2466/3125], train_loss:0.039693\n",
      "Epoch [1/10], Iter [2467/3125], train_loss:0.044370\n",
      "Epoch [1/10], Iter [2468/3125], train_loss:0.072034\n",
      "Epoch [1/10], Iter [2469/3125], train_loss:0.039117\n",
      "Epoch [1/10], Iter [2470/3125], train_loss:0.041900\n",
      "Epoch [1/10], Iter [2471/3125], train_loss:0.078160\n",
      "Epoch [1/10], Iter [2472/3125], train_loss:0.043799\n",
      "Epoch [1/10], Iter [2473/3125], train_loss:0.034027\n",
      "Epoch [1/10], Iter [2474/3125], train_loss:0.033906\n",
      "Epoch [1/10], Iter [2475/3125], train_loss:0.040556\n",
      "Epoch [1/10], Iter [2476/3125], train_loss:0.076365\n",
      "Epoch [1/10], Iter [2477/3125], train_loss:0.044474\n",
      "Epoch [1/10], Iter [2478/3125], train_loss:0.050639\n",
      "Epoch [1/10], Iter [2479/3125], train_loss:0.094295\n",
      "Epoch [1/10], Iter [2480/3125], train_loss:0.049790\n",
      "Epoch [1/10], Iter [2481/3125], train_loss:0.058790\n",
      "Epoch [1/10], Iter [2482/3125], train_loss:0.063505\n",
      "Epoch [1/10], Iter [2483/3125], train_loss:0.049205\n",
      "Epoch [1/10], Iter [2484/3125], train_loss:0.056420\n",
      "Epoch [1/10], Iter [2485/3125], train_loss:0.034539\n",
      "Epoch [1/10], Iter [2486/3125], train_loss:0.060778\n",
      "Epoch [1/10], Iter [2487/3125], train_loss:0.061710\n",
      "Epoch [1/10], Iter [2488/3125], train_loss:0.059184\n",
      "Epoch [1/10], Iter [2489/3125], train_loss:0.051106\n",
      "Epoch [1/10], Iter [2490/3125], train_loss:0.055393\n",
      "Epoch [1/10], Iter [2491/3125], train_loss:0.069071\n",
      "Epoch [1/10], Iter [2492/3125], train_loss:0.038927\n",
      "Epoch [1/10], Iter [2493/3125], train_loss:0.055511\n",
      "Epoch [1/10], Iter [2494/3125], train_loss:0.030150\n",
      "Epoch [1/10], Iter [2495/3125], train_loss:0.046406\n",
      "Epoch [1/10], Iter [2496/3125], train_loss:0.050650\n",
      "Epoch [1/10], Iter [2497/3125], train_loss:0.067050\n",
      "Epoch [1/10], Iter [2498/3125], train_loss:0.065522\n",
      "Epoch [1/10], Iter [2499/3125], train_loss:0.039835\n",
      "Epoch [1/10], Iter [2500/3125], train_loss:0.037947\n",
      "Epoch [1/10], Iter [2501/3125], train_loss:0.087482\n",
      "Epoch [1/10], Iter [2502/3125], train_loss:0.049749\n",
      "Epoch [1/10], Iter [2503/3125], train_loss:0.075907\n",
      "Epoch [1/10], Iter [2504/3125], train_loss:0.048454\n",
      "Epoch [1/10], Iter [2505/3125], train_loss:0.056744\n",
      "Epoch [1/10], Iter [2506/3125], train_loss:0.063433\n",
      "Epoch [1/10], Iter [2507/3125], train_loss:0.093217\n",
      "Epoch [1/10], Iter [2508/3125], train_loss:0.060091\n",
      "Epoch [1/10], Iter [2509/3125], train_loss:0.038879\n",
      "Epoch [1/10], Iter [2510/3125], train_loss:0.073510\n",
      "Epoch [1/10], Iter [2511/3125], train_loss:0.078042\n",
      "Epoch [1/10], Iter [2512/3125], train_loss:0.018318\n",
      "Epoch [1/10], Iter [2513/3125], train_loss:0.071369\n",
      "Epoch [1/10], Iter [2514/3125], train_loss:0.055521\n",
      "Epoch [1/10], Iter [2515/3125], train_loss:0.074205\n",
      "Epoch [1/10], Iter [2516/3125], train_loss:0.034892\n",
      "Epoch [1/10], Iter [2517/3125], train_loss:0.059679\n",
      "Epoch [1/10], Iter [2518/3125], train_loss:0.044943\n",
      "Epoch [1/10], Iter [2519/3125], train_loss:0.039163\n",
      "Epoch [1/10], Iter [2520/3125], train_loss:0.033841\n",
      "Epoch [1/10], Iter [2521/3125], train_loss:0.095452\n",
      "Epoch [1/10], Iter [2522/3125], train_loss:0.052355\n",
      "Epoch [1/10], Iter [2523/3125], train_loss:0.097691\n",
      "Epoch [1/10], Iter [2524/3125], train_loss:0.043344\n",
      "Epoch [1/10], Iter [2525/3125], train_loss:0.082170\n",
      "Epoch [1/10], Iter [2526/3125], train_loss:0.037574\n",
      "Epoch [1/10], Iter [2527/3125], train_loss:0.046212\n",
      "Epoch [1/10], Iter [2528/3125], train_loss:0.028267\n",
      "Epoch [1/10], Iter [2529/3125], train_loss:0.048699\n",
      "Epoch [1/10], Iter [2530/3125], train_loss:0.089290\n",
      "Epoch [1/10], Iter [2531/3125], train_loss:0.080898\n",
      "Epoch [1/10], Iter [2532/3125], train_loss:0.040260\n",
      "Epoch [1/10], Iter [2533/3125], train_loss:0.079006\n",
      "Epoch [1/10], Iter [2534/3125], train_loss:0.044073\n",
      "Epoch [1/10], Iter [2535/3125], train_loss:0.056003\n",
      "Epoch [1/10], Iter [2536/3125], train_loss:0.049989\n",
      "Epoch [1/10], Iter [2537/3125], train_loss:0.045744\n",
      "Epoch [1/10], Iter [2538/3125], train_loss:0.049811\n",
      "Epoch [1/10], Iter [2539/3125], train_loss:0.059298\n",
      "Epoch [1/10], Iter [2540/3125], train_loss:0.041965\n",
      "Epoch [1/10], Iter [2541/3125], train_loss:0.044184\n",
      "Epoch [1/10], Iter [2542/3125], train_loss:0.070333\n",
      "Epoch [1/10], Iter [2543/3125], train_loss:0.061322\n",
      "Epoch [1/10], Iter [2544/3125], train_loss:0.033247\n",
      "Epoch [1/10], Iter [2545/3125], train_loss:0.037805\n",
      "Epoch [1/10], Iter [2546/3125], train_loss:0.031448\n",
      "Epoch [1/10], Iter [2547/3125], train_loss:0.034567\n",
      "Epoch [1/10], Iter [2548/3125], train_loss:0.053322\n",
      "Epoch [1/10], Iter [2549/3125], train_loss:0.081269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [2550/3125], train_loss:0.078102\n",
      "Epoch [1/10], Iter [2551/3125], train_loss:0.022630\n",
      "Epoch [1/10], Iter [2552/3125], train_loss:0.032897\n",
      "Epoch [1/10], Iter [2553/3125], train_loss:0.050063\n",
      "Epoch [1/10], Iter [2554/3125], train_loss:0.053164\n",
      "Epoch [1/10], Iter [2555/3125], train_loss:0.033120\n",
      "Epoch [1/10], Iter [2556/3125], train_loss:0.046334\n",
      "Epoch [1/10], Iter [2557/3125], train_loss:0.068456\n",
      "Epoch [1/10], Iter [2558/3125], train_loss:0.070154\n",
      "Epoch [1/10], Iter [2559/3125], train_loss:0.036025\n",
      "Epoch [1/10], Iter [2560/3125], train_loss:0.070635\n",
      "Epoch [1/10], Iter [2561/3125], train_loss:0.052198\n",
      "Epoch [1/10], Iter [2562/3125], train_loss:0.043804\n",
      "Epoch [1/10], Iter [2563/3125], train_loss:0.067197\n",
      "Epoch [1/10], Iter [2564/3125], train_loss:0.080402\n",
      "Epoch [1/10], Iter [2565/3125], train_loss:0.071421\n",
      "Epoch [1/10], Iter [2566/3125], train_loss:0.044109\n",
      "Epoch [1/10], Iter [2567/3125], train_loss:0.063801\n",
      "Epoch [1/10], Iter [2568/3125], train_loss:0.075022\n",
      "Epoch [1/10], Iter [2569/3125], train_loss:0.030197\n",
      "Epoch [1/10], Iter [2570/3125], train_loss:0.060289\n",
      "Epoch [1/10], Iter [2571/3125], train_loss:0.041631\n",
      "Epoch [1/10], Iter [2572/3125], train_loss:0.047699\n",
      "Epoch [1/10], Iter [2573/3125], train_loss:0.028659\n",
      "Epoch [1/10], Iter [2574/3125], train_loss:0.046188\n",
      "Epoch [1/10], Iter [2575/3125], train_loss:0.031889\n",
      "Epoch [1/10], Iter [2576/3125], train_loss:0.066076\n",
      "Epoch [1/10], Iter [2577/3125], train_loss:0.062998\n",
      "Epoch [1/10], Iter [2578/3125], train_loss:0.034345\n",
      "Epoch [1/10], Iter [2579/3125], train_loss:0.045776\n",
      "Epoch [1/10], Iter [2580/3125], train_loss:0.063058\n",
      "Epoch [1/10], Iter [2581/3125], train_loss:0.049935\n",
      "Epoch [1/10], Iter [2582/3125], train_loss:0.084482\n",
      "Epoch [1/10], Iter [2583/3125], train_loss:0.057923\n",
      "Epoch [1/10], Iter [2584/3125], train_loss:0.045246\n",
      "Epoch [1/10], Iter [2585/3125], train_loss:0.058265\n",
      "Epoch [1/10], Iter [2586/3125], train_loss:0.035428\n",
      "Epoch [1/10], Iter [2587/3125], train_loss:0.042721\n",
      "Epoch [1/10], Iter [2588/3125], train_loss:0.067164\n",
      "Epoch [1/10], Iter [2589/3125], train_loss:0.045646\n",
      "Epoch [1/10], Iter [2590/3125], train_loss:0.038400\n",
      "Epoch [1/10], Iter [2591/3125], train_loss:0.038546\n",
      "Epoch [1/10], Iter [2592/3125], train_loss:0.072927\n",
      "Epoch [1/10], Iter [2593/3125], train_loss:0.030221\n",
      "Epoch [1/10], Iter [2594/3125], train_loss:0.056022\n",
      "Epoch [1/10], Iter [2595/3125], train_loss:0.056454\n",
      "Epoch [1/10], Iter [2596/3125], train_loss:0.044413\n",
      "Epoch [1/10], Iter [2597/3125], train_loss:0.031464\n",
      "Epoch [1/10], Iter [2598/3125], train_loss:0.051813\n",
      "Epoch [1/10], Iter [2599/3125], train_loss:0.077083\n",
      "Epoch [1/10], Iter [2600/3125], train_loss:0.040987\n",
      "Epoch [1/10], Iter [2601/3125], train_loss:0.037267\n",
      "Epoch [1/10], Iter [2602/3125], train_loss:0.033299\n",
      "Epoch [1/10], Iter [2603/3125], train_loss:0.049933\n",
      "Epoch [1/10], Iter [2604/3125], train_loss:0.050345\n",
      "Epoch [1/10], Iter [2605/3125], train_loss:0.068158\n",
      "Epoch [1/10], Iter [2606/3125], train_loss:0.063846\n",
      "Epoch [1/10], Iter [2607/3125], train_loss:0.057081\n",
      "Epoch [1/10], Iter [2608/3125], train_loss:0.050321\n",
      "Epoch [1/10], Iter [2609/3125], train_loss:0.084901\n",
      "Epoch [1/10], Iter [2610/3125], train_loss:0.061853\n",
      "Epoch [1/10], Iter [2611/3125], train_loss:0.059709\n",
      "Epoch [1/10], Iter [2612/3125], train_loss:0.057150\n",
      "Epoch [1/10], Iter [2613/3125], train_loss:0.034964\n",
      "Epoch [1/10], Iter [2614/3125], train_loss:0.044947\n",
      "Epoch [1/10], Iter [2615/3125], train_loss:0.089898\n",
      "Epoch [1/10], Iter [2616/3125], train_loss:0.052279\n",
      "Epoch [1/10], Iter [2617/3125], train_loss:0.065590\n",
      "Epoch [1/10], Iter [2618/3125], train_loss:0.079470\n",
      "Epoch [1/10], Iter [2619/3125], train_loss:0.064696\n",
      "Epoch [1/10], Iter [2620/3125], train_loss:0.031827\n",
      "Epoch [1/10], Iter [2621/3125], train_loss:0.057286\n",
      "Epoch [1/10], Iter [2622/3125], train_loss:0.059908\n",
      "Epoch [1/10], Iter [2623/3125], train_loss:0.050808\n",
      "Epoch [1/10], Iter [2624/3125], train_loss:0.076302\n",
      "Epoch [1/10], Iter [2625/3125], train_loss:0.054479\n",
      "Epoch [1/10], Iter [2626/3125], train_loss:0.050685\n",
      "Epoch [1/10], Iter [2627/3125], train_loss:0.057106\n",
      "Epoch [1/10], Iter [2628/3125], train_loss:0.050811\n",
      "Epoch [1/10], Iter [2629/3125], train_loss:0.025450\n",
      "Epoch [1/10], Iter [2630/3125], train_loss:0.035107\n",
      "Epoch [1/10], Iter [2631/3125], train_loss:0.037918\n",
      "Epoch [1/10], Iter [2632/3125], train_loss:0.049256\n",
      "Epoch [1/10], Iter [2633/3125], train_loss:0.062963\n",
      "Epoch [1/10], Iter [2634/3125], train_loss:0.043879\n",
      "Epoch [1/10], Iter [2635/3125], train_loss:0.043937\n",
      "Epoch [1/10], Iter [2636/3125], train_loss:0.043007\n",
      "Epoch [1/10], Iter [2637/3125], train_loss:0.033700\n",
      "Epoch [1/10], Iter [2638/3125], train_loss:0.024870\n",
      "Epoch [1/10], Iter [2639/3125], train_loss:0.039514\n",
      "Epoch [1/10], Iter [2640/3125], train_loss:0.067759\n",
      "Epoch [1/10], Iter [2641/3125], train_loss:0.062978\n",
      "Epoch [1/10], Iter [2642/3125], train_loss:0.073482\n",
      "Epoch [1/10], Iter [2643/3125], train_loss:0.051648\n",
      "Epoch [1/10], Iter [2644/3125], train_loss:0.065120\n",
      "Epoch [1/10], Iter [2645/3125], train_loss:0.023624\n",
      "Epoch [1/10], Iter [2646/3125], train_loss:0.019855\n",
      "Epoch [1/10], Iter [2647/3125], train_loss:0.106905\n",
      "Epoch [1/10], Iter [2648/3125], train_loss:0.058358\n",
      "Epoch [1/10], Iter [2649/3125], train_loss:0.072519\n",
      "Epoch [1/10], Iter [2650/3125], train_loss:0.070563\n",
      "Epoch [1/10], Iter [2651/3125], train_loss:0.073849\n",
      "Epoch [1/10], Iter [2652/3125], train_loss:0.051423\n",
      "Epoch [1/10], Iter [2653/3125], train_loss:0.041773\n",
      "Epoch [1/10], Iter [2654/3125], train_loss:0.042694\n",
      "Epoch [1/10], Iter [2655/3125], train_loss:0.041109\n",
      "Epoch [1/10], Iter [2656/3125], train_loss:0.046723\n",
      "Epoch [1/10], Iter [2657/3125], train_loss:0.032426\n",
      "Epoch [1/10], Iter [2658/3125], train_loss:0.031085\n",
      "Epoch [1/10], Iter [2659/3125], train_loss:0.071443\n",
      "Epoch [1/10], Iter [2660/3125], train_loss:0.034657\n",
      "Epoch [1/10], Iter [2661/3125], train_loss:0.064858\n",
      "Epoch [1/10], Iter [2662/3125], train_loss:0.011753\n",
      "Epoch [1/10], Iter [2663/3125], train_loss:0.056094\n",
      "Epoch [1/10], Iter [2664/3125], train_loss:0.039091\n",
      "Epoch [1/10], Iter [2665/3125], train_loss:0.067260\n",
      "Epoch [1/10], Iter [2666/3125], train_loss:0.054605\n",
      "Epoch [1/10], Iter [2667/3125], train_loss:0.073443\n",
      "Epoch [1/10], Iter [2668/3125], train_loss:0.047724\n",
      "Epoch [1/10], Iter [2669/3125], train_loss:0.061778\n",
      "Epoch [1/10], Iter [2670/3125], train_loss:0.052013\n",
      "Epoch [1/10], Iter [2671/3125], train_loss:0.040040\n",
      "Epoch [1/10], Iter [2672/3125], train_loss:0.058101\n",
      "Epoch [1/10], Iter [2673/3125], train_loss:0.058269\n",
      "Epoch [1/10], Iter [2674/3125], train_loss:0.056329\n",
      "Epoch [1/10], Iter [2675/3125], train_loss:0.074943\n",
      "Epoch [1/10], Iter [2676/3125], train_loss:0.060055\n",
      "Epoch [1/10], Iter [2677/3125], train_loss:0.066210\n",
      "Epoch [1/10], Iter [2678/3125], train_loss:0.077830\n",
      "Epoch [1/10], Iter [2679/3125], train_loss:0.069789\n",
      "Epoch [1/10], Iter [2680/3125], train_loss:0.022511\n",
      "Epoch [1/10], Iter [2681/3125], train_loss:0.074430\n",
      "Epoch [1/10], Iter [2682/3125], train_loss:0.064221\n",
      "Epoch [1/10], Iter [2683/3125], train_loss:0.033731\n",
      "Epoch [1/10], Iter [2684/3125], train_loss:0.057155\n",
      "Epoch [1/10], Iter [2685/3125], train_loss:0.071050\n",
      "Epoch [1/10], Iter [2686/3125], train_loss:0.031468\n",
      "Epoch [1/10], Iter [2687/3125], train_loss:0.061247\n",
      "Epoch [1/10], Iter [2688/3125], train_loss:0.033162\n",
      "Epoch [1/10], Iter [2689/3125], train_loss:0.053674\n",
      "Epoch [1/10], Iter [2690/3125], train_loss:0.052903\n",
      "Epoch [1/10], Iter [2691/3125], train_loss:0.053036\n",
      "Epoch [1/10], Iter [2692/3125], train_loss:0.031536\n",
      "Epoch [1/10], Iter [2693/3125], train_loss:0.047191\n",
      "Epoch [1/10], Iter [2694/3125], train_loss:0.053092\n",
      "Epoch [1/10], Iter [2695/3125], train_loss:0.046388\n",
      "Epoch [1/10], Iter [2696/3125], train_loss:0.081545\n",
      "Epoch [1/10], Iter [2697/3125], train_loss:0.031258\n",
      "Epoch [1/10], Iter [2698/3125], train_loss:0.065705\n",
      "Epoch [1/10], Iter [2699/3125], train_loss:0.085829\n",
      "Epoch [1/10], Iter [2700/3125], train_loss:0.036830\n",
      "Epoch [1/10], Iter [2701/3125], train_loss:0.039658\n",
      "Epoch [1/10], Iter [2702/3125], train_loss:0.034230\n",
      "Epoch [1/10], Iter [2703/3125], train_loss:0.046603\n",
      "Epoch [1/10], Iter [2704/3125], train_loss:0.062321\n",
      "Epoch [1/10], Iter [2705/3125], train_loss:0.074843\n",
      "Epoch [1/10], Iter [2706/3125], train_loss:0.064365\n",
      "Epoch [1/10], Iter [2707/3125], train_loss:0.041580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [2708/3125], train_loss:0.042753\n",
      "Epoch [1/10], Iter [2709/3125], train_loss:0.054325\n",
      "Epoch [1/10], Iter [2710/3125], train_loss:0.029269\n",
      "Epoch [1/10], Iter [2711/3125], train_loss:0.056201\n",
      "Epoch [1/10], Iter [2712/3125], train_loss:0.032027\n",
      "Epoch [1/10], Iter [2713/3125], train_loss:0.041384\n",
      "Epoch [1/10], Iter [2714/3125], train_loss:0.042245\n",
      "Epoch [1/10], Iter [2715/3125], train_loss:0.049180\n",
      "Epoch [1/10], Iter [2716/3125], train_loss:0.071382\n",
      "Epoch [1/10], Iter [2717/3125], train_loss:0.053056\n",
      "Epoch [1/10], Iter [2718/3125], train_loss:0.076437\n",
      "Epoch [1/10], Iter [2719/3125], train_loss:0.036449\n",
      "Epoch [1/10], Iter [2720/3125], train_loss:0.037378\n",
      "Epoch [1/10], Iter [2721/3125], train_loss:0.056445\n",
      "Epoch [1/10], Iter [2722/3125], train_loss:0.070102\n",
      "Epoch [1/10], Iter [2723/3125], train_loss:0.032661\n",
      "Epoch [1/10], Iter [2724/3125], train_loss:0.045753\n",
      "Epoch [1/10], Iter [2725/3125], train_loss:0.051136\n",
      "Epoch [1/10], Iter [2726/3125], train_loss:0.048787\n",
      "Epoch [1/10], Iter [2727/3125], train_loss:0.078822\n",
      "Epoch [1/10], Iter [2728/3125], train_loss:0.053859\n",
      "Epoch [1/10], Iter [2729/3125], train_loss:0.061877\n",
      "Epoch [1/10], Iter [2730/3125], train_loss:0.068190\n",
      "Epoch [1/10], Iter [2731/3125], train_loss:0.059085\n",
      "Epoch [1/10], Iter [2732/3125], train_loss:0.041527\n",
      "Epoch [1/10], Iter [2733/3125], train_loss:0.037386\n",
      "Epoch [1/10], Iter [2734/3125], train_loss:0.045102\n",
      "Epoch [1/10], Iter [2735/3125], train_loss:0.072924\n",
      "Epoch [1/10], Iter [2736/3125], train_loss:0.024766\n",
      "Epoch [1/10], Iter [2737/3125], train_loss:0.036317\n",
      "Epoch [1/10], Iter [2738/3125], train_loss:0.060391\n",
      "Epoch [1/10], Iter [2739/3125], train_loss:0.026071\n",
      "Epoch [1/10], Iter [2740/3125], train_loss:0.045086\n",
      "Epoch [1/10], Iter [2741/3125], train_loss:0.060746\n",
      "Epoch [1/10], Iter [2742/3125], train_loss:0.037758\n",
      "Epoch [1/10], Iter [2743/3125], train_loss:0.042991\n",
      "Epoch [1/10], Iter [2744/3125], train_loss:0.057417\n",
      "Epoch [1/10], Iter [2745/3125], train_loss:0.029067\n",
      "Epoch [1/10], Iter [2746/3125], train_loss:0.095886\n",
      "Epoch [1/10], Iter [2747/3125], train_loss:0.033592\n",
      "Epoch [1/10], Iter [2748/3125], train_loss:0.043915\n",
      "Epoch [1/10], Iter [2749/3125], train_loss:0.085850\n",
      "Epoch [1/10], Iter [2750/3125], train_loss:0.066093\n",
      "Epoch [1/10], Iter [2751/3125], train_loss:0.062001\n",
      "Epoch [1/10], Iter [2752/3125], train_loss:0.069263\n",
      "Epoch [1/10], Iter [2753/3125], train_loss:0.041522\n",
      "Epoch [1/10], Iter [2754/3125], train_loss:0.056623\n",
      "Epoch [1/10], Iter [2755/3125], train_loss:0.076867\n",
      "Epoch [1/10], Iter [2756/3125], train_loss:0.063004\n",
      "Epoch [1/10], Iter [2757/3125], train_loss:0.055485\n",
      "Epoch [1/10], Iter [2758/3125], train_loss:0.066020\n",
      "Epoch [1/10], Iter [2759/3125], train_loss:0.033939\n",
      "Epoch [1/10], Iter [2760/3125], train_loss:0.032806\n",
      "Epoch [1/10], Iter [2761/3125], train_loss:0.054655\n",
      "Epoch [1/10], Iter [2762/3125], train_loss:0.050211\n",
      "Epoch [1/10], Iter [2763/3125], train_loss:0.025504\n",
      "Epoch [1/10], Iter [2764/3125], train_loss:0.052584\n",
      "Epoch [1/10], Iter [2765/3125], train_loss:0.029184\n",
      "Epoch [1/10], Iter [2766/3125], train_loss:0.020083\n",
      "Epoch [1/10], Iter [2767/3125], train_loss:0.027875\n",
      "Epoch [1/10], Iter [2768/3125], train_loss:0.024596\n",
      "Epoch [1/10], Iter [2769/3125], train_loss:0.055002\n",
      "Epoch [1/10], Iter [2770/3125], train_loss:0.055419\n",
      "Epoch [1/10], Iter [2771/3125], train_loss:0.024973\n",
      "Epoch [1/10], Iter [2772/3125], train_loss:0.086723\n",
      "Epoch [1/10], Iter [2773/3125], train_loss:0.048133\n",
      "Epoch [1/10], Iter [2774/3125], train_loss:0.046027\n",
      "Epoch [1/10], Iter [2775/3125], train_loss:0.047695\n",
      "Epoch [1/10], Iter [2776/3125], train_loss:0.037621\n",
      "Epoch [1/10], Iter [2777/3125], train_loss:0.049847\n",
      "Epoch [1/10], Iter [2778/3125], train_loss:0.050305\n",
      "Epoch [1/10], Iter [2779/3125], train_loss:0.028408\n",
      "Epoch [1/10], Iter [2780/3125], train_loss:0.057841\n",
      "Epoch [1/10], Iter [2781/3125], train_loss:0.037195\n",
      "Epoch [1/10], Iter [2782/3125], train_loss:0.046566\n",
      "Epoch [1/10], Iter [2783/3125], train_loss:0.059322\n",
      "Epoch [1/10], Iter [2784/3125], train_loss:0.089970\n",
      "Epoch [1/10], Iter [2785/3125], train_loss:0.035622\n",
      "Epoch [1/10], Iter [2786/3125], train_loss:0.036376\n",
      "Epoch [1/10], Iter [2787/3125], train_loss:0.049406\n",
      "Epoch [1/10], Iter [2788/3125], train_loss:0.027285\n",
      "Epoch [1/10], Iter [2789/3125], train_loss:0.024182\n",
      "Epoch [1/10], Iter [2790/3125], train_loss:0.058590\n",
      "Epoch [1/10], Iter [2791/3125], train_loss:0.031623\n",
      "Epoch [1/10], Iter [2792/3125], train_loss:0.064973\n",
      "Epoch [1/10], Iter [2793/3125], train_loss:0.083880\n",
      "Epoch [1/10], Iter [2794/3125], train_loss:0.063413\n",
      "Epoch [1/10], Iter [2795/3125], train_loss:0.027198\n",
      "Epoch [1/10], Iter [2796/3125], train_loss:0.065740\n",
      "Epoch [1/10], Iter [2797/3125], train_loss:0.045814\n",
      "Epoch [1/10], Iter [2798/3125], train_loss:0.058582\n",
      "Epoch [1/10], Iter [2799/3125], train_loss:0.037425\n",
      "Epoch [1/10], Iter [2800/3125], train_loss:0.040245\n",
      "Epoch [1/10], Iter [2801/3125], train_loss:0.069127\n",
      "Epoch [1/10], Iter [2802/3125], train_loss:0.038190\n",
      "Epoch [1/10], Iter [2803/3125], train_loss:0.076748\n",
      "Epoch [1/10], Iter [2804/3125], train_loss:0.063528\n",
      "Epoch [1/10], Iter [2805/3125], train_loss:0.050070\n",
      "Epoch [1/10], Iter [2806/3125], train_loss:0.043468\n",
      "Epoch [1/10], Iter [2807/3125], train_loss:0.037768\n",
      "Epoch [1/10], Iter [2808/3125], train_loss:0.069925\n",
      "Epoch [1/10], Iter [2809/3125], train_loss:0.027971\n",
      "Epoch [1/10], Iter [2810/3125], train_loss:0.045305\n",
      "Epoch [1/10], Iter [2811/3125], train_loss:0.072035\n",
      "Epoch [1/10], Iter [2812/3125], train_loss:0.027901\n",
      "Epoch [1/10], Iter [2813/3125], train_loss:0.055258\n",
      "Epoch [1/10], Iter [2814/3125], train_loss:0.033380\n",
      "Epoch [1/10], Iter [2815/3125], train_loss:0.035067\n",
      "Epoch [1/10], Iter [2816/3125], train_loss:0.062196\n",
      "Epoch [1/10], Iter [2817/3125], train_loss:0.031055\n",
      "Epoch [1/10], Iter [2818/3125], train_loss:0.027535\n",
      "Epoch [1/10], Iter [2819/3125], train_loss:0.074925\n",
      "Epoch [1/10], Iter [2820/3125], train_loss:0.014863\n",
      "Epoch [1/10], Iter [2821/3125], train_loss:0.040033\n",
      "Epoch [1/10], Iter [2822/3125], train_loss:0.073055\n",
      "Epoch [1/10], Iter [2823/3125], train_loss:0.044778\n",
      "Epoch [1/10], Iter [2824/3125], train_loss:0.041350\n",
      "Epoch [1/10], Iter [2825/3125], train_loss:0.045701\n",
      "Epoch [1/10], Iter [2826/3125], train_loss:0.069052\n",
      "Epoch [1/10], Iter [2827/3125], train_loss:0.070689\n",
      "Epoch [1/10], Iter [2828/3125], train_loss:0.073792\n",
      "Epoch [1/10], Iter [2829/3125], train_loss:0.027273\n",
      "Epoch [1/10], Iter [2830/3125], train_loss:0.070355\n",
      "Epoch [1/10], Iter [2831/3125], train_loss:0.050928\n",
      "Epoch [1/10], Iter [2832/3125], train_loss:0.063157\n",
      "Epoch [1/10], Iter [2833/3125], train_loss:0.052722\n",
      "Epoch [1/10], Iter [2834/3125], train_loss:0.066621\n",
      "Epoch [1/10], Iter [2835/3125], train_loss:0.049870\n",
      "Epoch [1/10], Iter [2836/3125], train_loss:0.045198\n",
      "Epoch [1/10], Iter [2837/3125], train_loss:0.047708\n",
      "Epoch [1/10], Iter [2838/3125], train_loss:0.031084\n",
      "Epoch [1/10], Iter [2839/3125], train_loss:0.054982\n",
      "Epoch [1/10], Iter [2840/3125], train_loss:0.062080\n",
      "Epoch [1/10], Iter [2841/3125], train_loss:0.052313\n",
      "Epoch [1/10], Iter [2842/3125], train_loss:0.027638\n",
      "Epoch [1/10], Iter [2843/3125], train_loss:0.069474\n",
      "Epoch [1/10], Iter [2844/3125], train_loss:0.051465\n",
      "Epoch [1/10], Iter [2845/3125], train_loss:0.047240\n",
      "Epoch [1/10], Iter [2846/3125], train_loss:0.043358\n",
      "Epoch [1/10], Iter [2847/3125], train_loss:0.046753\n",
      "Epoch [1/10], Iter [2848/3125], train_loss:0.059748\n",
      "Epoch [1/10], Iter [2849/3125], train_loss:0.032166\n",
      "Epoch [1/10], Iter [2850/3125], train_loss:0.051633\n",
      "Epoch [1/10], Iter [2851/3125], train_loss:0.032861\n",
      "Epoch [1/10], Iter [2852/3125], train_loss:0.046734\n",
      "Epoch [1/10], Iter [2853/3125], train_loss:0.031587\n",
      "Epoch [1/10], Iter [2854/3125], train_loss:0.028285\n",
      "Epoch [1/10], Iter [2855/3125], train_loss:0.063359\n",
      "Epoch [1/10], Iter [2856/3125], train_loss:0.063512\n",
      "Epoch [1/10], Iter [2857/3125], train_loss:0.048190\n",
      "Epoch [1/10], Iter [2858/3125], train_loss:0.070683\n",
      "Epoch [1/10], Iter [2859/3125], train_loss:0.016137\n",
      "Epoch [1/10], Iter [2860/3125], train_loss:0.045513\n",
      "Epoch [1/10], Iter [2861/3125], train_loss:0.033696\n",
      "Epoch [1/10], Iter [2862/3125], train_loss:0.056089\n",
      "Epoch [1/10], Iter [2863/3125], train_loss:0.040835\n",
      "Epoch [1/10], Iter [2864/3125], train_loss:0.059301\n",
      "Epoch [1/10], Iter [2865/3125], train_loss:0.065590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [2866/3125], train_loss:0.054262\n",
      "Epoch [1/10], Iter [2867/3125], train_loss:0.032128\n",
      "Epoch [1/10], Iter [2868/3125], train_loss:0.070486\n",
      "Epoch [1/10], Iter [2869/3125], train_loss:0.050579\n",
      "Epoch [1/10], Iter [2870/3125], train_loss:0.048929\n",
      "Epoch [1/10], Iter [2871/3125], train_loss:0.059329\n",
      "Epoch [1/10], Iter [2872/3125], train_loss:0.059987\n",
      "Epoch [1/10], Iter [2873/3125], train_loss:0.038087\n",
      "Epoch [1/10], Iter [2874/3125], train_loss:0.042215\n",
      "Epoch [1/10], Iter [2875/3125], train_loss:0.037359\n",
      "Epoch [1/10], Iter [2876/3125], train_loss:0.064945\n",
      "Epoch [1/10], Iter [2877/3125], train_loss:0.032644\n",
      "Epoch [1/10], Iter [2878/3125], train_loss:0.035471\n",
      "Epoch [1/10], Iter [2879/3125], train_loss:0.054034\n",
      "Epoch [1/10], Iter [2880/3125], train_loss:0.055840\n",
      "Epoch [1/10], Iter [2881/3125], train_loss:0.040988\n",
      "Epoch [1/10], Iter [2882/3125], train_loss:0.076851\n",
      "Epoch [1/10], Iter [2883/3125], train_loss:0.084683\n",
      "Epoch [1/10], Iter [2884/3125], train_loss:0.052963\n",
      "Epoch [1/10], Iter [2885/3125], train_loss:0.033718\n",
      "Epoch [1/10], Iter [2886/3125], train_loss:0.047949\n",
      "Epoch [1/10], Iter [2887/3125], train_loss:0.066821\n",
      "Epoch [1/10], Iter [2888/3125], train_loss:0.062198\n",
      "Epoch [1/10], Iter [2889/3125], train_loss:0.064902\n",
      "Epoch [1/10], Iter [2890/3125], train_loss:0.057373\n",
      "Epoch [1/10], Iter [2891/3125], train_loss:0.048909\n",
      "Epoch [1/10], Iter [2892/3125], train_loss:0.047169\n",
      "Epoch [1/10], Iter [2893/3125], train_loss:0.037598\n",
      "Epoch [1/10], Iter [2894/3125], train_loss:0.044367\n",
      "Epoch [1/10], Iter [2895/3125], train_loss:0.059186\n",
      "Epoch [1/10], Iter [2896/3125], train_loss:0.027673\n",
      "Epoch [1/10], Iter [2897/3125], train_loss:0.046781\n",
      "Epoch [1/10], Iter [2898/3125], train_loss:0.044963\n",
      "Epoch [1/10], Iter [2899/3125], train_loss:0.053782\n",
      "Epoch [1/10], Iter [2900/3125], train_loss:0.037537\n",
      "Epoch [1/10], Iter [2901/3125], train_loss:0.043916\n",
      "Epoch [1/10], Iter [2902/3125], train_loss:0.056527\n",
      "Epoch [1/10], Iter [2903/3125], train_loss:0.025347\n",
      "Epoch [1/10], Iter [2904/3125], train_loss:0.038642\n",
      "Epoch [1/10], Iter [2905/3125], train_loss:0.066414\n",
      "Epoch [1/10], Iter [2906/3125], train_loss:0.041623\n",
      "Epoch [1/10], Iter [2907/3125], train_loss:0.050016\n",
      "Epoch [1/10], Iter [2908/3125], train_loss:0.043550\n",
      "Epoch [1/10], Iter [2909/3125], train_loss:0.039868\n",
      "Epoch [1/10], Iter [2910/3125], train_loss:0.026067\n",
      "Epoch [1/10], Iter [2911/3125], train_loss:0.045635\n",
      "Epoch [1/10], Iter [2912/3125], train_loss:0.070421\n",
      "Epoch [1/10], Iter [2913/3125], train_loss:0.063436\n",
      "Epoch [1/10], Iter [2914/3125], train_loss:0.049509\n",
      "Epoch [1/10], Iter [2915/3125], train_loss:0.071456\n",
      "Epoch [1/10], Iter [2916/3125], train_loss:0.029413\n",
      "Epoch [1/10], Iter [2917/3125], train_loss:0.042938\n",
      "Epoch [1/10], Iter [2918/3125], train_loss:0.060789\n",
      "Epoch [1/10], Iter [2919/3125], train_loss:0.035195\n",
      "Epoch [1/10], Iter [2920/3125], train_loss:0.049221\n",
      "Epoch [1/10], Iter [2921/3125], train_loss:0.032330\n",
      "Epoch [1/10], Iter [2922/3125], train_loss:0.037042\n",
      "Epoch [1/10], Iter [2923/3125], train_loss:0.065629\n",
      "Epoch [1/10], Iter [2924/3125], train_loss:0.022151\n",
      "Epoch [1/10], Iter [2925/3125], train_loss:0.056095\n",
      "Epoch [1/10], Iter [2926/3125], train_loss:0.034682\n",
      "Epoch [1/10], Iter [2927/3125], train_loss:0.081066\n",
      "Epoch [1/10], Iter [2928/3125], train_loss:0.038369\n",
      "Epoch [1/10], Iter [2929/3125], train_loss:0.025391\n",
      "Epoch [1/10], Iter [2930/3125], train_loss:0.043224\n",
      "Epoch [1/10], Iter [2931/3125], train_loss:0.073949\n",
      "Epoch [1/10], Iter [2932/3125], train_loss:0.062411\n",
      "Epoch [1/10], Iter [2933/3125], train_loss:0.048195\n",
      "Epoch [1/10], Iter [2934/3125], train_loss:0.041265\n",
      "Epoch [1/10], Iter [2935/3125], train_loss:0.051641\n",
      "Epoch [1/10], Iter [2936/3125], train_loss:0.051737\n",
      "Epoch [1/10], Iter [2937/3125], train_loss:0.085035\n",
      "Epoch [1/10], Iter [2938/3125], train_loss:0.041058\n",
      "Epoch [1/10], Iter [2939/3125], train_loss:0.052639\n",
      "Epoch [1/10], Iter [2940/3125], train_loss:0.067252\n",
      "Epoch [1/10], Iter [2941/3125], train_loss:0.067398\n",
      "Epoch [1/10], Iter [2942/3125], train_loss:0.035560\n",
      "Epoch [1/10], Iter [2943/3125], train_loss:0.026009\n",
      "Epoch [1/10], Iter [2944/3125], train_loss:0.028872\n",
      "Epoch [1/10], Iter [2945/3125], train_loss:0.100868\n",
      "Epoch [1/10], Iter [2946/3125], train_loss:0.073545\n",
      "Epoch [1/10], Iter [2947/3125], train_loss:0.064018\n",
      "Epoch [1/10], Iter [2948/3125], train_loss:0.038802\n",
      "Epoch [1/10], Iter [2949/3125], train_loss:0.035678\n",
      "Epoch [1/10], Iter [2950/3125], train_loss:0.057404\n",
      "Epoch [1/10], Iter [2951/3125], train_loss:0.038700\n",
      "Epoch [1/10], Iter [2952/3125], train_loss:0.066487\n",
      "Epoch [1/10], Iter [2953/3125], train_loss:0.036224\n",
      "Epoch [1/10], Iter [2954/3125], train_loss:0.049169\n",
      "Epoch [1/10], Iter [2955/3125], train_loss:0.060712\n",
      "Epoch [1/10], Iter [2956/3125], train_loss:0.054164\n",
      "Epoch [1/10], Iter [2957/3125], train_loss:0.045852\n",
      "Epoch [1/10], Iter [2958/3125], train_loss:0.046974\n",
      "Epoch [1/10], Iter [2959/3125], train_loss:0.046566\n",
      "Epoch [1/10], Iter [2960/3125], train_loss:0.029474\n",
      "Epoch [1/10], Iter [2961/3125], train_loss:0.048267\n",
      "Epoch [1/10], Iter [2962/3125], train_loss:0.093090\n",
      "Epoch [1/10], Iter [2963/3125], train_loss:0.059621\n",
      "Epoch [1/10], Iter [2964/3125], train_loss:0.053808\n",
      "Epoch [1/10], Iter [2965/3125], train_loss:0.019410\n",
      "Epoch [1/10], Iter [2966/3125], train_loss:0.080236\n",
      "Epoch [1/10], Iter [2967/3125], train_loss:0.048073\n",
      "Epoch [1/10], Iter [2968/3125], train_loss:0.045536\n",
      "Epoch [1/10], Iter [2969/3125], train_loss:0.037549\n",
      "Epoch [1/10], Iter [2970/3125], train_loss:0.077696\n",
      "Epoch [1/10], Iter [2971/3125], train_loss:0.044552\n",
      "Epoch [1/10], Iter [2972/3125], train_loss:0.028185\n",
      "Epoch [1/10], Iter [2973/3125], train_loss:0.027866\n",
      "Epoch [1/10], Iter [2974/3125], train_loss:0.047479\n",
      "Epoch [1/10], Iter [2975/3125], train_loss:0.047819\n",
      "Epoch [1/10], Iter [2976/3125], train_loss:0.040483\n",
      "Epoch [1/10], Iter [2977/3125], train_loss:0.070177\n",
      "Epoch [1/10], Iter [2978/3125], train_loss:0.021798\n",
      "Epoch [1/10], Iter [2979/3125], train_loss:0.041524\n",
      "Epoch [1/10], Iter [2980/3125], train_loss:0.038104\n",
      "Epoch [1/10], Iter [2981/3125], train_loss:0.050260\n",
      "Epoch [1/10], Iter [2982/3125], train_loss:0.047825\n",
      "Epoch [1/10], Iter [2983/3125], train_loss:0.059096\n",
      "Epoch [1/10], Iter [2984/3125], train_loss:0.036488\n",
      "Epoch [1/10], Iter [2985/3125], train_loss:0.048905\n",
      "Epoch [1/10], Iter [2986/3125], train_loss:0.092370\n",
      "Epoch [1/10], Iter [2987/3125], train_loss:0.065375\n",
      "Epoch [1/10], Iter [2988/3125], train_loss:0.050387\n",
      "Epoch [1/10], Iter [2989/3125], train_loss:0.040478\n",
      "Epoch [1/10], Iter [2990/3125], train_loss:0.070799\n",
      "Epoch [1/10], Iter [2991/3125], train_loss:0.074366\n",
      "Epoch [1/10], Iter [2992/3125], train_loss:0.035977\n",
      "Epoch [1/10], Iter [2993/3125], train_loss:0.050263\n",
      "Epoch [1/10], Iter [2994/3125], train_loss:0.038603\n",
      "Epoch [1/10], Iter [2995/3125], train_loss:0.091508\n",
      "Epoch [1/10], Iter [2996/3125], train_loss:0.041844\n",
      "Epoch [1/10], Iter [2997/3125], train_loss:0.037022\n",
      "Epoch [1/10], Iter [2998/3125], train_loss:0.035034\n",
      "Epoch [1/10], Iter [2999/3125], train_loss:0.035311\n",
      "Epoch [1/10], Iter [3000/3125], train_loss:0.027116\n",
      "Epoch [1/10], Iter [3001/3125], train_loss:0.029279\n",
      "Epoch [1/10], Iter [3002/3125], train_loss:0.033700\n",
      "Epoch [1/10], Iter [3003/3125], train_loss:0.058413\n",
      "Epoch [1/10], Iter [3004/3125], train_loss:0.023097\n",
      "Epoch [1/10], Iter [3005/3125], train_loss:0.045443\n",
      "Epoch [1/10], Iter [3006/3125], train_loss:0.029848\n",
      "Epoch [1/10], Iter [3007/3125], train_loss:0.052713\n",
      "Epoch [1/10], Iter [3008/3125], train_loss:0.035926\n",
      "Epoch [1/10], Iter [3009/3125], train_loss:0.058838\n",
      "Epoch [1/10], Iter [3010/3125], train_loss:0.056548\n",
      "Epoch [1/10], Iter [3011/3125], train_loss:0.039738\n",
      "Epoch [1/10], Iter [3012/3125], train_loss:0.053625\n",
      "Epoch [1/10], Iter [3013/3125], train_loss:0.032034\n",
      "Epoch [1/10], Iter [3014/3125], train_loss:0.099142\n",
      "Epoch [1/10], Iter [3015/3125], train_loss:0.041366\n",
      "Epoch [1/10], Iter [3016/3125], train_loss:0.041256\n",
      "Epoch [1/10], Iter [3017/3125], train_loss:0.037890\n",
      "Epoch [1/10], Iter [3018/3125], train_loss:0.051505\n",
      "Epoch [1/10], Iter [3019/3125], train_loss:0.032262\n",
      "Epoch [1/10], Iter [3020/3125], train_loss:0.108767\n",
      "Epoch [1/10], Iter [3021/3125], train_loss:0.039950\n",
      "Epoch [1/10], Iter [3022/3125], train_loss:0.074630\n",
      "Epoch [1/10], Iter [3023/3125], train_loss:0.074800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Iter [3024/3125], train_loss:0.068196\n",
      "Epoch [1/10], Iter [3025/3125], train_loss:0.039287\n",
      "Epoch [1/10], Iter [3026/3125], train_loss:0.052125\n",
      "Epoch [1/10], Iter [3027/3125], train_loss:0.025400\n",
      "Epoch [1/10], Iter [3028/3125], train_loss:0.066438\n",
      "Epoch [1/10], Iter [3029/3125], train_loss:0.038479\n",
      "Epoch [1/10], Iter [3030/3125], train_loss:0.057109\n",
      "Epoch [1/10], Iter [3031/3125], train_loss:0.034795\n",
      "Epoch [1/10], Iter [3032/3125], train_loss:0.027901\n",
      "Epoch [1/10], Iter [3033/3125], train_loss:0.050128\n",
      "Epoch [1/10], Iter [3034/3125], train_loss:0.032854\n",
      "Epoch [1/10], Iter [3035/3125], train_loss:0.053708\n",
      "Epoch [1/10], Iter [3036/3125], train_loss:0.088014\n",
      "Epoch [1/10], Iter [3037/3125], train_loss:0.075370\n",
      "Epoch [1/10], Iter [3038/3125], train_loss:0.075677\n",
      "Epoch [1/10], Iter [3039/3125], train_loss:0.063172\n",
      "Epoch [1/10], Iter [3040/3125], train_loss:0.076501\n",
      "Epoch [1/10], Iter [3041/3125], train_loss:0.058156\n",
      "Epoch [1/10], Iter [3042/3125], train_loss:0.061623\n",
      "Epoch [1/10], Iter [3043/3125], train_loss:0.066724\n",
      "Epoch [1/10], Iter [3044/3125], train_loss:0.053383\n",
      "Epoch [1/10], Iter [3045/3125], train_loss:0.050633\n",
      "Epoch [1/10], Iter [3046/3125], train_loss:0.058951\n",
      "Epoch [1/10], Iter [3047/3125], train_loss:0.042557\n",
      "Epoch [1/10], Iter [3048/3125], train_loss:0.030441\n",
      "Epoch [1/10], Iter [3049/3125], train_loss:0.024813\n",
      "Epoch [1/10], Iter [3050/3125], train_loss:0.033426\n",
      "Epoch [1/10], Iter [3051/3125], train_loss:0.055847\n",
      "Epoch [1/10], Iter [3052/3125], train_loss:0.044011\n",
      "Epoch [1/10], Iter [3053/3125], train_loss:0.027693\n",
      "Epoch [1/10], Iter [3054/3125], train_loss:0.051109\n",
      "Epoch [1/10], Iter [3055/3125], train_loss:0.040254\n",
      "Epoch [1/10], Iter [3056/3125], train_loss:0.022783\n",
      "Epoch [1/10], Iter [3057/3125], train_loss:0.052132\n",
      "Epoch [1/10], Iter [3058/3125], train_loss:0.056355\n",
      "Epoch [1/10], Iter [3059/3125], train_loss:0.058088\n",
      "Epoch [1/10], Iter [3060/3125], train_loss:0.031884\n",
      "Epoch [1/10], Iter [3061/3125], train_loss:0.049938\n",
      "Epoch [1/10], Iter [3062/3125], train_loss:0.039419\n",
      "Epoch [1/10], Iter [3063/3125], train_loss:0.083298\n",
      "Epoch [1/10], Iter [3064/3125], train_loss:0.052872\n",
      "Epoch [1/10], Iter [3065/3125], train_loss:0.035879\n",
      "Epoch [1/10], Iter [3066/3125], train_loss:0.040194\n",
      "Epoch [1/10], Iter [3067/3125], train_loss:0.053528\n",
      "Epoch [1/10], Iter [3068/3125], train_loss:0.036000\n",
      "Epoch [1/10], Iter [3069/3125], train_loss:0.039297\n",
      "Epoch [1/10], Iter [3070/3125], train_loss:0.058124\n",
      "Epoch [1/10], Iter [3071/3125], train_loss:0.032619\n",
      "Epoch [1/10], Iter [3072/3125], train_loss:0.056250\n",
      "Epoch [1/10], Iter [3073/3125], train_loss:0.053652\n",
      "Epoch [1/10], Iter [3074/3125], train_loss:0.033999\n",
      "Epoch [1/10], Iter [3075/3125], train_loss:0.041154\n",
      "Epoch [1/10], Iter [3076/3125], train_loss:0.064491\n",
      "Epoch [1/10], Iter [3077/3125], train_loss:0.051499\n",
      "Epoch [1/10], Iter [3078/3125], train_loss:0.072850\n",
      "Epoch [1/10], Iter [3079/3125], train_loss:0.074374\n",
      "Epoch [1/10], Iter [3080/3125], train_loss:0.037571\n",
      "Epoch [1/10], Iter [3081/3125], train_loss:0.043772\n",
      "Epoch [1/10], Iter [3082/3125], train_loss:0.042835\n",
      "Epoch [1/10], Iter [3083/3125], train_loss:0.049374\n",
      "Epoch [1/10], Iter [3084/3125], train_loss:0.069075\n",
      "Epoch [1/10], Iter [3085/3125], train_loss:0.028113\n",
      "Epoch [1/10], Iter [3086/3125], train_loss:0.037884\n",
      "Epoch [1/10], Iter [3087/3125], train_loss:0.050082\n",
      "Epoch [1/10], Iter [3088/3125], train_loss:0.063452\n",
      "Epoch [1/10], Iter [3089/3125], train_loss:0.053441\n",
      "Epoch [1/10], Iter [3090/3125], train_loss:0.041038\n",
      "Epoch [1/10], Iter [3091/3125], train_loss:0.059465\n",
      "Epoch [1/10], Iter [3092/3125], train_loss:0.027648\n",
      "Epoch [1/10], Iter [3093/3125], train_loss:0.034605\n",
      "Epoch [1/10], Iter [3094/3125], train_loss:0.019859\n",
      "Epoch [1/10], Iter [3095/3125], train_loss:0.031989\n",
      "Epoch [1/10], Iter [3096/3125], train_loss:0.051489\n",
      "Epoch [1/10], Iter [3097/3125], train_loss:0.056322\n",
      "Epoch [1/10], Iter [3098/3125], train_loss:0.046863\n",
      "Epoch [1/10], Iter [3099/3125], train_loss:0.047653\n",
      "Epoch [1/10], Iter [3100/3125], train_loss:0.050260\n",
      "Epoch [1/10], Iter [3101/3125], train_loss:0.080984\n",
      "Epoch [1/10], Iter [3102/3125], train_loss:0.039387\n",
      "Epoch [1/10], Iter [3103/3125], train_loss:0.029410\n",
      "Epoch [1/10], Iter [3104/3125], train_loss:0.038941\n",
      "Epoch [1/10], Iter [3105/3125], train_loss:0.043713\n",
      "Epoch [1/10], Iter [3106/3125], train_loss:0.037539\n",
      "Epoch [1/10], Iter [3107/3125], train_loss:0.025358\n",
      "Epoch [1/10], Iter [3108/3125], train_loss:0.071836\n",
      "Epoch [1/10], Iter [3109/3125], train_loss:0.056706\n",
      "Epoch [1/10], Iter [3110/3125], train_loss:0.033099\n",
      "Epoch [1/10], Iter [3111/3125], train_loss:0.037032\n",
      "Epoch [1/10], Iter [3112/3125], train_loss:0.038965\n",
      "Epoch [1/10], Iter [3113/3125], train_loss:0.041378\n",
      "Epoch [1/10], Iter [3114/3125], train_loss:0.049832\n",
      "Epoch [1/10], Iter [3115/3125], train_loss:0.044040\n",
      "Epoch [1/10], Iter [3116/3125], train_loss:0.029385\n",
      "Epoch [1/10], Iter [3117/3125], train_loss:0.059979\n",
      "Epoch [1/10], Iter [3118/3125], train_loss:0.067147\n",
      "Epoch [1/10], Iter [3119/3125], train_loss:0.057981\n",
      "Epoch [1/10], Iter [3120/3125], train_loss:0.028045\n",
      "Epoch [1/10], Iter [3121/3125], train_loss:0.042211\n",
      "Epoch [1/10], Iter [3122/3125], train_loss:0.056431\n",
      "Epoch [1/10], Iter [3123/3125], train_loss:0.044317\n",
      "Epoch [1/10], Iter [3124/3125], train_loss:0.054007\n",
      "Epoch [1/10], Iter [3125/3125], train_loss:0.042914\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14844/2960384600.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mtest_total_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mtest_total_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "#训练&验证\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# 损失函数：自定义损失函数\n",
    "criterion = MyLoss()\n",
    "# 优化器\n",
    "optimizer = torch.optim.Adam(Resnet50.parameters(), lr=lr)\n",
    "epoch = max_epochs\n",
    "Resnet50 = Resnet50.to(device)\n",
    "total_step = len(train_loader)\n",
    "train_all_loss = []\n",
    "test_all_loss = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    Resnet50.train()\n",
    "    train_total_loss = 0\n",
    "    train_total_num = 0\n",
    "    train_total_correct = 0\n",
    "\n",
    "    for iter, (images,labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = Resnet50(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        train_total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        \n",
    "        #backword\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_total_num += labels.shape[0]\n",
    "        train_total_loss += loss.item()\n",
    "        print(\"Epoch [{}/{}], Iter [{}/{}], train_loss:{:4f}\".format(i+1,epoch,iter+1,total_step,loss.item()/labels.shape[0]))\n",
    "    \n",
    "    Resnet50.eval()\n",
    "    test_total_loss = 0\n",
    "    test_total_correct = 0\n",
    "    test_total_num = 0\n",
    "    for iter,(images,labels) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = Resnet50(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        test_total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        test_total_loss += loss.item()\n",
    "        test_total_num += labels.shape[0]\n",
    "    print(\"Epoch [{}/{}], train_loss:{:.4f}, train_acc:{:.4f}%, test_loss:{:.4f}, test_acc:{:.4f}%\".format(\n",
    "        i+1, epoch, train_total_loss / train_total_num, train_total_correct / train_total_num * 100, test_total_loss / test_total_num, test_total_correct / test_total_num * 100\n",
    "    \n",
    "    ))\n",
    "    train_all_loss.append(np.round(train_total_loss / train_total_num,4))\n",
    "    test_all_loss.append(np.round(test_total_loss / test_total_num,4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757cdce7",
   "metadata": {},
   "source": [
    "### 2、动态调整学习率\n",
    "#### 2.1 torch.optim.lr_scheduler\n",
    "学习率选择的问题：\n",
    "- 1、学习率设置过小，会极大降低收敛速度，增加训练时间\n",
    "- 2、学习率设置太大，可能导致参数在最优解两侧来回振荡\n",
    "\n",
    "以上问题都是学习率设置不满足模型训练的需求，解决方案：\n",
    "- PyTorch中提供了scheduler\n",
    "\n",
    "官方API提供的torch.optim.lr_scheduler动态学习率：\n",
    "- [lr_scheduler.LambdaLR](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.LambdaLR.html#torch.optim.lr_scheduler.LambdaLR)\n",
    "\n",
    "- [lr_scheduler.MultiplicativeLR](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.MultiplicativeLR.html#torch.optim.lr_scheduler.MultiplicativeLR)\n",
    "\n",
    "- [lr_scheduler.StepLR](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html#torch.optim.lr_scheduler.StepLR)\n",
    "\n",
    "- [lr_scheduler.MultiStepLR](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.MultiStepLR.html#torch.optim.lr_scheduler.MultiStepLR)\n",
    "\n",
    "- lr_scheduler.ExponentialLR\n",
    "\n",
    "- lr_scheduler.CosineAnnealingLR\n",
    "\n",
    "- lr_scheduler.ReduceLROnPlateau\n",
    "\n",
    "- lr_scheduler.CyclicLR\n",
    "\n",
    "- lr_scheduler.OneCycleLR\n",
    "\n",
    "- lr_scheduler.CosineAnnealingWarmRestarts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde47b88",
   "metadata": {},
   "source": [
    "#### 2.2、torch.optim.lr_scheduler.LambdaLR\n",
    "\n",
    "torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=- 1, verbose=False)\n",
    "\n",
    "```python\n",
    "# LambdaLR 实现\n",
    "lr_lambda = f(epoch)\n",
    "new_lr = lr_lambda * init_lr\n",
    "```\n",
    "\n",
    "思想:初始学习率乘以系数，由于每一次乘系数都是乘初始学习率，因此系数往往是epoch的函数。\n",
    "\n",
    "```python\n",
    "#伪代码：Assuming optimizer has two groups.\n",
    "    \n",
    "    \n",
    "lambda1 = lambda epoch: 1 / (epoch+1)\n",
    "    \n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lambda1)\n",
    "    \n",
    "for epoch in range(100):\n",
    "    \n",
    "    train(...)\n",
    "    \n",
    "    validate(...)\n",
    "    \n",
    "    scheduler.step()\n",
    "```\n"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "a76b27c0",
   "metadata": {},
   "source": [
    "![image-2.png](attachment:image-2.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "222ff8b7",
   "metadata": {},
   "source": [
    "#### MultiplicativeLR\n",
    "torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda, last_epoch=- 1, verbose=False)\n",
    "\n",
    "与LambdaLR不同，该方法用前一次的学习率乘以lr_lambda,因此通常lr_lambda函数不需要与epoch有关。\n",
    "\n",
    "```python\n",
    "new_lr = lr_lambda * old_lr\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "6418c6ce",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f3822",
   "metadata": {},
   "source": [
    "#### 2.2、自定义scheduler\n",
    "官方给的动态学习率调整的API如果均不能满足我们的诉求，应该怎么办？\n",
    "\n",
    "##### 我们可以通过自定义函数adjust_learning_rate来改变param_group中lr的值\n",
    "\n",
    "- 1、官方的API均不能满足诉求\n",
    "- 2、我们根据adjust_learning_rate实现学习率调整方法\n",
    "\n",
    "```python\n",
    "# 训练中调用学习率方法\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = args.lr,momentum = 0.9)\n",
    "for epoch in range(10):\n",
    "    train(...)\n",
    "    validate(...)\n",
    "    adjust_learning_rate(optimizer,epoch)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "187ddaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#函数：分段，每隔几(10)段个epoch,第一个epoch为序号0不计，使学习率变乘以0.1的epoch次方数\n",
    "def adjust_learning_rate(optim, epoch, size=10, gamma=0.1):\n",
    "    if (epoch + 1) % size == 0:\n",
    "        pow = (epoch + 1) // size\n",
    "        lr = learning_rate * np.power(gamma, pow)\n",
    "        for param_group in optim.param_groups:\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f9fc5c",
   "metadata": {},
   "source": [
    "#### 代码实例\n",
    "- lr_scheduler.LambdaLR\n",
    "- adjust_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d60cfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "初始化的学习率： 0.0001\n",
      "Epoch [1/2], Iter [1/3125], train_loss:0.777986\n",
      "Epoch [1/2], Iter [2/3125], train_loss:0.662992\n",
      "Epoch [1/2], Iter [3/3125], train_loss:0.767887\n",
      "Epoch [1/2], Iter [4/3125], train_loss:0.748286\n",
      "Epoch [1/2], Iter [5/3125], train_loss:0.686887\n",
      "Epoch [1/2], Iter [6/3125], train_loss:0.675070\n",
      "Epoch [1/2], Iter [7/3125], train_loss:0.655532\n",
      "Epoch [1/2], Iter [8/3125], train_loss:0.713970\n",
      "Epoch [1/2], Iter [9/3125], train_loss:0.675706\n",
      "Epoch [1/2], Iter [10/3125], train_loss:0.665308\n",
      "Epoch [1/2], Iter [11/3125], train_loss:0.670263\n",
      "Epoch [1/2], Iter [12/3125], train_loss:0.597091\n",
      "Epoch [1/2], Iter [13/3125], train_loss:0.541138\n",
      "Epoch [1/2], Iter [14/3125], train_loss:0.471112\n",
      "Epoch [1/2], Iter [15/3125], train_loss:0.570017\n",
      "Epoch [1/2], Iter [16/3125], train_loss:0.569556\n",
      "Epoch [1/2], Iter [17/3125], train_loss:0.552114\n",
      "Epoch [1/2], Iter [18/3125], train_loss:0.569929\n",
      "Epoch [1/2], Iter [19/3125], train_loss:0.524716\n",
      "Epoch [1/2], Iter [20/3125], train_loss:0.522762\n",
      "Epoch [1/2], Iter [21/3125], train_loss:0.499370\n",
      "Epoch [1/2], Iter [22/3125], train_loss:0.459812\n",
      "Epoch [1/2], Iter [23/3125], train_loss:0.407852\n",
      "Epoch [1/2], Iter [24/3125], train_loss:0.472173\n",
      "Epoch [1/2], Iter [25/3125], train_loss:0.370801\n",
      "Epoch [1/2], Iter [26/3125], train_loss:0.459706\n",
      "Epoch [1/2], Iter [27/3125], train_loss:0.403983\n",
      "Epoch [1/2], Iter [28/3125], train_loss:0.372209\n",
      "Epoch [1/2], Iter [29/3125], train_loss:0.357835\n",
      "Epoch [1/2], Iter [30/3125], train_loss:0.501332\n",
      "Epoch [1/2], Iter [31/3125], train_loss:0.354409\n",
      "Epoch [1/2], Iter [32/3125], train_loss:0.352994\n",
      "Epoch [1/2], Iter [33/3125], train_loss:0.359231\n",
      "Epoch [1/2], Iter [34/3125], train_loss:0.378708\n",
      "Epoch [1/2], Iter [35/3125], train_loss:0.445062\n",
      "Epoch [1/2], Iter [36/3125], train_loss:0.345325\n",
      "Epoch [1/2], Iter [37/3125], train_loss:0.290598\n",
      "Epoch [1/2], Iter [38/3125], train_loss:0.355161\n",
      "Epoch [1/2], Iter [39/3125], train_loss:0.295590\n",
      "Epoch [1/2], Iter [40/3125], train_loss:0.269099\n",
      "Epoch [1/2], Iter [41/3125], train_loss:0.339802\n",
      "Epoch [1/2], Iter [42/3125], train_loss:0.251694\n",
      "Epoch [1/2], Iter [43/3125], train_loss:0.328401\n",
      "Epoch [1/2], Iter [44/3125], train_loss:0.257955\n",
      "Epoch [1/2], Iter [45/3125], train_loss:0.325558\n",
      "Epoch [1/2], Iter [46/3125], train_loss:0.342137\n",
      "Epoch [1/2], Iter [47/3125], train_loss:0.259149\n",
      "Epoch [1/2], Iter [48/3125], train_loss:0.249372\n",
      "Epoch [1/2], Iter [49/3125], train_loss:0.257600\n",
      "Epoch [1/2], Iter [50/3125], train_loss:0.289483\n",
      "Epoch [1/2], Iter [51/3125], train_loss:0.301230\n",
      "Epoch [1/2], Iter [52/3125], train_loss:0.217237\n",
      "Epoch [1/2], Iter [53/3125], train_loss:0.279841\n",
      "Epoch [1/2], Iter [54/3125], train_loss:0.261875\n",
      "Epoch [1/2], Iter [55/3125], train_loss:0.216530\n",
      "Epoch [1/2], Iter [56/3125], train_loss:0.279174\n",
      "Epoch [1/2], Iter [57/3125], train_loss:0.188948\n",
      "Epoch [1/2], Iter [58/3125], train_loss:0.207412\n",
      "Epoch [1/2], Iter [59/3125], train_loss:0.239609\n",
      "Epoch [1/2], Iter [60/3125], train_loss:0.195655\n",
      "Epoch [1/2], Iter [61/3125], train_loss:0.196358\n",
      "Epoch [1/2], Iter [62/3125], train_loss:0.264320\n",
      "Epoch [1/2], Iter [63/3125], train_loss:0.193350\n",
      "Epoch [1/2], Iter [64/3125], train_loss:0.165940\n",
      "Epoch [1/2], Iter [65/3125], train_loss:0.267849\n",
      "Epoch [1/2], Iter [66/3125], train_loss:0.221301\n",
      "Epoch [1/2], Iter [67/3125], train_loss:0.269790\n",
      "Epoch [1/2], Iter [68/3125], train_loss:0.227033\n",
      "Epoch [1/2], Iter [69/3125], train_loss:0.156358\n",
      "Epoch [1/2], Iter [70/3125], train_loss:0.210391\n",
      "Epoch [1/2], Iter [71/3125], train_loss:0.251990\n",
      "Epoch [1/2], Iter [72/3125], train_loss:0.177134\n",
      "Epoch [1/2], Iter [73/3125], train_loss:0.155195\n",
      "Epoch [1/2], Iter [74/3125], train_loss:0.251515\n",
      "Epoch [1/2], Iter [75/3125], train_loss:0.159152\n",
      "Epoch [1/2], Iter [76/3125], train_loss:0.166255\n",
      "Epoch [1/2], Iter [77/3125], train_loss:0.115882\n",
      "Epoch [1/2], Iter [78/3125], train_loss:0.175745\n",
      "Epoch [1/2], Iter [79/3125], train_loss:0.138844\n",
      "Epoch [1/2], Iter [80/3125], train_loss:0.176611\n",
      "Epoch [1/2], Iter [81/3125], train_loss:0.161312\n",
      "Epoch [1/2], Iter [82/3125], train_loss:0.148712\n",
      "Epoch [1/2], Iter [83/3125], train_loss:0.207151\n",
      "Epoch [1/2], Iter [84/3125], train_loss:0.111603\n",
      "Epoch [1/2], Iter [85/3125], train_loss:0.107699\n",
      "Epoch [1/2], Iter [86/3125], train_loss:0.162084\n",
      "Epoch [1/2], Iter [87/3125], train_loss:0.199193\n",
      "Epoch [1/2], Iter [88/3125], train_loss:0.138881\n",
      "Epoch [1/2], Iter [89/3125], train_loss:0.161221\n",
      "Epoch [1/2], Iter [90/3125], train_loss:0.149200\n",
      "Epoch [1/2], Iter [91/3125], train_loss:0.151864\n",
      "Epoch [1/2], Iter [92/3125], train_loss:0.201360\n",
      "Epoch [1/2], Iter [93/3125], train_loss:0.169258\n",
      "Epoch [1/2], Iter [94/3125], train_loss:0.149062\n",
      "Epoch [1/2], Iter [95/3125], train_loss:0.149584\n",
      "Epoch [1/2], Iter [96/3125], train_loss:0.145563\n",
      "Epoch [1/2], Iter [97/3125], train_loss:0.126489\n",
      "Epoch [1/2], Iter [98/3125], train_loss:0.139146\n",
      "Epoch [1/2], Iter [99/3125], train_loss:0.138828\n",
      "Epoch [1/2], Iter [100/3125], train_loss:0.133510\n",
      "Epoch [1/2], Iter [101/3125], train_loss:0.137596\n",
      "Epoch [1/2], Iter [102/3125], train_loss:0.130815\n",
      "Epoch [1/2], Iter [103/3125], train_loss:0.156223\n",
      "Epoch [1/2], Iter [104/3125], train_loss:0.101501\n",
      "Epoch [1/2], Iter [105/3125], train_loss:0.119640\n",
      "Epoch [1/2], Iter [106/3125], train_loss:0.145987\n",
      "Epoch [1/2], Iter [107/3125], train_loss:0.182159\n",
      "Epoch [1/2], Iter [108/3125], train_loss:0.134178\n",
      "Epoch [1/2], Iter [109/3125], train_loss:0.125466\n",
      "Epoch [1/2], Iter [110/3125], train_loss:0.136854\n",
      "Epoch [1/2], Iter [111/3125], train_loss:0.114577\n",
      "Epoch [1/2], Iter [112/3125], train_loss:0.176352\n",
      "Epoch [1/2], Iter [113/3125], train_loss:0.114336\n",
      "Epoch [1/2], Iter [114/3125], train_loss:0.132073\n",
      "Epoch [1/2], Iter [115/3125], train_loss:0.132009\n",
      "Epoch [1/2], Iter [116/3125], train_loss:0.138485\n",
      "Epoch [1/2], Iter [117/3125], train_loss:0.131889\n",
      "Epoch [1/2], Iter [118/3125], train_loss:0.127713\n",
      "Epoch [1/2], Iter [119/3125], train_loss:0.136108\n",
      "Epoch [1/2], Iter [120/3125], train_loss:0.099374\n",
      "Epoch [1/2], Iter [121/3125], train_loss:0.177180\n",
      "Epoch [1/2], Iter [122/3125], train_loss:0.133789\n",
      "Epoch [1/2], Iter [123/3125], train_loss:0.108010\n",
      "Epoch [1/2], Iter [124/3125], train_loss:0.124499\n",
      "Epoch [1/2], Iter [125/3125], train_loss:0.145130\n",
      "Epoch [1/2], Iter [126/3125], train_loss:0.139046\n",
      "Epoch [1/2], Iter [127/3125], train_loss:0.162694\n",
      "Epoch [1/2], Iter [128/3125], train_loss:0.106318\n",
      "Epoch [1/2], Iter [129/3125], train_loss:0.136911\n",
      "Epoch [1/2], Iter [130/3125], train_loss:0.161438\n",
      "Epoch [1/2], Iter [131/3125], train_loss:0.116436\n",
      "Epoch [1/2], Iter [132/3125], train_loss:0.145941\n",
      "Epoch [1/2], Iter [133/3125], train_loss:0.114138\n",
      "Epoch [1/2], Iter [134/3125], train_loss:0.167708\n",
      "Epoch [1/2], Iter [135/3125], train_loss:0.137426\n",
      "Epoch [1/2], Iter [136/3125], train_loss:0.181821\n",
      "Epoch [1/2], Iter [137/3125], train_loss:0.126747\n",
      "Epoch [1/2], Iter [138/3125], train_loss:0.161444\n",
      "Epoch [1/2], Iter [139/3125], train_loss:0.137294\n",
      "Epoch [1/2], Iter [140/3125], train_loss:0.140909\n",
      "Epoch [1/2], Iter [141/3125], train_loss:0.127225\n",
      "Epoch [1/2], Iter [142/3125], train_loss:0.086217\n",
      "Epoch [1/2], Iter [143/3125], train_loss:0.125356\n",
      "Epoch [1/2], Iter [144/3125], train_loss:0.152855\n",
      "Epoch [1/2], Iter [145/3125], train_loss:0.182545\n",
      "Epoch [1/2], Iter [146/3125], train_loss:0.076299\n",
      "Epoch [1/2], Iter [147/3125], train_loss:0.154243\n",
      "Epoch [1/2], Iter [148/3125], train_loss:0.101580\n",
      "Epoch [1/2], Iter [149/3125], train_loss:0.136949\n",
      "Epoch [1/2], Iter [150/3125], train_loss:0.137361\n",
      "Epoch [1/2], Iter [151/3125], train_loss:0.119204\n",
      "Epoch [1/2], Iter [152/3125], train_loss:0.126940\n",
      "Epoch [1/2], Iter [153/3125], train_loss:0.127168\n",
      "Epoch [1/2], Iter [154/3125], train_loss:0.132602\n",
      "Epoch [1/2], Iter [155/3125], train_loss:0.112731\n",
      "Epoch [1/2], Iter [156/3125], train_loss:0.128222\n",
      "Epoch [1/2], Iter [157/3125], train_loss:0.112968\n",
      "Epoch [1/2], Iter [158/3125], train_loss:0.106631\n",
      "Epoch [1/2], Iter [159/3125], train_loss:0.131883\n",
      "Epoch [1/2], Iter [160/3125], train_loss:0.105249\n",
      "Epoch [1/2], Iter [161/3125], train_loss:0.148656\n",
      "Epoch [1/2], Iter [162/3125], train_loss:0.115082\n",
      "Epoch [1/2], Iter [163/3125], train_loss:0.099327\n",
      "Epoch [1/2], Iter [164/3125], train_loss:0.131512\n",
      "Epoch [1/2], Iter [165/3125], train_loss:0.121838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [166/3125], train_loss:0.122599\n",
      "Epoch [1/2], Iter [167/3125], train_loss:0.108223\n",
      "Epoch [1/2], Iter [168/3125], train_loss:0.157398\n",
      "Epoch [1/2], Iter [169/3125], train_loss:0.112632\n",
      "Epoch [1/2], Iter [170/3125], train_loss:0.092063\n",
      "Epoch [1/2], Iter [171/3125], train_loss:0.092099\n",
      "Epoch [1/2], Iter [172/3125], train_loss:0.143247\n",
      "Epoch [1/2], Iter [173/3125], train_loss:0.107952\n",
      "Epoch [1/2], Iter [174/3125], train_loss:0.150982\n",
      "Epoch [1/2], Iter [175/3125], train_loss:0.154513\n",
      "Epoch [1/2], Iter [176/3125], train_loss:0.122460\n",
      "Epoch [1/2], Iter [177/3125], train_loss:0.130054\n",
      "Epoch [1/2], Iter [178/3125], train_loss:0.075364\n",
      "Epoch [1/2], Iter [179/3125], train_loss:0.092844\n",
      "Epoch [1/2], Iter [180/3125], train_loss:0.131176\n",
      "Epoch [1/2], Iter [181/3125], train_loss:0.089559\n",
      "Epoch [1/2], Iter [182/3125], train_loss:0.137490\n",
      "Epoch [1/2], Iter [183/3125], train_loss:0.148960\n",
      "Epoch [1/2], Iter [184/3125], train_loss:0.088713\n",
      "Epoch [1/2], Iter [185/3125], train_loss:0.098040\n",
      "Epoch [1/2], Iter [186/3125], train_loss:0.159430\n",
      "Epoch [1/2], Iter [187/3125], train_loss:0.091044\n",
      "Epoch [1/2], Iter [188/3125], train_loss:0.108532\n",
      "Epoch [1/2], Iter [189/3125], train_loss:0.089453\n",
      "Epoch [1/2], Iter [190/3125], train_loss:0.112841\n",
      "Epoch [1/2], Iter [191/3125], train_loss:0.150818\n",
      "Epoch [1/2], Iter [192/3125], train_loss:0.112883\n",
      "Epoch [1/2], Iter [193/3125], train_loss:0.124884\n",
      "Epoch [1/2], Iter [194/3125], train_loss:0.107502\n",
      "Epoch [1/2], Iter [195/3125], train_loss:0.099678\n",
      "Epoch [1/2], Iter [196/3125], train_loss:0.183032\n",
      "Epoch [1/2], Iter [197/3125], train_loss:0.111150\n",
      "Epoch [1/2], Iter [198/3125], train_loss:0.136155\n",
      "Epoch [1/2], Iter [199/3125], train_loss:0.113451\n",
      "Epoch [1/2], Iter [200/3125], train_loss:0.144825\n",
      "Epoch [1/2], Iter [201/3125], train_loss:0.133655\n",
      "Epoch [1/2], Iter [202/3125], train_loss:0.111885\n",
      "Epoch [1/2], Iter [203/3125], train_loss:0.111356\n",
      "Epoch [1/2], Iter [204/3125], train_loss:0.107932\n",
      "Epoch [1/2], Iter [205/3125], train_loss:0.143930\n",
      "Epoch [1/2], Iter [206/3125], train_loss:0.097970\n",
      "Epoch [1/2], Iter [207/3125], train_loss:0.088761\n",
      "Epoch [1/2], Iter [208/3125], train_loss:0.131987\n",
      "Epoch [1/2], Iter [209/3125], train_loss:0.135780\n",
      "Epoch [1/2], Iter [210/3125], train_loss:0.096630\n",
      "Epoch [1/2], Iter [211/3125], train_loss:0.128221\n",
      "Epoch [1/2], Iter [212/3125], train_loss:0.155038\n",
      "Epoch [1/2], Iter [213/3125], train_loss:0.099105\n",
      "Epoch [1/2], Iter [214/3125], train_loss:0.111038\n",
      "Epoch [1/2], Iter [215/3125], train_loss:0.142604\n",
      "Epoch [1/2], Iter [216/3125], train_loss:0.145580\n",
      "Epoch [1/2], Iter [217/3125], train_loss:0.111073\n",
      "Epoch [1/2], Iter [218/3125], train_loss:0.128455\n",
      "Epoch [1/2], Iter [219/3125], train_loss:0.096221\n",
      "Epoch [1/2], Iter [220/3125], train_loss:0.086480\n",
      "Epoch [1/2], Iter [221/3125], train_loss:0.115596\n",
      "Epoch [1/2], Iter [222/3125], train_loss:0.093819\n",
      "Epoch [1/2], Iter [223/3125], train_loss:0.068540\n",
      "Epoch [1/2], Iter [224/3125], train_loss:0.105397\n",
      "Epoch [1/2], Iter [225/3125], train_loss:0.081237\n",
      "Epoch [1/2], Iter [226/3125], train_loss:0.127183\n",
      "Epoch [1/2], Iter [227/3125], train_loss:0.133673\n",
      "Epoch [1/2], Iter [228/3125], train_loss:0.102121\n",
      "Epoch [1/2], Iter [229/3125], train_loss:0.124757\n",
      "Epoch [1/2], Iter [230/3125], train_loss:0.124150\n",
      "Epoch [1/2], Iter [231/3125], train_loss:0.109962\n",
      "Epoch [1/2], Iter [232/3125], train_loss:0.121613\n",
      "Epoch [1/2], Iter [233/3125], train_loss:0.122472\n",
      "Epoch [1/2], Iter [234/3125], train_loss:0.093679\n",
      "Epoch [1/2], Iter [235/3125], train_loss:0.104721\n",
      "Epoch [1/2], Iter [236/3125], train_loss:0.102781\n",
      "Epoch [1/2], Iter [237/3125], train_loss:0.093572\n",
      "Epoch [1/2], Iter [238/3125], train_loss:0.094514\n",
      "Epoch [1/2], Iter [239/3125], train_loss:0.099495\n",
      "Epoch [1/2], Iter [240/3125], train_loss:0.106375\n",
      "Epoch [1/2], Iter [241/3125], train_loss:0.111261\n",
      "Epoch [1/2], Iter [242/3125], train_loss:0.089024\n",
      "Epoch [1/2], Iter [243/3125], train_loss:0.107102\n",
      "Epoch [1/2], Iter [244/3125], train_loss:0.098898\n",
      "Epoch [1/2], Iter [245/3125], train_loss:0.105752\n",
      "Epoch [1/2], Iter [246/3125], train_loss:0.098761\n",
      "Epoch [1/2], Iter [247/3125], train_loss:0.110852\n",
      "Epoch [1/2], Iter [248/3125], train_loss:0.110072\n",
      "Epoch [1/2], Iter [249/3125], train_loss:0.106461\n",
      "Epoch [1/2], Iter [250/3125], train_loss:0.123407\n",
      "Epoch [1/2], Iter [251/3125], train_loss:0.092958\n",
      "Epoch [1/2], Iter [252/3125], train_loss:0.111045\n",
      "Epoch [1/2], Iter [253/3125], train_loss:0.129692\n",
      "Epoch [1/2], Iter [254/3125], train_loss:0.096450\n",
      "Epoch [1/2], Iter [255/3125], train_loss:0.084925\n",
      "Epoch [1/2], Iter [256/3125], train_loss:0.141627\n",
      "Epoch [1/2], Iter [257/3125], train_loss:0.088181\n",
      "Epoch [1/2], Iter [258/3125], train_loss:0.110038\n",
      "Epoch [1/2], Iter [259/3125], train_loss:0.132803\n",
      "Epoch [1/2], Iter [260/3125], train_loss:0.098667\n",
      "Epoch [1/2], Iter [261/3125], train_loss:0.085513\n",
      "Epoch [1/2], Iter [262/3125], train_loss:0.121055\n",
      "Epoch [1/2], Iter [263/3125], train_loss:0.099879\n",
      "Epoch [1/2], Iter [264/3125], train_loss:0.149433\n",
      "Epoch [1/2], Iter [265/3125], train_loss:0.116061\n",
      "Epoch [1/2], Iter [266/3125], train_loss:0.090697\n",
      "Epoch [1/2], Iter [267/3125], train_loss:0.087413\n",
      "Epoch [1/2], Iter [268/3125], train_loss:0.146219\n",
      "Epoch [1/2], Iter [269/3125], train_loss:0.097796\n",
      "Epoch [1/2], Iter [270/3125], train_loss:0.088155\n",
      "Epoch [1/2], Iter [271/3125], train_loss:0.107575\n",
      "Epoch [1/2], Iter [272/3125], train_loss:0.101357\n",
      "Epoch [1/2], Iter [273/3125], train_loss:0.090542\n",
      "Epoch [1/2], Iter [274/3125], train_loss:0.092936\n",
      "Epoch [1/2], Iter [275/3125], train_loss:0.107296\n",
      "Epoch [1/2], Iter [276/3125], train_loss:0.078067\n",
      "Epoch [1/2], Iter [277/3125], train_loss:0.099335\n",
      "Epoch [1/2], Iter [278/3125], train_loss:0.118054\n",
      "Epoch [1/2], Iter [279/3125], train_loss:0.098823\n",
      "Epoch [1/2], Iter [280/3125], train_loss:0.100404\n",
      "Epoch [1/2], Iter [281/3125], train_loss:0.116890\n",
      "Epoch [1/2], Iter [282/3125], train_loss:0.083836\n",
      "Epoch [1/2], Iter [283/3125], train_loss:0.134695\n",
      "Epoch [1/2], Iter [284/3125], train_loss:0.092292\n",
      "Epoch [1/2], Iter [285/3125], train_loss:0.089188\n",
      "Epoch [1/2], Iter [286/3125], train_loss:0.103081\n",
      "Epoch [1/2], Iter [287/3125], train_loss:0.127043\n",
      "Epoch [1/2], Iter [288/3125], train_loss:0.116650\n",
      "Epoch [1/2], Iter [289/3125], train_loss:0.121881\n",
      "Epoch [1/2], Iter [290/3125], train_loss:0.186911\n",
      "Epoch [1/2], Iter [291/3125], train_loss:0.126078\n",
      "Epoch [1/2], Iter [292/3125], train_loss:0.091569\n",
      "Epoch [1/2], Iter [293/3125], train_loss:0.079495\n",
      "Epoch [1/2], Iter [294/3125], train_loss:0.099240\n",
      "Epoch [1/2], Iter [295/3125], train_loss:0.118772\n",
      "Epoch [1/2], Iter [296/3125], train_loss:0.093694\n",
      "Epoch [1/2], Iter [297/3125], train_loss:0.108655\n",
      "Epoch [1/2], Iter [298/3125], train_loss:0.095032\n",
      "Epoch [1/2], Iter [299/3125], train_loss:0.111288\n",
      "Epoch [1/2], Iter [300/3125], train_loss:0.098187\n",
      "Epoch [1/2], Iter [301/3125], train_loss:0.097793\n",
      "Epoch [1/2], Iter [302/3125], train_loss:0.096069\n",
      "Epoch [1/2], Iter [303/3125], train_loss:0.098303\n",
      "Epoch [1/2], Iter [304/3125], train_loss:0.053307\n",
      "Epoch [1/2], Iter [305/3125], train_loss:0.089034\n",
      "Epoch [1/2], Iter [306/3125], train_loss:0.079592\n",
      "Epoch [1/2], Iter [307/3125], train_loss:0.127933\n",
      "Epoch [1/2], Iter [308/3125], train_loss:0.098109\n",
      "Epoch [1/2], Iter [309/3125], train_loss:0.064728\n",
      "Epoch [1/2], Iter [310/3125], train_loss:0.173963\n",
      "Epoch [1/2], Iter [311/3125], train_loss:0.076444\n",
      "Epoch [1/2], Iter [312/3125], train_loss:0.104166\n",
      "Epoch [1/2], Iter [313/3125], train_loss:0.098701\n",
      "Epoch [1/2], Iter [314/3125], train_loss:0.080666\n",
      "Epoch [1/2], Iter [315/3125], train_loss:0.114130\n",
      "Epoch [1/2], Iter [316/3125], train_loss:0.077030\n",
      "Epoch [1/2], Iter [317/3125], train_loss:0.118316\n",
      "Epoch [1/2], Iter [318/3125], train_loss:0.057820\n",
      "Epoch [1/2], Iter [319/3125], train_loss:0.126976\n",
      "Epoch [1/2], Iter [320/3125], train_loss:0.071933\n",
      "Epoch [1/2], Iter [321/3125], train_loss:0.090767\n",
      "Epoch [1/2], Iter [322/3125], train_loss:0.090457\n",
      "Epoch [1/2], Iter [323/3125], train_loss:0.105079\n",
      "Epoch [1/2], Iter [324/3125], train_loss:0.101791\n",
      "Epoch [1/2], Iter [325/3125], train_loss:0.106632\n",
      "Epoch [1/2], Iter [326/3125], train_loss:0.087738\n",
      "Epoch [1/2], Iter [327/3125], train_loss:0.082531\n",
      "Epoch [1/2], Iter [328/3125], train_loss:0.123027\n",
      "Epoch [1/2], Iter [329/3125], train_loss:0.089840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [330/3125], train_loss:0.123866\n",
      "Epoch [1/2], Iter [331/3125], train_loss:0.139623\n",
      "Epoch [1/2], Iter [332/3125], train_loss:0.097267\n",
      "Epoch [1/2], Iter [333/3125], train_loss:0.087837\n",
      "Epoch [1/2], Iter [334/3125], train_loss:0.079422\n",
      "Epoch [1/2], Iter [335/3125], train_loss:0.085209\n",
      "Epoch [1/2], Iter [336/3125], train_loss:0.147867\n",
      "Epoch [1/2], Iter [337/3125], train_loss:0.149562\n",
      "Epoch [1/2], Iter [338/3125], train_loss:0.107306\n",
      "Epoch [1/2], Iter [339/3125], train_loss:0.114367\n",
      "Epoch [1/2], Iter [340/3125], train_loss:0.075745\n",
      "Epoch [1/2], Iter [341/3125], train_loss:0.081646\n",
      "Epoch [1/2], Iter [342/3125], train_loss:0.114543\n",
      "Epoch [1/2], Iter [343/3125], train_loss:0.107771\n",
      "Epoch [1/2], Iter [344/3125], train_loss:0.091723\n",
      "Epoch [1/2], Iter [345/3125], train_loss:0.085628\n",
      "Epoch [1/2], Iter [346/3125], train_loss:0.069710\n",
      "Epoch [1/2], Iter [347/3125], train_loss:0.080913\n",
      "Epoch [1/2], Iter [348/3125], train_loss:0.078024\n",
      "Epoch [1/2], Iter [349/3125], train_loss:0.132719\n",
      "Epoch [1/2], Iter [350/3125], train_loss:0.119744\n",
      "Epoch [1/2], Iter [351/3125], train_loss:0.116647\n",
      "Epoch [1/2], Iter [352/3125], train_loss:0.109735\n",
      "Epoch [1/2], Iter [353/3125], train_loss:0.081496\n",
      "Epoch [1/2], Iter [354/3125], train_loss:0.073368\n",
      "Epoch [1/2], Iter [355/3125], train_loss:0.111581\n",
      "Epoch [1/2], Iter [356/3125], train_loss:0.075484\n",
      "Epoch [1/2], Iter [357/3125], train_loss:0.072975\n",
      "Epoch [1/2], Iter [358/3125], train_loss:0.062364\n",
      "Epoch [1/2], Iter [359/3125], train_loss:0.076667\n",
      "Epoch [1/2], Iter [360/3125], train_loss:0.080340\n",
      "Epoch [1/2], Iter [361/3125], train_loss:0.063418\n",
      "Epoch [1/2], Iter [362/3125], train_loss:0.061630\n",
      "Epoch [1/2], Iter [363/3125], train_loss:0.062767\n",
      "Epoch [1/2], Iter [364/3125], train_loss:0.084588\n",
      "Epoch [1/2], Iter [365/3125], train_loss:0.105539\n",
      "Epoch [1/2], Iter [366/3125], train_loss:0.071236\n",
      "Epoch [1/2], Iter [367/3125], train_loss:0.087279\n",
      "Epoch [1/2], Iter [368/3125], train_loss:0.076322\n",
      "Epoch [1/2], Iter [369/3125], train_loss:0.116615\n",
      "Epoch [1/2], Iter [370/3125], train_loss:0.100660\n",
      "Epoch [1/2], Iter [371/3125], train_loss:0.099755\n",
      "Epoch [1/2], Iter [372/3125], train_loss:0.114215\n",
      "Epoch [1/2], Iter [373/3125], train_loss:0.112513\n",
      "Epoch [1/2], Iter [374/3125], train_loss:0.101781\n",
      "Epoch [1/2], Iter [375/3125], train_loss:0.067294\n",
      "Epoch [1/2], Iter [376/3125], train_loss:0.098053\n",
      "Epoch [1/2], Iter [377/3125], train_loss:0.107353\n",
      "Epoch [1/2], Iter [378/3125], train_loss:0.081777\n",
      "Epoch [1/2], Iter [379/3125], train_loss:0.080122\n",
      "Epoch [1/2], Iter [380/3125], train_loss:0.107728\n",
      "Epoch [1/2], Iter [381/3125], train_loss:0.095094\n",
      "Epoch [1/2], Iter [382/3125], train_loss:0.083242\n",
      "Epoch [1/2], Iter [383/3125], train_loss:0.102041\n",
      "Epoch [1/2], Iter [384/3125], train_loss:0.072550\n",
      "Epoch [1/2], Iter [385/3125], train_loss:0.088450\n",
      "Epoch [1/2], Iter [386/3125], train_loss:0.092246\n",
      "Epoch [1/2], Iter [387/3125], train_loss:0.105446\n",
      "Epoch [1/2], Iter [388/3125], train_loss:0.127865\n",
      "Epoch [1/2], Iter [389/3125], train_loss:0.072769\n",
      "Epoch [1/2], Iter [390/3125], train_loss:0.073997\n",
      "Epoch [1/2], Iter [391/3125], train_loss:0.066677\n",
      "Epoch [1/2], Iter [392/3125], train_loss:0.102232\n",
      "Epoch [1/2], Iter [393/3125], train_loss:0.117690\n",
      "Epoch [1/2], Iter [394/3125], train_loss:0.084889\n",
      "Epoch [1/2], Iter [395/3125], train_loss:0.103554\n",
      "Epoch [1/2], Iter [396/3125], train_loss:0.073418\n",
      "Epoch [1/2], Iter [397/3125], train_loss:0.096942\n",
      "Epoch [1/2], Iter [398/3125], train_loss:0.089206\n",
      "Epoch [1/2], Iter [399/3125], train_loss:0.126500\n",
      "Epoch [1/2], Iter [400/3125], train_loss:0.119990\n",
      "Epoch [1/2], Iter [401/3125], train_loss:0.065327\n",
      "Epoch [1/2], Iter [402/3125], train_loss:0.127086\n",
      "Epoch [1/2], Iter [403/3125], train_loss:0.089086\n",
      "Epoch [1/2], Iter [404/3125], train_loss:0.088689\n",
      "Epoch [1/2], Iter [405/3125], train_loss:0.118437\n",
      "Epoch [1/2], Iter [406/3125], train_loss:0.111353\n",
      "Epoch [1/2], Iter [407/3125], train_loss:0.128636\n",
      "Epoch [1/2], Iter [408/3125], train_loss:0.104118\n",
      "Epoch [1/2], Iter [409/3125], train_loss:0.090673\n",
      "Epoch [1/2], Iter [410/3125], train_loss:0.125681\n",
      "Epoch [1/2], Iter [411/3125], train_loss:0.115205\n",
      "Epoch [1/2], Iter [412/3125], train_loss:0.077153\n",
      "Epoch [1/2], Iter [413/3125], train_loss:0.094824\n",
      "Epoch [1/2], Iter [414/3125], train_loss:0.098783\n",
      "Epoch [1/2], Iter [415/3125], train_loss:0.087345\n",
      "Epoch [1/2], Iter [416/3125], train_loss:0.097017\n",
      "Epoch [1/2], Iter [417/3125], train_loss:0.096015\n",
      "Epoch [1/2], Iter [418/3125], train_loss:0.075332\n",
      "Epoch [1/2], Iter [419/3125], train_loss:0.084599\n",
      "Epoch [1/2], Iter [420/3125], train_loss:0.111044\n",
      "Epoch [1/2], Iter [421/3125], train_loss:0.093526\n",
      "Epoch [1/2], Iter [422/3125], train_loss:0.063629\n",
      "Epoch [1/2], Iter [423/3125], train_loss:0.067428\n",
      "Epoch [1/2], Iter [424/3125], train_loss:0.079753\n",
      "Epoch [1/2], Iter [425/3125], train_loss:0.135439\n",
      "Epoch [1/2], Iter [426/3125], train_loss:0.112857\n",
      "Epoch [1/2], Iter [427/3125], train_loss:0.074499\n",
      "Epoch [1/2], Iter [428/3125], train_loss:0.052821\n",
      "Epoch [1/2], Iter [429/3125], train_loss:0.075851\n",
      "Epoch [1/2], Iter [430/3125], train_loss:0.104684\n",
      "Epoch [1/2], Iter [431/3125], train_loss:0.102066\n",
      "Epoch [1/2], Iter [432/3125], train_loss:0.083621\n",
      "Epoch [1/2], Iter [433/3125], train_loss:0.064658\n",
      "Epoch [1/2], Iter [434/3125], train_loss:0.111376\n",
      "Epoch [1/2], Iter [435/3125], train_loss:0.055758\n",
      "Epoch [1/2], Iter [436/3125], train_loss:0.128865\n",
      "Epoch [1/2], Iter [437/3125], train_loss:0.100289\n",
      "Epoch [1/2], Iter [438/3125], train_loss:0.084247\n",
      "Epoch [1/2], Iter [439/3125], train_loss:0.073448\n",
      "Epoch [1/2], Iter [440/3125], train_loss:0.080761\n",
      "Epoch [1/2], Iter [441/3125], train_loss:0.119340\n",
      "Epoch [1/2], Iter [442/3125], train_loss:0.173922\n",
      "Epoch [1/2], Iter [443/3125], train_loss:0.067979\n",
      "Epoch [1/2], Iter [444/3125], train_loss:0.080348\n",
      "Epoch [1/2], Iter [445/3125], train_loss:0.132988\n",
      "Epoch [1/2], Iter [446/3125], train_loss:0.069152\n",
      "Epoch [1/2], Iter [447/3125], train_loss:0.084873\n",
      "Epoch [1/2], Iter [448/3125], train_loss:0.088424\n",
      "Epoch [1/2], Iter [449/3125], train_loss:0.094467\n",
      "Epoch [1/2], Iter [450/3125], train_loss:0.111121\n",
      "Epoch [1/2], Iter [451/3125], train_loss:0.067928\n",
      "Epoch [1/2], Iter [452/3125], train_loss:0.065471\n",
      "Epoch [1/2], Iter [453/3125], train_loss:0.075276\n",
      "Epoch [1/2], Iter [454/3125], train_loss:0.076016\n",
      "Epoch [1/2], Iter [455/3125], train_loss:0.088840\n",
      "Epoch [1/2], Iter [456/3125], train_loss:0.061118\n",
      "Epoch [1/2], Iter [457/3125], train_loss:0.079531\n",
      "Epoch [1/2], Iter [458/3125], train_loss:0.122364\n",
      "Epoch [1/2], Iter [459/3125], train_loss:0.100249\n",
      "Epoch [1/2], Iter [460/3125], train_loss:0.073599\n",
      "Epoch [1/2], Iter [461/3125], train_loss:0.084068\n",
      "Epoch [1/2], Iter [462/3125], train_loss:0.056314\n",
      "Epoch [1/2], Iter [463/3125], train_loss:0.079495\n",
      "Epoch [1/2], Iter [464/3125], train_loss:0.076411\n",
      "Epoch [1/2], Iter [465/3125], train_loss:0.130830\n",
      "Epoch [1/2], Iter [466/3125], train_loss:0.086917\n",
      "Epoch [1/2], Iter [467/3125], train_loss:0.093509\n",
      "Epoch [1/2], Iter [468/3125], train_loss:0.084006\n",
      "Epoch [1/2], Iter [469/3125], train_loss:0.070421\n",
      "Epoch [1/2], Iter [470/3125], train_loss:0.107369\n",
      "Epoch [1/2], Iter [471/3125], train_loss:0.065467\n",
      "Epoch [1/2], Iter [472/3125], train_loss:0.069032\n",
      "Epoch [1/2], Iter [473/3125], train_loss:0.073237\n",
      "Epoch [1/2], Iter [474/3125], train_loss:0.151757\n",
      "Epoch [1/2], Iter [475/3125], train_loss:0.097692\n",
      "Epoch [1/2], Iter [476/3125], train_loss:0.100925\n",
      "Epoch [1/2], Iter [477/3125], train_loss:0.091285\n",
      "Epoch [1/2], Iter [478/3125], train_loss:0.103061\n",
      "Epoch [1/2], Iter [479/3125], train_loss:0.064359\n",
      "Epoch [1/2], Iter [480/3125], train_loss:0.082491\n",
      "Epoch [1/2], Iter [481/3125], train_loss:0.057366\n",
      "Epoch [1/2], Iter [482/3125], train_loss:0.092543\n",
      "Epoch [1/2], Iter [483/3125], train_loss:0.067777\n",
      "Epoch [1/2], Iter [484/3125], train_loss:0.067935\n",
      "Epoch [1/2], Iter [485/3125], train_loss:0.105495\n",
      "Epoch [1/2], Iter [486/3125], train_loss:0.136604\n",
      "Epoch [1/2], Iter [487/3125], train_loss:0.092469\n",
      "Epoch [1/2], Iter [488/3125], train_loss:0.082614\n",
      "Epoch [1/2], Iter [489/3125], train_loss:0.122642\n",
      "Epoch [1/2], Iter [490/3125], train_loss:0.064453\n",
      "Epoch [1/2], Iter [491/3125], train_loss:0.127374\n",
      "Epoch [1/2], Iter [492/3125], train_loss:0.090427\n",
      "Epoch [1/2], Iter [493/3125], train_loss:0.076251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [494/3125], train_loss:0.061046\n",
      "Epoch [1/2], Iter [495/3125], train_loss:0.103997\n",
      "Epoch [1/2], Iter [496/3125], train_loss:0.109734\n",
      "Epoch [1/2], Iter [497/3125], train_loss:0.070913\n",
      "Epoch [1/2], Iter [498/3125], train_loss:0.069599\n",
      "Epoch [1/2], Iter [499/3125], train_loss:0.078603\n",
      "Epoch [1/2], Iter [500/3125], train_loss:0.133940\n",
      "Epoch [1/2], Iter [501/3125], train_loss:0.072970\n",
      "Epoch [1/2], Iter [502/3125], train_loss:0.075337\n",
      "Epoch [1/2], Iter [503/3125], train_loss:0.094221\n",
      "Epoch [1/2], Iter [504/3125], train_loss:0.091344\n",
      "Epoch [1/2], Iter [505/3125], train_loss:0.085541\n",
      "Epoch [1/2], Iter [506/3125], train_loss:0.089418\n",
      "Epoch [1/2], Iter [507/3125], train_loss:0.066250\n",
      "Epoch [1/2], Iter [508/3125], train_loss:0.112804\n",
      "Epoch [1/2], Iter [509/3125], train_loss:0.084062\n",
      "Epoch [1/2], Iter [510/3125], train_loss:0.087550\n",
      "Epoch [1/2], Iter [511/3125], train_loss:0.073422\n",
      "Epoch [1/2], Iter [512/3125], train_loss:0.089989\n",
      "Epoch [1/2], Iter [513/3125], train_loss:0.056597\n",
      "Epoch [1/2], Iter [514/3125], train_loss:0.084649\n",
      "Epoch [1/2], Iter [515/3125], train_loss:0.095353\n",
      "Epoch [1/2], Iter [516/3125], train_loss:0.057524\n",
      "Epoch [1/2], Iter [517/3125], train_loss:0.086105\n",
      "Epoch [1/2], Iter [518/3125], train_loss:0.100302\n",
      "Epoch [1/2], Iter [519/3125], train_loss:0.085303\n",
      "Epoch [1/2], Iter [520/3125], train_loss:0.097001\n",
      "Epoch [1/2], Iter [521/3125], train_loss:0.078477\n",
      "Epoch [1/2], Iter [522/3125], train_loss:0.118421\n",
      "Epoch [1/2], Iter [523/3125], train_loss:0.094699\n",
      "Epoch [1/2], Iter [524/3125], train_loss:0.081237\n",
      "Epoch [1/2], Iter [525/3125], train_loss:0.082480\n",
      "Epoch [1/2], Iter [526/3125], train_loss:0.082260\n",
      "Epoch [1/2], Iter [527/3125], train_loss:0.088543\n",
      "Epoch [1/2], Iter [528/3125], train_loss:0.072576\n",
      "Epoch [1/2], Iter [529/3125], train_loss:0.095206\n",
      "Epoch [1/2], Iter [530/3125], train_loss:0.076497\n",
      "Epoch [1/2], Iter [531/3125], train_loss:0.051827\n",
      "Epoch [1/2], Iter [532/3125], train_loss:0.051135\n",
      "Epoch [1/2], Iter [533/3125], train_loss:0.088031\n",
      "Epoch [1/2], Iter [534/3125], train_loss:0.111677\n",
      "Epoch [1/2], Iter [535/3125], train_loss:0.070332\n",
      "Epoch [1/2], Iter [536/3125], train_loss:0.084658\n",
      "Epoch [1/2], Iter [537/3125], train_loss:0.099877\n",
      "Epoch [1/2], Iter [538/3125], train_loss:0.083049\n",
      "Epoch [1/2], Iter [539/3125], train_loss:0.080456\n",
      "Epoch [1/2], Iter [540/3125], train_loss:0.060653\n",
      "Epoch [1/2], Iter [541/3125], train_loss:0.126004\n",
      "Epoch [1/2], Iter [542/3125], train_loss:0.089957\n",
      "Epoch [1/2], Iter [543/3125], train_loss:0.097005\n",
      "Epoch [1/2], Iter [544/3125], train_loss:0.098928\n",
      "Epoch [1/2], Iter [545/3125], train_loss:0.050157\n",
      "Epoch [1/2], Iter [546/3125], train_loss:0.068912\n",
      "Epoch [1/2], Iter [547/3125], train_loss:0.105661\n",
      "Epoch [1/2], Iter [548/3125], train_loss:0.063028\n",
      "Epoch [1/2], Iter [549/3125], train_loss:0.101849\n",
      "Epoch [1/2], Iter [550/3125], train_loss:0.087718\n",
      "Epoch [1/2], Iter [551/3125], train_loss:0.085455\n",
      "Epoch [1/2], Iter [552/3125], train_loss:0.101876\n",
      "Epoch [1/2], Iter [553/3125], train_loss:0.069947\n",
      "Epoch [1/2], Iter [554/3125], train_loss:0.082198\n",
      "Epoch [1/2], Iter [555/3125], train_loss:0.078910\n",
      "Epoch [1/2], Iter [556/3125], train_loss:0.071619\n",
      "Epoch [1/2], Iter [557/3125], train_loss:0.091170\n",
      "Epoch [1/2], Iter [558/3125], train_loss:0.073899\n",
      "Epoch [1/2], Iter [559/3125], train_loss:0.097393\n",
      "Epoch [1/2], Iter [560/3125], train_loss:0.059482\n",
      "Epoch [1/2], Iter [561/3125], train_loss:0.086727\n",
      "Epoch [1/2], Iter [562/3125], train_loss:0.067922\n",
      "Epoch [1/2], Iter [563/3125], train_loss:0.049343\n",
      "Epoch [1/2], Iter [564/3125], train_loss:0.079434\n",
      "Epoch [1/2], Iter [565/3125], train_loss:0.082183\n",
      "Epoch [1/2], Iter [566/3125], train_loss:0.093476\n",
      "Epoch [1/2], Iter [567/3125], train_loss:0.078752\n",
      "Epoch [1/2], Iter [568/3125], train_loss:0.091465\n",
      "Epoch [1/2], Iter [569/3125], train_loss:0.089662\n",
      "Epoch [1/2], Iter [570/3125], train_loss:0.080252\n",
      "Epoch [1/2], Iter [571/3125], train_loss:0.068077\n",
      "Epoch [1/2], Iter [572/3125], train_loss:0.061509\n",
      "Epoch [1/2], Iter [573/3125], train_loss:0.085185\n",
      "Epoch [1/2], Iter [574/3125], train_loss:0.079471\n",
      "Epoch [1/2], Iter [575/3125], train_loss:0.053422\n",
      "Epoch [1/2], Iter [576/3125], train_loss:0.077580\n",
      "Epoch [1/2], Iter [577/3125], train_loss:0.097711\n",
      "Epoch [1/2], Iter [578/3125], train_loss:0.088529\n",
      "Epoch [1/2], Iter [579/3125], train_loss:0.078072\n",
      "Epoch [1/2], Iter [580/3125], train_loss:0.066475\n",
      "Epoch [1/2], Iter [581/3125], train_loss:0.100759\n",
      "Epoch [1/2], Iter [582/3125], train_loss:0.059701\n",
      "Epoch [1/2], Iter [583/3125], train_loss:0.109780\n",
      "Epoch [1/2], Iter [584/3125], train_loss:0.091762\n",
      "Epoch [1/2], Iter [585/3125], train_loss:0.092769\n",
      "Epoch [1/2], Iter [586/3125], train_loss:0.087646\n",
      "Epoch [1/2], Iter [587/3125], train_loss:0.077475\n",
      "Epoch [1/2], Iter [588/3125], train_loss:0.082140\n",
      "Epoch [1/2], Iter [589/3125], train_loss:0.064143\n",
      "Epoch [1/2], Iter [590/3125], train_loss:0.118475\n",
      "Epoch [1/2], Iter [591/3125], train_loss:0.061369\n",
      "Epoch [1/2], Iter [592/3125], train_loss:0.103518\n",
      "Epoch [1/2], Iter [593/3125], train_loss:0.109588\n",
      "Epoch [1/2], Iter [594/3125], train_loss:0.075540\n",
      "Epoch [1/2], Iter [595/3125], train_loss:0.066279\n",
      "Epoch [1/2], Iter [596/3125], train_loss:0.084220\n",
      "Epoch [1/2], Iter [597/3125], train_loss:0.093858\n",
      "Epoch [1/2], Iter [598/3125], train_loss:0.064187\n",
      "Epoch [1/2], Iter [599/3125], train_loss:0.066326\n",
      "Epoch [1/2], Iter [600/3125], train_loss:0.081327\n",
      "Epoch [1/2], Iter [601/3125], train_loss:0.083892\n",
      "Epoch [1/2], Iter [602/3125], train_loss:0.072193\n",
      "Epoch [1/2], Iter [603/3125], train_loss:0.070572\n",
      "Epoch [1/2], Iter [604/3125], train_loss:0.099174\n",
      "Epoch [1/2], Iter [605/3125], train_loss:0.073340\n",
      "Epoch [1/2], Iter [606/3125], train_loss:0.075066\n",
      "Epoch [1/2], Iter [607/3125], train_loss:0.089540\n",
      "Epoch [1/2], Iter [608/3125], train_loss:0.087063\n",
      "Epoch [1/2], Iter [609/3125], train_loss:0.067917\n",
      "Epoch [1/2], Iter [610/3125], train_loss:0.078777\n",
      "Epoch [1/2], Iter [611/3125], train_loss:0.073020\n",
      "Epoch [1/2], Iter [612/3125], train_loss:0.053916\n",
      "Epoch [1/2], Iter [613/3125], train_loss:0.099749\n",
      "Epoch [1/2], Iter [614/3125], train_loss:0.076472\n",
      "Epoch [1/2], Iter [615/3125], train_loss:0.092774\n",
      "Epoch [1/2], Iter [616/3125], train_loss:0.072519\n",
      "Epoch [1/2], Iter [617/3125], train_loss:0.115796\n",
      "Epoch [1/2], Iter [618/3125], train_loss:0.111423\n",
      "Epoch [1/2], Iter [619/3125], train_loss:0.035930\n",
      "Epoch [1/2], Iter [620/3125], train_loss:0.053881\n",
      "Epoch [1/2], Iter [621/3125], train_loss:0.121114\n",
      "Epoch [1/2], Iter [622/3125], train_loss:0.121951\n",
      "Epoch [1/2], Iter [623/3125], train_loss:0.073308\n",
      "Epoch [1/2], Iter [624/3125], train_loss:0.048398\n",
      "Epoch [1/2], Iter [625/3125], train_loss:0.107412\n",
      "Epoch [1/2], Iter [626/3125], train_loss:0.068145\n",
      "Epoch [1/2], Iter [627/3125], train_loss:0.077340\n",
      "Epoch [1/2], Iter [628/3125], train_loss:0.085913\n",
      "Epoch [1/2], Iter [629/3125], train_loss:0.085568\n",
      "Epoch [1/2], Iter [630/3125], train_loss:0.075331\n",
      "Epoch [1/2], Iter [631/3125], train_loss:0.063729\n",
      "Epoch [1/2], Iter [632/3125], train_loss:0.096395\n",
      "Epoch [1/2], Iter [633/3125], train_loss:0.091692\n",
      "Epoch [1/2], Iter [634/3125], train_loss:0.087556\n",
      "Epoch [1/2], Iter [635/3125], train_loss:0.128987\n",
      "Epoch [1/2], Iter [636/3125], train_loss:0.078282\n",
      "Epoch [1/2], Iter [637/3125], train_loss:0.072686\n",
      "Epoch [1/2], Iter [638/3125], train_loss:0.101055\n",
      "Epoch [1/2], Iter [639/3125], train_loss:0.088135\n",
      "Epoch [1/2], Iter [640/3125], train_loss:0.076548\n",
      "Epoch [1/2], Iter [641/3125], train_loss:0.074535\n",
      "Epoch [1/2], Iter [642/3125], train_loss:0.133764\n",
      "Epoch [1/2], Iter [643/3125], train_loss:0.081785\n",
      "Epoch [1/2], Iter [644/3125], train_loss:0.081873\n",
      "Epoch [1/2], Iter [645/3125], train_loss:0.052027\n",
      "Epoch [1/2], Iter [646/3125], train_loss:0.065710\n",
      "Epoch [1/2], Iter [647/3125], train_loss:0.066639\n",
      "Epoch [1/2], Iter [648/3125], train_loss:0.077497\n",
      "Epoch [1/2], Iter [649/3125], train_loss:0.071994\n",
      "Epoch [1/2], Iter [650/3125], train_loss:0.077160\n",
      "Epoch [1/2], Iter [651/3125], train_loss:0.088668\n",
      "Epoch [1/2], Iter [652/3125], train_loss:0.091575\n",
      "Epoch [1/2], Iter [653/3125], train_loss:0.063036\n",
      "Epoch [1/2], Iter [654/3125], train_loss:0.077080\n",
      "Epoch [1/2], Iter [655/3125], train_loss:0.120097\n",
      "Epoch [1/2], Iter [656/3125], train_loss:0.057079\n",
      "Epoch [1/2], Iter [657/3125], train_loss:0.078749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [658/3125], train_loss:0.080975\n",
      "Epoch [1/2], Iter [659/3125], train_loss:0.084412\n",
      "Epoch [1/2], Iter [660/3125], train_loss:0.081507\n",
      "Epoch [1/2], Iter [661/3125], train_loss:0.106032\n",
      "Epoch [1/2], Iter [662/3125], train_loss:0.044990\n",
      "Epoch [1/2], Iter [663/3125], train_loss:0.071733\n",
      "Epoch [1/2], Iter [664/3125], train_loss:0.068678\n",
      "Epoch [1/2], Iter [665/3125], train_loss:0.060852\n",
      "Epoch [1/2], Iter [666/3125], train_loss:0.061496\n",
      "Epoch [1/2], Iter [667/3125], train_loss:0.099616\n",
      "Epoch [1/2], Iter [668/3125], train_loss:0.043187\n",
      "Epoch [1/2], Iter [669/3125], train_loss:0.042735\n",
      "Epoch [1/2], Iter [670/3125], train_loss:0.063698\n",
      "Epoch [1/2], Iter [671/3125], train_loss:0.054137\n",
      "Epoch [1/2], Iter [672/3125], train_loss:0.122349\n",
      "Epoch [1/2], Iter [673/3125], train_loss:0.045259\n",
      "Epoch [1/2], Iter [674/3125], train_loss:0.096469\n",
      "Epoch [1/2], Iter [675/3125], train_loss:0.058725\n",
      "Epoch [1/2], Iter [676/3125], train_loss:0.092602\n",
      "Epoch [1/2], Iter [677/3125], train_loss:0.066935\n",
      "Epoch [1/2], Iter [678/3125], train_loss:0.077298\n",
      "Epoch [1/2], Iter [679/3125], train_loss:0.110552\n",
      "Epoch [1/2], Iter [680/3125], train_loss:0.048738\n",
      "Epoch [1/2], Iter [681/3125], train_loss:0.096448\n",
      "Epoch [1/2], Iter [682/3125], train_loss:0.110349\n",
      "Epoch [1/2], Iter [683/3125], train_loss:0.119194\n",
      "Epoch [1/2], Iter [684/3125], train_loss:0.078200\n",
      "Epoch [1/2], Iter [685/3125], train_loss:0.090346\n",
      "Epoch [1/2], Iter [686/3125], train_loss:0.067279\n",
      "Epoch [1/2], Iter [687/3125], train_loss:0.056750\n",
      "Epoch [1/2], Iter [688/3125], train_loss:0.103682\n",
      "Epoch [1/2], Iter [689/3125], train_loss:0.070194\n",
      "Epoch [1/2], Iter [690/3125], train_loss:0.077888\n",
      "Epoch [1/2], Iter [691/3125], train_loss:0.089339\n",
      "Epoch [1/2], Iter [692/3125], train_loss:0.069433\n",
      "Epoch [1/2], Iter [693/3125], train_loss:0.062627\n",
      "Epoch [1/2], Iter [694/3125], train_loss:0.088834\n",
      "Epoch [1/2], Iter [695/3125], train_loss:0.057176\n",
      "Epoch [1/2], Iter [696/3125], train_loss:0.062857\n",
      "Epoch [1/2], Iter [697/3125], train_loss:0.107247\n",
      "Epoch [1/2], Iter [698/3125], train_loss:0.075563\n",
      "Epoch [1/2], Iter [699/3125], train_loss:0.075217\n",
      "Epoch [1/2], Iter [700/3125], train_loss:0.073498\n",
      "Epoch [1/2], Iter [701/3125], train_loss:0.084294\n",
      "Epoch [1/2], Iter [702/3125], train_loss:0.055456\n",
      "Epoch [1/2], Iter [703/3125], train_loss:0.101781\n",
      "Epoch [1/2], Iter [704/3125], train_loss:0.102988\n",
      "Epoch [1/2], Iter [705/3125], train_loss:0.090018\n",
      "Epoch [1/2], Iter [706/3125], train_loss:0.071555\n",
      "Epoch [1/2], Iter [707/3125], train_loss:0.066634\n",
      "Epoch [1/2], Iter [708/3125], train_loss:0.075814\n",
      "Epoch [1/2], Iter [709/3125], train_loss:0.077288\n",
      "Epoch [1/2], Iter [710/3125], train_loss:0.104503\n",
      "Epoch [1/2], Iter [711/3125], train_loss:0.067886\n",
      "Epoch [1/2], Iter [712/3125], train_loss:0.079606\n",
      "Epoch [1/2], Iter [713/3125], train_loss:0.071527\n",
      "Epoch [1/2], Iter [714/3125], train_loss:0.085514\n",
      "Epoch [1/2], Iter [715/3125], train_loss:0.057681\n",
      "Epoch [1/2], Iter [716/3125], train_loss:0.078999\n",
      "Epoch [1/2], Iter [717/3125], train_loss:0.071168\n",
      "Epoch [1/2], Iter [718/3125], train_loss:0.089825\n",
      "Epoch [1/2], Iter [719/3125], train_loss:0.045149\n",
      "Epoch [1/2], Iter [720/3125], train_loss:0.084063\n",
      "Epoch [1/2], Iter [721/3125], train_loss:0.066844\n",
      "Epoch [1/2], Iter [722/3125], train_loss:0.111551\n",
      "Epoch [1/2], Iter [723/3125], train_loss:0.090148\n",
      "Epoch [1/2], Iter [724/3125], train_loss:0.088762\n",
      "Epoch [1/2], Iter [725/3125], train_loss:0.053935\n",
      "Epoch [1/2], Iter [726/3125], train_loss:0.097556\n",
      "Epoch [1/2], Iter [727/3125], train_loss:0.057640\n",
      "Epoch [1/2], Iter [728/3125], train_loss:0.099852\n",
      "Epoch [1/2], Iter [729/3125], train_loss:0.072951\n",
      "Epoch [1/2], Iter [730/3125], train_loss:0.086131\n",
      "Epoch [1/2], Iter [731/3125], train_loss:0.076418\n",
      "Epoch [1/2], Iter [732/3125], train_loss:0.093934\n",
      "Epoch [1/2], Iter [733/3125], train_loss:0.086792\n",
      "Epoch [1/2], Iter [734/3125], train_loss:0.076435\n",
      "Epoch [1/2], Iter [735/3125], train_loss:0.098343\n",
      "Epoch [1/2], Iter [736/3125], train_loss:0.064591\n",
      "Epoch [1/2], Iter [737/3125], train_loss:0.136798\n",
      "Epoch [1/2], Iter [738/3125], train_loss:0.086149\n",
      "Epoch [1/2], Iter [739/3125], train_loss:0.071737\n",
      "Epoch [1/2], Iter [740/3125], train_loss:0.064806\n",
      "Epoch [1/2], Iter [741/3125], train_loss:0.080049\n",
      "Epoch [1/2], Iter [742/3125], train_loss:0.096013\n",
      "Epoch [1/2], Iter [743/3125], train_loss:0.060116\n",
      "Epoch [1/2], Iter [744/3125], train_loss:0.067535\n",
      "Epoch [1/2], Iter [745/3125], train_loss:0.093100\n",
      "Epoch [1/2], Iter [746/3125], train_loss:0.072566\n",
      "Epoch [1/2], Iter [747/3125], train_loss:0.103533\n",
      "Epoch [1/2], Iter [748/3125], train_loss:0.083829\n",
      "Epoch [1/2], Iter [749/3125], train_loss:0.058632\n",
      "Epoch [1/2], Iter [750/3125], train_loss:0.063049\n",
      "Epoch [1/2], Iter [751/3125], train_loss:0.072190\n",
      "Epoch [1/2], Iter [752/3125], train_loss:0.081107\n",
      "Epoch [1/2], Iter [753/3125], train_loss:0.073657\n",
      "Epoch [1/2], Iter [754/3125], train_loss:0.063324\n",
      "Epoch [1/2], Iter [755/3125], train_loss:0.061974\n",
      "Epoch [1/2], Iter [756/3125], train_loss:0.064494\n",
      "Epoch [1/2], Iter [757/3125], train_loss:0.077813\n",
      "Epoch [1/2], Iter [758/3125], train_loss:0.070678\n",
      "Epoch [1/2], Iter [759/3125], train_loss:0.062416\n",
      "Epoch [1/2], Iter [760/3125], train_loss:0.062071\n",
      "Epoch [1/2], Iter [761/3125], train_loss:0.030896\n",
      "Epoch [1/2], Iter [762/3125], train_loss:0.054023\n",
      "Epoch [1/2], Iter [763/3125], train_loss:0.123419\n",
      "Epoch [1/2], Iter [764/3125], train_loss:0.080511\n",
      "Epoch [1/2], Iter [765/3125], train_loss:0.088166\n",
      "Epoch [1/2], Iter [766/3125], train_loss:0.044754\n",
      "Epoch [1/2], Iter [767/3125], train_loss:0.065380\n",
      "Epoch [1/2], Iter [768/3125], train_loss:0.062831\n",
      "Epoch [1/2], Iter [769/3125], train_loss:0.082807\n",
      "Epoch [1/2], Iter [770/3125], train_loss:0.106045\n",
      "Epoch [1/2], Iter [771/3125], train_loss:0.039265\n",
      "Epoch [1/2], Iter [772/3125], train_loss:0.040538\n",
      "Epoch [1/2], Iter [773/3125], train_loss:0.064032\n",
      "Epoch [1/2], Iter [774/3125], train_loss:0.098438\n",
      "Epoch [1/2], Iter [775/3125], train_loss:0.044762\n",
      "Epoch [1/2], Iter [776/3125], train_loss:0.059482\n",
      "Epoch [1/2], Iter [777/3125], train_loss:0.071769\n",
      "Epoch [1/2], Iter [778/3125], train_loss:0.081381\n",
      "Epoch [1/2], Iter [779/3125], train_loss:0.077327\n",
      "Epoch [1/2], Iter [780/3125], train_loss:0.062736\n",
      "Epoch [1/2], Iter [781/3125], train_loss:0.093462\n",
      "Epoch [1/2], Iter [782/3125], train_loss:0.072988\n",
      "Epoch [1/2], Iter [783/3125], train_loss:0.060638\n",
      "Epoch [1/2], Iter [784/3125], train_loss:0.093783\n",
      "Epoch [1/2], Iter [785/3125], train_loss:0.071993\n",
      "Epoch [1/2], Iter [786/3125], train_loss:0.100763\n",
      "Epoch [1/2], Iter [787/3125], train_loss:0.072992\n",
      "Epoch [1/2], Iter [788/3125], train_loss:0.092503\n",
      "Epoch [1/2], Iter [789/3125], train_loss:0.087834\n",
      "Epoch [1/2], Iter [790/3125], train_loss:0.112599\n",
      "Epoch [1/2], Iter [791/3125], train_loss:0.078161\n",
      "Epoch [1/2], Iter [792/3125], train_loss:0.080000\n",
      "Epoch [1/2], Iter [793/3125], train_loss:0.043560\n",
      "Epoch [1/2], Iter [794/3125], train_loss:0.080028\n",
      "Epoch [1/2], Iter [795/3125], train_loss:0.104163\n",
      "Epoch [1/2], Iter [796/3125], train_loss:0.064733\n",
      "Epoch [1/2], Iter [797/3125], train_loss:0.051298\n",
      "Epoch [1/2], Iter [798/3125], train_loss:0.069372\n",
      "Epoch [1/2], Iter [799/3125], train_loss:0.044411\n",
      "Epoch [1/2], Iter [800/3125], train_loss:0.071995\n",
      "Epoch [1/2], Iter [801/3125], train_loss:0.058943\n",
      "Epoch [1/2], Iter [802/3125], train_loss:0.075079\n",
      "Epoch [1/2], Iter [803/3125], train_loss:0.065944\n",
      "Epoch [1/2], Iter [804/3125], train_loss:0.054138\n",
      "Epoch [1/2], Iter [805/3125], train_loss:0.061844\n",
      "Epoch [1/2], Iter [806/3125], train_loss:0.075249\n",
      "Epoch [1/2], Iter [807/3125], train_loss:0.090213\n",
      "Epoch [1/2], Iter [808/3125], train_loss:0.106900\n",
      "Epoch [1/2], Iter [809/3125], train_loss:0.087969\n",
      "Epoch [1/2], Iter [810/3125], train_loss:0.082871\n",
      "Epoch [1/2], Iter [811/3125], train_loss:0.083834\n",
      "Epoch [1/2], Iter [812/3125], train_loss:0.067130\n",
      "Epoch [1/2], Iter [813/3125], train_loss:0.081398\n",
      "Epoch [1/2], Iter [814/3125], train_loss:0.075722\n",
      "Epoch [1/2], Iter [815/3125], train_loss:0.102066\n",
      "Epoch [1/2], Iter [816/3125], train_loss:0.095934\n",
      "Epoch [1/2], Iter [817/3125], train_loss:0.073375\n",
      "Epoch [1/2], Iter [818/3125], train_loss:0.114593\n",
      "Epoch [1/2], Iter [819/3125], train_loss:0.080349\n",
      "Epoch [1/2], Iter [820/3125], train_loss:0.093809\n",
      "Epoch [1/2], Iter [821/3125], train_loss:0.057519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [822/3125], train_loss:0.060332\n",
      "Epoch [1/2], Iter [823/3125], train_loss:0.069837\n",
      "Epoch [1/2], Iter [824/3125], train_loss:0.081108\n",
      "Epoch [1/2], Iter [825/3125], train_loss:0.064217\n",
      "Epoch [1/2], Iter [826/3125], train_loss:0.077845\n",
      "Epoch [1/2], Iter [827/3125], train_loss:0.062394\n",
      "Epoch [1/2], Iter [828/3125], train_loss:0.078574\n",
      "Epoch [1/2], Iter [829/3125], train_loss:0.077207\n",
      "Epoch [1/2], Iter [830/3125], train_loss:0.052881\n",
      "Epoch [1/2], Iter [831/3125], train_loss:0.105506\n",
      "Epoch [1/2], Iter [832/3125], train_loss:0.085921\n",
      "Epoch [1/2], Iter [833/3125], train_loss:0.062045\n",
      "Epoch [1/2], Iter [834/3125], train_loss:0.078639\n",
      "Epoch [1/2], Iter [835/3125], train_loss:0.091643\n",
      "Epoch [1/2], Iter [836/3125], train_loss:0.070230\n",
      "Epoch [1/2], Iter [837/3125], train_loss:0.061350\n",
      "Epoch [1/2], Iter [838/3125], train_loss:0.100740\n",
      "Epoch [1/2], Iter [839/3125], train_loss:0.085829\n",
      "Epoch [1/2], Iter [840/3125], train_loss:0.060633\n",
      "Epoch [1/2], Iter [841/3125], train_loss:0.071548\n",
      "Epoch [1/2], Iter [842/3125], train_loss:0.083561\n",
      "Epoch [1/2], Iter [843/3125], train_loss:0.066375\n",
      "Epoch [1/2], Iter [844/3125], train_loss:0.100119\n",
      "Epoch [1/2], Iter [845/3125], train_loss:0.088684\n",
      "Epoch [1/2], Iter [846/3125], train_loss:0.055062\n",
      "Epoch [1/2], Iter [847/3125], train_loss:0.074315\n",
      "Epoch [1/2], Iter [848/3125], train_loss:0.069999\n",
      "Epoch [1/2], Iter [849/3125], train_loss:0.035895\n",
      "Epoch [1/2], Iter [850/3125], train_loss:0.037956\n",
      "Epoch [1/2], Iter [851/3125], train_loss:0.100308\n",
      "Epoch [1/2], Iter [852/3125], train_loss:0.067342\n",
      "Epoch [1/2], Iter [853/3125], train_loss:0.100173\n",
      "Epoch [1/2], Iter [854/3125], train_loss:0.095898\n",
      "Epoch [1/2], Iter [855/3125], train_loss:0.037566\n",
      "Epoch [1/2], Iter [856/3125], train_loss:0.109127\n",
      "Epoch [1/2], Iter [857/3125], train_loss:0.086012\n",
      "Epoch [1/2], Iter [858/3125], train_loss:0.042612\n",
      "Epoch [1/2], Iter [859/3125], train_loss:0.095185\n",
      "Epoch [1/2], Iter [860/3125], train_loss:0.041484\n",
      "Epoch [1/2], Iter [861/3125], train_loss:0.077971\n",
      "Epoch [1/2], Iter [862/3125], train_loss:0.077879\n",
      "Epoch [1/2], Iter [863/3125], train_loss:0.074702\n",
      "Epoch [1/2], Iter [864/3125], train_loss:0.065591\n",
      "Epoch [1/2], Iter [865/3125], train_loss:0.044043\n",
      "Epoch [1/2], Iter [866/3125], train_loss:0.086357\n",
      "Epoch [1/2], Iter [867/3125], train_loss:0.076382\n",
      "Epoch [1/2], Iter [868/3125], train_loss:0.126473\n",
      "Epoch [1/2], Iter [869/3125], train_loss:0.111014\n",
      "Epoch [1/2], Iter [870/3125], train_loss:0.053985\n",
      "Epoch [1/2], Iter [871/3125], train_loss:0.066713\n",
      "Epoch [1/2], Iter [872/3125], train_loss:0.092710\n",
      "Epoch [1/2], Iter [873/3125], train_loss:0.072230\n",
      "Epoch [1/2], Iter [874/3125], train_loss:0.072040\n",
      "Epoch [1/2], Iter [875/3125], train_loss:0.128901\n",
      "Epoch [1/2], Iter [876/3125], train_loss:0.094567\n",
      "Epoch [1/2], Iter [877/3125], train_loss:0.068851\n",
      "Epoch [1/2], Iter [878/3125], train_loss:0.124406\n",
      "Epoch [1/2], Iter [879/3125], train_loss:0.060597\n",
      "Epoch [1/2], Iter [880/3125], train_loss:0.053799\n",
      "Epoch [1/2], Iter [881/3125], train_loss:0.089491\n",
      "Epoch [1/2], Iter [882/3125], train_loss:0.056719\n",
      "Epoch [1/2], Iter [883/3125], train_loss:0.076862\n",
      "Epoch [1/2], Iter [884/3125], train_loss:0.068522\n",
      "Epoch [1/2], Iter [885/3125], train_loss:0.104225\n",
      "Epoch [1/2], Iter [886/3125], train_loss:0.082506\n",
      "Epoch [1/2], Iter [887/3125], train_loss:0.052971\n",
      "Epoch [1/2], Iter [888/3125], train_loss:0.059774\n",
      "Epoch [1/2], Iter [889/3125], train_loss:0.086975\n",
      "Epoch [1/2], Iter [890/3125], train_loss:0.056777\n",
      "Epoch [1/2], Iter [891/3125], train_loss:0.087735\n",
      "Epoch [1/2], Iter [892/3125], train_loss:0.070902\n",
      "Epoch [1/2], Iter [893/3125], train_loss:0.111826\n",
      "Epoch [1/2], Iter [894/3125], train_loss:0.059331\n",
      "Epoch [1/2], Iter [895/3125], train_loss:0.094341\n",
      "Epoch [1/2], Iter [896/3125], train_loss:0.051812\n",
      "Epoch [1/2], Iter [897/3125], train_loss:0.112401\n",
      "Epoch [1/2], Iter [898/3125], train_loss:0.061509\n",
      "Epoch [1/2], Iter [899/3125], train_loss:0.064180\n",
      "Epoch [1/2], Iter [900/3125], train_loss:0.038741\n",
      "Epoch [1/2], Iter [901/3125], train_loss:0.053055\n",
      "Epoch [1/2], Iter [902/3125], train_loss:0.054728\n",
      "Epoch [1/2], Iter [903/3125], train_loss:0.078024\n",
      "Epoch [1/2], Iter [904/3125], train_loss:0.044780\n",
      "Epoch [1/2], Iter [905/3125], train_loss:0.089853\n",
      "Epoch [1/2], Iter [906/3125], train_loss:0.101245\n",
      "Epoch [1/2], Iter [907/3125], train_loss:0.052246\n",
      "Epoch [1/2], Iter [908/3125], train_loss:0.071536\n",
      "Epoch [1/2], Iter [909/3125], train_loss:0.075075\n",
      "Epoch [1/2], Iter [910/3125], train_loss:0.074174\n",
      "Epoch [1/2], Iter [911/3125], train_loss:0.072227\n",
      "Epoch [1/2], Iter [912/3125], train_loss:0.101729\n",
      "Epoch [1/2], Iter [913/3125], train_loss:0.071239\n",
      "Epoch [1/2], Iter [914/3125], train_loss:0.101731\n",
      "Epoch [1/2], Iter [915/3125], train_loss:0.066899\n",
      "Epoch [1/2], Iter [916/3125], train_loss:0.042201\n",
      "Epoch [1/2], Iter [917/3125], train_loss:0.057565\n",
      "Epoch [1/2], Iter [918/3125], train_loss:0.043300\n",
      "Epoch [1/2], Iter [919/3125], train_loss:0.101549\n",
      "Epoch [1/2], Iter [920/3125], train_loss:0.080133\n",
      "Epoch [1/2], Iter [921/3125], train_loss:0.088354\n",
      "Epoch [1/2], Iter [922/3125], train_loss:0.079794\n",
      "Epoch [1/2], Iter [923/3125], train_loss:0.082035\n",
      "Epoch [1/2], Iter [924/3125], train_loss:0.043397\n",
      "Epoch [1/2], Iter [925/3125], train_loss:0.101342\n",
      "Epoch [1/2], Iter [926/3125], train_loss:0.070656\n",
      "Epoch [1/2], Iter [927/3125], train_loss:0.068928\n",
      "Epoch [1/2], Iter [928/3125], train_loss:0.086801\n",
      "Epoch [1/2], Iter [929/3125], train_loss:0.059911\n",
      "Epoch [1/2], Iter [930/3125], train_loss:0.079392\n",
      "Epoch [1/2], Iter [931/3125], train_loss:0.083579\n",
      "Epoch [1/2], Iter [932/3125], train_loss:0.051975\n",
      "Epoch [1/2], Iter [933/3125], train_loss:0.083430\n",
      "Epoch [1/2], Iter [934/3125], train_loss:0.066587\n",
      "Epoch [1/2], Iter [935/3125], train_loss:0.087434\n",
      "Epoch [1/2], Iter [936/3125], train_loss:0.087518\n",
      "Epoch [1/2], Iter [937/3125], train_loss:0.075971\n",
      "Epoch [1/2], Iter [938/3125], train_loss:0.060921\n",
      "Epoch [1/2], Iter [939/3125], train_loss:0.059609\n",
      "Epoch [1/2], Iter [940/3125], train_loss:0.053374\n",
      "Epoch [1/2], Iter [941/3125], train_loss:0.059154\n",
      "Epoch [1/2], Iter [942/3125], train_loss:0.037160\n",
      "Epoch [1/2], Iter [943/3125], train_loss:0.094307\n",
      "Epoch [1/2], Iter [944/3125], train_loss:0.069412\n",
      "Epoch [1/2], Iter [945/3125], train_loss:0.093543\n",
      "Epoch [1/2], Iter [946/3125], train_loss:0.057713\n",
      "Epoch [1/2], Iter [947/3125], train_loss:0.050613\n",
      "Epoch [1/2], Iter [948/3125], train_loss:0.101521\n",
      "Epoch [1/2], Iter [949/3125], train_loss:0.099398\n",
      "Epoch [1/2], Iter [950/3125], train_loss:0.098440\n",
      "Epoch [1/2], Iter [951/3125], train_loss:0.036929\n",
      "Epoch [1/2], Iter [952/3125], train_loss:0.062752\n",
      "Epoch [1/2], Iter [953/3125], train_loss:0.048165\n",
      "Epoch [1/2], Iter [954/3125], train_loss:0.075584\n",
      "Epoch [1/2], Iter [955/3125], train_loss:0.080492\n",
      "Epoch [1/2], Iter [956/3125], train_loss:0.087700\n",
      "Epoch [1/2], Iter [957/3125], train_loss:0.043403\n",
      "Epoch [1/2], Iter [958/3125], train_loss:0.069215\n",
      "Epoch [1/2], Iter [959/3125], train_loss:0.044430\n",
      "Epoch [1/2], Iter [960/3125], train_loss:0.066561\n",
      "Epoch [1/2], Iter [961/3125], train_loss:0.106058\n",
      "Epoch [1/2], Iter [962/3125], train_loss:0.066117\n",
      "Epoch [1/2], Iter [963/3125], train_loss:0.075821\n",
      "Epoch [1/2], Iter [964/3125], train_loss:0.076452\n",
      "Epoch [1/2], Iter [965/3125], train_loss:0.068917\n",
      "Epoch [1/2], Iter [966/3125], train_loss:0.073009\n",
      "Epoch [1/2], Iter [967/3125], train_loss:0.066570\n",
      "Epoch [1/2], Iter [968/3125], train_loss:0.078626\n",
      "Epoch [1/2], Iter [969/3125], train_loss:0.071714\n",
      "Epoch [1/2], Iter [970/3125], train_loss:0.073739\n",
      "Epoch [1/2], Iter [971/3125], train_loss:0.036135\n",
      "Epoch [1/2], Iter [972/3125], train_loss:0.077290\n",
      "Epoch [1/2], Iter [973/3125], train_loss:0.108345\n",
      "Epoch [1/2], Iter [974/3125], train_loss:0.085700\n",
      "Epoch [1/2], Iter [975/3125], train_loss:0.081209\n",
      "Epoch [1/2], Iter [976/3125], train_loss:0.034647\n",
      "Epoch [1/2], Iter [977/3125], train_loss:0.056354\n",
      "Epoch [1/2], Iter [978/3125], train_loss:0.075032\n",
      "Epoch [1/2], Iter [979/3125], train_loss:0.076893\n",
      "Epoch [1/2], Iter [980/3125], train_loss:0.076325\n",
      "Epoch [1/2], Iter [981/3125], train_loss:0.069418\n",
      "Epoch [1/2], Iter [982/3125], train_loss:0.020680\n",
      "Epoch [1/2], Iter [983/3125], train_loss:0.103943\n",
      "Epoch [1/2], Iter [984/3125], train_loss:0.051262\n",
      "Epoch [1/2], Iter [985/3125], train_loss:0.060635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [986/3125], train_loss:0.037591\n",
      "Epoch [1/2], Iter [987/3125], train_loss:0.067814\n",
      "Epoch [1/2], Iter [988/3125], train_loss:0.079620\n",
      "Epoch [1/2], Iter [989/3125], train_loss:0.061091\n",
      "Epoch [1/2], Iter [990/3125], train_loss:0.059746\n",
      "Epoch [1/2], Iter [991/3125], train_loss:0.053879\n",
      "Epoch [1/2], Iter [992/3125], train_loss:0.072848\n",
      "Epoch [1/2], Iter [993/3125], train_loss:0.079221\n",
      "Epoch [1/2], Iter [994/3125], train_loss:0.057892\n",
      "Epoch [1/2], Iter [995/3125], train_loss:0.063789\n",
      "Epoch [1/2], Iter [996/3125], train_loss:0.049382\n",
      "Epoch [1/2], Iter [997/3125], train_loss:0.027435\n",
      "Epoch [1/2], Iter [998/3125], train_loss:0.045928\n",
      "Epoch [1/2], Iter [999/3125], train_loss:0.048198\n",
      "Epoch [1/2], Iter [1000/3125], train_loss:0.092894\n",
      "Epoch [1/2], Iter [1001/3125], train_loss:0.083124\n",
      "Epoch [1/2], Iter [1002/3125], train_loss:0.089966\n",
      "Epoch [1/2], Iter [1003/3125], train_loss:0.068988\n",
      "Epoch [1/2], Iter [1004/3125], train_loss:0.077688\n",
      "Epoch [1/2], Iter [1005/3125], train_loss:0.062349\n",
      "Epoch [1/2], Iter [1006/3125], train_loss:0.060515\n",
      "Epoch [1/2], Iter [1007/3125], train_loss:0.089559\n",
      "Epoch [1/2], Iter [1008/3125], train_loss:0.045570\n",
      "Epoch [1/2], Iter [1009/3125], train_loss:0.077456\n",
      "Epoch [1/2], Iter [1010/3125], train_loss:0.041812\n",
      "Epoch [1/2], Iter [1011/3125], train_loss:0.044731\n",
      "Epoch [1/2], Iter [1012/3125], train_loss:0.051256\n",
      "Epoch [1/2], Iter [1013/3125], train_loss:0.075668\n",
      "Epoch [1/2], Iter [1014/3125], train_loss:0.095900\n",
      "Epoch [1/2], Iter [1015/3125], train_loss:0.059299\n",
      "Epoch [1/2], Iter [1016/3125], train_loss:0.060926\n",
      "Epoch [1/2], Iter [1017/3125], train_loss:0.068421\n",
      "Epoch [1/2], Iter [1018/3125], train_loss:0.097368\n",
      "Epoch [1/2], Iter [1019/3125], train_loss:0.033662\n",
      "Epoch [1/2], Iter [1020/3125], train_loss:0.136685\n",
      "Epoch [1/2], Iter [1021/3125], train_loss:0.056440\n",
      "Epoch [1/2], Iter [1022/3125], train_loss:0.075458\n",
      "Epoch [1/2], Iter [1023/3125], train_loss:0.045817\n",
      "Epoch [1/2], Iter [1024/3125], train_loss:0.053181\n",
      "Epoch [1/2], Iter [1025/3125], train_loss:0.063542\n",
      "Epoch [1/2], Iter [1026/3125], train_loss:0.069446\n",
      "Epoch [1/2], Iter [1027/3125], train_loss:0.051694\n",
      "Epoch [1/2], Iter [1028/3125], train_loss:0.054209\n",
      "Epoch [1/2], Iter [1029/3125], train_loss:0.119787\n",
      "Epoch [1/2], Iter [1030/3125], train_loss:0.098382\n",
      "Epoch [1/2], Iter [1031/3125], train_loss:0.069575\n",
      "Epoch [1/2], Iter [1032/3125], train_loss:0.116773\n",
      "Epoch [1/2], Iter [1033/3125], train_loss:0.063445\n",
      "Epoch [1/2], Iter [1034/3125], train_loss:0.076749\n",
      "Epoch [1/2], Iter [1035/3125], train_loss:0.086057\n",
      "Epoch [1/2], Iter [1036/3125], train_loss:0.064961\n",
      "Epoch [1/2], Iter [1037/3125], train_loss:0.055600\n",
      "Epoch [1/2], Iter [1038/3125], train_loss:0.040970\n",
      "Epoch [1/2], Iter [1039/3125], train_loss:0.091605\n",
      "Epoch [1/2], Iter [1040/3125], train_loss:0.091537\n",
      "Epoch [1/2], Iter [1041/3125], train_loss:0.081064\n",
      "Epoch [1/2], Iter [1042/3125], train_loss:0.086757\n",
      "Epoch [1/2], Iter [1043/3125], train_loss:0.083962\n",
      "Epoch [1/2], Iter [1044/3125], train_loss:0.104746\n",
      "Epoch [1/2], Iter [1045/3125], train_loss:0.063942\n",
      "Epoch [1/2], Iter [1046/3125], train_loss:0.043309\n",
      "Epoch [1/2], Iter [1047/3125], train_loss:0.090998\n",
      "Epoch [1/2], Iter [1048/3125], train_loss:0.032485\n",
      "Epoch [1/2], Iter [1049/3125], train_loss:0.095370\n",
      "Epoch [1/2], Iter [1050/3125], train_loss:0.050759\n",
      "Epoch [1/2], Iter [1051/3125], train_loss:0.069511\n",
      "Epoch [1/2], Iter [1052/3125], train_loss:0.089467\n",
      "Epoch [1/2], Iter [1053/3125], train_loss:0.079172\n",
      "Epoch [1/2], Iter [1054/3125], train_loss:0.102735\n",
      "Epoch [1/2], Iter [1055/3125], train_loss:0.063806\n",
      "Epoch [1/2], Iter [1056/3125], train_loss:0.079286\n",
      "Epoch [1/2], Iter [1057/3125], train_loss:0.077189\n",
      "Epoch [1/2], Iter [1058/3125], train_loss:0.051110\n",
      "Epoch [1/2], Iter [1059/3125], train_loss:0.055856\n",
      "Epoch [1/2], Iter [1060/3125], train_loss:0.067028\n",
      "Epoch [1/2], Iter [1061/3125], train_loss:0.063569\n",
      "Epoch [1/2], Iter [1062/3125], train_loss:0.068734\n",
      "Epoch [1/2], Iter [1063/3125], train_loss:0.092909\n",
      "Epoch [1/2], Iter [1064/3125], train_loss:0.093629\n",
      "Epoch [1/2], Iter [1065/3125], train_loss:0.067477\n",
      "Epoch [1/2], Iter [1066/3125], train_loss:0.060750\n",
      "Epoch [1/2], Iter [1067/3125], train_loss:0.065684\n",
      "Epoch [1/2], Iter [1068/3125], train_loss:0.053156\n",
      "Epoch [1/2], Iter [1069/3125], train_loss:0.048712\n",
      "Epoch [1/2], Iter [1070/3125], train_loss:0.049419\n",
      "Epoch [1/2], Iter [1071/3125], train_loss:0.060127\n",
      "Epoch [1/2], Iter [1072/3125], train_loss:0.034652\n",
      "Epoch [1/2], Iter [1073/3125], train_loss:0.040840\n",
      "Epoch [1/2], Iter [1074/3125], train_loss:0.091034\n",
      "Epoch [1/2], Iter [1075/3125], train_loss:0.065437\n",
      "Epoch [1/2], Iter [1076/3125], train_loss:0.094817\n",
      "Epoch [1/2], Iter [1077/3125], train_loss:0.092368\n",
      "Epoch [1/2], Iter [1078/3125], train_loss:0.060444\n",
      "Epoch [1/2], Iter [1079/3125], train_loss:0.052913\n",
      "Epoch [1/2], Iter [1080/3125], train_loss:0.062483\n",
      "Epoch [1/2], Iter [1081/3125], train_loss:0.113684\n",
      "Epoch [1/2], Iter [1082/3125], train_loss:0.044885\n",
      "Epoch [1/2], Iter [1083/3125], train_loss:0.075739\n",
      "Epoch [1/2], Iter [1084/3125], train_loss:0.053488\n",
      "Epoch [1/2], Iter [1085/3125], train_loss:0.089901\n",
      "Epoch [1/2], Iter [1086/3125], train_loss:0.061393\n",
      "Epoch [1/2], Iter [1087/3125], train_loss:0.085048\n",
      "Epoch [1/2], Iter [1088/3125], train_loss:0.059352\n",
      "Epoch [1/2], Iter [1089/3125], train_loss:0.059604\n",
      "Epoch [1/2], Iter [1090/3125], train_loss:0.089003\n",
      "Epoch [1/2], Iter [1091/3125], train_loss:0.058759\n",
      "Epoch [1/2], Iter [1092/3125], train_loss:0.075966\n",
      "Epoch [1/2], Iter [1093/3125], train_loss:0.091234\n",
      "Epoch [1/2], Iter [1094/3125], train_loss:0.083317\n",
      "Epoch [1/2], Iter [1095/3125], train_loss:0.060966\n",
      "Epoch [1/2], Iter [1096/3125], train_loss:0.061635\n",
      "Epoch [1/2], Iter [1097/3125], train_loss:0.053883\n",
      "Epoch [1/2], Iter [1098/3125], train_loss:0.080749\n",
      "Epoch [1/2], Iter [1099/3125], train_loss:0.071457\n",
      "Epoch [1/2], Iter [1100/3125], train_loss:0.091418\n",
      "Epoch [1/2], Iter [1101/3125], train_loss:0.113359\n",
      "Epoch [1/2], Iter [1102/3125], train_loss:0.070664\n",
      "Epoch [1/2], Iter [1103/3125], train_loss:0.055264\n",
      "Epoch [1/2], Iter [1104/3125], train_loss:0.051449\n",
      "Epoch [1/2], Iter [1105/3125], train_loss:0.103443\n",
      "Epoch [1/2], Iter [1106/3125], train_loss:0.051545\n",
      "Epoch [1/2], Iter [1107/3125], train_loss:0.029491\n",
      "Epoch [1/2], Iter [1108/3125], train_loss:0.056622\n",
      "Epoch [1/2], Iter [1109/3125], train_loss:0.055818\n",
      "Epoch [1/2], Iter [1110/3125], train_loss:0.090003\n",
      "Epoch [1/2], Iter [1111/3125], train_loss:0.064216\n",
      "Epoch [1/2], Iter [1112/3125], train_loss:0.037958\n",
      "Epoch [1/2], Iter [1113/3125], train_loss:0.056145\n",
      "Epoch [1/2], Iter [1114/3125], train_loss:0.060302\n",
      "Epoch [1/2], Iter [1115/3125], train_loss:0.074383\n",
      "Epoch [1/2], Iter [1116/3125], train_loss:0.076622\n",
      "Epoch [1/2], Iter [1117/3125], train_loss:0.080233\n",
      "Epoch [1/2], Iter [1118/3125], train_loss:0.052805\n",
      "Epoch [1/2], Iter [1119/3125], train_loss:0.056796\n",
      "Epoch [1/2], Iter [1120/3125], train_loss:0.083323\n",
      "Epoch [1/2], Iter [1121/3125], train_loss:0.071229\n",
      "Epoch [1/2], Iter [1122/3125], train_loss:0.051466\n",
      "Epoch [1/2], Iter [1123/3125], train_loss:0.093439\n",
      "Epoch [1/2], Iter [1124/3125], train_loss:0.067538\n",
      "Epoch [1/2], Iter [1125/3125], train_loss:0.100750\n",
      "Epoch [1/2], Iter [1126/3125], train_loss:0.071976\n",
      "Epoch [1/2], Iter [1127/3125], train_loss:0.060272\n",
      "Epoch [1/2], Iter [1128/3125], train_loss:0.036088\n",
      "Epoch [1/2], Iter [1129/3125], train_loss:0.035010\n",
      "Epoch [1/2], Iter [1130/3125], train_loss:0.126011\n",
      "Epoch [1/2], Iter [1131/3125], train_loss:0.106866\n",
      "Epoch [1/2], Iter [1132/3125], train_loss:0.070480\n",
      "Epoch [1/2], Iter [1133/3125], train_loss:0.060872\n",
      "Epoch [1/2], Iter [1134/3125], train_loss:0.105912\n",
      "Epoch [1/2], Iter [1135/3125], train_loss:0.036590\n",
      "Epoch [1/2], Iter [1136/3125], train_loss:0.054868\n",
      "Epoch [1/2], Iter [1137/3125], train_loss:0.050877\n",
      "Epoch [1/2], Iter [1138/3125], train_loss:0.066920\n",
      "Epoch [1/2], Iter [1139/3125], train_loss:0.055382\n",
      "Epoch [1/2], Iter [1140/3125], train_loss:0.105463\n",
      "Epoch [1/2], Iter [1141/3125], train_loss:0.053746\n",
      "Epoch [1/2], Iter [1142/3125], train_loss:0.053149\n",
      "Epoch [1/2], Iter [1143/3125], train_loss:0.072852\n",
      "Epoch [1/2], Iter [1144/3125], train_loss:0.054036\n",
      "Epoch [1/2], Iter [1145/3125], train_loss:0.054626\n",
      "Epoch [1/2], Iter [1146/3125], train_loss:0.068747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [1147/3125], train_loss:0.057350\n",
      "Epoch [1/2], Iter [1148/3125], train_loss:0.082387\n",
      "Epoch [1/2], Iter [1149/3125], train_loss:0.049732\n",
      "Epoch [1/2], Iter [1150/3125], train_loss:0.062127\n",
      "Epoch [1/2], Iter [1151/3125], train_loss:0.059988\n",
      "Epoch [1/2], Iter [1152/3125], train_loss:0.046885\n",
      "Epoch [1/2], Iter [1153/3125], train_loss:0.063260\n",
      "Epoch [1/2], Iter [1154/3125], train_loss:0.076795\n",
      "Epoch [1/2], Iter [1155/3125], train_loss:0.039343\n",
      "Epoch [1/2], Iter [1156/3125], train_loss:0.044740\n",
      "Epoch [1/2], Iter [1157/3125], train_loss:0.079429\n",
      "Epoch [1/2], Iter [1158/3125], train_loss:0.080212\n",
      "Epoch [1/2], Iter [1159/3125], train_loss:0.072169\n",
      "Epoch [1/2], Iter [1160/3125], train_loss:0.065028\n",
      "Epoch [1/2], Iter [1161/3125], train_loss:0.062723\n",
      "Epoch [1/2], Iter [1162/3125], train_loss:0.058256\n",
      "Epoch [1/2], Iter [1163/3125], train_loss:0.069095\n",
      "Epoch [1/2], Iter [1164/3125], train_loss:0.047539\n",
      "Epoch [1/2], Iter [1165/3125], train_loss:0.083530\n",
      "Epoch [1/2], Iter [1166/3125], train_loss:0.086239\n",
      "Epoch [1/2], Iter [1167/3125], train_loss:0.057173\n",
      "Epoch [1/2], Iter [1168/3125], train_loss:0.052767\n",
      "Epoch [1/2], Iter [1169/3125], train_loss:0.082897\n",
      "Epoch [1/2], Iter [1170/3125], train_loss:0.070313\n",
      "Epoch [1/2], Iter [1171/3125], train_loss:0.096355\n",
      "Epoch [1/2], Iter [1172/3125], train_loss:0.068814\n",
      "Epoch [1/2], Iter [1173/3125], train_loss:0.061837\n",
      "Epoch [1/2], Iter [1174/3125], train_loss:0.072589\n",
      "Epoch [1/2], Iter [1175/3125], train_loss:0.063685\n",
      "Epoch [1/2], Iter [1176/3125], train_loss:0.060172\n",
      "Epoch [1/2], Iter [1177/3125], train_loss:0.065577\n",
      "Epoch [1/2], Iter [1178/3125], train_loss:0.064333\n",
      "Epoch [1/2], Iter [1179/3125], train_loss:0.076662\n",
      "Epoch [1/2], Iter [1180/3125], train_loss:0.053044\n",
      "Epoch [1/2], Iter [1181/3125], train_loss:0.037250\n",
      "Epoch [1/2], Iter [1182/3125], train_loss:0.060777\n",
      "Epoch [1/2], Iter [1183/3125], train_loss:0.070558\n",
      "Epoch [1/2], Iter [1184/3125], train_loss:0.085242\n",
      "Epoch [1/2], Iter [1185/3125], train_loss:0.040594\n",
      "Epoch [1/2], Iter [1186/3125], train_loss:0.034206\n",
      "Epoch [1/2], Iter [1187/3125], train_loss:0.105238\n",
      "Epoch [1/2], Iter [1188/3125], train_loss:0.072560\n",
      "Epoch [1/2], Iter [1189/3125], train_loss:0.069086\n",
      "Epoch [1/2], Iter [1190/3125], train_loss:0.120019\n",
      "Epoch [1/2], Iter [1191/3125], train_loss:0.056550\n",
      "Epoch [1/2], Iter [1192/3125], train_loss:0.072585\n",
      "Epoch [1/2], Iter [1193/3125], train_loss:0.076867\n",
      "Epoch [1/2], Iter [1194/3125], train_loss:0.062452\n",
      "Epoch [1/2], Iter [1195/3125], train_loss:0.095873\n",
      "Epoch [1/2], Iter [1196/3125], train_loss:0.025498\n",
      "Epoch [1/2], Iter [1197/3125], train_loss:0.035894\n",
      "Epoch [1/2], Iter [1198/3125], train_loss:0.098561\n",
      "Epoch [1/2], Iter [1199/3125], train_loss:0.076576\n",
      "Epoch [1/2], Iter [1200/3125], train_loss:0.055447\n",
      "Epoch [1/2], Iter [1201/3125], train_loss:0.052262\n",
      "Epoch [1/2], Iter [1202/3125], train_loss:0.041633\n",
      "Epoch [1/2], Iter [1203/3125], train_loss:0.045114\n",
      "Epoch [1/2], Iter [1204/3125], train_loss:0.093328\n",
      "Epoch [1/2], Iter [1205/3125], train_loss:0.056414\n",
      "Epoch [1/2], Iter [1206/3125], train_loss:0.036658\n",
      "Epoch [1/2], Iter [1207/3125], train_loss:0.044359\n",
      "Epoch [1/2], Iter [1208/3125], train_loss:0.080115\n",
      "Epoch [1/2], Iter [1209/3125], train_loss:0.098730\n",
      "Epoch [1/2], Iter [1210/3125], train_loss:0.100679\n",
      "Epoch [1/2], Iter [1211/3125], train_loss:0.057707\n",
      "Epoch [1/2], Iter [1212/3125], train_loss:0.069084\n",
      "Epoch [1/2], Iter [1213/3125], train_loss:0.048492\n",
      "Epoch [1/2], Iter [1214/3125], train_loss:0.070946\n",
      "Epoch [1/2], Iter [1215/3125], train_loss:0.113210\n",
      "Epoch [1/2], Iter [1216/3125], train_loss:0.127455\n",
      "Epoch [1/2], Iter [1217/3125], train_loss:0.047101\n",
      "Epoch [1/2], Iter [1218/3125], train_loss:0.061642\n",
      "Epoch [1/2], Iter [1219/3125], train_loss:0.078047\n",
      "Epoch [1/2], Iter [1220/3125], train_loss:0.080457\n",
      "Epoch [1/2], Iter [1221/3125], train_loss:0.044102\n",
      "Epoch [1/2], Iter [1222/3125], train_loss:0.064150\n",
      "Epoch [1/2], Iter [1223/3125], train_loss:0.057298\n",
      "Epoch [1/2], Iter [1224/3125], train_loss:0.071499\n",
      "Epoch [1/2], Iter [1225/3125], train_loss:0.053042\n",
      "Epoch [1/2], Iter [1226/3125], train_loss:0.086983\n",
      "Epoch [1/2], Iter [1227/3125], train_loss:0.057042\n",
      "Epoch [1/2], Iter [1228/3125], train_loss:0.065075\n",
      "Epoch [1/2], Iter [1229/3125], train_loss:0.061014\n",
      "Epoch [1/2], Iter [1230/3125], train_loss:0.058813\n",
      "Epoch [1/2], Iter [1231/3125], train_loss:0.056526\n",
      "Epoch [1/2], Iter [1232/3125], train_loss:0.043590\n",
      "Epoch [1/2], Iter [1233/3125], train_loss:0.040934\n",
      "Epoch [1/2], Iter [1234/3125], train_loss:0.044075\n",
      "Epoch [1/2], Iter [1235/3125], train_loss:0.029717\n",
      "Epoch [1/2], Iter [1236/3125], train_loss:0.027465\n",
      "Epoch [1/2], Iter [1237/3125], train_loss:0.065296\n",
      "Epoch [1/2], Iter [1238/3125], train_loss:0.058775\n",
      "Epoch [1/2], Iter [1239/3125], train_loss:0.067117\n",
      "Epoch [1/2], Iter [1240/3125], train_loss:0.029257\n",
      "Epoch [1/2], Iter [1241/3125], train_loss:0.052835\n",
      "Epoch [1/2], Iter [1242/3125], train_loss:0.047112\n",
      "Epoch [1/2], Iter [1243/3125], train_loss:0.066244\n",
      "Epoch [1/2], Iter [1244/3125], train_loss:0.060530\n",
      "Epoch [1/2], Iter [1245/3125], train_loss:0.055298\n",
      "Epoch [1/2], Iter [1246/3125], train_loss:0.064894\n",
      "Epoch [1/2], Iter [1247/3125], train_loss:0.082662\n",
      "Epoch [1/2], Iter [1248/3125], train_loss:0.076094\n",
      "Epoch [1/2], Iter [1249/3125], train_loss:0.061603\n",
      "Epoch [1/2], Iter [1250/3125], train_loss:0.051030\n",
      "Epoch [1/2], Iter [1251/3125], train_loss:0.069845\n",
      "Epoch [1/2], Iter [1252/3125], train_loss:0.067748\n",
      "Epoch [1/2], Iter [1253/3125], train_loss:0.061906\n",
      "Epoch [1/2], Iter [1254/3125], train_loss:0.056520\n",
      "Epoch [1/2], Iter [1255/3125], train_loss:0.042112\n",
      "Epoch [1/2], Iter [1256/3125], train_loss:0.100822\n",
      "Epoch [1/2], Iter [1257/3125], train_loss:0.063709\n",
      "Epoch [1/2], Iter [1258/3125], train_loss:0.104122\n",
      "Epoch [1/2], Iter [1259/3125], train_loss:0.065639\n",
      "Epoch [1/2], Iter [1260/3125], train_loss:0.035611\n",
      "Epoch [1/2], Iter [1261/3125], train_loss:0.055489\n",
      "Epoch [1/2], Iter [1262/3125], train_loss:0.064043\n",
      "Epoch [1/2], Iter [1263/3125], train_loss:0.090029\n",
      "Epoch [1/2], Iter [1264/3125], train_loss:0.076312\n",
      "Epoch [1/2], Iter [1265/3125], train_loss:0.045376\n",
      "Epoch [1/2], Iter [1266/3125], train_loss:0.063570\n",
      "Epoch [1/2], Iter [1267/3125], train_loss:0.025818\n",
      "Epoch [1/2], Iter [1268/3125], train_loss:0.109694\n",
      "Epoch [1/2], Iter [1269/3125], train_loss:0.052160\n",
      "Epoch [1/2], Iter [1270/3125], train_loss:0.059498\n",
      "Epoch [1/2], Iter [1271/3125], train_loss:0.072778\n",
      "Epoch [1/2], Iter [1272/3125], train_loss:0.086213\n",
      "Epoch [1/2], Iter [1273/3125], train_loss:0.028716\n",
      "Epoch [1/2], Iter [1274/3125], train_loss:0.036459\n",
      "Epoch [1/2], Iter [1275/3125], train_loss:0.073973\n",
      "Epoch [1/2], Iter [1276/3125], train_loss:0.064626\n",
      "Epoch [1/2], Iter [1277/3125], train_loss:0.038327\n",
      "Epoch [1/2], Iter [1278/3125], train_loss:0.050703\n",
      "Epoch [1/2], Iter [1279/3125], train_loss:0.068968\n",
      "Epoch [1/2], Iter [1280/3125], train_loss:0.097951\n",
      "Epoch [1/2], Iter [1281/3125], train_loss:0.045419\n",
      "Epoch [1/2], Iter [1282/3125], train_loss:0.072516\n",
      "Epoch [1/2], Iter [1283/3125], train_loss:0.055500\n",
      "Epoch [1/2], Iter [1284/3125], train_loss:0.082389\n",
      "Epoch [1/2], Iter [1285/3125], train_loss:0.053246\n",
      "Epoch [1/2], Iter [1286/3125], train_loss:0.035698\n",
      "Epoch [1/2], Iter [1287/3125], train_loss:0.047823\n",
      "Epoch [1/2], Iter [1288/3125], train_loss:0.063062\n",
      "Epoch [1/2], Iter [1289/3125], train_loss:0.048336\n",
      "Epoch [1/2], Iter [1290/3125], train_loss:0.062241\n",
      "Epoch [1/2], Iter [1291/3125], train_loss:0.033438\n",
      "Epoch [1/2], Iter [1292/3125], train_loss:0.082936\n",
      "Epoch [1/2], Iter [1293/3125], train_loss:0.065842\n",
      "Epoch [1/2], Iter [1294/3125], train_loss:0.059168\n",
      "Epoch [1/2], Iter [1295/3125], train_loss:0.083336\n",
      "Epoch [1/2], Iter [1296/3125], train_loss:0.059518\n",
      "Epoch [1/2], Iter [1297/3125], train_loss:0.112821\n",
      "Epoch [1/2], Iter [1298/3125], train_loss:0.064456\n",
      "Epoch [1/2], Iter [1299/3125], train_loss:0.058668\n",
      "Epoch [1/2], Iter [1300/3125], train_loss:0.064106\n",
      "Epoch [1/2], Iter [1301/3125], train_loss:0.056958\n",
      "Epoch [1/2], Iter [1302/3125], train_loss:0.073535\n",
      "Epoch [1/2], Iter [1303/3125], train_loss:0.070046\n",
      "Epoch [1/2], Iter [1304/3125], train_loss:0.059019\n",
      "Epoch [1/2], Iter [1305/3125], train_loss:0.054772\n",
      "Epoch [1/2], Iter [1306/3125], train_loss:0.076289\n",
      "Epoch [1/2], Iter [1307/3125], train_loss:0.041246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [1308/3125], train_loss:0.069067\n",
      "Epoch [1/2], Iter [1309/3125], train_loss:0.058699\n",
      "Epoch [1/2], Iter [1310/3125], train_loss:0.065380\n",
      "Epoch [1/2], Iter [1311/3125], train_loss:0.075818\n",
      "Epoch [1/2], Iter [1312/3125], train_loss:0.052236\n",
      "Epoch [1/2], Iter [1313/3125], train_loss:0.082141\n",
      "Epoch [1/2], Iter [1314/3125], train_loss:0.069464\n",
      "Epoch [1/2], Iter [1315/3125], train_loss:0.091378\n",
      "Epoch [1/2], Iter [1316/3125], train_loss:0.064676\n",
      "Epoch [1/2], Iter [1317/3125], train_loss:0.067352\n",
      "Epoch [1/2], Iter [1318/3125], train_loss:0.057192\n",
      "Epoch [1/2], Iter [1319/3125], train_loss:0.074985\n",
      "Epoch [1/2], Iter [1320/3125], train_loss:0.067657\n",
      "Epoch [1/2], Iter [1321/3125], train_loss:0.040115\n",
      "Epoch [1/2], Iter [1322/3125], train_loss:0.076123\n",
      "Epoch [1/2], Iter [1323/3125], train_loss:0.043271\n",
      "Epoch [1/2], Iter [1324/3125], train_loss:0.053576\n",
      "Epoch [1/2], Iter [1325/3125], train_loss:0.040913\n",
      "Epoch [1/2], Iter [1326/3125], train_loss:0.059898\n",
      "Epoch [1/2], Iter [1327/3125], train_loss:0.054811\n",
      "Epoch [1/2], Iter [1328/3125], train_loss:0.066339\n",
      "Epoch [1/2], Iter [1329/3125], train_loss:0.071503\n",
      "Epoch [1/2], Iter [1330/3125], train_loss:0.081515\n",
      "Epoch [1/2], Iter [1331/3125], train_loss:0.074402\n",
      "Epoch [1/2], Iter [1332/3125], train_loss:0.057387\n",
      "Epoch [1/2], Iter [1333/3125], train_loss:0.055268\n",
      "Epoch [1/2], Iter [1334/3125], train_loss:0.102751\n",
      "Epoch [1/2], Iter [1335/3125], train_loss:0.073028\n",
      "Epoch [1/2], Iter [1336/3125], train_loss:0.047864\n",
      "Epoch [1/2], Iter [1337/3125], train_loss:0.036029\n",
      "Epoch [1/2], Iter [1338/3125], train_loss:0.054840\n",
      "Epoch [1/2], Iter [1339/3125], train_loss:0.050733\n",
      "Epoch [1/2], Iter [1340/3125], train_loss:0.056505\n",
      "Epoch [1/2], Iter [1341/3125], train_loss:0.073293\n",
      "Epoch [1/2], Iter [1342/3125], train_loss:0.075892\n",
      "Epoch [1/2], Iter [1343/3125], train_loss:0.110042\n",
      "Epoch [1/2], Iter [1344/3125], train_loss:0.054741\n",
      "Epoch [1/2], Iter [1345/3125], train_loss:0.060880\n",
      "Epoch [1/2], Iter [1346/3125], train_loss:0.078891\n",
      "Epoch [1/2], Iter [1347/3125], train_loss:0.062290\n",
      "Epoch [1/2], Iter [1348/3125], train_loss:0.074273\n",
      "Epoch [1/2], Iter [1349/3125], train_loss:0.063277\n",
      "Epoch [1/2], Iter [1350/3125], train_loss:0.054052\n",
      "Epoch [1/2], Iter [1351/3125], train_loss:0.044630\n",
      "Epoch [1/2], Iter [1352/3125], train_loss:0.053519\n",
      "Epoch [1/2], Iter [1353/3125], train_loss:0.067007\n",
      "Epoch [1/2], Iter [1354/3125], train_loss:0.069891\n",
      "Epoch [1/2], Iter [1355/3125], train_loss:0.074535\n",
      "Epoch [1/2], Iter [1356/3125], train_loss:0.067320\n",
      "Epoch [1/2], Iter [1357/3125], train_loss:0.066666\n",
      "Epoch [1/2], Iter [1358/3125], train_loss:0.070315\n",
      "Epoch [1/2], Iter [1359/3125], train_loss:0.065148\n",
      "Epoch [1/2], Iter [1360/3125], train_loss:0.093950\n",
      "Epoch [1/2], Iter [1361/3125], train_loss:0.064184\n",
      "Epoch [1/2], Iter [1362/3125], train_loss:0.022358\n",
      "Epoch [1/2], Iter [1363/3125], train_loss:0.059711\n",
      "Epoch [1/2], Iter [1364/3125], train_loss:0.076467\n",
      "Epoch [1/2], Iter [1365/3125], train_loss:0.059158\n",
      "Epoch [1/2], Iter [1366/3125], train_loss:0.055849\n",
      "Epoch [1/2], Iter [1367/3125], train_loss:0.100875\n",
      "Epoch [1/2], Iter [1368/3125], train_loss:0.039223\n",
      "Epoch [1/2], Iter [1369/3125], train_loss:0.058115\n",
      "Epoch [1/2], Iter [1370/3125], train_loss:0.101089\n",
      "Epoch [1/2], Iter [1371/3125], train_loss:0.048331\n",
      "Epoch [1/2], Iter [1372/3125], train_loss:0.057206\n",
      "Epoch [1/2], Iter [1373/3125], train_loss:0.039609\n",
      "Epoch [1/2], Iter [1374/3125], train_loss:0.040379\n",
      "Epoch [1/2], Iter [1375/3125], train_loss:0.053494\n",
      "Epoch [1/2], Iter [1376/3125], train_loss:0.083363\n",
      "Epoch [1/2], Iter [1377/3125], train_loss:0.075522\n",
      "Epoch [1/2], Iter [1378/3125], train_loss:0.095169\n",
      "Epoch [1/2], Iter [1379/3125], train_loss:0.078565\n",
      "Epoch [1/2], Iter [1380/3125], train_loss:0.088956\n",
      "Epoch [1/2], Iter [1381/3125], train_loss:0.057567\n",
      "Epoch [1/2], Iter [1382/3125], train_loss:0.104427\n",
      "Epoch [1/2], Iter [1383/3125], train_loss:0.062440\n",
      "Epoch [1/2], Iter [1384/3125], train_loss:0.084636\n",
      "Epoch [1/2], Iter [1385/3125], train_loss:0.078697\n",
      "Epoch [1/2], Iter [1386/3125], train_loss:0.059165\n",
      "Epoch [1/2], Iter [1387/3125], train_loss:0.071965\n",
      "Epoch [1/2], Iter [1388/3125], train_loss:0.062032\n",
      "Epoch [1/2], Iter [1389/3125], train_loss:0.084878\n",
      "Epoch [1/2], Iter [1390/3125], train_loss:0.076452\n",
      "Epoch [1/2], Iter [1391/3125], train_loss:0.077331\n",
      "Epoch [1/2], Iter [1392/3125], train_loss:0.077292\n",
      "Epoch [1/2], Iter [1393/3125], train_loss:0.052816\n",
      "Epoch [1/2], Iter [1394/3125], train_loss:0.073340\n",
      "Epoch [1/2], Iter [1395/3125], train_loss:0.047919\n",
      "Epoch [1/2], Iter [1396/3125], train_loss:0.070727\n",
      "Epoch [1/2], Iter [1397/3125], train_loss:0.086594\n",
      "Epoch [1/2], Iter [1398/3125], train_loss:0.048007\n",
      "Epoch [1/2], Iter [1399/3125], train_loss:0.067961\n",
      "Epoch [1/2], Iter [1400/3125], train_loss:0.071931\n",
      "Epoch [1/2], Iter [1401/3125], train_loss:0.065579\n",
      "Epoch [1/2], Iter [1402/3125], train_loss:0.066283\n",
      "Epoch [1/2], Iter [1403/3125], train_loss:0.103649\n",
      "Epoch [1/2], Iter [1404/3125], train_loss:0.058382\n",
      "Epoch [1/2], Iter [1405/3125], train_loss:0.056717\n",
      "Epoch [1/2], Iter [1406/3125], train_loss:0.055356\n",
      "Epoch [1/2], Iter [1407/3125], train_loss:0.048075\n",
      "Epoch [1/2], Iter [1408/3125], train_loss:0.059935\n",
      "Epoch [1/2], Iter [1409/3125], train_loss:0.082990\n",
      "Epoch [1/2], Iter [1410/3125], train_loss:0.082503\n",
      "Epoch [1/2], Iter [1411/3125], train_loss:0.075653\n",
      "Epoch [1/2], Iter [1412/3125], train_loss:0.044993\n",
      "Epoch [1/2], Iter [1413/3125], train_loss:0.123454\n",
      "Epoch [1/2], Iter [1414/3125], train_loss:0.061871\n",
      "Epoch [1/2], Iter [1415/3125], train_loss:0.054964\n",
      "Epoch [1/2], Iter [1416/3125], train_loss:0.049831\n",
      "Epoch [1/2], Iter [1417/3125], train_loss:0.047856\n",
      "Epoch [1/2], Iter [1418/3125], train_loss:0.061028\n",
      "Epoch [1/2], Iter [1419/3125], train_loss:0.071758\n",
      "Epoch [1/2], Iter [1420/3125], train_loss:0.070022\n",
      "Epoch [1/2], Iter [1421/3125], train_loss:0.043766\n",
      "Epoch [1/2], Iter [1422/3125], train_loss:0.051223\n",
      "Epoch [1/2], Iter [1423/3125], train_loss:0.059658\n",
      "Epoch [1/2], Iter [1424/3125], train_loss:0.055461\n",
      "Epoch [1/2], Iter [1425/3125], train_loss:0.070961\n",
      "Epoch [1/2], Iter [1426/3125], train_loss:0.109766\n",
      "Epoch [1/2], Iter [1427/3125], train_loss:0.054892\n",
      "Epoch [1/2], Iter [1428/3125], train_loss:0.050329\n",
      "Epoch [1/2], Iter [1429/3125], train_loss:0.024136\n",
      "Epoch [1/2], Iter [1430/3125], train_loss:0.069089\n",
      "Epoch [1/2], Iter [1431/3125], train_loss:0.082888\n",
      "Epoch [1/2], Iter [1432/3125], train_loss:0.086450\n",
      "Epoch [1/2], Iter [1433/3125], train_loss:0.086286\n",
      "Epoch [1/2], Iter [1434/3125], train_loss:0.063713\n",
      "Epoch [1/2], Iter [1435/3125], train_loss:0.046686\n",
      "Epoch [1/2], Iter [1436/3125], train_loss:0.047476\n",
      "Epoch [1/2], Iter [1437/3125], train_loss:0.072645\n",
      "Epoch [1/2], Iter [1438/3125], train_loss:0.081674\n",
      "Epoch [1/2], Iter [1439/3125], train_loss:0.076656\n",
      "Epoch [1/2], Iter [1440/3125], train_loss:0.034710\n",
      "Epoch [1/2], Iter [1441/3125], train_loss:0.093613\n",
      "Epoch [1/2], Iter [1442/3125], train_loss:0.079334\n",
      "Epoch [1/2], Iter [1443/3125], train_loss:0.057202\n",
      "Epoch [1/2], Iter [1444/3125], train_loss:0.082810\n",
      "Epoch [1/2], Iter [1445/3125], train_loss:0.063731\n",
      "Epoch [1/2], Iter [1446/3125], train_loss:0.085478\n",
      "Epoch [1/2], Iter [1447/3125], train_loss:0.054432\n",
      "Epoch [1/2], Iter [1448/3125], train_loss:0.048268\n",
      "Epoch [1/2], Iter [1449/3125], train_loss:0.062852\n",
      "Epoch [1/2], Iter [1450/3125], train_loss:0.073689\n",
      "Epoch [1/2], Iter [1451/3125], train_loss:0.074127\n",
      "Epoch [1/2], Iter [1452/3125], train_loss:0.090930\n",
      "Epoch [1/2], Iter [1453/3125], train_loss:0.036279\n",
      "Epoch [1/2], Iter [1454/3125], train_loss:0.048434\n",
      "Epoch [1/2], Iter [1455/3125], train_loss:0.048179\n",
      "Epoch [1/2], Iter [1456/3125], train_loss:0.070204\n",
      "Epoch [1/2], Iter [1457/3125], train_loss:0.065104\n",
      "Epoch [1/2], Iter [1458/3125], train_loss:0.035224\n",
      "Epoch [1/2], Iter [1459/3125], train_loss:0.098810\n",
      "Epoch [1/2], Iter [1460/3125], train_loss:0.054749\n",
      "Epoch [1/2], Iter [1461/3125], train_loss:0.045833\n",
      "Epoch [1/2], Iter [1462/3125], train_loss:0.043375\n",
      "Epoch [1/2], Iter [1463/3125], train_loss:0.056820\n",
      "Epoch [1/2], Iter [1464/3125], train_loss:0.069608\n",
      "Epoch [1/2], Iter [1465/3125], train_loss:0.051774\n",
      "Epoch [1/2], Iter [1466/3125], train_loss:0.052715\n",
      "Epoch [1/2], Iter [1467/3125], train_loss:0.097593\n",
      "Epoch [1/2], Iter [1468/3125], train_loss:0.053041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [1469/3125], train_loss:0.049064\n",
      "Epoch [1/2], Iter [1470/3125], train_loss:0.046045\n",
      "Epoch [1/2], Iter [1471/3125], train_loss:0.044542\n",
      "Epoch [1/2], Iter [1472/3125], train_loss:0.071227\n",
      "Epoch [1/2], Iter [1473/3125], train_loss:0.091338\n",
      "Epoch [1/2], Iter [1474/3125], train_loss:0.045170\n",
      "Epoch [1/2], Iter [1475/3125], train_loss:0.066202\n",
      "Epoch [1/2], Iter [1476/3125], train_loss:0.094935\n",
      "Epoch [1/2], Iter [1477/3125], train_loss:0.062110\n",
      "Epoch [1/2], Iter [1478/3125], train_loss:0.054103\n",
      "Epoch [1/2], Iter [1479/3125], train_loss:0.061626\n",
      "Epoch [1/2], Iter [1480/3125], train_loss:0.041887\n",
      "Epoch [1/2], Iter [1481/3125], train_loss:0.069576\n",
      "Epoch [1/2], Iter [1482/3125], train_loss:0.059234\n",
      "Epoch [1/2], Iter [1483/3125], train_loss:0.054864\n",
      "Epoch [1/2], Iter [1484/3125], train_loss:0.034114\n",
      "Epoch [1/2], Iter [1485/3125], train_loss:0.090967\n",
      "Epoch [1/2], Iter [1486/3125], train_loss:0.050541\n",
      "Epoch [1/2], Iter [1487/3125], train_loss:0.066801\n",
      "Epoch [1/2], Iter [1488/3125], train_loss:0.075162\n",
      "Epoch [1/2], Iter [1489/3125], train_loss:0.042652\n",
      "Epoch [1/2], Iter [1490/3125], train_loss:0.072371\n",
      "Epoch [1/2], Iter [1491/3125], train_loss:0.038219\n",
      "Epoch [1/2], Iter [1492/3125], train_loss:0.037537\n",
      "Epoch [1/2], Iter [1493/3125], train_loss:0.079373\n",
      "Epoch [1/2], Iter [1494/3125], train_loss:0.073377\n",
      "Epoch [1/2], Iter [1495/3125], train_loss:0.041809\n",
      "Epoch [1/2], Iter [1496/3125], train_loss:0.064887\n",
      "Epoch [1/2], Iter [1497/3125], train_loss:0.058225\n",
      "Epoch [1/2], Iter [1498/3125], train_loss:0.038329\n",
      "Epoch [1/2], Iter [1499/3125], train_loss:0.067080\n",
      "Epoch [1/2], Iter [1500/3125], train_loss:0.048972\n",
      "Epoch [1/2], Iter [1501/3125], train_loss:0.064772\n",
      "Epoch [1/2], Iter [1502/3125], train_loss:0.048429\n",
      "Epoch [1/2], Iter [1503/3125], train_loss:0.060913\n",
      "Epoch [1/2], Iter [1504/3125], train_loss:0.064597\n",
      "Epoch [1/2], Iter [1505/3125], train_loss:0.051886\n",
      "Epoch [1/2], Iter [1506/3125], train_loss:0.027022\n",
      "Epoch [1/2], Iter [1507/3125], train_loss:0.059435\n",
      "Epoch [1/2], Iter [1508/3125], train_loss:0.024598\n",
      "Epoch [1/2], Iter [1509/3125], train_loss:0.078125\n",
      "Epoch [1/2], Iter [1510/3125], train_loss:0.059248\n",
      "Epoch [1/2], Iter [1511/3125], train_loss:0.064376\n",
      "Epoch [1/2], Iter [1512/3125], train_loss:0.085473\n",
      "Epoch [1/2], Iter [1513/3125], train_loss:0.051975\n",
      "Epoch [1/2], Iter [1514/3125], train_loss:0.063966\n",
      "Epoch [1/2], Iter [1515/3125], train_loss:0.060354\n",
      "Epoch [1/2], Iter [1516/3125], train_loss:0.077393\n",
      "Epoch [1/2], Iter [1517/3125], train_loss:0.090876\n",
      "Epoch [1/2], Iter [1518/3125], train_loss:0.039705\n",
      "Epoch [1/2], Iter [1519/3125], train_loss:0.051554\n",
      "Epoch [1/2], Iter [1520/3125], train_loss:0.048568\n",
      "Epoch [1/2], Iter [1521/3125], train_loss:0.045856\n",
      "Epoch [1/2], Iter [1522/3125], train_loss:0.042794\n",
      "Epoch [1/2], Iter [1523/3125], train_loss:0.055325\n",
      "Epoch [1/2], Iter [1524/3125], train_loss:0.056123\n",
      "Epoch [1/2], Iter [1525/3125], train_loss:0.055300\n",
      "Epoch [1/2], Iter [1526/3125], train_loss:0.068287\n",
      "Epoch [1/2], Iter [1527/3125], train_loss:0.068934\n",
      "Epoch [1/2], Iter [1528/3125], train_loss:0.090264\n",
      "Epoch [1/2], Iter [1529/3125], train_loss:0.086150\n",
      "Epoch [1/2], Iter [1530/3125], train_loss:0.085605\n",
      "Epoch [1/2], Iter [1531/3125], train_loss:0.060180\n",
      "Epoch [1/2], Iter [1532/3125], train_loss:0.053924\n",
      "Epoch [1/2], Iter [1533/3125], train_loss:0.051664\n",
      "Epoch [1/2], Iter [1534/3125], train_loss:0.067069\n",
      "Epoch [1/2], Iter [1535/3125], train_loss:0.078200\n",
      "Epoch [1/2], Iter [1536/3125], train_loss:0.039644\n",
      "Epoch [1/2], Iter [1537/3125], train_loss:0.029653\n",
      "Epoch [1/2], Iter [1538/3125], train_loss:0.082864\n",
      "Epoch [1/2], Iter [1539/3125], train_loss:0.048271\n",
      "Epoch [1/2], Iter [1540/3125], train_loss:0.100229\n",
      "Epoch [1/2], Iter [1541/3125], train_loss:0.079987\n",
      "Epoch [1/2], Iter [1542/3125], train_loss:0.100760\n",
      "Epoch [1/2], Iter [1543/3125], train_loss:0.053410\n",
      "Epoch [1/2], Iter [1544/3125], train_loss:0.073399\n",
      "Epoch [1/2], Iter [1545/3125], train_loss:0.044690\n",
      "Epoch [1/2], Iter [1546/3125], train_loss:0.093413\n",
      "Epoch [1/2], Iter [1547/3125], train_loss:0.079578\n",
      "Epoch [1/2], Iter [1548/3125], train_loss:0.056036\n",
      "Epoch [1/2], Iter [1549/3125], train_loss:0.050954\n",
      "Epoch [1/2], Iter [1550/3125], train_loss:0.055047\n",
      "Epoch [1/2], Iter [1551/3125], train_loss:0.063432\n",
      "Epoch [1/2], Iter [1552/3125], train_loss:0.050429\n",
      "Epoch [1/2], Iter [1553/3125], train_loss:0.087075\n",
      "Epoch [1/2], Iter [1554/3125], train_loss:0.048071\n",
      "Epoch [1/2], Iter [1555/3125], train_loss:0.069939\n",
      "Epoch [1/2], Iter [1556/3125], train_loss:0.055035\n",
      "Epoch [1/2], Iter [1557/3125], train_loss:0.053458\n",
      "Epoch [1/2], Iter [1558/3125], train_loss:0.023761\n",
      "Epoch [1/2], Iter [1559/3125], train_loss:0.069739\n",
      "Epoch [1/2], Iter [1560/3125], train_loss:0.045433\n",
      "Epoch [1/2], Iter [1561/3125], train_loss:0.101361\n",
      "Epoch [1/2], Iter [1562/3125], train_loss:0.056074\n",
      "Epoch [1/2], Iter [1563/3125], train_loss:0.077272\n",
      "Epoch [1/2], Iter [1564/3125], train_loss:0.082052\n",
      "Epoch [1/2], Iter [1565/3125], train_loss:0.016295\n",
      "Epoch [1/2], Iter [1566/3125], train_loss:0.066365\n",
      "Epoch [1/2], Iter [1567/3125], train_loss:0.065722\n",
      "Epoch [1/2], Iter [1568/3125], train_loss:0.057400\n",
      "Epoch [1/2], Iter [1569/3125], train_loss:0.033856\n",
      "Epoch [1/2], Iter [1570/3125], train_loss:0.102682\n",
      "Epoch [1/2], Iter [1571/3125], train_loss:0.044889\n",
      "Epoch [1/2], Iter [1572/3125], train_loss:0.113790\n",
      "Epoch [1/2], Iter [1573/3125], train_loss:0.072076\n",
      "Epoch [1/2], Iter [1574/3125], train_loss:0.072569\n",
      "Epoch [1/2], Iter [1575/3125], train_loss:0.090950\n",
      "Epoch [1/2], Iter [1576/3125], train_loss:0.085775\n",
      "Epoch [1/2], Iter [1577/3125], train_loss:0.053182\n",
      "Epoch [1/2], Iter [1578/3125], train_loss:0.039224\n",
      "Epoch [1/2], Iter [1579/3125], train_loss:0.039575\n",
      "Epoch [1/2], Iter [1580/3125], train_loss:0.052193\n",
      "Epoch [1/2], Iter [1581/3125], train_loss:0.086704\n",
      "Epoch [1/2], Iter [1582/3125], train_loss:0.068953\n",
      "Epoch [1/2], Iter [1583/3125], train_loss:0.093973\n",
      "Epoch [1/2], Iter [1584/3125], train_loss:0.054096\n",
      "Epoch [1/2], Iter [1585/3125], train_loss:0.040414\n",
      "Epoch [1/2], Iter [1586/3125], train_loss:0.081859\n",
      "Epoch [1/2], Iter [1587/3125], train_loss:0.046547\n",
      "Epoch [1/2], Iter [1588/3125], train_loss:0.078302\n",
      "Epoch [1/2], Iter [1589/3125], train_loss:0.066540\n",
      "Epoch [1/2], Iter [1590/3125], train_loss:0.066337\n",
      "Epoch [1/2], Iter [1591/3125], train_loss:0.103384\n",
      "Epoch [1/2], Iter [1592/3125], train_loss:0.107090\n",
      "Epoch [1/2], Iter [1593/3125], train_loss:0.052589\n",
      "Epoch [1/2], Iter [1594/3125], train_loss:0.051050\n",
      "Epoch [1/2], Iter [1595/3125], train_loss:0.057997\n",
      "Epoch [1/2], Iter [1596/3125], train_loss:0.045927\n",
      "Epoch [1/2], Iter [1597/3125], train_loss:0.026922\n",
      "Epoch [1/2], Iter [1598/3125], train_loss:0.079594\n",
      "Epoch [1/2], Iter [1599/3125], train_loss:0.108077\n",
      "Epoch [1/2], Iter [1600/3125], train_loss:0.064568\n",
      "Epoch [1/2], Iter [1601/3125], train_loss:0.067058\n",
      "Epoch [1/2], Iter [1602/3125], train_loss:0.038885\n",
      "Epoch [1/2], Iter [1603/3125], train_loss:0.068173\n",
      "Epoch [1/2], Iter [1604/3125], train_loss:0.067247\n",
      "Epoch [1/2], Iter [1605/3125], train_loss:0.063042\n",
      "Epoch [1/2], Iter [1606/3125], train_loss:0.049664\n",
      "Epoch [1/2], Iter [1607/3125], train_loss:0.090726\n",
      "Epoch [1/2], Iter [1608/3125], train_loss:0.037748\n",
      "Epoch [1/2], Iter [1609/3125], train_loss:0.040481\n",
      "Epoch [1/2], Iter [1610/3125], train_loss:0.034004\n",
      "Epoch [1/2], Iter [1611/3125], train_loss:0.054413\n",
      "Epoch [1/2], Iter [1612/3125], train_loss:0.109730\n",
      "Epoch [1/2], Iter [1613/3125], train_loss:0.073276\n",
      "Epoch [1/2], Iter [1614/3125], train_loss:0.054118\n",
      "Epoch [1/2], Iter [1615/3125], train_loss:0.087692\n",
      "Epoch [1/2], Iter [1616/3125], train_loss:0.082834\n",
      "Epoch [1/2], Iter [1617/3125], train_loss:0.036885\n",
      "Epoch [1/2], Iter [1618/3125], train_loss:0.067564\n",
      "Epoch [1/2], Iter [1619/3125], train_loss:0.072032\n",
      "Epoch [1/2], Iter [1620/3125], train_loss:0.068011\n",
      "Epoch [1/2], Iter [1621/3125], train_loss:0.058409\n",
      "Epoch [1/2], Iter [1622/3125], train_loss:0.071471\n",
      "Epoch [1/2], Iter [1623/3125], train_loss:0.106375\n",
      "Epoch [1/2], Iter [1624/3125], train_loss:0.074669\n",
      "Epoch [1/2], Iter [1625/3125], train_loss:0.067558\n",
      "Epoch [1/2], Iter [1626/3125], train_loss:0.088888\n",
      "Epoch [1/2], Iter [1627/3125], train_loss:0.083325\n",
      "Epoch [1/2], Iter [1628/3125], train_loss:0.038460\n",
      "Epoch [1/2], Iter [1629/3125], train_loss:0.070888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [1630/3125], train_loss:0.063961\n",
      "Epoch [1/2], Iter [1631/3125], train_loss:0.060558\n",
      "Epoch [1/2], Iter [1632/3125], train_loss:0.080888\n",
      "Epoch [1/2], Iter [1633/3125], train_loss:0.057318\n",
      "Epoch [1/2], Iter [1634/3125], train_loss:0.061407\n",
      "Epoch [1/2], Iter [1635/3125], train_loss:0.057165\n",
      "Epoch [1/2], Iter [1636/3125], train_loss:0.061597\n",
      "Epoch [1/2], Iter [1637/3125], train_loss:0.054902\n",
      "Epoch [1/2], Iter [1638/3125], train_loss:0.054311\n",
      "Epoch [1/2], Iter [1639/3125], train_loss:0.030938\n",
      "Epoch [1/2], Iter [1640/3125], train_loss:0.049676\n",
      "Epoch [1/2], Iter [1641/3125], train_loss:0.066437\n",
      "Epoch [1/2], Iter [1642/3125], train_loss:0.076029\n",
      "Epoch [1/2], Iter [1643/3125], train_loss:0.056621\n",
      "Epoch [1/2], Iter [1644/3125], train_loss:0.063559\n",
      "Epoch [1/2], Iter [1645/3125], train_loss:0.062448\n",
      "Epoch [1/2], Iter [1646/3125], train_loss:0.049044\n",
      "Epoch [1/2], Iter [1647/3125], train_loss:0.035747\n",
      "Epoch [1/2], Iter [1648/3125], train_loss:0.072715\n",
      "Epoch [1/2], Iter [1649/3125], train_loss:0.062477\n",
      "Epoch [1/2], Iter [1650/3125], train_loss:0.055026\n",
      "Epoch [1/2], Iter [1651/3125], train_loss:0.064695\n",
      "Epoch [1/2], Iter [1652/3125], train_loss:0.061484\n",
      "Epoch [1/2], Iter [1653/3125], train_loss:0.058785\n",
      "Epoch [1/2], Iter [1654/3125], train_loss:0.036252\n",
      "Epoch [1/2], Iter [1655/3125], train_loss:0.056090\n",
      "Epoch [1/2], Iter [1656/3125], train_loss:0.041533\n",
      "Epoch [1/2], Iter [1657/3125], train_loss:0.025879\n",
      "Epoch [1/2], Iter [1658/3125], train_loss:0.064852\n",
      "Epoch [1/2], Iter [1659/3125], train_loss:0.058176\n",
      "Epoch [1/2], Iter [1660/3125], train_loss:0.069005\n",
      "Epoch [1/2], Iter [1661/3125], train_loss:0.065743\n",
      "Epoch [1/2], Iter [1662/3125], train_loss:0.089958\n",
      "Epoch [1/2], Iter [1663/3125], train_loss:0.036494\n",
      "Epoch [1/2], Iter [1664/3125], train_loss:0.053051\n",
      "Epoch [1/2], Iter [1665/3125], train_loss:0.050961\n",
      "Epoch [1/2], Iter [1666/3125], train_loss:0.082720\n",
      "Epoch [1/2], Iter [1667/3125], train_loss:0.078918\n",
      "Epoch [1/2], Iter [1668/3125], train_loss:0.038705\n",
      "Epoch [1/2], Iter [1669/3125], train_loss:0.068167\n",
      "Epoch [1/2], Iter [1670/3125], train_loss:0.087199\n",
      "Epoch [1/2], Iter [1671/3125], train_loss:0.064287\n",
      "Epoch [1/2], Iter [1672/3125], train_loss:0.057262\n",
      "Epoch [1/2], Iter [1673/3125], train_loss:0.076913\n",
      "Epoch [1/2], Iter [1674/3125], train_loss:0.068706\n",
      "Epoch [1/2], Iter [1675/3125], train_loss:0.056607\n",
      "Epoch [1/2], Iter [1676/3125], train_loss:0.072395\n",
      "Epoch [1/2], Iter [1677/3125], train_loss:0.047097\n",
      "Epoch [1/2], Iter [1678/3125], train_loss:0.056314\n",
      "Epoch [1/2], Iter [1679/3125], train_loss:0.048934\n",
      "Epoch [1/2], Iter [1680/3125], train_loss:0.068537\n",
      "Epoch [1/2], Iter [1681/3125], train_loss:0.090709\n",
      "Epoch [1/2], Iter [1682/3125], train_loss:0.037840\n",
      "Epoch [1/2], Iter [1683/3125], train_loss:0.055547\n",
      "Epoch [1/2], Iter [1684/3125], train_loss:0.055707\n",
      "Epoch [1/2], Iter [1685/3125], train_loss:0.103139\n",
      "Epoch [1/2], Iter [1686/3125], train_loss:0.047331\n",
      "Epoch [1/2], Iter [1687/3125], train_loss:0.045159\n",
      "Epoch [1/2], Iter [1688/3125], train_loss:0.030743\n",
      "Epoch [1/2], Iter [1689/3125], train_loss:0.050401\n",
      "Epoch [1/2], Iter [1690/3125], train_loss:0.078010\n",
      "Epoch [1/2], Iter [1691/3125], train_loss:0.065569\n",
      "Epoch [1/2], Iter [1692/3125], train_loss:0.056428\n",
      "Epoch [1/2], Iter [1693/3125], train_loss:0.050786\n",
      "Epoch [1/2], Iter [1694/3125], train_loss:0.082159\n",
      "Epoch [1/2], Iter [1695/3125], train_loss:0.069655\n",
      "Epoch [1/2], Iter [1696/3125], train_loss:0.075545\n",
      "Epoch [1/2], Iter [1697/3125], train_loss:0.057627\n",
      "Epoch [1/2], Iter [1698/3125], train_loss:0.046487\n",
      "Epoch [1/2], Iter [1699/3125], train_loss:0.070732\n",
      "Epoch [1/2], Iter [1700/3125], train_loss:0.050626\n",
      "Epoch [1/2], Iter [1701/3125], train_loss:0.031116\n",
      "Epoch [1/2], Iter [1702/3125], train_loss:0.059067\n",
      "Epoch [1/2], Iter [1703/3125], train_loss:0.054479\n",
      "Epoch [1/2], Iter [1704/3125], train_loss:0.054491\n",
      "Epoch [1/2], Iter [1705/3125], train_loss:0.039773\n",
      "Epoch [1/2], Iter [1706/3125], train_loss:0.031027\n",
      "Epoch [1/2], Iter [1707/3125], train_loss:0.047340\n",
      "Epoch [1/2], Iter [1708/3125], train_loss:0.076403\n",
      "Epoch [1/2], Iter [1709/3125], train_loss:0.016199\n",
      "Epoch [1/2], Iter [1710/3125], train_loss:0.060465\n",
      "Epoch [1/2], Iter [1711/3125], train_loss:0.044954\n",
      "Epoch [1/2], Iter [1712/3125], train_loss:0.066598\n",
      "Epoch [1/2], Iter [1713/3125], train_loss:0.047684\n",
      "Epoch [1/2], Iter [1714/3125], train_loss:0.073774\n",
      "Epoch [1/2], Iter [1715/3125], train_loss:0.069056\n",
      "Epoch [1/2], Iter [1716/3125], train_loss:0.044322\n",
      "Epoch [1/2], Iter [1717/3125], train_loss:0.057016\n",
      "Epoch [1/2], Iter [1718/3125], train_loss:0.058875\n",
      "Epoch [1/2], Iter [1719/3125], train_loss:0.074158\n",
      "Epoch [1/2], Iter [1720/3125], train_loss:0.047174\n",
      "Epoch [1/2], Iter [1721/3125], train_loss:0.076804\n",
      "Epoch [1/2], Iter [1722/3125], train_loss:0.072642\n",
      "Epoch [1/2], Iter [1723/3125], train_loss:0.033976\n",
      "Epoch [1/2], Iter [1724/3125], train_loss:0.060109\n",
      "Epoch [1/2], Iter [1725/3125], train_loss:0.040534\n",
      "Epoch [1/2], Iter [1726/3125], train_loss:0.059091\n",
      "Epoch [1/2], Iter [1727/3125], train_loss:0.033449\n",
      "Epoch [1/2], Iter [1728/3125], train_loss:0.050518\n",
      "Epoch [1/2], Iter [1729/3125], train_loss:0.049076\n",
      "Epoch [1/2], Iter [1730/3125], train_loss:0.053084\n",
      "Epoch [1/2], Iter [1731/3125], train_loss:0.021780\n",
      "Epoch [1/2], Iter [1732/3125], train_loss:0.046233\n",
      "Epoch [1/2], Iter [1733/3125], train_loss:0.046873\n",
      "Epoch [1/2], Iter [1734/3125], train_loss:0.042442\n",
      "Epoch [1/2], Iter [1735/3125], train_loss:0.038350\n",
      "Epoch [1/2], Iter [1736/3125], train_loss:0.064056\n",
      "Epoch [1/2], Iter [1737/3125], train_loss:0.058172\n",
      "Epoch [1/2], Iter [1738/3125], train_loss:0.060895\n",
      "Epoch [1/2], Iter [1739/3125], train_loss:0.043917\n",
      "Epoch [1/2], Iter [1740/3125], train_loss:0.038549\n",
      "Epoch [1/2], Iter [1741/3125], train_loss:0.067692\n",
      "Epoch [1/2], Iter [1742/3125], train_loss:0.060698\n",
      "Epoch [1/2], Iter [1743/3125], train_loss:0.046502\n",
      "Epoch [1/2], Iter [1744/3125], train_loss:0.024765\n",
      "Epoch [1/2], Iter [1745/3125], train_loss:0.080761\n",
      "Epoch [1/2], Iter [1746/3125], train_loss:0.041602\n",
      "Epoch [1/2], Iter [1747/3125], train_loss:0.060167\n",
      "Epoch [1/2], Iter [1748/3125], train_loss:0.070037\n",
      "Epoch [1/2], Iter [1749/3125], train_loss:0.085924\n",
      "Epoch [1/2], Iter [1750/3125], train_loss:0.065671\n",
      "Epoch [1/2], Iter [1751/3125], train_loss:0.049206\n",
      "Epoch [1/2], Iter [1752/3125], train_loss:0.045379\n",
      "Epoch [1/2], Iter [1753/3125], train_loss:0.074098\n",
      "Epoch [1/2], Iter [1754/3125], train_loss:0.048899\n",
      "Epoch [1/2], Iter [1755/3125], train_loss:0.049306\n",
      "Epoch [1/2], Iter [1756/3125], train_loss:0.058869\n",
      "Epoch [1/2], Iter [1757/3125], train_loss:0.057438\n",
      "Epoch [1/2], Iter [1758/3125], train_loss:0.034412\n",
      "Epoch [1/2], Iter [1759/3125], train_loss:0.066396\n",
      "Epoch [1/2], Iter [1760/3125], train_loss:0.065056\n",
      "Epoch [1/2], Iter [1761/3125], train_loss:0.069635\n",
      "Epoch [1/2], Iter [1762/3125], train_loss:0.059543\n",
      "Epoch [1/2], Iter [1763/3125], train_loss:0.041596\n",
      "Epoch [1/2], Iter [1764/3125], train_loss:0.071567\n",
      "Epoch [1/2], Iter [1765/3125], train_loss:0.060290\n",
      "Epoch [1/2], Iter [1766/3125], train_loss:0.045262\n",
      "Epoch [1/2], Iter [1767/3125], train_loss:0.056432\n",
      "Epoch [1/2], Iter [1768/3125], train_loss:0.103849\n",
      "Epoch [1/2], Iter [1769/3125], train_loss:0.050002\n",
      "Epoch [1/2], Iter [1770/3125], train_loss:0.032755\n",
      "Epoch [1/2], Iter [1771/3125], train_loss:0.047242\n",
      "Epoch [1/2], Iter [1772/3125], train_loss:0.059000\n",
      "Epoch [1/2], Iter [1773/3125], train_loss:0.050834\n",
      "Epoch [1/2], Iter [1774/3125], train_loss:0.027920\n",
      "Epoch [1/2], Iter [1775/3125], train_loss:0.052240\n",
      "Epoch [1/2], Iter [1776/3125], train_loss:0.062811\n",
      "Epoch [1/2], Iter [1777/3125], train_loss:0.075824\n",
      "Epoch [1/2], Iter [1778/3125], train_loss:0.051999\n",
      "Epoch [1/2], Iter [1779/3125], train_loss:0.072262\n",
      "Epoch [1/2], Iter [1780/3125], train_loss:0.061145\n",
      "Epoch [1/2], Iter [1781/3125], train_loss:0.043785\n",
      "Epoch [1/2], Iter [1782/3125], train_loss:0.044300\n",
      "Epoch [1/2], Iter [1783/3125], train_loss:0.096426\n",
      "Epoch [1/2], Iter [1784/3125], train_loss:0.067243\n",
      "Epoch [1/2], Iter [1785/3125], train_loss:0.055974\n",
      "Epoch [1/2], Iter [1786/3125], train_loss:0.061448\n",
      "Epoch [1/2], Iter [1787/3125], train_loss:0.042843\n",
      "Epoch [1/2], Iter [1788/3125], train_loss:0.079202\n",
      "Epoch [1/2], Iter [1789/3125], train_loss:0.051137\n",
      "Epoch [1/2], Iter [1790/3125], train_loss:0.086277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Iter [1791/3125], train_loss:0.081263\n",
      "Epoch [1/2], Iter [1792/3125], train_loss:0.034454\n",
      "Epoch [1/2], Iter [1793/3125], train_loss:0.046444\n",
      "Epoch [1/2], Iter [1794/3125], train_loss:0.075485\n",
      "Epoch [1/2], Iter [1795/3125], train_loss:0.046044\n",
      "Epoch [1/2], Iter [1796/3125], train_loss:0.052903\n",
      "Epoch [1/2], Iter [1797/3125], train_loss:0.088825\n",
      "Epoch [1/2], Iter [1798/3125], train_loss:0.056114\n",
      "Epoch [1/2], Iter [1799/3125], train_loss:0.090675\n",
      "Epoch [1/2], Iter [1800/3125], train_loss:0.033013\n",
      "Epoch [1/2], Iter [1801/3125], train_loss:0.038212\n",
      "Epoch [1/2], Iter [1802/3125], train_loss:0.044110\n",
      "Epoch [1/2], Iter [1803/3125], train_loss:0.047596\n",
      "Epoch [1/2], Iter [1804/3125], train_loss:0.043175\n",
      "Epoch [1/2], Iter [1805/3125], train_loss:0.073386\n",
      "Epoch [1/2], Iter [1806/3125], train_loss:0.066542\n",
      "Epoch [1/2], Iter [1807/3125], train_loss:0.046511\n",
      "Epoch [1/2], Iter [1808/3125], train_loss:0.020690\n",
      "Epoch [1/2], Iter [1809/3125], train_loss:0.028680\n",
      "Epoch [1/2], Iter [1810/3125], train_loss:0.037293\n",
      "Epoch [1/2], Iter [1811/3125], train_loss:0.062722\n",
      "Epoch [1/2], Iter [1812/3125], train_loss:0.048105\n",
      "Epoch [1/2], Iter [1813/3125], train_loss:0.063843\n",
      "Epoch [1/2], Iter [1814/3125], train_loss:0.030292\n",
      "Epoch [1/2], Iter [1815/3125], train_loss:0.056470\n",
      "Epoch [1/2], Iter [1816/3125], train_loss:0.075830\n",
      "Epoch [1/2], Iter [1817/3125], train_loss:0.039826\n",
      "Epoch [1/2], Iter [1818/3125], train_loss:0.052718\n",
      "Epoch [1/2], Iter [1819/3125], train_loss:0.046239\n",
      "Epoch [1/2], Iter [1820/3125], train_loss:0.020768\n",
      "Epoch [1/2], Iter [1821/3125], train_loss:0.048362\n",
      "Epoch [1/2], Iter [1822/3125], train_loss:0.058436\n",
      "Epoch [1/2], Iter [1823/3125], train_loss:0.050674\n",
      "Epoch [1/2], Iter [1824/3125], train_loss:0.048693\n",
      "Epoch [1/2], Iter [1825/3125], train_loss:0.057657\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#训练&验证\n",
    "writer = SummaryWriter(\"../train_skills\")\n",
    "# 定义损失函数和优化器\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# 损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 优化器\n",
    "optimizer = torch.optim.Adam(Resnet50.parameters(), lr=lr)\n",
    "\n",
    "# 自定义 scheduler \n",
    "scheduler_my = LambdaLR(optimizer, lr_lambda=lambda epoch: 1/(epoch+1),verbose = True)\n",
    "print(\"初始化的学习率：\", optimizer.defaults['lr'])\n",
    "\n",
    "epoch = max_epochs\n",
    "Resnet50 = Resnet50.to(device)\n",
    "total_step = len(train_loader)\n",
    "train_all_loss = []\n",
    "test_all_loss = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    Resnet50.train()\n",
    "    train_total_loss = 0\n",
    "    train_total_num = 0\n",
    "    train_total_correct = 0\n",
    "\n",
    "    for iter, (images,labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = Resnet50(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        train_total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        \n",
    "        #backword\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "       \n",
    "        \n",
    "        train_total_num += labels.shape[0]\n",
    "        train_total_loss += loss.item()\n",
    "        print(\"Epoch [{}/{}], Iter [{}/{}], train_loss:{:4f}\".format(i+1,epoch,iter+1,total_step,loss.item()/labels.shape[0]))\n",
    "    \n",
    "    writer.add_scalar(\"lr\", optim.param_groups[0]['lr'], i)\n",
    "    \n",
    "    print(\"第%d个epoch的学习率：%f\" % (epoch, optimizer.param_groups[0]['lr']))\n",
    "    scheduler_my.step() #scheduler\n",
    "    #自定义调整lr\n",
    "#     adjust_learning_rate(optimizer, i)\n",
    "    \n",
    "    Resnet50.eval()\n",
    "    test_total_loss = 0\n",
    "    test_total_correct = 0\n",
    "    test_total_num = 0\n",
    "    for iter,(images,labels) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = Resnet50(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "        test_total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "        test_total_loss += loss.item()\n",
    "        test_total_num += labels.shape[0]\n",
    "    print(\"Epoch [{}/{}], train_loss:{:.4f}, train_acc:{:.4f}%, test_loss:{:.4f}, test_acc:{:.4f}%\".format(\n",
    "        i+1, epoch, train_total_loss / train_total_num, train_total_correct / train_total_num * 100, test_total_loss / test_total_num, test_total_correct / test_total_num * 100\n",
    "    \n",
    "    ))\n",
    "    train_all_loss.append(np.round(train_total_loss / train_total_num,4))\n",
    "    test_all_loss.append(np.round(test_total_loss / test_total_num,4))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c6e47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
